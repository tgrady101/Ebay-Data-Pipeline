[2023-01-07 00:00:19,030] {processor.py:153} INFO - Started process (PID=6845) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:00:19,031] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:00:19,031] {logging_mixin.py:115} INFO - [2023-01-07 00:00:19,031] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:00:19,798] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:00:19,799] {logging_mixin.py:115} INFO - [2023-01-07 00:00:19,799] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:00:19,799] {logging_mixin.py:115} INFO - [2023-01-07 00:00:19,799] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:00:19,806] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:00:19,826] {logging_mixin.py:115} INFO - [2023-01-07 00:00:19,826] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:00:19,846] {logging_mixin.py:115} INFO - [2023-01-07 00:00:19,846] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:00:19,855] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.829 seconds
[2023-01-07 00:00:50,113] {processor.py:153} INFO - Started process (PID=6869) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:00:50,114] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:00:50,114] {logging_mixin.py:115} INFO - [2023-01-07 00:00:50,114] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:00:50,881] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:00:50,882] {logging_mixin.py:115} INFO - [2023-01-07 00:00:50,882] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:00:50,883] {logging_mixin.py:115} INFO - [2023-01-07 00:00:50,883] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:00:50,890] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:00:50,911] {logging_mixin.py:115} INFO - [2023-01-07 00:00:50,911] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:00:50,931] {logging_mixin.py:115} INFO - [2023-01-07 00:00:50,931] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:00:50,941] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.832 seconds
[2023-01-07 00:01:21,033] {processor.py:153} INFO - Started process (PID=6887) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:01:21,036] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:01:21,037] {logging_mixin.py:115} INFO - [2023-01-07 00:01:21,037] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:01:21,841] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:01:21,842] {logging_mixin.py:115} INFO - [2023-01-07 00:01:21,842] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:01:21,843] {logging_mixin.py:115} INFO - [2023-01-07 00:01:21,842] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:01:21,849] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:01:21,871] {logging_mixin.py:115} INFO - [2023-01-07 00:01:21,870] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:01:21,891] {logging_mixin.py:115} INFO - [2023-01-07 00:01:21,891] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:01:21,901] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.872 seconds
[2023-01-07 00:01:51,994] {processor.py:153} INFO - Started process (PID=6913) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:01:51,995] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:01:51,995] {logging_mixin.py:115} INFO - [2023-01-07 00:01:51,995] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:01:52,759] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:01:52,760] {logging_mixin.py:115} INFO - [2023-01-07 00:01:52,760] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:01:52,761] {logging_mixin.py:115} INFO - [2023-01-07 00:01:52,761] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:01:52,768] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:01:52,789] {logging_mixin.py:115} INFO - [2023-01-07 00:01:52,788] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:01:52,812] {logging_mixin.py:115} INFO - [2023-01-07 00:01:52,812] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:01:52,821] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.832 seconds
[2023-01-07 00:02:22,911] {processor.py:153} INFO - Started process (PID=6937) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:02:22,913] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:02:22,913] {logging_mixin.py:115} INFO - [2023-01-07 00:02:22,913] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:02:23,684] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:02:23,685] {logging_mixin.py:115} INFO - [2023-01-07 00:02:23,685] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:02:23,686] {logging_mixin.py:115} INFO - [2023-01-07 00:02:23,686] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:02:23,692] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:02:23,713] {logging_mixin.py:115} INFO - [2023-01-07 00:02:23,713] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:02:23,734] {logging_mixin.py:115} INFO - [2023-01-07 00:02:23,734] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:02:23,743] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.836 seconds
[2023-01-07 00:02:54,251] {processor.py:153} INFO - Started process (PID=6962) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:02:54,251] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:02:54,252] {logging_mixin.py:115} INFO - [2023-01-07 00:02:54,252] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:02:55,003] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:02:55,004] {logging_mixin.py:115} INFO - [2023-01-07 00:02:55,004] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:02:55,005] {logging_mixin.py:115} INFO - [2023-01-07 00:02:55,005] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:02:55,012] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:02:55,032] {logging_mixin.py:115} INFO - [2023-01-07 00:02:55,032] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:02:55,052] {logging_mixin.py:115} INFO - [2023-01-07 00:02:55,052] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:02:55,061] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.815 seconds
[2023-01-07 00:03:25,152] {processor.py:153} INFO - Started process (PID=6987) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:03:25,153] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:03:25,153] {logging_mixin.py:115} INFO - [2023-01-07 00:03:25,153] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:03:25,919] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:03:25,921] {logging_mixin.py:115} INFO - [2023-01-07 00:03:25,920] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:03:25,921] {logging_mixin.py:115} INFO - [2023-01-07 00:03:25,921] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:03:25,931] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:03:25,953] {logging_mixin.py:115} INFO - [2023-01-07 00:03:25,953] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:03:25,975] {logging_mixin.py:115} INFO - [2023-01-07 00:03:25,975] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:03:25,985] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.838 seconds
[2023-01-07 00:03:56,087] {processor.py:153} INFO - Started process (PID=7005) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:03:56,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:03:56,089] {logging_mixin.py:115} INFO - [2023-01-07 00:03:56,089] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:03:56,891] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:03:56,892] {logging_mixin.py:115} INFO - [2023-01-07 00:03:56,892] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:03:56,893] {logging_mixin.py:115} INFO - [2023-01-07 00:03:56,893] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:03:56,900] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:03:56,921] {logging_mixin.py:115} INFO - [2023-01-07 00:03:56,921] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:03:56,942] {logging_mixin.py:115} INFO - [2023-01-07 00:03:56,941] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:03:56,951] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.868 seconds
[2023-01-07 00:04:27,047] {processor.py:153} INFO - Started process (PID=7031) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:04:27,048] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:04:27,049] {logging_mixin.py:115} INFO - [2023-01-07 00:04:27,049] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:04:27,818] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:04:27,820] {logging_mixin.py:115} INFO - [2023-01-07 00:04:27,820] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:04:27,821] {logging_mixin.py:115} INFO - [2023-01-07 00:04:27,820] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:04:27,830] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:04:27,861] {logging_mixin.py:115} INFO - [2023-01-07 00:04:27,861] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:04:27,888] {logging_mixin.py:115} INFO - [2023-01-07 00:04:27,888] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:04:27,897] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.854 seconds
[2023-01-07 00:04:57,989] {processor.py:153} INFO - Started process (PID=7056) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:04:57,990] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:04:57,991] {logging_mixin.py:115} INFO - [2023-01-07 00:04:57,991] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:04:58,765] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:04:58,767] {logging_mixin.py:115} INFO - [2023-01-07 00:04:58,767] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:04:58,767] {logging_mixin.py:115} INFO - [2023-01-07 00:04:58,767] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:04:58,774] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:04:58,795] {logging_mixin.py:115} INFO - [2023-01-07 00:04:58,795] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:04:58,816] {logging_mixin.py:115} INFO - [2023-01-07 00:04:58,816] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:04:58,825] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-07 00:05:28,912] {processor.py:153} INFO - Started process (PID=7081) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:05:28,913] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:05:28,914] {logging_mixin.py:115} INFO - [2023-01-07 00:05:28,914] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:05:29,689] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:05:29,690] {logging_mixin.py:115} INFO - [2023-01-07 00:05:29,690] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:05:29,691] {logging_mixin.py:115} INFO - [2023-01-07 00:05:29,690] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:05:29,698] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:05:29,719] {logging_mixin.py:115} INFO - [2023-01-07 00:05:29,719] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:05:29,740] {logging_mixin.py:115} INFO - [2023-01-07 00:05:29,740] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:05:29,749] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-07 00:05:59,828] {processor.py:153} INFO - Started process (PID=7099) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:05:59,829] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:05:59,830] {logging_mixin.py:115} INFO - [2023-01-07 00:05:59,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:06:00,609] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:06:00,610] {logging_mixin.py:115} INFO - [2023-01-07 00:06:00,610] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:06:00,610] {logging_mixin.py:115} INFO - [2023-01-07 00:06:00,610] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:06:00,617] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:06:00,638] {logging_mixin.py:115} INFO - [2023-01-07 00:06:00,638] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:06:00,658] {logging_mixin.py:115} INFO - [2023-01-07 00:06:00,658] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:06:00,667] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.844 seconds
[2023-01-07 00:06:30,743] {processor.py:153} INFO - Started process (PID=7124) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:06:30,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:06:30,746] {logging_mixin.py:115} INFO - [2023-01-07 00:06:30,746] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:06:31,492] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:06:31,493] {logging_mixin.py:115} INFO - [2023-01-07 00:06:31,493] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:06:31,494] {logging_mixin.py:115} INFO - [2023-01-07 00:06:31,494] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:06:31,500] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:06:31,528] {logging_mixin.py:115} INFO - [2023-01-07 00:06:31,528] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:06:31,549] {logging_mixin.py:115} INFO - [2023-01-07 00:06:31,549] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:06:31,559] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.820 seconds
[2023-01-07 00:07:01,629] {processor.py:153} INFO - Started process (PID=7150) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:07:01,630] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:07:01,632] {logging_mixin.py:115} INFO - [2023-01-07 00:07:01,631] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:07:02,392] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:07:02,393] {logging_mixin.py:115} INFO - [2023-01-07 00:07:02,393] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:07:02,394] {logging_mixin.py:115} INFO - [2023-01-07 00:07:02,393] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:07:02,401] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:07:02,430] {logging_mixin.py:115} INFO - [2023-01-07 00:07:02,430] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:07:02,452] {logging_mixin.py:115} INFO - [2023-01-07 00:07:02,452] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:07:02,461] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.837 seconds
[2023-01-07 00:07:32,529] {processor.py:153} INFO - Started process (PID=7175) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:07:32,530] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:07:32,532] {logging_mixin.py:115} INFO - [2023-01-07 00:07:32,531] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:07:33,333] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:07:33,334] {logging_mixin.py:115} INFO - [2023-01-07 00:07:33,334] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:07:33,335] {logging_mixin.py:115} INFO - [2023-01-07 00:07:33,334] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:07:33,341] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:07:33,362] {logging_mixin.py:115} INFO - [2023-01-07 00:07:33,362] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:07:33,383] {logging_mixin.py:115} INFO - [2023-01-07 00:07:33,383] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:07:33,393] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.868 seconds
[2023-01-07 00:08:03,457] {processor.py:153} INFO - Started process (PID=7193) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:08:03,458] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:08:03,460] {logging_mixin.py:115} INFO - [2023-01-07 00:08:03,459] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:08:04,244] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:08:04,245] {logging_mixin.py:115} INFO - [2023-01-07 00:08:04,245] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:08:04,246] {logging_mixin.py:115} INFO - [2023-01-07 00:08:04,245] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:08:04,252] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:08:04,274] {logging_mixin.py:115} INFO - [2023-01-07 00:08:04,274] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:08:04,294] {logging_mixin.py:115} INFO - [2023-01-07 00:08:04,294] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:08:04,303] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.851 seconds
[2023-01-07 00:08:34,373] {processor.py:153} INFO - Started process (PID=7219) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:08:34,374] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:08:34,376] {logging_mixin.py:115} INFO - [2023-01-07 00:08:34,376] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:08:35,129] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:08:35,131] {logging_mixin.py:115} INFO - [2023-01-07 00:08:35,131] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:08:35,131] {logging_mixin.py:115} INFO - [2023-01-07 00:08:35,131] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:08:35,138] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:08:35,159] {logging_mixin.py:115} INFO - [2023-01-07 00:08:35,159] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:08:35,180] {logging_mixin.py:115} INFO - [2023-01-07 00:08:35,180] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:08:35,189] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.820 seconds
[2023-01-07 00:09:05,439] {processor.py:153} INFO - Started process (PID=7244) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:09:05,439] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:09:05,440] {logging_mixin.py:115} INFO - [2023-01-07 00:09:05,440] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:09:06,205] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:09:06,207] {logging_mixin.py:115} INFO - [2023-01-07 00:09:06,207] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:09:06,207] {logging_mixin.py:115} INFO - [2023-01-07 00:09:06,207] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:09:06,214] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:09:06,236] {logging_mixin.py:115} INFO - [2023-01-07 00:09:06,236] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:09:06,257] {logging_mixin.py:115} INFO - [2023-01-07 00:09:06,257] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:09:06,266] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.832 seconds
[2023-01-07 00:09:36,359] {processor.py:153} INFO - Started process (PID=7271) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:09:36,360] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:09:36,362] {logging_mixin.py:115} INFO - [2023-01-07 00:09:36,362] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:09:37,149] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:09:37,150] {logging_mixin.py:115} INFO - [2023-01-07 00:09:37,150] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:09:37,151] {logging_mixin.py:115} INFO - [2023-01-07 00:09:37,150] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:09:37,157] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:09:37,178] {logging_mixin.py:115} INFO - [2023-01-07 00:09:37,178] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:09:37,199] {logging_mixin.py:115} INFO - [2023-01-07 00:09:37,199] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:09:37,208] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.854 seconds
[2023-01-07 00:10:07,300] {processor.py:153} INFO - Started process (PID=7290) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:10:07,301] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:10:07,302] {logging_mixin.py:115} INFO - [2023-01-07 00:10:07,302] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:10:08,083] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:10:08,085] {logging_mixin.py:115} INFO - [2023-01-07 00:10:08,085] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:10:08,086] {logging_mixin.py:115} INFO - [2023-01-07 00:10:08,085] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:10:08,095] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:10:08,121] {logging_mixin.py:115} INFO - [2023-01-07 00:10:08,121] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:10:08,151] {logging_mixin.py:115} INFO - [2023-01-07 00:10:08,150] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:10:08,162] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.866 seconds
[2023-01-07 00:10:38,268] {processor.py:153} INFO - Started process (PID=7315) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:10:38,270] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:10:38,270] {logging_mixin.py:115} INFO - [2023-01-07 00:10:38,270] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:10:39,037] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:10:39,039] {logging_mixin.py:115} INFO - [2023-01-07 00:10:39,039] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:10:39,039] {logging_mixin.py:115} INFO - [2023-01-07 00:10:39,039] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:10:39,046] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:10:39,066] {logging_mixin.py:115} INFO - [2023-01-07 00:10:39,066] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:10:39,087] {logging_mixin.py:115} INFO - [2023-01-07 00:10:39,087] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:10:39,096] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.832 seconds
[2023-01-07 00:11:09,192] {processor.py:153} INFO - Started process (PID=7340) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:11:09,193] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:11:09,194] {logging_mixin.py:115} INFO - [2023-01-07 00:11:09,193] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:11:09,951] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:11:09,952] {logging_mixin.py:115} INFO - [2023-01-07 00:11:09,952] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:11:09,952] {logging_mixin.py:115} INFO - [2023-01-07 00:11:09,952] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:11:09,959] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:11:09,979] {logging_mixin.py:115} INFO - [2023-01-07 00:11:09,979] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:11:10,000] {logging_mixin.py:115} INFO - [2023-01-07 00:11:10,000] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:11:10,009] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.821 seconds
[2023-01-07 00:11:40,505] {processor.py:153} INFO - Started process (PID=7365) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:11:40,507] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:11:40,507] {logging_mixin.py:115} INFO - [2023-01-07 00:11:40,507] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:11:41,269] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:11:41,270] {logging_mixin.py:115} INFO - [2023-01-07 00:11:41,270] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:11:41,271] {logging_mixin.py:115} INFO - [2023-01-07 00:11:41,270] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:11:41,277] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:11:41,298] {logging_mixin.py:115} INFO - [2023-01-07 00:11:41,298] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:11:41,319] {logging_mixin.py:115} INFO - [2023-01-07 00:11:41,319] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:11:41,328] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.827 seconds
[2023-01-07 00:12:11,426] {processor.py:153} INFO - Started process (PID=7383) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:12:11,426] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:12:11,427] {logging_mixin.py:115} INFO - [2023-01-07 00:12:11,427] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:12:12,261] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:12:12,262] {logging_mixin.py:115} INFO - [2023-01-07 00:12:12,262] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:12:12,263] {logging_mixin.py:115} INFO - [2023-01-07 00:12:12,262] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:12:12,269] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:12:12,291] {logging_mixin.py:115} INFO - [2023-01-07 00:12:12,291] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:12:12,312] {logging_mixin.py:115} INFO - [2023-01-07 00:12:12,312] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:12:12,322] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.901 seconds
[2023-01-07 00:12:42,413] {processor.py:153} INFO - Started process (PID=7409) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:12:42,414] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:12:42,415] {logging_mixin.py:115} INFO - [2023-01-07 00:12:42,415] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:12:43,166] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:12:43,168] {logging_mixin.py:115} INFO - [2023-01-07 00:12:43,168] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:12:43,168] {logging_mixin.py:115} INFO - [2023-01-07 00:12:43,168] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:12:43,175] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:12:43,195] {logging_mixin.py:115} INFO - [2023-01-07 00:12:43,195] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:12:43,216] {logging_mixin.py:115} INFO - [2023-01-07 00:12:43,216] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:12:43,225] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.817 seconds
[2023-01-07 00:13:13,319] {processor.py:153} INFO - Started process (PID=7434) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:13:13,319] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:13:13,320] {logging_mixin.py:115} INFO - [2023-01-07 00:13:13,320] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:13:14,081] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:13:14,083] {logging_mixin.py:115} INFO - [2023-01-07 00:13:14,082] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:13:14,083] {logging_mixin.py:115} INFO - [2023-01-07 00:13:14,083] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:13:14,090] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:13:14,110] {logging_mixin.py:115} INFO - [2023-01-07 00:13:14,110] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:13:14,130] {logging_mixin.py:115} INFO - [2023-01-07 00:13:14,130] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:13:14,139] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.826 seconds
[2023-01-07 00:13:44,228] {processor.py:153} INFO - Started process (PID=7459) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:13:44,229] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:13:44,230] {logging_mixin.py:115} INFO - [2023-01-07 00:13:44,229] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:13:44,982] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:13:44,984] {logging_mixin.py:115} INFO - [2023-01-07 00:13:44,984] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:13:44,984] {logging_mixin.py:115} INFO - [2023-01-07 00:13:44,984] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:13:44,991] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:13:45,012] {logging_mixin.py:115} INFO - [2023-01-07 00:13:45,011] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:13:45,032] {logging_mixin.py:115} INFO - [2023-01-07 00:13:45,032] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:13:45,041] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.818 seconds
[2023-01-07 00:14:15,110] {processor.py:153} INFO - Started process (PID=7478) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:14:15,111] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:14:15,112] {logging_mixin.py:115} INFO - [2023-01-07 00:14:15,112] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:14:15,872] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:14:15,874] {logging_mixin.py:115} INFO - [2023-01-07 00:14:15,874] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:14:15,874] {logging_mixin.py:115} INFO - [2023-01-07 00:14:15,874] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:14:15,881] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:14:15,902] {logging_mixin.py:115} INFO - [2023-01-07 00:14:15,902] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:14:15,923] {logging_mixin.py:115} INFO - [2023-01-07 00:14:15,923] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:14:15,933] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.827 seconds
[2023-01-07 00:14:46,002] {processor.py:153} INFO - Started process (PID=7502) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:14:46,003] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:14:46,004] {logging_mixin.py:115} INFO - [2023-01-07 00:14:46,004] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:14:46,766] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:14:46,768] {logging_mixin.py:115} INFO - [2023-01-07 00:14:46,768] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:14:46,768] {logging_mixin.py:115} INFO - [2023-01-07 00:14:46,768] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:14:46,775] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:14:46,796] {logging_mixin.py:115} INFO - [2023-01-07 00:14:46,796] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:14:46,816] {logging_mixin.py:115} INFO - [2023-01-07 00:14:46,816] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:14:46,826] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.828 seconds
[2023-01-07 00:15:16,892] {processor.py:153} INFO - Started process (PID=7527) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:15:16,893] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:15:16,894] {logging_mixin.py:115} INFO - [2023-01-07 00:15:16,893] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:15:17,650] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:15:17,651] {logging_mixin.py:115} INFO - [2023-01-07 00:15:17,651] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:15:17,652] {logging_mixin.py:115} INFO - [2023-01-07 00:15:17,651] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:15:17,659] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:15:17,679] {logging_mixin.py:115} INFO - [2023-01-07 00:15:17,679] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:15:17,700] {logging_mixin.py:115} INFO - [2023-01-07 00:15:17,700] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:15:17,709] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.821 seconds
[2023-01-07 00:15:47,775] {processor.py:153} INFO - Started process (PID=7553) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:15:47,778] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:15:47,778] {logging_mixin.py:115} INFO - [2023-01-07 00:15:47,778] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:15:48,528] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:15:48,530] {logging_mixin.py:115} INFO - [2023-01-07 00:15:48,530] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:15:48,530] {logging_mixin.py:115} INFO - [2023-01-07 00:15:48,530] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:15:48,537] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:15:48,558] {logging_mixin.py:115} INFO - [2023-01-07 00:15:48,558] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:15:48,578] {logging_mixin.py:115} INFO - [2023-01-07 00:15:48,578] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:15:48,587] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.817 seconds
[2023-01-07 00:16:18,653] {processor.py:153} INFO - Started process (PID=7571) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:16:18,654] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:16:18,655] {logging_mixin.py:115} INFO - [2023-01-07 00:16:18,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:16:19,445] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:16:19,447] {logging_mixin.py:115} INFO - [2023-01-07 00:16:19,447] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:16:19,448] {logging_mixin.py:115} INFO - [2023-01-07 00:16:19,447] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:16:19,459] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:16:19,487] {logging_mixin.py:115} INFO - [2023-01-07 00:16:19,487] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:16:19,517] {logging_mixin.py:115} INFO - [2023-01-07 00:16:19,517] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:16:19,528] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.880 seconds
[2023-01-07 00:16:49,620] {processor.py:153} INFO - Started process (PID=7596) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:16:49,621] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:16:49,621] {logging_mixin.py:115} INFO - [2023-01-07 00:16:49,621] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:16:50,385] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:16:50,386] {logging_mixin.py:115} INFO - [2023-01-07 00:16:50,386] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:16:50,387] {logging_mixin.py:115} INFO - [2023-01-07 00:16:50,386] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:16:50,393] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:16:50,415] {logging_mixin.py:115} INFO - [2023-01-07 00:16:50,415] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:16:50,435] {logging_mixin.py:115} INFO - [2023-01-07 00:16:50,435] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:16:50,444] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.829 seconds
[2023-01-07 00:17:20,533] {processor.py:153} INFO - Started process (PID=7621) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:17:20,534] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:17:20,535] {logging_mixin.py:115} INFO - [2023-01-07 00:17:20,535] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:17:21,301] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:17:21,303] {logging_mixin.py:115} INFO - [2023-01-07 00:17:21,303] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:17:21,303] {logging_mixin.py:115} INFO - [2023-01-07 00:17:21,303] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:17:21,310] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:17:21,338] {logging_mixin.py:115} INFO - [2023-01-07 00:17:21,338] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:17:21,362] {logging_mixin.py:115} INFO - [2023-01-07 00:17:21,362] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:17:21,372] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.843 seconds
[2023-01-07 00:17:51,457] {processor.py:153} INFO - Started process (PID=7645) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:17:51,459] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:17:51,459] {logging_mixin.py:115} INFO - [2023-01-07 00:17:51,459] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:17:52,232] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:17:52,233] {logging_mixin.py:115} INFO - [2023-01-07 00:17:52,233] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:17:52,233] {logging_mixin.py:115} INFO - [2023-01-07 00:17:52,233] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:17:52,240] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:17:52,261] {logging_mixin.py:115} INFO - [2023-01-07 00:17:52,260] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:17:52,281] {logging_mixin.py:115} INFO - [2023-01-07 00:17:52,281] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:17:52,290] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.837 seconds
[2023-01-07 00:18:22,359] {processor.py:153} INFO - Started process (PID=7663) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:18:22,360] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:18:22,361] {logging_mixin.py:115} INFO - [2023-01-07 00:18:22,361] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:18:23,133] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:18:23,134] {logging_mixin.py:115} INFO - [2023-01-07 00:18:23,134] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:18:23,135] {logging_mixin.py:115} INFO - [2023-01-07 00:18:23,134] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:18:23,141] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:18:23,162] {logging_mixin.py:115} INFO - [2023-01-07 00:18:23,162] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:18:23,183] {logging_mixin.py:115} INFO - [2023-01-07 00:18:23,183] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:18:23,192] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.837 seconds
[2023-01-07 00:18:53,258] {processor.py:153} INFO - Started process (PID=7688) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:18:53,259] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:18:53,259] {logging_mixin.py:115} INFO - [2023-01-07 00:18:53,259] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:18:54,026] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:18:54,028] {logging_mixin.py:115} INFO - [2023-01-07 00:18:54,028] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:18:54,028] {logging_mixin.py:115} INFO - [2023-01-07 00:18:54,028] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:18:54,035] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:18:54,055] {logging_mixin.py:115} INFO - [2023-01-07 00:18:54,055] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:18:54,076] {logging_mixin.py:115} INFO - [2023-01-07 00:18:54,075] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:18:54,084] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.831 seconds
[2023-01-07 00:19:24,151] {processor.py:153} INFO - Started process (PID=7714) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:19:24,152] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:19:24,153] {logging_mixin.py:115} INFO - [2023-01-07 00:19:24,153] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:19:24,931] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:19:24,932] {logging_mixin.py:115} INFO - [2023-01-07 00:19:24,932] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:19:24,933] {logging_mixin.py:115} INFO - [2023-01-07 00:19:24,932] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:19:24,939] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:19:24,963] {logging_mixin.py:115} INFO - [2023-01-07 00:19:24,962] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:19:24,984] {logging_mixin.py:115} INFO - [2023-01-07 00:19:24,984] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:19:24,993] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.846 seconds
[2023-01-07 00:19:55,071] {processor.py:153} INFO - Started process (PID=7739) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:19:55,072] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:19:55,073] {logging_mixin.py:115} INFO - [2023-01-07 00:19:55,073] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:19:55,870] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:19:55,871] {logging_mixin.py:115} INFO - [2023-01-07 00:19:55,871] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:19:55,872] {logging_mixin.py:115} INFO - [2023-01-07 00:19:55,871] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:19:55,878] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:19:55,900] {logging_mixin.py:115} INFO - [2023-01-07 00:19:55,899] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:19:55,920] {logging_mixin.py:115} INFO - [2023-01-07 00:19:55,920] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:19:55,929] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.862 seconds
[2023-01-07 00:20:26,239] {processor.py:153} INFO - Started process (PID=7757) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:20:26,240] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:20:26,241] {logging_mixin.py:115} INFO - [2023-01-07 00:20:26,241] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:20:27,087] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:20:27,089] {logging_mixin.py:115} INFO - [2023-01-07 00:20:27,089] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:20:27,089] {logging_mixin.py:115} INFO - [2023-01-07 00:20:27,089] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:20:27,096] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:20:27,117] {logging_mixin.py:115} INFO - [2023-01-07 00:20:27,116] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:20:27,137] {logging_mixin.py:115} INFO - [2023-01-07 00:20:27,137] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:20:27,146] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.911 seconds
[2023-01-07 00:20:57,243] {processor.py:153} INFO - Started process (PID=7784) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:20:57,244] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:20:57,245] {logging_mixin.py:115} INFO - [2023-01-07 00:20:57,245] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:20:58,009] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:20:58,010] {logging_mixin.py:115} INFO - [2023-01-07 00:20:58,010] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:20:58,010] {logging_mixin.py:115} INFO - [2023-01-07 00:20:58,010] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:20:58,017] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:20:58,038] {logging_mixin.py:115} INFO - [2023-01-07 00:20:58,038] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:20:58,058] {logging_mixin.py:115} INFO - [2023-01-07 00:20:58,058] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:20:58,067] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.829 seconds
[2023-01-07 00:21:28,165] {processor.py:153} INFO - Started process (PID=7809) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:21:28,168] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:21:28,169] {logging_mixin.py:115} INFO - [2023-01-07 00:21:28,169] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:21:28,931] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:21:28,933] {logging_mixin.py:115} INFO - [2023-01-07 00:21:28,933] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:21:28,933] {logging_mixin.py:115} INFO - [2023-01-07 00:21:28,933] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:21:28,940] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:21:28,960] {logging_mixin.py:115} INFO - [2023-01-07 00:21:28,960] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:21:28,980] {logging_mixin.py:115} INFO - [2023-01-07 00:21:28,980] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:21:28,989] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.829 seconds
[2023-01-07 00:21:59,080] {processor.py:153} INFO - Started process (PID=7833) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:21:59,081] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:21:59,081] {logging_mixin.py:115} INFO - [2023-01-07 00:21:59,081] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:21:59,833] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:21:59,834] {logging_mixin.py:115} INFO - [2023-01-07 00:21:59,834] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:21:59,835] {logging_mixin.py:115} INFO - [2023-01-07 00:21:59,834] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:21:59,841] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:21:59,862] {logging_mixin.py:115} INFO - [2023-01-07 00:21:59,862] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:21:59,882] {logging_mixin.py:115} INFO - [2023-01-07 00:21:59,882] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:21:59,893] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.818 seconds
[2023-01-07 00:22:29,988] {processor.py:153} INFO - Started process (PID=7857) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:22:29,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:22:29,990] {logging_mixin.py:115} INFO - [2023-01-07 00:22:29,990] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:22:30,772] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:22:30,775] {logging_mixin.py:115} INFO - [2023-01-07 00:22:30,774] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:22:30,775] {logging_mixin.py:115} INFO - [2023-01-07 00:22:30,775] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:22:30,783] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:22:30,827] {logging_mixin.py:115} INFO - [2023-01-07 00:22:30,827] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:22:30,853] {logging_mixin.py:115} INFO - [2023-01-07 00:22:30,853] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:22:30,862] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.879 seconds
[2023-01-07 00:23:00,951] {processor.py:153} INFO - Started process (PID=7875) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:23:00,953] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:23:00,953] {logging_mixin.py:115} INFO - [2023-01-07 00:23:00,953] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:23:01,720] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:23:01,721] {logging_mixin.py:115} INFO - [2023-01-07 00:23:01,721] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:23:01,721] {logging_mixin.py:115} INFO - [2023-01-07 00:23:01,721] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:23:01,728] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:23:01,749] {logging_mixin.py:115} INFO - [2023-01-07 00:23:01,749] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:23:01,769] {logging_mixin.py:115} INFO - [2023-01-07 00:23:01,769] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:23:01,779] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.832 seconds
[2023-01-07 00:23:31,853] {processor.py:153} INFO - Started process (PID=7900) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:23:31,854] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:23:31,854] {logging_mixin.py:115} INFO - [2023-01-07 00:23:31,854] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:23:32,603] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:23:32,605] {logging_mixin.py:115} INFO - [2023-01-07 00:23:32,605] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:23:32,605] {logging_mixin.py:115} INFO - [2023-01-07 00:23:32,605] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:23:32,612] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:23:32,633] {logging_mixin.py:115} INFO - [2023-01-07 00:23:32,632] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:23:32,653] {logging_mixin.py:115} INFO - [2023-01-07 00:23:32,653] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:23:32,662] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.814 seconds
[2023-01-07 00:24:02,731] {processor.py:153} INFO - Started process (PID=7925) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:24:02,732] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:24:02,733] {logging_mixin.py:115} INFO - [2023-01-07 00:24:02,733] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:24:03,492] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:24:03,493] {logging_mixin.py:115} INFO - [2023-01-07 00:24:03,493] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:24:03,494] {logging_mixin.py:115} INFO - [2023-01-07 00:24:03,494] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:24:03,504] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:24:03,526] {logging_mixin.py:115} INFO - [2023-01-07 00:24:03,526] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:24:03,546] {logging_mixin.py:115} INFO - [2023-01-07 00:24:03,546] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:24:03,555] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.828 seconds
[2023-01-07 00:24:33,619] {processor.py:153} INFO - Started process (PID=7951) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:24:33,620] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:24:33,620] {logging_mixin.py:115} INFO - [2023-01-07 00:24:33,620] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:24:34,407] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:24:34,409] {logging_mixin.py:115} INFO - [2023-01-07 00:24:34,408] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:24:34,409] {logging_mixin.py:115} INFO - [2023-01-07 00:24:34,409] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:24:34,416] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:24:34,439] {logging_mixin.py:115} INFO - [2023-01-07 00:24:34,439] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:24:34,460] {logging_mixin.py:115} INFO - [2023-01-07 00:24:34,460] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:24:34,468] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.854 seconds
[2023-01-07 00:25:04,531] {processor.py:153} INFO - Started process (PID=7970) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:25:04,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:25:04,533] {logging_mixin.py:115} INFO - [2023-01-07 00:25:04,532] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:25:05,306] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:25:05,307] {logging_mixin.py:115} INFO - [2023-01-07 00:25:05,307] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:25:05,307] {logging_mixin.py:115} INFO - [2023-01-07 00:25:05,307] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:25:05,314] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:25:05,335] {logging_mixin.py:115} INFO - [2023-01-07 00:25:05,335] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:25:05,356] {logging_mixin.py:115} INFO - [2023-01-07 00:25:05,356] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:25:05,365] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.839 seconds
[2023-01-07 00:25:35,395] {processor.py:153} INFO - Started process (PID=7995) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:25:35,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:25:35,397] {logging_mixin.py:115} INFO - [2023-01-07 00:25:35,397] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:25:36,151] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:25:36,153] {logging_mixin.py:115} INFO - [2023-01-07 00:25:36,153] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:25:36,153] {logging_mixin.py:115} INFO - [2023-01-07 00:25:36,153] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:25:36,160] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:25:36,180] {logging_mixin.py:115} INFO - [2023-01-07 00:25:36,180] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:25:36,200] {logging_mixin.py:115} INFO - [2023-01-07 00:25:36,200] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:25:36,209] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.819 seconds
[2023-01-07 00:26:06,313] {processor.py:153} INFO - Started process (PID=8020) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:26:06,315] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:26:06,315] {logging_mixin.py:115} INFO - [2023-01-07 00:26:06,315] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:26:07,085] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:26:07,086] {logging_mixin.py:115} INFO - [2023-01-07 00:26:07,086] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:26:07,087] {logging_mixin.py:115} INFO - [2023-01-07 00:26:07,086] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:26:07,093] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:26:07,114] {logging_mixin.py:115} INFO - [2023-01-07 00:26:07,114] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:26:07,134] {logging_mixin.py:115} INFO - [2023-01-07 00:26:07,134] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:26:07,143] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.835 seconds
[2023-01-07 00:26:37,235] {processor.py:153} INFO - Started process (PID=8046) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:26:37,236] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:26:37,236] {logging_mixin.py:115} INFO - [2023-01-07 00:26:37,236] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:26:38,000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:26:38,002] {logging_mixin.py:115} INFO - [2023-01-07 00:26:38,002] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:26:38,002] {logging_mixin.py:115} INFO - [2023-01-07 00:26:38,002] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:26:38,009] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:26:38,030] {logging_mixin.py:115} INFO - [2023-01-07 00:26:38,030] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:26:38,051] {logging_mixin.py:115} INFO - [2023-01-07 00:26:38,051] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:26:38,061] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.831 seconds
[2023-01-07 00:27:08,131] {processor.py:153} INFO - Started process (PID=8064) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:27:08,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:27:08,133] {logging_mixin.py:115} INFO - [2023-01-07 00:27:08,133] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:27:08,902] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:27:08,903] {logging_mixin.py:115} INFO - [2023-01-07 00:27:08,903] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:27:08,903] {logging_mixin.py:115} INFO - [2023-01-07 00:27:08,903] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:27:08,910] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:27:08,931] {logging_mixin.py:115} INFO - [2023-01-07 00:27:08,931] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:27:08,951] {logging_mixin.py:115} INFO - [2023-01-07 00:27:08,951] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:27:08,960] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.834 seconds
[2023-01-07 00:27:39,033] {processor.py:153} INFO - Started process (PID=8089) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:27:39,034] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:27:39,035] {logging_mixin.py:115} INFO - [2023-01-07 00:27:39,035] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:27:39,804] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:27:39,806] {logging_mixin.py:115} INFO - [2023-01-07 00:27:39,806] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:27:39,806] {logging_mixin.py:115} INFO - [2023-01-07 00:27:39,806] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:27:39,813] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:27:39,834] {logging_mixin.py:115} INFO - [2023-01-07 00:27:39,833] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:27:39,854] {logging_mixin.py:115} INFO - [2023-01-07 00:27:39,854] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:27:39,863] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.835 seconds
[2023-01-07 00:28:09,932] {processor.py:153} INFO - Started process (PID=8114) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:28:09,933] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:28:09,934] {logging_mixin.py:115} INFO - [2023-01-07 00:28:09,934] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:28:10,695] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:28:10,697] {logging_mixin.py:115} INFO - [2023-01-07 00:28:10,697] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:28:10,697] {logging_mixin.py:115} INFO - [2023-01-07 00:28:10,697] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:28:10,704] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:28:10,734] {logging_mixin.py:115} INFO - [2023-01-07 00:28:10,733] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:28:10,756] {logging_mixin.py:115} INFO - [2023-01-07 00:28:10,756] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:28:10,765] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.837 seconds
[2023-01-07 00:28:40,831] {processor.py:153} INFO - Started process (PID=8138) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:28:40,832] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:28:40,832] {logging_mixin.py:115} INFO - [2023-01-07 00:28:40,832] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:28:41,615] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:28:41,616] {logging_mixin.py:115} INFO - [2023-01-07 00:28:41,616] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:28:41,617] {logging_mixin.py:115} INFO - [2023-01-07 00:28:41,617] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:28:41,624] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:28:41,645] {logging_mixin.py:115} INFO - [2023-01-07 00:28:41,645] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:28:41,665] {logging_mixin.py:115} INFO - [2023-01-07 00:28:41,665] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:28:41,674] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.847 seconds
[2023-01-07 00:29:11,728] {processor.py:153} INFO - Started process (PID=8156) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:29:11,729] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:29:11,730] {logging_mixin.py:115} INFO - [2023-01-07 00:29:11,730] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:29:12,538] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:29:12,540] {logging_mixin.py:115} INFO - [2023-01-07 00:29:12,540] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:29:12,540] {logging_mixin.py:115} INFO - [2023-01-07 00:29:12,540] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:29:12,551] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:29:12,574] {logging_mixin.py:115} INFO - [2023-01-07 00:29:12,573] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:29:12,595] {logging_mixin.py:115} INFO - [2023-01-07 00:29:12,595] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:29:12,604] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.883 seconds
[2023-01-07 00:29:42,697] {processor.py:153} INFO - Started process (PID=8181) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:29:42,698] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:29:42,698] {logging_mixin.py:115} INFO - [2023-01-07 00:29:42,698] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:29:43,472] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:29:43,473] {logging_mixin.py:115} INFO - [2023-01-07 00:29:43,473] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:29:43,473] {logging_mixin.py:115} INFO - [2023-01-07 00:29:43,473] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:29:43,480] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:29:43,501] {logging_mixin.py:115} INFO - [2023-01-07 00:29:43,501] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:29:43,521] {logging_mixin.py:115} INFO - [2023-01-07 00:29:43,521] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:29:43,530] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.837 seconds
[2023-01-07 00:30:13,622] {processor.py:153} INFO - Started process (PID=8206) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:30:13,623] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:30:13,624] {logging_mixin.py:115} INFO - [2023-01-07 00:30:13,624] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:30:14,400] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:30:14,402] {logging_mixin.py:115} INFO - [2023-01-07 00:30:14,402] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:30:14,402] {logging_mixin.py:115} INFO - [2023-01-07 00:30:14,402] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:30:14,409] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:30:14,430] {logging_mixin.py:115} INFO - [2023-01-07 00:30:14,430] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:30:14,451] {logging_mixin.py:115} INFO - [2023-01-07 00:30:14,451] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:30:14,460] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.843 seconds
[2023-01-07 00:30:44,570] {processor.py:153} INFO - Started process (PID=8232) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:30:44,571] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:30:44,571] {logging_mixin.py:115} INFO - [2023-01-07 00:30:44,571] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:30:45,345] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:30:45,347] {logging_mixin.py:115} INFO - [2023-01-07 00:30:45,347] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:30:45,347] {logging_mixin.py:115} INFO - [2023-01-07 00:30:45,347] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:30:45,354] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:30:45,375] {logging_mixin.py:115} INFO - [2023-01-07 00:30:45,374] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:30:45,395] {logging_mixin.py:115} INFO - [2023-01-07 00:30:45,395] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:30:45,404] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.839 seconds
[2023-01-07 00:31:15,765] {processor.py:153} INFO - Started process (PID=8250) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:31:15,766] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:31:15,767] {logging_mixin.py:115} INFO - [2023-01-07 00:31:15,767] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:31:16,534] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:31:16,535] {logging_mixin.py:115} INFO - [2023-01-07 00:31:16,535] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:31:16,536] {logging_mixin.py:115} INFO - [2023-01-07 00:31:16,535] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:31:16,542] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:31:16,569] {logging_mixin.py:115} INFO - [2023-01-07 00:31:16,569] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:31:16,590] {logging_mixin.py:115} INFO - [2023-01-07 00:31:16,590] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:31:16,599] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.839 seconds
[2023-01-07 00:31:46,698] {processor.py:153} INFO - Started process (PID=8274) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:31:46,698] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:31:46,699] {logging_mixin.py:115} INFO - [2023-01-07 00:31:46,699] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:31:47,449] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:31:47,450] {logging_mixin.py:115} INFO - [2023-01-07 00:31:47,450] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:31:47,451] {logging_mixin.py:115} INFO - [2023-01-07 00:31:47,450] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:31:47,457] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:31:47,478] {logging_mixin.py:115} INFO - [2023-01-07 00:31:47,478] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:31:47,498] {logging_mixin.py:115} INFO - [2023-01-07 00:31:47,498] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:31:47,507] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.814 seconds
[2023-01-07 00:32:17,597] {processor.py:153} INFO - Started process (PID=8300) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:32:17,599] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:32:17,599] {logging_mixin.py:115} INFO - [2023-01-07 00:32:17,599] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:32:18,377] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:32:18,378] {logging_mixin.py:115} INFO - [2023-01-07 00:32:18,378] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:32:18,378] {logging_mixin.py:115} INFO - [2023-01-07 00:32:18,378] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:32:18,385] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:32:18,406] {logging_mixin.py:115} INFO - [2023-01-07 00:32:18,405] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:32:18,426] {logging_mixin.py:115} INFO - [2023-01-07 00:32:18,426] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:32:18,435] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.843 seconds
[2023-01-07 00:32:48,525] {processor.py:153} INFO - Started process (PID=8325) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:32:48,526] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:32:48,527] {logging_mixin.py:115} INFO - [2023-01-07 00:32:48,527] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:32:49,281] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:32:49,282] {logging_mixin.py:115} INFO - [2023-01-07 00:32:49,282] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:32:49,283] {logging_mixin.py:115} INFO - [2023-01-07 00:32:49,283] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:32:49,290] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:32:49,311] {logging_mixin.py:115} INFO - [2023-01-07 00:32:49,311] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:32:49,332] {logging_mixin.py:115} INFO - [2023-01-07 00:32:49,332] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:32:49,342] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.821 seconds
[2023-01-07 00:33:19,408] {processor.py:153} INFO - Started process (PID=8344) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:33:19,408] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:33:19,409] {logging_mixin.py:115} INFO - [2023-01-07 00:33:19,409] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:33:20,214] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:33:20,216] {logging_mixin.py:115} INFO - [2023-01-07 00:33:20,215] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:33:20,216] {logging_mixin.py:115} INFO - [2023-01-07 00:33:20,216] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:33:20,223] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:33:20,244] {logging_mixin.py:115} INFO - [2023-01-07 00:33:20,244] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:33:20,265] {logging_mixin.py:115} INFO - [2023-01-07 00:33:20,265] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:33:20,274] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.871 seconds
[2023-01-07 00:33:50,341] {processor.py:153} INFO - Started process (PID=8370) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:33:50,342] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:33:50,343] {logging_mixin.py:115} INFO - [2023-01-07 00:33:50,343] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:33:51,109] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:33:51,111] {logging_mixin.py:115} INFO - [2023-01-07 00:33:51,110] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:33:51,111] {logging_mixin.py:115} INFO - [2023-01-07 00:33:51,111] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:33:51,118] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:33:51,138] {logging_mixin.py:115} INFO - [2023-01-07 00:33:51,138] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:33:51,159] {logging_mixin.py:115} INFO - [2023-01-07 00:33:51,159] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:33:51,168] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.832 seconds
[2023-01-07 00:34:21,233] {processor.py:153} INFO - Started process (PID=8395) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:34:21,234] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:34:21,234] {logging_mixin.py:115} INFO - [2023-01-07 00:34:21,234] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:34:21,993] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:34:21,994] {logging_mixin.py:115} INFO - [2023-01-07 00:34:21,994] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:34:21,995] {logging_mixin.py:115} INFO - [2023-01-07 00:34:21,994] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:34:22,001] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:34:22,022] {logging_mixin.py:115} INFO - [2023-01-07 00:34:22,022] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:34:22,043] {logging_mixin.py:115} INFO - [2023-01-07 00:34:22,043] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:34:22,052] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.823 seconds
[2023-01-07 00:34:52,115] {processor.py:153} INFO - Started process (PID=8421) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:34:52,116] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:34:52,117] {logging_mixin.py:115} INFO - [2023-01-07 00:34:52,117] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:34:52,875] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:34:52,876] {logging_mixin.py:115} INFO - [2023-01-07 00:34:52,876] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:34:52,877] {logging_mixin.py:115} INFO - [2023-01-07 00:34:52,877] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:34:52,883] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:34:52,905] {logging_mixin.py:115} INFO - [2023-01-07 00:34:52,904] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:34:52,925] {logging_mixin.py:115} INFO - [2023-01-07 00:34:52,925] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:34:52,935] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.824 seconds
[2023-01-07 00:35:23,036] {processor.py:153} INFO - Started process (PID=8439) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:35:23,038] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:35:23,038] {logging_mixin.py:115} INFO - [2023-01-07 00:35:23,038] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:35:23,894] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:35:23,895] {logging_mixin.py:115} INFO - [2023-01-07 00:35:23,895] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:35:23,895] {logging_mixin.py:115} INFO - [2023-01-07 00:35:23,895] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:35:23,902] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:35:23,923] {logging_mixin.py:115} INFO - [2023-01-07 00:35:23,923] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:35:23,944] {logging_mixin.py:115} INFO - [2023-01-07 00:35:23,944] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:35:23,953] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.922 seconds
[2023-01-07 00:35:54,012] {processor.py:153} INFO - Started process (PID=8465) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:35:54,013] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:35:54,013] {logging_mixin.py:115} INFO - [2023-01-07 00:35:54,013] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:35:54,769] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:35:54,770] {logging_mixin.py:115} INFO - [2023-01-07 00:35:54,770] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:35:54,771] {logging_mixin.py:115} INFO - [2023-01-07 00:35:54,770] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:35:54,777] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:35:54,798] {logging_mixin.py:115} INFO - [2023-01-07 00:35:54,797] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:35:54,818] {logging_mixin.py:115} INFO - [2023-01-07 00:35:54,818] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:35:54,827] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.819 seconds
[2023-01-07 00:36:24,916] {processor.py:153} INFO - Started process (PID=8489) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:36:24,917] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:36:24,918] {logging_mixin.py:115} INFO - [2023-01-07 00:36:24,918] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:36:25,678] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:36:25,680] {logging_mixin.py:115} INFO - [2023-01-07 00:36:25,680] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:36:25,680] {logging_mixin.py:115} INFO - [2023-01-07 00:36:25,680] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:36:25,687] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:36:25,708] {logging_mixin.py:115} INFO - [2023-01-07 00:36:25,708] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:36:25,729] {logging_mixin.py:115} INFO - [2023-01-07 00:36:25,729] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:36:25,738] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.827 seconds
[2023-01-07 00:36:55,820] {processor.py:153} INFO - Started process (PID=8515) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:36:55,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:36:55,822] {logging_mixin.py:115} INFO - [2023-01-07 00:36:55,822] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:36:56,585] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:36:56,587] {logging_mixin.py:115} INFO - [2023-01-07 00:36:56,587] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:36:56,587] {logging_mixin.py:115} INFO - [2023-01-07 00:36:56,587] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:36:56,594] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:36:56,615] {logging_mixin.py:115} INFO - [2023-01-07 00:36:56,614] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:36:56,635] {logging_mixin.py:115} INFO - [2023-01-07 00:36:56,635] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:36:56,644] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.829 seconds
[2023-01-07 00:37:27,233] {processor.py:153} INFO - Started process (PID=8534) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:37:27,234] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:37:27,236] {logging_mixin.py:115} INFO - [2023-01-07 00:37:27,236] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:37:28,064] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:37:28,065] {logging_mixin.py:115} INFO - [2023-01-07 00:37:28,065] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:37:28,066] {logging_mixin.py:115} INFO - [2023-01-07 00:37:28,065] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:37:28,072] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:37:28,094] {logging_mixin.py:115} INFO - [2023-01-07 00:37:28,094] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:37:28,114] {logging_mixin.py:115} INFO - [2023-01-07 00:37:28,114] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:37:28,123] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.895 seconds
[2023-01-07 00:37:58,218] {processor.py:153} INFO - Started process (PID=8559) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:37:58,219] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:37:58,221] {logging_mixin.py:115} INFO - [2023-01-07 00:37:58,220] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:37:58,987] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:37:58,989] {logging_mixin.py:115} INFO - [2023-01-07 00:37:58,988] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:37:58,989] {logging_mixin.py:115} INFO - [2023-01-07 00:37:58,989] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:37:58,998] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:37:59,019] {logging_mixin.py:115} INFO - [2023-01-07 00:37:59,019] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:37:59,040] {logging_mixin.py:115} INFO - [2023-01-07 00:37:59,040] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:37:59,049] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.836 seconds
[2023-01-07 00:38:29,134] {processor.py:153} INFO - Started process (PID=8583) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:38:29,134] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:38:29,136] {logging_mixin.py:115} INFO - [2023-01-07 00:38:29,136] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:38:29,926] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:38:29,927] {logging_mixin.py:115} INFO - [2023-01-07 00:38:29,927] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:38:29,928] {logging_mixin.py:115} INFO - [2023-01-07 00:38:29,927] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:38:29,934] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:38:29,956] {logging_mixin.py:115} INFO - [2023-01-07 00:38:29,955] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:38:29,976] {logging_mixin.py:115} INFO - [2023-01-07 00:38:29,976] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:38:29,985] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.856 seconds
[2023-01-07 00:39:00,056] {processor.py:153} INFO - Started process (PID=8608) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:39:00,059] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:39:00,060] {logging_mixin.py:115} INFO - [2023-01-07 00:39:00,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:39:00,850] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:39:00,851] {logging_mixin.py:115} INFO - [2023-01-07 00:39:00,851] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:39:00,852] {logging_mixin.py:115} INFO - [2023-01-07 00:39:00,851] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:39:00,858] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:39:00,879] {logging_mixin.py:115} INFO - [2023-01-07 00:39:00,879] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:39:00,899] {logging_mixin.py:115} INFO - [2023-01-07 00:39:00,899] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:39:00,908] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.857 seconds
[2023-01-07 00:39:30,975] {processor.py:153} INFO - Started process (PID=8625) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:39:30,977] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:39:30,979] {logging_mixin.py:115} INFO - [2023-01-07 00:39:30,979] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:39:31,796] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:39:31,798] {logging_mixin.py:115} INFO - [2023-01-07 00:39:31,798] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:39:31,798] {logging_mixin.py:115} INFO - [2023-01-07 00:39:31,798] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:39:31,805] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:39:31,826] {logging_mixin.py:115} INFO - [2023-01-07 00:39:31,826] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:39:31,847] {logging_mixin.py:115} INFO - [2023-01-07 00:39:31,847] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:39:31,856] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.886 seconds
[2023-01-07 00:40:01,924] {processor.py:153} INFO - Started process (PID=8650) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:40:01,927] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:40:01,928] {logging_mixin.py:115} INFO - [2023-01-07 00:40:01,928] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:40:02,689] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:40:02,691] {logging_mixin.py:115} INFO - [2023-01-07 00:40:02,691] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:40:02,691] {logging_mixin.py:115} INFO - [2023-01-07 00:40:02,691] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:40:02,698] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:40:02,718] {logging_mixin.py:115} INFO - [2023-01-07 00:40:02,718] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:40:02,739] {logging_mixin.py:115} INFO - [2023-01-07 00:40:02,739] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:40:02,748] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.829 seconds
[2023-01-07 00:40:32,817] {processor.py:153} INFO - Started process (PID=8675) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:40:32,818] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:40:32,819] {logging_mixin.py:115} INFO - [2023-01-07 00:40:32,819] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:40:33,564] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:40:33,565] {logging_mixin.py:115} INFO - [2023-01-07 00:40:33,565] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:40:33,566] {logging_mixin.py:115} INFO - [2023-01-07 00:40:33,566] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:40:33,572] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:40:33,593] {logging_mixin.py:115} INFO - [2023-01-07 00:40:33,593] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:40:33,614] {logging_mixin.py:115} INFO - [2023-01-07 00:40:33,614] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:40:33,623] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.811 seconds
[2023-01-07 00:41:03,690] {processor.py:153} INFO - Started process (PID=8699) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:41:03,691] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:41:03,691] {logging_mixin.py:115} INFO - [2023-01-07 00:41:03,691] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:41:04,443] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:41:04,444] {logging_mixin.py:115} INFO - [2023-01-07 00:41:04,444] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:41:04,444] {logging_mixin.py:115} INFO - [2023-01-07 00:41:04,444] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:41:04,451] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:41:04,472] {logging_mixin.py:115} INFO - [2023-01-07 00:41:04,472] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:41:04,493] {logging_mixin.py:115} INFO - [2023-01-07 00:41:04,493] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:41:04,502] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.817 seconds
[2023-01-07 00:41:34,564] {processor.py:153} INFO - Started process (PID=8716) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:41:34,566] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:41:34,566] {logging_mixin.py:115} INFO - [2023-01-07 00:41:34,566] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:41:35,364] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:41:35,365] {logging_mixin.py:115} INFO - [2023-01-07 00:41:35,365] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:41:35,366] {logging_mixin.py:115} INFO - [2023-01-07 00:41:35,365] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:41:35,372] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:41:35,394] {logging_mixin.py:115} INFO - [2023-01-07 00:41:35,393] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:41:35,414] {logging_mixin.py:115} INFO - [2023-01-07 00:41:35,414] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:41:35,423] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.864 seconds
[2023-01-07 00:42:05,615] {processor.py:153} INFO - Started process (PID=8740) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:42:05,616] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:42:05,616] {logging_mixin.py:115} INFO - [2023-01-07 00:42:05,616] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:42:06,374] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:42:06,376] {logging_mixin.py:115} INFO - [2023-01-07 00:42:06,375] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:42:06,376] {logging_mixin.py:115} INFO - [2023-01-07 00:42:06,376] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:42:06,383] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:42:06,404] {logging_mixin.py:115} INFO - [2023-01-07 00:42:06,403] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:42:06,424] {logging_mixin.py:115} INFO - [2023-01-07 00:42:06,424] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:42:06,433] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.822 seconds
[2023-01-07 00:42:36,523] {processor.py:153} INFO - Started process (PID=8764) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:42:36,525] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:42:36,525] {logging_mixin.py:115} INFO - [2023-01-07 00:42:36,525] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:42:37,284] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:42:37,286] {logging_mixin.py:115} INFO - [2023-01-07 00:42:37,286] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:42:37,286] {logging_mixin.py:115} INFO - [2023-01-07 00:42:37,286] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:42:37,293] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:42:37,314] {logging_mixin.py:115} INFO - [2023-01-07 00:42:37,314] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:42:37,334] {logging_mixin.py:115} INFO - [2023-01-07 00:42:37,334] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:42:37,343] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.825 seconds
[2023-01-07 00:43:07,435] {processor.py:153} INFO - Started process (PID=8790) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:43:07,436] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:43:07,436] {logging_mixin.py:115} INFO - [2023-01-07 00:43:07,436] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:43:08,215] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:43:08,216] {logging_mixin.py:115} INFO - [2023-01-07 00:43:08,216] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:43:08,217] {logging_mixin.py:115} INFO - [2023-01-07 00:43:08,216] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:43:08,223] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:43:08,244] {logging_mixin.py:115} INFO - [2023-01-07 00:43:08,244] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:43:08,265] {logging_mixin.py:115} INFO - [2023-01-07 00:43:08,265] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:43:08,274] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.844 seconds
[2023-01-07 00:43:38,368] {processor.py:153} INFO - Started process (PID=8808) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:43:38,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:43:38,370] {logging_mixin.py:115} INFO - [2023-01-07 00:43:38,370] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:43:39,243] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:43:39,245] {logging_mixin.py:115} INFO - [2023-01-07 00:43:39,244] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:43:39,245] {logging_mixin.py:115} INFO - [2023-01-07 00:43:39,245] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:43:39,252] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:43:39,279] {logging_mixin.py:115} INFO - [2023-01-07 00:43:39,279] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:43:39,302] {logging_mixin.py:115} INFO - [2023-01-07 00:43:39,302] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:43:39,311] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.948 seconds
[2023-01-07 00:44:09,749] {processor.py:153} INFO - Started process (PID=8833) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:44:09,750] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:44:09,750] {logging_mixin.py:115} INFO - [2023-01-07 00:44:09,750] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:44:10,499] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:44:10,500] {logging_mixin.py:115} INFO - [2023-01-07 00:44:10,500] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:44:10,501] {logging_mixin.py:115} INFO - [2023-01-07 00:44:10,500] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:44:10,507] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:44:10,528] {logging_mixin.py:115} INFO - [2023-01-07 00:44:10,528] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:44:10,549] {logging_mixin.py:115} INFO - [2023-01-07 00:44:10,549] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:44:10,558] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.814 seconds
[2023-01-07 00:44:40,649] {processor.py:153} INFO - Started process (PID=8858) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:44:40,651] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:44:40,651] {logging_mixin.py:115} INFO - [2023-01-07 00:44:40,651] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:44:41,404] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:44:41,406] {logging_mixin.py:115} INFO - [2023-01-07 00:44:41,406] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:44:41,406] {logging_mixin.py:115} INFO - [2023-01-07 00:44:41,406] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:44:41,413] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:44:41,433] {logging_mixin.py:115} INFO - [2023-01-07 00:44:41,433] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:44:41,454] {logging_mixin.py:115} INFO - [2023-01-07 00:44:41,454] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:44:41,462] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.818 seconds
[2023-01-07 00:45:11,557] {processor.py:153} INFO - Started process (PID=8884) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:45:11,559] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:45:11,559] {logging_mixin.py:115} INFO - [2023-01-07 00:45:11,559] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:45:12,305] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:45:12,306] {logging_mixin.py:115} INFO - [2023-01-07 00:45:12,306] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:45:12,307] {logging_mixin.py:115} INFO - [2023-01-07 00:45:12,307] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:45:12,313] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:45:12,335] {logging_mixin.py:115} INFO - [2023-01-07 00:45:12,335] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:45:12,356] {logging_mixin.py:115} INFO - [2023-01-07 00:45:12,355] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:45:12,367] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.814 seconds
[2023-01-07 00:45:42,454] {processor.py:153} INFO - Started process (PID=8902) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:45:42,455] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:45:42,455] {logging_mixin.py:115} INFO - [2023-01-07 00:45:42,455] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:45:43,451] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:45:43,452] {logging_mixin.py:115} INFO - [2023-01-07 00:45:43,452] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:45:43,453] {logging_mixin.py:115} INFO - [2023-01-07 00:45:43,453] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:45:43,459] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:45:43,480] {logging_mixin.py:115} INFO - [2023-01-07 00:45:43,480] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:45:43,501] {logging_mixin.py:115} INFO - [2023-01-07 00:45:43,501] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:45:43,511] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.062 seconds
[2023-01-07 00:46:13,583] {processor.py:153} INFO - Started process (PID=8926) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:46:13,584] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:46:13,585] {logging_mixin.py:115} INFO - [2023-01-07 00:46:13,585] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:46:14,335] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:46:14,337] {logging_mixin.py:115} INFO - [2023-01-07 00:46:14,336] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:46:14,337] {logging_mixin.py:115} INFO - [2023-01-07 00:46:14,337] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:46:14,344] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:46:14,364] {logging_mixin.py:115} INFO - [2023-01-07 00:46:14,364] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:46:14,386] {logging_mixin.py:115} INFO - [2023-01-07 00:46:14,386] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:46:14,395] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.817 seconds
[2023-01-07 00:46:44,492] {processor.py:153} INFO - Started process (PID=8951) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:46:44,495] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:46:44,495] {logging_mixin.py:115} INFO - [2023-01-07 00:46:44,495] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:46:45,241] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:46:45,242] {logging_mixin.py:115} INFO - [2023-01-07 00:46:45,242] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:46:45,242] {logging_mixin.py:115} INFO - [2023-01-07 00:46:45,242] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:46:45,249] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:46:45,272] {logging_mixin.py:115} INFO - [2023-01-07 00:46:45,271] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:46:45,292] {logging_mixin.py:115} INFO - [2023-01-07 00:46:45,292] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:46:45,302] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.815 seconds
[2023-01-07 00:47:15,395] {processor.py:153} INFO - Started process (PID=8978) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:47:15,397] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:47:15,397] {logging_mixin.py:115} INFO - [2023-01-07 00:47:15,397] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:47:16,163] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:47:16,164] {logging_mixin.py:115} INFO - [2023-01-07 00:47:16,164] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:47:16,165] {logging_mixin.py:115} INFO - [2023-01-07 00:47:16,164] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:47:16,172] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:47:16,200] {logging_mixin.py:115} INFO - [2023-01-07 00:47:16,199] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:47:16,221] {logging_mixin.py:115} INFO - [2023-01-07 00:47:16,221] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:47:16,231] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.840 seconds
[2023-01-07 00:47:46,328] {processor.py:153} INFO - Started process (PID=8996) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:47:46,328] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:47:46,329] {logging_mixin.py:115} INFO - [2023-01-07 00:47:46,329] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:47:47,312] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:47:47,313] {logging_mixin.py:115} INFO - [2023-01-07 00:47:47,313] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:47:47,314] {logging_mixin.py:115} INFO - [2023-01-07 00:47:47,313] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:47:47,321] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:47:47,343] {logging_mixin.py:115} INFO - [2023-01-07 00:47:47,342] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:47:47,369] {logging_mixin.py:115} INFO - [2023-01-07 00:47:47,369] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:47:47,381] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.059 seconds
[2023-01-07 00:48:17,456] {processor.py:153} INFO - Started process (PID=9022) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:48:17,457] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:48:17,458] {logging_mixin.py:115} INFO - [2023-01-07 00:48:17,458] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:48:18,237] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:48:18,238] {logging_mixin.py:115} INFO - [2023-01-07 00:48:18,238] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:48:18,239] {logging_mixin.py:115} INFO - [2023-01-07 00:48:18,239] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:48:18,247] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:48:18,269] {logging_mixin.py:115} INFO - [2023-01-07 00:48:18,269] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:48:18,289] {logging_mixin.py:115} INFO - [2023-01-07 00:48:18,289] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:48:18,299] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.847 seconds
[2023-01-07 00:48:48,343] {processor.py:153} INFO - Started process (PID=9049) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:48:48,344] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:48:48,344] {logging_mixin.py:115} INFO - [2023-01-07 00:48:48,344] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:48:49,113] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:48:49,114] {logging_mixin.py:115} INFO - [2023-01-07 00:48:49,114] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:48:49,114] {logging_mixin.py:115} INFO - [2023-01-07 00:48:49,114] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:48:49,121] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:48:49,142] {logging_mixin.py:115} INFO - [2023-01-07 00:48:49,142] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:48:49,163] {logging_mixin.py:115} INFO - [2023-01-07 00:48:49,162] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:48:49,172] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.833 seconds
[2023-01-07 00:49:19,279] {processor.py:153} INFO - Started process (PID=9075) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:49:19,286] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:49:19,287] {logging_mixin.py:115} INFO - [2023-01-07 00:49:19,287] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:49:20,154] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:49:20,156] {logging_mixin.py:115} INFO - [2023-01-07 00:49:20,156] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:49:20,156] {logging_mixin.py:115} INFO - [2023-01-07 00:49:20,156] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:49:20,167] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:49:20,234] {logging_mixin.py:115} INFO - [2023-01-07 00:49:20,234] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:49:20,266] {logging_mixin.py:115} INFO - [2023-01-07 00:49:20,266] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:49:20,277] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.012 seconds
[2023-01-07 00:49:50,344] {processor.py:153} INFO - Started process (PID=9092) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:49:50,344] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:49:50,345] {logging_mixin.py:115} INFO - [2023-01-07 00:49:50,345] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:49:51,216] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:49:51,217] {logging_mixin.py:115} INFO - [2023-01-07 00:49:51,217] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:49:51,218] {logging_mixin.py:115} INFO - [2023-01-07 00:49:51,218] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:49:51,225] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:49:51,246] {logging_mixin.py:115} INFO - [2023-01-07 00:49:51,246] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:49:51,269] {logging_mixin.py:115} INFO - [2023-01-07 00:49:51,269] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:49:51,283] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.946 seconds
[2023-01-07 00:50:21,373] {processor.py:153} INFO - Started process (PID=9117) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:50:21,375] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:50:21,375] {logging_mixin.py:115} INFO - [2023-01-07 00:50:21,375] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:50:22,138] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:50:22,139] {logging_mixin.py:115} INFO - [2023-01-07 00:50:22,139] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:50:22,140] {logging_mixin.py:115} INFO - [2023-01-07 00:50:22,139] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:50:22,146] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:50:22,173] {logging_mixin.py:115} INFO - [2023-01-07 00:50:22,173] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:50:22,201] {logging_mixin.py:115} INFO - [2023-01-07 00:50:22,201] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:50:22,211] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.842 seconds
[2023-01-07 00:50:52,304] {processor.py:153} INFO - Started process (PID=9142) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:50:52,305] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:50:52,305] {logging_mixin.py:115} INFO - [2023-01-07 00:50:52,305] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:50:53,127] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:50:53,128] {logging_mixin.py:115} INFO - [2023-01-07 00:50:53,128] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:50:53,129] {logging_mixin.py:115} INFO - [2023-01-07 00:50:53,129] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:50:53,136] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:50:53,159] {logging_mixin.py:115} INFO - [2023-01-07 00:50:53,159] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:50:53,180] {logging_mixin.py:115} INFO - [2023-01-07 00:50:53,180] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:50:53,190] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.891 seconds
[2023-01-07 00:51:23,286] {processor.py:153} INFO - Started process (PID=9167) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:51:23,288] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:51:23,288] {logging_mixin.py:115} INFO - [2023-01-07 00:51:23,288] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:51:24,067] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:51:24,069] {logging_mixin.py:115} INFO - [2023-01-07 00:51:24,068] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:51:24,069] {logging_mixin.py:115} INFO - [2023-01-07 00:51:24,069] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:51:24,076] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:51:24,096] {logging_mixin.py:115} INFO - [2023-01-07 00:51:24,096] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:51:24,118] {logging_mixin.py:115} INFO - [2023-01-07 00:51:24,118] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:51:24,128] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.846 seconds
[2023-01-07 00:51:54,187] {processor.py:153} INFO - Started process (PID=9186) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:51:54,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:51:54,188] {logging_mixin.py:115} INFO - [2023-01-07 00:51:54,188] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:51:54,964] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:51:54,965] {logging_mixin.py:115} INFO - [2023-01-07 00:51:54,965] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:51:54,966] {logging_mixin.py:115} INFO - [2023-01-07 00:51:54,965] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:51:54,973] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:51:54,994] {logging_mixin.py:115} INFO - [2023-01-07 00:51:54,994] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:51:55,014] {logging_mixin.py:115} INFO - [2023-01-07 00:51:55,014] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:51:55,024] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.842 seconds
[2023-01-07 00:52:25,113] {processor.py:153} INFO - Started process (PID=9212) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:52:25,114] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:52:25,115] {logging_mixin.py:115} INFO - [2023-01-07 00:52:25,115] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:52:25,894] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:52:25,895] {logging_mixin.py:115} INFO - [2023-01-07 00:52:25,895] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:52:25,895] {logging_mixin.py:115} INFO - [2023-01-07 00:52:25,895] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:52:25,902] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:52:25,924] {logging_mixin.py:115} INFO - [2023-01-07 00:52:25,924] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:52:25,946] {logging_mixin.py:115} INFO - [2023-01-07 00:52:25,945] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:52:25,956] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.847 seconds
[2023-01-07 00:52:56,511] {processor.py:153} INFO - Started process (PID=9237) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:52:56,512] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:52:56,513] {logging_mixin.py:115} INFO - [2023-01-07 00:52:56,513] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:52:57,272] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:52:57,273] {logging_mixin.py:115} INFO - [2023-01-07 00:52:57,273] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:52:57,274] {logging_mixin.py:115} INFO - [2023-01-07 00:52:57,274] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:52:57,280] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:52:57,307] {logging_mixin.py:115} INFO - [2023-01-07 00:52:57,307] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:52:57,328] {logging_mixin.py:115} INFO - [2023-01-07 00:52:57,328] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:52:57,339] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.833 seconds
[2023-01-07 00:53:27,440] {processor.py:153} INFO - Started process (PID=9262) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:53:27,441] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:53:27,442] {logging_mixin.py:115} INFO - [2023-01-07 00:53:27,442] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:53:28,214] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:53:28,215] {logging_mixin.py:115} INFO - [2023-01-07 00:53:28,215] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:53:28,216] {logging_mixin.py:115} INFO - [2023-01-07 00:53:28,215] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:53:28,222] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:53:28,244] {logging_mixin.py:115} INFO - [2023-01-07 00:53:28,243] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:53:28,264] {logging_mixin.py:115} INFO - [2023-01-07 00:53:28,264] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:53:28,274] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.839 seconds
[2023-01-07 00:53:58,366] {processor.py:153} INFO - Started process (PID=9280) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:53:58,366] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:53:58,367] {logging_mixin.py:115} INFO - [2023-01-07 00:53:58,367] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:53:59,448] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:53:59,450] {logging_mixin.py:115} INFO - [2023-01-07 00:53:59,449] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:53:59,450] {logging_mixin.py:115} INFO - [2023-01-07 00:53:59,450] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:53:59,462] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:53:59,491] {logging_mixin.py:115} INFO - [2023-01-07 00:53:59,491] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:53:59,521] {logging_mixin.py:115} INFO - [2023-01-07 00:53:59,521] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:53:59,534] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.173 seconds
[2023-01-07 00:54:29,595] {processor.py:153} INFO - Started process (PID=9306) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:54:29,596] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:54:29,596] {logging_mixin.py:115} INFO - [2023-01-07 00:54:29,596] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:54:30,351] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:54:30,352] {logging_mixin.py:115} INFO - [2023-01-07 00:54:30,352] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:54:30,352] {logging_mixin.py:115} INFO - [2023-01-07 00:54:30,352] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:54:30,359] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:54:30,380] {logging_mixin.py:115} INFO - [2023-01-07 00:54:30,379] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:54:30,400] {logging_mixin.py:115} INFO - [2023-01-07 00:54:30,400] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:54:30,410] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.819 seconds
[2023-01-07 00:55:00,667] {processor.py:153} INFO - Started process (PID=9330) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:55:00,668] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:55:00,669] {logging_mixin.py:115} INFO - [2023-01-07 00:55:00,669] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:55:01,472] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:55:01,474] {logging_mixin.py:115} INFO - [2023-01-07 00:55:01,474] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:55:01,474] {logging_mixin.py:115} INFO - [2023-01-07 00:55:01,474] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:55:01,488] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:55:01,524] {logging_mixin.py:115} INFO - [2023-01-07 00:55:01,523] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:55:01,556] {logging_mixin.py:115} INFO - [2023-01-07 00:55:01,556] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:55:01,573] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.911 seconds
[2023-01-07 00:55:31,671] {processor.py:153} INFO - Started process (PID=9354) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:55:31,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:55:31,672] {logging_mixin.py:115} INFO - [2023-01-07 00:55:31,672] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:55:32,492] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:55:32,494] {logging_mixin.py:115} INFO - [2023-01-07 00:55:32,494] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:55:32,494] {logging_mixin.py:115} INFO - [2023-01-07 00:55:32,494] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:55:32,501] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:55:32,522] {logging_mixin.py:115} INFO - [2023-01-07 00:55:32,522] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:55:32,542] {logging_mixin.py:115} INFO - [2023-01-07 00:55:32,542] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:55:32,551] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.885 seconds
[2023-01-07 00:56:02,754] {processor.py:153} INFO - Started process (PID=9372) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:56:02,755] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:56:02,755] {logging_mixin.py:115} INFO - [2023-01-07 00:56:02,755] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:56:03,706] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:56:03,707] {logging_mixin.py:115} INFO - [2023-01-07 00:56:03,707] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:56:03,707] {logging_mixin.py:115} INFO - [2023-01-07 00:56:03,707] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:56:03,714] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:56:03,740] {logging_mixin.py:115} INFO - [2023-01-07 00:56:03,740] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:56:03,762] {logging_mixin.py:115} INFO - [2023-01-07 00:56:03,762] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:56:03,771] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.022 seconds
[2023-01-07 00:56:33,850] {processor.py:153} INFO - Started process (PID=9396) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:56:33,851] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:56:33,851] {logging_mixin.py:115} INFO - [2023-01-07 00:56:33,851] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:56:34,627] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:56:34,629] {logging_mixin.py:115} INFO - [2023-01-07 00:56:34,629] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:56:34,629] {logging_mixin.py:115} INFO - [2023-01-07 00:56:34,629] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:56:34,636] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:56:34,657] {logging_mixin.py:115} INFO - [2023-01-07 00:56:34,657] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:56:34,677] {logging_mixin.py:115} INFO - [2023-01-07 00:56:34,677] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:56:34,687] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.842 seconds
[2023-01-07 00:57:04,786] {processor.py:153} INFO - Started process (PID=9421) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:57:04,787] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:57:04,788] {logging_mixin.py:115} INFO - [2023-01-07 00:57:04,788] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:57:05,541] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:57:05,543] {logging_mixin.py:115} INFO - [2023-01-07 00:57:05,542] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:57:05,543] {logging_mixin.py:115} INFO - [2023-01-07 00:57:05,543] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:57:05,550] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:57:05,570] {logging_mixin.py:115} INFO - [2023-01-07 00:57:05,570] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:57:05,591] {logging_mixin.py:115} INFO - [2023-01-07 00:57:05,591] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:57:05,600] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.819 seconds
[2023-01-07 00:57:35,693] {processor.py:153} INFO - Started process (PID=9446) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:57:35,694] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:57:35,694] {logging_mixin.py:115} INFO - [2023-01-07 00:57:35,694] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:57:36,466] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:57:36,468] {logging_mixin.py:115} INFO - [2023-01-07 00:57:36,467] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:57:36,468] {logging_mixin.py:115} INFO - [2023-01-07 00:57:36,468] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:57:36,475] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:57:36,496] {logging_mixin.py:115} INFO - [2023-01-07 00:57:36,496] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:57:36,517] {logging_mixin.py:115} INFO - [2023-01-07 00:57:36,517] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:57:36,526] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.838 seconds
[2023-01-07 00:58:06,622] {processor.py:153} INFO - Started process (PID=9465) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:58:06,623] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:58:06,624] {logging_mixin.py:115} INFO - [2023-01-07 00:58:06,623] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:58:07,438] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:58:07,440] {logging_mixin.py:115} INFO - [2023-01-07 00:58:07,440] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:58:07,441] {logging_mixin.py:115} INFO - [2023-01-07 00:58:07,440] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:58:07,448] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:58:07,469] {logging_mixin.py:115} INFO - [2023-01-07 00:58:07,469] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:58:07,490] {logging_mixin.py:115} INFO - [2023-01-07 00:58:07,490] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:58:07,499] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.882 seconds
[2023-01-07 00:58:37,595] {processor.py:153} INFO - Started process (PID=9491) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:58:37,596] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:58:37,597] {logging_mixin.py:115} INFO - [2023-01-07 00:58:37,597] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:58:38,369] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:58:38,371] {logging_mixin.py:115} INFO - [2023-01-07 00:58:38,371] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:58:38,371] {logging_mixin.py:115} INFO - [2023-01-07 00:58:38,371] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:58:38,378] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:58:38,400] {logging_mixin.py:115} INFO - [2023-01-07 00:58:38,400] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:58:38,420] {logging_mixin.py:115} INFO - [2023-01-07 00:58:38,420] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:58:38,430] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.840 seconds
[2023-01-07 00:59:08,520] {processor.py:153} INFO - Started process (PID=9518) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:59:08,521] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:59:08,521] {logging_mixin.py:115} INFO - [2023-01-07 00:59:08,521] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:59:09,282] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:59:09,283] {logging_mixin.py:115} INFO - [2023-01-07 00:59:09,283] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:59:09,284] {logging_mixin.py:115} INFO - [2023-01-07 00:59:09,284] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:59:09,290] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:59:09,311] {logging_mixin.py:115} INFO - [2023-01-07 00:59:09,311] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:59:09,332] {logging_mixin.py:115} INFO - [2023-01-07 00:59:09,331] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:59:09,340] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.825 seconds
[2023-01-07 00:59:39,410] {processor.py:153} INFO - Started process (PID=9542) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:59:39,411] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 00:59:39,412] {logging_mixin.py:115} INFO - [2023-01-07 00:59:39,412] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:59:40,171] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 00:59:40,172] {logging_mixin.py:115} INFO - [2023-01-07 00:59:40,172] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 00:59:40,172] {logging_mixin.py:115} INFO - [2023-01-07 00:59:40,172] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 00:59:40,179] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 00:59:40,200] {logging_mixin.py:115} INFO - [2023-01-07 00:59:40,200] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 00:59:40,220] {logging_mixin.py:115} INFO - [2023-01-07 00:59:40,220] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 00:59:40,229] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.824 seconds
[2023-01-07 01:00:10,298] {processor.py:153} INFO - Started process (PID=9561) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:00:10,298] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:00:10,299] {logging_mixin.py:115} INFO - [2023-01-07 01:00:10,299] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:00:11,126] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:00:11,127] {logging_mixin.py:115} INFO - [2023-01-07 01:00:11,127] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:00:11,128] {logging_mixin.py:115} INFO - [2023-01-07 01:00:11,127] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:00:11,134] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:00:11,156] {logging_mixin.py:115} INFO - [2023-01-07 01:00:11,156] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:00:11,177] {logging_mixin.py:115} INFO - [2023-01-07 01:00:11,177] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:00:11,186] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.894 seconds
[2023-01-07 01:00:41,260] {processor.py:153} INFO - Started process (PID=9588) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:00:41,261] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:00:41,262] {logging_mixin.py:115} INFO - [2023-01-07 01:00:41,262] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:00:42,037] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:00:42,038] {logging_mixin.py:115} INFO - [2023-01-07 01:00:42,038] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:00:42,039] {logging_mixin.py:115} INFO - [2023-01-07 01:00:42,038] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:00:42,045] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:00:42,066] {logging_mixin.py:115} INFO - [2023-01-07 01:00:42,066] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:00:42,086] {logging_mixin.py:115} INFO - [2023-01-07 01:00:42,086] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:00:42,095] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.839 seconds
[2023-01-07 01:01:12,159] {processor.py:153} INFO - Started process (PID=9614) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:01:12,160] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:01:12,161] {logging_mixin.py:115} INFO - [2023-01-07 01:01:12,161] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:01:12,912] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:01:12,913] {logging_mixin.py:115} INFO - [2023-01-07 01:01:12,913] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:01:12,914] {logging_mixin.py:115} INFO - [2023-01-07 01:01:12,914] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:01:12,921] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:01:12,943] {logging_mixin.py:115} INFO - [2023-01-07 01:01:12,942] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:01:12,964] {logging_mixin.py:115} INFO - [2023-01-07 01:01:12,964] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:01:12,973] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.818 seconds
[2023-01-07 01:01:43,037] {processor.py:153} INFO - Started process (PID=9640) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:01:43,038] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:01:43,039] {logging_mixin.py:115} INFO - [2023-01-07 01:01:43,039] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:01:43,814] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:01:43,815] {logging_mixin.py:115} INFO - [2023-01-07 01:01:43,815] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:01:43,816] {logging_mixin.py:115} INFO - [2023-01-07 01:01:43,816] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:01:43,823] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:01:43,848] {logging_mixin.py:115} INFO - [2023-01-07 01:01:43,848] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:01:43,871] {logging_mixin.py:115} INFO - [2023-01-07 01:01:43,871] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:01:43,881] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.848 seconds
[2023-01-07 01:02:13,974] {processor.py:153} INFO - Started process (PID=9657) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:02:13,975] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:02:13,975] {logging_mixin.py:115} INFO - [2023-01-07 01:02:13,975] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:02:14,752] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:02:14,754] {logging_mixin.py:115} INFO - [2023-01-07 01:02:14,754] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:02:14,754] {logging_mixin.py:115} INFO - [2023-01-07 01:02:14,754] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:02:14,761] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:02:14,782] {logging_mixin.py:115} INFO - [2023-01-07 01:02:14,782] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:02:14,803] {logging_mixin.py:115} INFO - [2023-01-07 01:02:14,803] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:02:14,813] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.843 seconds
[2023-01-07 01:02:44,907] {processor.py:153} INFO - Started process (PID=9682) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:02:44,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:02:44,909] {logging_mixin.py:115} INFO - [2023-01-07 01:02:44,909] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:02:45,681] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:02:45,683] {logging_mixin.py:115} INFO - [2023-01-07 01:02:45,683] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:02:45,683] {logging_mixin.py:115} INFO - [2023-01-07 01:02:45,683] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:02:45,690] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:02:45,711] {logging_mixin.py:115} INFO - [2023-01-07 01:02:45,711] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:02:45,732] {logging_mixin.py:115} INFO - [2023-01-07 01:02:45,732] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:02:45,741] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.838 seconds
[2023-01-07 01:03:15,832] {processor.py:153} INFO - Started process (PID=9707) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:03:15,832] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:03:15,833] {logging_mixin.py:115} INFO - [2023-01-07 01:03:15,833] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:03:16,629] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:03:16,630] {logging_mixin.py:115} INFO - [2023-01-07 01:03:16,630] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:03:16,630] {logging_mixin.py:115} INFO - [2023-01-07 01:03:16,630] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:03:16,637] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:03:16,658] {logging_mixin.py:115} INFO - [2023-01-07 01:03:16,658] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:03:16,679] {logging_mixin.py:115} INFO - [2023-01-07 01:03:16,679] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:03:16,688] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.861 seconds
[2023-01-07 01:03:46,784] {processor.py:153} INFO - Started process (PID=9733) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:03:46,786] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:03:46,786] {logging_mixin.py:115} INFO - [2023-01-07 01:03:46,786] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:03:47,554] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:03:47,556] {logging_mixin.py:115} INFO - [2023-01-07 01:03:47,556] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:03:47,556] {logging_mixin.py:115} INFO - [2023-01-07 01:03:47,556] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:03:47,563] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:03:47,584] {logging_mixin.py:115} INFO - [2023-01-07 01:03:47,584] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:03:47,605] {logging_mixin.py:115} INFO - [2023-01-07 01:03:47,605] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:03:47,614] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.834 seconds
[2023-01-07 01:04:17,709] {processor.py:153} INFO - Started process (PID=9752) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:04:17,710] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:04:17,711] {logging_mixin.py:115} INFO - [2023-01-07 01:04:17,710] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:04:18,495] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:04:18,497] {logging_mixin.py:115} INFO - [2023-01-07 01:04:18,497] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:04:18,497] {logging_mixin.py:115} INFO - [2023-01-07 01:04:18,497] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:04:18,504] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:04:18,528] {logging_mixin.py:115} INFO - [2023-01-07 01:04:18,528] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:04:18,557] {logging_mixin.py:115} INFO - [2023-01-07 01:04:18,556] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:04:18,566] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.861 seconds
[2023-01-07 01:04:48,646] {processor.py:153} INFO - Started process (PID=9777) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:04:48,647] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:04:48,648] {logging_mixin.py:115} INFO - [2023-01-07 01:04:48,648] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:04:49,426] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:04:49,428] {logging_mixin.py:115} INFO - [2023-01-07 01:04:49,428] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:04:49,429] {logging_mixin.py:115} INFO - [2023-01-07 01:04:49,428] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:04:49,439] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:04:49,470] {logging_mixin.py:115} INFO - [2023-01-07 01:04:49,470] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:04:49,493] {logging_mixin.py:115} INFO - [2023-01-07 01:04:49,493] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:04:49,505] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.863 seconds
[2023-01-07 01:05:20,117] {processor.py:153} INFO - Started process (PID=9802) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:05:20,118] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:05:20,119] {logging_mixin.py:115} INFO - [2023-01-07 01:05:20,119] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:05:20,890] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:05:20,892] {logging_mixin.py:115} INFO - [2023-01-07 01:05:20,892] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:05:20,892] {logging_mixin.py:115} INFO - [2023-01-07 01:05:20,892] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:05:20,899] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:05:20,921] {logging_mixin.py:115} INFO - [2023-01-07 01:05:20,921] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:05:20,942] {logging_mixin.py:115} INFO - [2023-01-07 01:05:20,942] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:05:20,951] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.839 seconds
[2023-01-07 01:05:51,054] {processor.py:153} INFO - Started process (PID=9827) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:05:51,054] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:05:51,055] {logging_mixin.py:115} INFO - [2023-01-07 01:05:51,055] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:05:51,820] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:05:51,821] {logging_mixin.py:115} INFO - [2023-01-07 01:05:51,821] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:05:51,822] {logging_mixin.py:115} INFO - [2023-01-07 01:05:51,821] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:05:51,828] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:05:51,849] {logging_mixin.py:115} INFO - [2023-01-07 01:05:51,849] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:05:51,870] {logging_mixin.py:115} INFO - [2023-01-07 01:05:51,870] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:05:51,879] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.830 seconds
[2023-01-07 01:06:21,974] {processor.py:153} INFO - Started process (PID=9852) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:06:21,977] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:06:21,978] {logging_mixin.py:115} INFO - [2023-01-07 01:06:21,978] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:06:22,769] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:06:22,771] {logging_mixin.py:115} INFO - [2023-01-07 01:06:22,771] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:06:22,771] {logging_mixin.py:115} INFO - [2023-01-07 01:06:22,771] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:06:22,778] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:06:22,799] {logging_mixin.py:115} INFO - [2023-01-07 01:06:22,799] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:06:22,820] {logging_mixin.py:115} INFO - [2023-01-07 01:06:22,820] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:06:22,830] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.860 seconds
[2023-01-07 01:06:52,921] {processor.py:153} INFO - Started process (PID=9870) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:06:52,922] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:06:52,923] {logging_mixin.py:115} INFO - [2023-01-07 01:06:52,923] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:06:53,724] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:06:53,726] {logging_mixin.py:115} INFO - [2023-01-07 01:06:53,725] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:06:53,726] {logging_mixin.py:115} INFO - [2023-01-07 01:06:53,726] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:06:53,733] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:06:53,761] {logging_mixin.py:115} INFO - [2023-01-07 01:06:53,760] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:06:53,789] {logging_mixin.py:115} INFO - [2023-01-07 01:06:53,789] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:06:53,801] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.884 seconds
[2023-01-07 01:07:23,891] {processor.py:153} INFO - Started process (PID=9895) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:07:23,893] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:07:23,894] {logging_mixin.py:115} INFO - [2023-01-07 01:07:23,894] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:07:24,663] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:07:24,665] {logging_mixin.py:115} INFO - [2023-01-07 01:07:24,665] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:07:24,665] {logging_mixin.py:115} INFO - [2023-01-07 01:07:24,665] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:07:24,672] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:07:24,693] {logging_mixin.py:115} INFO - [2023-01-07 01:07:24,692] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:07:24,713] {logging_mixin.py:115} INFO - [2023-01-07 01:07:24,713] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:07:24,722] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.836 seconds
[2023-01-07 01:07:55,230] {processor.py:153} INFO - Started process (PID=9921) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:07:55,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:07:55,232] {logging_mixin.py:115} INFO - [2023-01-07 01:07:55,232] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:07:56,038] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:07:56,039] {logging_mixin.py:115} INFO - [2023-01-07 01:07:56,039] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:07:56,040] {logging_mixin.py:115} INFO - [2023-01-07 01:07:56,040] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:07:56,047] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:07:56,069] {logging_mixin.py:115} INFO - [2023-01-07 01:07:56,069] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:07:56,090] {logging_mixin.py:115} INFO - [2023-01-07 01:07:56,090] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:07:56,100] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.875 seconds
[2023-01-07 01:08:26,196] {processor.py:153} INFO - Started process (PID=9947) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:08:26,196] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:08:26,198] {logging_mixin.py:115} INFO - [2023-01-07 01:08:26,198] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:08:26,958] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:08:26,959] {logging_mixin.py:115} INFO - [2023-01-07 01:08:26,959] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:08:26,960] {logging_mixin.py:115} INFO - [2023-01-07 01:08:26,960] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:08:26,966] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:08:26,987] {logging_mixin.py:115} INFO - [2023-01-07 01:08:26,987] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:08:27,008] {logging_mixin.py:115} INFO - [2023-01-07 01:08:27,008] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:08:27,017] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.826 seconds
[2023-01-07 01:08:57,108] {processor.py:153} INFO - Started process (PID=9965) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:08:57,109] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:08:57,111] {logging_mixin.py:115} INFO - [2023-01-07 01:08:57,111] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:08:57,908] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:08:57,909] {logging_mixin.py:115} INFO - [2023-01-07 01:08:57,909] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:08:57,910] {logging_mixin.py:115} INFO - [2023-01-07 01:08:57,909] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:08:57,916] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:08:57,937] {logging_mixin.py:115} INFO - [2023-01-07 01:08:57,937] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:08:57,958] {logging_mixin.py:115} INFO - [2023-01-07 01:08:57,958] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:08:57,968] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.864 seconds
[2023-01-07 01:09:28,059] {processor.py:153} INFO - Started process (PID=9991) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:09:28,060] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:09:28,062] {logging_mixin.py:115} INFO - [2023-01-07 01:09:28,062] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:09:28,842] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:09:28,844] {logging_mixin.py:115} INFO - [2023-01-07 01:09:28,843] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:09:28,844] {logging_mixin.py:115} INFO - [2023-01-07 01:09:28,844] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:09:28,851] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:09:28,872] {logging_mixin.py:115} INFO - [2023-01-07 01:09:28,871] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:09:28,892] {logging_mixin.py:115} INFO - [2023-01-07 01:09:28,892] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:09:28,902] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.850 seconds
[2023-01-07 01:09:58,981] {processor.py:153} INFO - Started process (PID=10016) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:09:58,982] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:09:58,984] {logging_mixin.py:115} INFO - [2023-01-07 01:09:58,983] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:09:59,754] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:09:59,755] {logging_mixin.py:115} INFO - [2023-01-07 01:09:59,755] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:09:59,756] {logging_mixin.py:115} INFO - [2023-01-07 01:09:59,755] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:09:59,762] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:09:59,784] {logging_mixin.py:115} INFO - [2023-01-07 01:09:59,783] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:09:59,804] {logging_mixin.py:115} INFO - [2023-01-07 01:09:59,804] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:09:59,814] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.837 seconds
[2023-01-07 01:10:29,888] {processor.py:153} INFO - Started process (PID=10039) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:10:29,889] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:10:29,890] {logging_mixin.py:115} INFO - [2023-01-07 01:10:29,890] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:10:30,660] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:10:30,662] {logging_mixin.py:115} INFO - [2023-01-07 01:10:30,661] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:10:30,662] {logging_mixin.py:115} INFO - [2023-01-07 01:10:30,662] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:10:30,669] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:10:30,690] {logging_mixin.py:115} INFO - [2023-01-07 01:10:30,690] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:10:30,710] {logging_mixin.py:115} INFO - [2023-01-07 01:10:30,710] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:10:30,719] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.837 seconds
[2023-01-07 01:11:00,788] {processor.py:153} INFO - Started process (PID=10057) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:11:00,789] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:11:00,789] {logging_mixin.py:115} INFO - [2023-01-07 01:11:00,789] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:11:01,769] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:11:01,771] {logging_mixin.py:115} INFO - [2023-01-07 01:11:01,770] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:11:01,771] {logging_mixin.py:115} INFO - [2023-01-07 01:11:01,771] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:11:01,782] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:11:01,814] {logging_mixin.py:115} INFO - [2023-01-07 01:11:01,814] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:11:01,839] {logging_mixin.py:115} INFO - [2023-01-07 01:11:01,839] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:11:01,850] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.067 seconds
[2023-01-07 01:11:32,872] {processor.py:153} INFO - Started process (PID=10083) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:11:32,874] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:11:32,874] {logging_mixin.py:115} INFO - [2023-01-07 01:11:32,874] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:11:33,654] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:11:33,656] {logging_mixin.py:115} INFO - [2023-01-07 01:11:33,655] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:11:33,656] {logging_mixin.py:115} INFO - [2023-01-07 01:11:33,656] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:11:33,663] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:11:33,685] {logging_mixin.py:115} INFO - [2023-01-07 01:11:33,685] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:11:33,705] {logging_mixin.py:115} INFO - [2023-01-07 01:11:33,705] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:11:33,715] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.847 seconds
[2023-01-07 01:12:03,812] {processor.py:153} INFO - Started process (PID=10108) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:12:03,813] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:12:03,814] {logging_mixin.py:115} INFO - [2023-01-07 01:12:03,814] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:12:04,606] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:12:04,607] {logging_mixin.py:115} INFO - [2023-01-07 01:12:04,607] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:12:04,608] {logging_mixin.py:115} INFO - [2023-01-07 01:12:04,608] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:12:04,614] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:12:04,637] {logging_mixin.py:115} INFO - [2023-01-07 01:12:04,637] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:12:04,657] {logging_mixin.py:115} INFO - [2023-01-07 01:12:04,657] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:12:04,666] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.859 seconds
[2023-01-07 01:12:34,762] {processor.py:153} INFO - Started process (PID=10132) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:12:34,763] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:12:34,764] {logging_mixin.py:115} INFO - [2023-01-07 01:12:34,764] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:12:35,576] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:12:35,578] {logging_mixin.py:115} INFO - [2023-01-07 01:12:35,578] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:12:35,578] {logging_mixin.py:115} INFO - [2023-01-07 01:12:35,578] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:12:35,585] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:12:35,607] {logging_mixin.py:115} INFO - [2023-01-07 01:12:35,607] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:12:35,627] {logging_mixin.py:115} INFO - [2023-01-07 01:12:35,627] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:12:35,636] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.878 seconds
[2023-01-07 01:13:05,730] {processor.py:153} INFO - Started process (PID=10150) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:13:05,732] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:13:05,732] {logging_mixin.py:115} INFO - [2023-01-07 01:13:05,732] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:13:06,516] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:13:06,517] {logging_mixin.py:115} INFO - [2023-01-07 01:13:06,517] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:13:06,518] {logging_mixin.py:115} INFO - [2023-01-07 01:13:06,517] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:13:06,524] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:13:06,548] {logging_mixin.py:115} INFO - [2023-01-07 01:13:06,548] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:13:06,571] {logging_mixin.py:115} INFO - [2023-01-07 01:13:06,571] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:13:06,580] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.854 seconds
[2023-01-07 01:13:36,681] {processor.py:153} INFO - Started process (PID=10175) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:13:36,682] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:13:36,683] {logging_mixin.py:115} INFO - [2023-01-07 01:13:36,683] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:13:37,454] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:13:37,455] {logging_mixin.py:115} INFO - [2023-01-07 01:13:37,455] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:13:37,456] {logging_mixin.py:115} INFO - [2023-01-07 01:13:37,455] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:13:37,462] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:13:37,484] {logging_mixin.py:115} INFO - [2023-01-07 01:13:37,484] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:13:37,503] {logging_mixin.py:115} INFO - [2023-01-07 01:13:37,503] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:13:37,512] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.836 seconds
[2023-01-07 01:14:07,607] {processor.py:153} INFO - Started process (PID=10200) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:14:07,608] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:14:07,608] {logging_mixin.py:115} INFO - [2023-01-07 01:14:07,608] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:14:08,385] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:14:08,386] {logging_mixin.py:115} INFO - [2023-01-07 01:14:08,386] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:14:08,387] {logging_mixin.py:115} INFO - [2023-01-07 01:14:08,387] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:14:08,394] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:14:08,416] {logging_mixin.py:115} INFO - [2023-01-07 01:14:08,416] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:14:08,436] {logging_mixin.py:115} INFO - [2023-01-07 01:14:08,436] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:14:08,445] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.844 seconds
[2023-01-07 01:14:38,516] {processor.py:153} INFO - Started process (PID=10227) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:14:38,517] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:14:38,518] {logging_mixin.py:115} INFO - [2023-01-07 01:14:38,518] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:14:39,292] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:14:39,293] {logging_mixin.py:115} INFO - [2023-01-07 01:14:39,293] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:14:39,294] {logging_mixin.py:115} INFO - [2023-01-07 01:14:39,293] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:14:39,300] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:14:39,323] {logging_mixin.py:115} INFO - [2023-01-07 01:14:39,323] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:14:39,343] {logging_mixin.py:115} INFO - [2023-01-07 01:14:39,343] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:14:39,353] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-07 01:15:10,039] {processor.py:153} INFO - Started process (PID=10245) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:15:10,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:15:10,041] {logging_mixin.py:115} INFO - [2023-01-07 01:15:10,041] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:15:10,825] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:15:10,826] {logging_mixin.py:115} INFO - [2023-01-07 01:15:10,826] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:15:10,827] {logging_mixin.py:115} INFO - [2023-01-07 01:15:10,826] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:15:10,833] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:15:10,856] {logging_mixin.py:115} INFO - [2023-01-07 01:15:10,855] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:15:10,875] {logging_mixin.py:115} INFO - [2023-01-07 01:15:10,875] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:15:10,885] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.850 seconds
[2023-01-07 01:15:40,990] {processor.py:153} INFO - Started process (PID=10269) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:15:40,991] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:15:40,992] {logging_mixin.py:115} INFO - [2023-01-07 01:15:40,992] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:15:41,805] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:15:41,806] {logging_mixin.py:115} INFO - [2023-01-07 01:15:41,806] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:15:41,807] {logging_mixin.py:115} INFO - [2023-01-07 01:15:41,806] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:15:41,813] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:15:41,836] {logging_mixin.py:115} INFO - [2023-01-07 01:15:41,836] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:15:41,856] {logging_mixin.py:115} INFO - [2023-01-07 01:15:41,855] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:15:41,865] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.880 seconds
[2023-01-07 01:16:11,965] {processor.py:153} INFO - Started process (PID=10293) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:16:11,965] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:16:11,966] {logging_mixin.py:115} INFO - [2023-01-07 01:16:11,966] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:16:12,740] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:16:12,741] {logging_mixin.py:115} INFO - [2023-01-07 01:16:12,741] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:16:12,742] {logging_mixin.py:115} INFO - [2023-01-07 01:16:12,742] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:16:12,749] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:16:12,772] {logging_mixin.py:115} INFO - [2023-01-07 01:16:12,771] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:16:12,792] {logging_mixin.py:115} INFO - [2023-01-07 01:16:12,792] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:16:12,801] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-07 01:16:42,891] {processor.py:153} INFO - Started process (PID=10319) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:16:42,893] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:16:42,893] {logging_mixin.py:115} INFO - [2023-01-07 01:16:42,893] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:16:43,669] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:16:43,671] {logging_mixin.py:115} INFO - [2023-01-07 01:16:43,671] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:16:43,671] {logging_mixin.py:115} INFO - [2023-01-07 01:16:43,671] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:16:43,678] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:16:43,699] {logging_mixin.py:115} INFO - [2023-01-07 01:16:43,699] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:16:43,719] {logging_mixin.py:115} INFO - [2023-01-07 01:16:43,719] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:16:43,728] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.842 seconds
[2023-01-07 01:17:13,826] {processor.py:153} INFO - Started process (PID=10337) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:17:13,826] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:17:13,827] {logging_mixin.py:115} INFO - [2023-01-07 01:17:13,827] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:17:14,645] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:17:14,647] {logging_mixin.py:115} INFO - [2023-01-07 01:17:14,647] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:17:14,647] {logging_mixin.py:115} INFO - [2023-01-07 01:17:14,647] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:17:14,654] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:17:14,677] {logging_mixin.py:115} INFO - [2023-01-07 01:17:14,676] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:17:14,696] {logging_mixin.py:115} INFO - [2023-01-07 01:17:14,696] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:17:14,706] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.886 seconds
[2023-01-07 01:17:44,798] {processor.py:153} INFO - Started process (PID=10362) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:17:44,799] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:17:44,800] {logging_mixin.py:115} INFO - [2023-01-07 01:17:44,800] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:17:45,593] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:17:45,594] {logging_mixin.py:115} INFO - [2023-01-07 01:17:45,594] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:17:45,594] {logging_mixin.py:115} INFO - [2023-01-07 01:17:45,594] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:17:45,601] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:17:45,623] {logging_mixin.py:115} INFO - [2023-01-07 01:17:45,623] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:17:45,643] {logging_mixin.py:115} INFO - [2023-01-07 01:17:45,643] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:17:45,652] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.859 seconds
[2023-01-07 01:18:16,132] {processor.py:153} INFO - Started process (PID=10388) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:18:16,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:18:16,133] {logging_mixin.py:115} INFO - [2023-01-07 01:18:16,133] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:18:16,894] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:18:16,896] {logging_mixin.py:115} INFO - [2023-01-07 01:18:16,896] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:18:16,896] {logging_mixin.py:115} INFO - [2023-01-07 01:18:16,896] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:18:16,903] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:18:16,925] {logging_mixin.py:115} INFO - [2023-01-07 01:18:16,925] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:18:16,945] {logging_mixin.py:115} INFO - [2023-01-07 01:18:16,945] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:18:16,954] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.827 seconds
[2023-01-07 01:18:47,242] {processor.py:153} INFO - Started process (PID=10413) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:18:47,242] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:18:47,243] {logging_mixin.py:115} INFO - [2023-01-07 01:18:47,243] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:18:48,030] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:18:48,031] {logging_mixin.py:115} INFO - [2023-01-07 01:18:48,031] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:18:48,032] {logging_mixin.py:115} INFO - [2023-01-07 01:18:48,031] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:18:48,038] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:18:48,065] {logging_mixin.py:115} INFO - [2023-01-07 01:18:48,065] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:18:48,085] {logging_mixin.py:115} INFO - [2023-01-07 01:18:48,085] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:18:48,094] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.856 seconds
[2023-01-07 01:19:18,209] {processor.py:153} INFO - Started process (PID=10436) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:19:18,212] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:19:18,213] {logging_mixin.py:115} INFO - [2023-01-07 01:19:18,213] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:19:19,026] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:19:19,027] {logging_mixin.py:115} INFO - [2023-01-07 01:19:19,027] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:19:19,028] {logging_mixin.py:115} INFO - [2023-01-07 01:19:19,027] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:19:19,034] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:19:19,057] {logging_mixin.py:115} INFO - [2023-01-07 01:19:19,056] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:19:19,079] {logging_mixin.py:115} INFO - [2023-01-07 01:19:19,079] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:19:19,089] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.885 seconds
[2023-01-07 01:19:49,184] {processor.py:153} INFO - Started process (PID=10456) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:19:49,185] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:19:49,186] {logging_mixin.py:115} INFO - [2023-01-07 01:19:49,186] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:19:50,013] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:19:50,014] {logging_mixin.py:115} INFO - [2023-01-07 01:19:50,014] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:19:50,015] {logging_mixin.py:115} INFO - [2023-01-07 01:19:50,014] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:19:50,021] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:19:50,044] {logging_mixin.py:115} INFO - [2023-01-07 01:19:50,043] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:19:50,064] {logging_mixin.py:115} INFO - [2023-01-07 01:19:50,064] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:19:50,074] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.894 seconds
[2023-01-07 01:20:20,170] {processor.py:153} INFO - Started process (PID=10482) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:20:20,171] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:20:20,171] {logging_mixin.py:115} INFO - [2023-01-07 01:20:20,171] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:20:21,001] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:20:21,003] {logging_mixin.py:115} INFO - [2023-01-07 01:20:21,003] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:20:21,003] {logging_mixin.py:115} INFO - [2023-01-07 01:20:21,003] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:20:21,010] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:20:21,037] {logging_mixin.py:115} INFO - [2023-01-07 01:20:21,037] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:20:21,065] {logging_mixin.py:115} INFO - [2023-01-07 01:20:21,065] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:20:21,077] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.911 seconds
[2023-01-07 01:20:51,270] {processor.py:153} INFO - Started process (PID=10507) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:20:51,271] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:20:51,271] {logging_mixin.py:115} INFO - [2023-01-07 01:20:51,271] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:20:52,032] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:20:52,033] {logging_mixin.py:115} INFO - [2023-01-07 01:20:52,033] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:20:52,033] {logging_mixin.py:115} INFO - [2023-01-07 01:20:52,033] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:20:52,040] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:20:52,068] {logging_mixin.py:115} INFO - [2023-01-07 01:20:52,067] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:20:52,087] {logging_mixin.py:115} INFO - [2023-01-07 01:20:52,087] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:20:52,099] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.833 seconds
[2023-01-07 01:21:22,194] {processor.py:153} INFO - Started process (PID=10532) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:21:22,195] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:21:22,196] {logging_mixin.py:115} INFO - [2023-01-07 01:21:22,196] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:21:22,992] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:21:22,993] {logging_mixin.py:115} INFO - [2023-01-07 01:21:22,993] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:21:22,994] {logging_mixin.py:115} INFO - [2023-01-07 01:21:22,994] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:21:23,005] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:21:23,028] {logging_mixin.py:115} INFO - [2023-01-07 01:21:23,028] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:21:23,048] {logging_mixin.py:115} INFO - [2023-01-07 01:21:23,048] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:21:23,059] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.870 seconds
[2023-01-07 01:21:53,151] {processor.py:153} INFO - Started process (PID=10549) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:21:53,152] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:21:53,153] {logging_mixin.py:115} INFO - [2023-01-07 01:21:53,153] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:21:54,129] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:21:54,131] {logging_mixin.py:115} INFO - [2023-01-07 01:21:54,131] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:21:54,131] {logging_mixin.py:115} INFO - [2023-01-07 01:21:54,131] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:21:54,138] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:21:54,161] {logging_mixin.py:115} INFO - [2023-01-07 01:21:54,161] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:21:54,181] {logging_mixin.py:115} INFO - [2023-01-07 01:21:54,181] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:21:54,191] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.044 seconds
[2023-01-07 01:22:24,254] {processor.py:153} INFO - Started process (PID=10575) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:22:24,256] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:22:24,257] {logging_mixin.py:115} INFO - [2023-01-07 01:22:24,257] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:22:25,022] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:22:25,023] {logging_mixin.py:115} INFO - [2023-01-07 01:22:25,023] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:22:25,024] {logging_mixin.py:115} INFO - [2023-01-07 01:22:25,024] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:22:25,030] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:22:25,053] {logging_mixin.py:115} INFO - [2023-01-07 01:22:25,052] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:22:25,072] {logging_mixin.py:115} INFO - [2023-01-07 01:22:25,072] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:22:25,081] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.832 seconds
[2023-01-07 01:22:55,320] {processor.py:153} INFO - Started process (PID=10600) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:22:55,322] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:22:55,323] {logging_mixin.py:115} INFO - [2023-01-07 01:22:55,323] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:22:56,085] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:22:56,086] {logging_mixin.py:115} INFO - [2023-01-07 01:22:56,086] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:22:56,087] {logging_mixin.py:115} INFO - [2023-01-07 01:22:56,086] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:22:56,093] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:22:56,115] {logging_mixin.py:115} INFO - [2023-01-07 01:22:56,115] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:22:56,135] {logging_mixin.py:115} INFO - [2023-01-07 01:22:56,135] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:22:56,145] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.829 seconds
[2023-01-07 01:23:26,242] {processor.py:153} INFO - Started process (PID=10625) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:23:26,243] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:23:26,244] {logging_mixin.py:115} INFO - [2023-01-07 01:23:26,243] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:23:27,059] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:23:27,061] {logging_mixin.py:115} INFO - [2023-01-07 01:23:27,061] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:23:27,062] {logging_mixin.py:115} INFO - [2023-01-07 01:23:27,061] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:23:27,073] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:23:27,095] {logging_mixin.py:115} INFO - [2023-01-07 01:23:27,095] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:23:27,115] {logging_mixin.py:115} INFO - [2023-01-07 01:23:27,115] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:23:27,124] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.887 seconds
[2023-01-07 01:23:57,219] {processor.py:153} INFO - Started process (PID=10643) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:23:57,219] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:23:57,220] {logging_mixin.py:115} INFO - [2023-01-07 01:23:57,220] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:23:58,035] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:23:58,036] {logging_mixin.py:115} INFO - [2023-01-07 01:23:58,036] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:23:58,037] {logging_mixin.py:115} INFO - [2023-01-07 01:23:58,037] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:23:58,048] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:23:58,072] {logging_mixin.py:115} INFO - [2023-01-07 01:23:58,072] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:23:58,094] {logging_mixin.py:115} INFO - [2023-01-07 01:23:58,094] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:23:58,104] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.890 seconds
[2023-01-07 01:24:28,200] {processor.py:153} INFO - Started process (PID=10669) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:24:28,201] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:24:28,201] {logging_mixin.py:115} INFO - [2023-01-07 01:24:28,201] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:24:28,984] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:24:28,985] {logging_mixin.py:115} INFO - [2023-01-07 01:24:28,985] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:24:28,986] {logging_mixin.py:115} INFO - [2023-01-07 01:24:28,986] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:24:28,992] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:24:29,015] {logging_mixin.py:115} INFO - [2023-01-07 01:24:29,014] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:24:29,034] {logging_mixin.py:115} INFO - [2023-01-07 01:24:29,034] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:24:29,045] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.850 seconds
[2023-01-07 01:24:59,137] {processor.py:153} INFO - Started process (PID=10695) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:24:59,138] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:24:59,139] {logging_mixin.py:115} INFO - [2023-01-07 01:24:59,139] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:24:59,925] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:24:59,927] {logging_mixin.py:115} INFO - [2023-01-07 01:24:59,927] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:24:59,927] {logging_mixin.py:115} INFO - [2023-01-07 01:24:59,927] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:24:59,934] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:24:59,956] {logging_mixin.py:115} INFO - [2023-01-07 01:24:59,956] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:24:59,976] {logging_mixin.py:115} INFO - [2023-01-07 01:24:59,976] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:24:59,985] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.853 seconds
[2023-01-07 01:25:30,077] {processor.py:153} INFO - Started process (PID=10720) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:25:30,078] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:25:30,079] {logging_mixin.py:115} INFO - [2023-01-07 01:25:30,079] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:25:30,840] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:25:30,841] {logging_mixin.py:115} INFO - [2023-01-07 01:25:30,841] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:25:30,841] {logging_mixin.py:115} INFO - [2023-01-07 01:25:30,841] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:25:30,848] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:25:30,872] {logging_mixin.py:115} INFO - [2023-01-07 01:25:30,872] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:25:30,892] {logging_mixin.py:115} INFO - [2023-01-07 01:25:30,892] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:25:30,902] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.829 seconds
[2023-01-07 01:26:01,448] {processor.py:153} INFO - Started process (PID=10738) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:26:01,449] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:26:01,450] {logging_mixin.py:115} INFO - [2023-01-07 01:26:01,450] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:26:02,271] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:26:02,273] {logging_mixin.py:115} INFO - [2023-01-07 01:26:02,273] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:26:02,273] {logging_mixin.py:115} INFO - [2023-01-07 01:26:02,273] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:26:02,280] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:26:02,302] {logging_mixin.py:115} INFO - [2023-01-07 01:26:02,301] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:26:02,321] {logging_mixin.py:115} INFO - [2023-01-07 01:26:02,321] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:26:02,330] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.889 seconds
[2023-01-07 01:26:32,420] {processor.py:153} INFO - Started process (PID=10764) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:26:32,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:26:32,421] {logging_mixin.py:115} INFO - [2023-01-07 01:26:32,421] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:26:33,200] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:26:33,201] {logging_mixin.py:115} INFO - [2023-01-07 01:26:33,201] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:26:33,202] {logging_mixin.py:115} INFO - [2023-01-07 01:26:33,201] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:26:33,208] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:26:33,231] {logging_mixin.py:115} INFO - [2023-01-07 01:26:33,230] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:26:33,252] {logging_mixin.py:115} INFO - [2023-01-07 01:26:33,252] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:26:33,261] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.845 seconds
[2023-01-07 01:27:03,354] {processor.py:153} INFO - Started process (PID=10789) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:27:03,356] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:27:03,356] {logging_mixin.py:115} INFO - [2023-01-07 01:27:03,356] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:27:04,128] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:27:04,129] {logging_mixin.py:115} INFO - [2023-01-07 01:27:04,129] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:27:04,130] {logging_mixin.py:115} INFO - [2023-01-07 01:27:04,129] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:27:04,137] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:27:04,165] {logging_mixin.py:115} INFO - [2023-01-07 01:27:04,165] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:27:04,189] {logging_mixin.py:115} INFO - [2023-01-07 01:27:04,189] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:27:04,202] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.852 seconds
[2023-01-07 01:27:34,549] {processor.py:153} INFO - Started process (PID=10813) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:27:34,550] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:27:34,550] {logging_mixin.py:115} INFO - [2023-01-07 01:27:34,550] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:27:35,319] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:27:35,320] {logging_mixin.py:115} INFO - [2023-01-07 01:27:35,320] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:27:35,320] {logging_mixin.py:115} INFO - [2023-01-07 01:27:35,320] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:27:35,327] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:27:35,350] {logging_mixin.py:115} INFO - [2023-01-07 01:27:35,350] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:27:35,369] {logging_mixin.py:115} INFO - [2023-01-07 01:27:35,369] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:27:35,378] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.834 seconds
[2023-01-07 01:28:05,471] {processor.py:153} INFO - Started process (PID=10831) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:28:05,473] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:28:05,473] {logging_mixin.py:115} INFO - [2023-01-07 01:28:05,473] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:28:06,326] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:28:06,327] {logging_mixin.py:115} INFO - [2023-01-07 01:28:06,327] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:28:06,328] {logging_mixin.py:115} INFO - [2023-01-07 01:28:06,327] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:28:06,334] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:28:06,364] {logging_mixin.py:115} INFO - [2023-01-07 01:28:06,363] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:28:06,392] {logging_mixin.py:115} INFO - [2023-01-07 01:28:06,391] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:28:06,404] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.937 seconds
[2023-01-07 01:28:36,506] {processor.py:153} INFO - Started process (PID=10855) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:28:36,506] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:28:36,507] {logging_mixin.py:115} INFO - [2023-01-07 01:28:36,507] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:28:37,260] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:28:37,261] {logging_mixin.py:115} INFO - [2023-01-07 01:28:37,261] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:28:37,261] {logging_mixin.py:115} INFO - [2023-01-07 01:28:37,261] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:28:37,268] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:28:37,290] {logging_mixin.py:115} INFO - [2023-01-07 01:28:37,289] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:28:37,309] {logging_mixin.py:115} INFO - [2023-01-07 01:28:37,309] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:28:37,318] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.817 seconds
[2023-01-07 01:29:07,685] {processor.py:153} INFO - Started process (PID=10880) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:29:07,687] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:29:07,688] {logging_mixin.py:115} INFO - [2023-01-07 01:29:07,688] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:29:08,455] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:29:08,457] {logging_mixin.py:115} INFO - [2023-01-07 01:29:08,457] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:29:08,457] {logging_mixin.py:115} INFO - [2023-01-07 01:29:08,457] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:29:08,464] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:29:08,486] {logging_mixin.py:115} INFO - [2023-01-07 01:29:08,486] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:29:08,506] {logging_mixin.py:115} INFO - [2023-01-07 01:29:08,506] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:29:08,515] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.835 seconds
[2023-01-07 01:29:39,047] {processor.py:153} INFO - Started process (PID=10905) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:29:39,049] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:29:39,050] {logging_mixin.py:115} INFO - [2023-01-07 01:29:39,049] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:29:39,870] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:29:39,871] {logging_mixin.py:115} INFO - [2023-01-07 01:29:39,871] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:29:39,872] {logging_mixin.py:115} INFO - [2023-01-07 01:29:39,871] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:29:39,878] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:29:39,908] {logging_mixin.py:115} INFO - [2023-01-07 01:29:39,908] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:29:39,933] {logging_mixin.py:115} INFO - [2023-01-07 01:29:39,932] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:29:39,942] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.899 seconds
[2023-01-07 01:30:10,032] {processor.py:153} INFO - Started process (PID=10923) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:30:10,033] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:30:10,033] {logging_mixin.py:115} INFO - [2023-01-07 01:30:10,033] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:30:10,817] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:30:10,818] {logging_mixin.py:115} INFO - [2023-01-07 01:30:10,818] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:30:10,819] {logging_mixin.py:115} INFO - [2023-01-07 01:30:10,819] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:30:10,826] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:30:10,848] {logging_mixin.py:115} INFO - [2023-01-07 01:30:10,848] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:30:10,868] {logging_mixin.py:115} INFO - [2023-01-07 01:30:10,868] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:30:10,878] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.850 seconds
[2023-01-07 01:30:40,975] {processor.py:153} INFO - Started process (PID=10948) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:30:40,976] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:30:40,977] {logging_mixin.py:115} INFO - [2023-01-07 01:30:40,977] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:30:41,750] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:30:41,751] {logging_mixin.py:115} INFO - [2023-01-07 01:30:41,751] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:30:41,752] {logging_mixin.py:115} INFO - [2023-01-07 01:30:41,751] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:30:41,758] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:30:41,780] {logging_mixin.py:115} INFO - [2023-01-07 01:30:41,780] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:30:41,800] {logging_mixin.py:115} INFO - [2023-01-07 01:30:41,800] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:30:41,809] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.838 seconds
[2023-01-07 01:31:11,919] {processor.py:153} INFO - Started process (PID=10973) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:31:11,919] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:31:11,920] {logging_mixin.py:115} INFO - [2023-01-07 01:31:11,920] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:31:12,761] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:31:12,762] {logging_mixin.py:115} INFO - [2023-01-07 01:31:12,762] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:31:12,763] {logging_mixin.py:115} INFO - [2023-01-07 01:31:12,763] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:31:12,774] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:31:12,796] {logging_mixin.py:115} INFO - [2023-01-07 01:31:12,796] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:31:12,815] {logging_mixin.py:115} INFO - [2023-01-07 01:31:12,815] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:31:12,825] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.911 seconds
[2023-01-07 01:31:42,918] {processor.py:153} INFO - Started process (PID=10999) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:31:42,919] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:31:42,920] {logging_mixin.py:115} INFO - [2023-01-07 01:31:42,920] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:31:43,678] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:31:43,679] {logging_mixin.py:115} INFO - [2023-01-07 01:31:43,679] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:31:43,680] {logging_mixin.py:115} INFO - [2023-01-07 01:31:43,680] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:31:43,687] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:31:43,708] {logging_mixin.py:115} INFO - [2023-01-07 01:31:43,708] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:31:43,728] {logging_mixin.py:115} INFO - [2023-01-07 01:31:43,728] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:31:43,737] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.824 seconds
[2023-01-07 01:32:13,830] {processor.py:153} INFO - Started process (PID=11017) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:32:13,831] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:32:13,832] {logging_mixin.py:115} INFO - [2023-01-07 01:32:13,831] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:32:14,631] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:32:14,632] {logging_mixin.py:115} INFO - [2023-01-07 01:32:14,632] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:32:14,633] {logging_mixin.py:115} INFO - [2023-01-07 01:32:14,632] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:32:14,639] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:32:14,661] {logging_mixin.py:115} INFO - [2023-01-07 01:32:14,661] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:32:14,680] {logging_mixin.py:115} INFO - [2023-01-07 01:32:14,680] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:32:14,689] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.864 seconds
[2023-01-07 01:32:44,786] {processor.py:153} INFO - Started process (PID=11042) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:32:44,788] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:32:44,788] {logging_mixin.py:115} INFO - [2023-01-07 01:32:44,788] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:32:45,636] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:32:45,637] {logging_mixin.py:115} INFO - [2023-01-07 01:32:45,637] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:32:45,638] {logging_mixin.py:115} INFO - [2023-01-07 01:32:45,638] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:32:45,649] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:32:45,680] {logging_mixin.py:115} INFO - [2023-01-07 01:32:45,680] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:32:45,709] {logging_mixin.py:115} INFO - [2023-01-07 01:32:45,708] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:32:45,721] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.939 seconds
[2023-01-07 01:33:15,822] {processor.py:153} INFO - Started process (PID=11066) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:33:15,823] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:33:15,823] {logging_mixin.py:115} INFO - [2023-01-07 01:33:15,823] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:33:16,597] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:33:16,598] {logging_mixin.py:115} INFO - [2023-01-07 01:33:16,598] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:33:16,599] {logging_mixin.py:115} INFO - [2023-01-07 01:33:16,599] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:33:16,606] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:33:16,628] {logging_mixin.py:115} INFO - [2023-01-07 01:33:16,627] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:33:16,647] {logging_mixin.py:115} INFO - [2023-01-07 01:33:16,647] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:33:16,656] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.839 seconds
[2023-01-07 01:33:47,128] {processor.py:153} INFO - Started process (PID=11091) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:33:47,128] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:33:47,129] {logging_mixin.py:115} INFO - [2023-01-07 01:33:47,129] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:33:47,893] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:33:47,894] {logging_mixin.py:115} INFO - [2023-01-07 01:33:47,894] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:33:47,895] {logging_mixin.py:115} INFO - [2023-01-07 01:33:47,894] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:33:47,901] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:33:47,924] {logging_mixin.py:115} INFO - [2023-01-07 01:33:47,924] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:33:47,943] {logging_mixin.py:115} INFO - [2023-01-07 01:33:47,943] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:33:47,952] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.830 seconds
[2023-01-07 01:34:18,046] {processor.py:153} INFO - Started process (PID=11116) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:34:18,047] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:34:18,048] {logging_mixin.py:115} INFO - [2023-01-07 01:34:18,048] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:34:18,954] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:34:18,956] {logging_mixin.py:115} INFO - [2023-01-07 01:34:18,956] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:34:18,957] {logging_mixin.py:115} INFO - [2023-01-07 01:34:18,957] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:34:18,969] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:34:19,007] {logging_mixin.py:115} INFO - [2023-01-07 01:34:19,006] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:34:19,038] {logging_mixin.py:115} INFO - [2023-01-07 01:34:19,038] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:34:19,053] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.013 seconds
[2023-01-07 01:34:49,091] {processor.py:153} INFO - Started process (PID=11133) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:34:49,092] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:34:49,092] {logging_mixin.py:115} INFO - [2023-01-07 01:34:49,092] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:34:49,943] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:34:49,945] {logging_mixin.py:115} INFO - [2023-01-07 01:34:49,945] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:34:49,945] {logging_mixin.py:115} INFO - [2023-01-07 01:34:49,945] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:34:49,952] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:34:49,974] {logging_mixin.py:115} INFO - [2023-01-07 01:34:49,974] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:34:49,994] {logging_mixin.py:115} INFO - [2023-01-07 01:34:49,994] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:34:50,003] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.917 seconds
[2023-01-07 01:35:20,095] {processor.py:153} INFO - Started process (PID=11157) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:35:20,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:35:20,097] {logging_mixin.py:115} INFO - [2023-01-07 01:35:20,097] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:35:20,874] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:35:20,875] {logging_mixin.py:115} INFO - [2023-01-07 01:35:20,875] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:35:20,876] {logging_mixin.py:115} INFO - [2023-01-07 01:35:20,875] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:35:20,882] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:35:20,905] {logging_mixin.py:115} INFO - [2023-01-07 01:35:20,904] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:35:20,924] {logging_mixin.py:115} INFO - [2023-01-07 01:35:20,924] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:35:20,934] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.843 seconds
[2023-01-07 01:35:51,041] {processor.py:153} INFO - Started process (PID=11182) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:35:51,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:35:51,043] {logging_mixin.py:115} INFO - [2023-01-07 01:35:51,043] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:35:51,882] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:35:51,883] {logging_mixin.py:115} INFO - [2023-01-07 01:35:51,883] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:35:51,884] {logging_mixin.py:115} INFO - [2023-01-07 01:35:51,884] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:35:51,895] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:35:51,919] {logging_mixin.py:115} INFO - [2023-01-07 01:35:51,919] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:35:51,939] {logging_mixin.py:115} INFO - [2023-01-07 01:35:51,939] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:35:51,948] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.913 seconds
[2023-01-07 01:36:22,042] {processor.py:153} INFO - Started process (PID=11208) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:36:22,043] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:36:22,044] {logging_mixin.py:115} INFO - [2023-01-07 01:36:22,044] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:36:22,832] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:36:22,833] {logging_mixin.py:115} INFO - [2023-01-07 01:36:22,833] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:36:22,834] {logging_mixin.py:115} INFO - [2023-01-07 01:36:22,834] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:36:22,842] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:36:22,864] {logging_mixin.py:115} INFO - [2023-01-07 01:36:22,864] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:36:22,885] {logging_mixin.py:115} INFO - [2023-01-07 01:36:22,885] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:36:22,894] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.856 seconds
[2023-01-07 01:36:52,984] {processor.py:153} INFO - Started process (PID=11226) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:36:52,985] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:36:52,986] {logging_mixin.py:115} INFO - [2023-01-07 01:36:52,986] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:36:53,786] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:36:53,788] {logging_mixin.py:115} INFO - [2023-01-07 01:36:53,787] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:36:53,788] {logging_mixin.py:115} INFO - [2023-01-07 01:36:53,788] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:36:53,795] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:36:53,821] {logging_mixin.py:115} INFO - [2023-01-07 01:36:53,820] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:36:53,840] {logging_mixin.py:115} INFO - [2023-01-07 01:36:53,840] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:36:53,850] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.870 seconds
[2023-01-07 01:37:23,941] {processor.py:153} INFO - Started process (PID=11250) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:37:23,942] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:37:23,943] {logging_mixin.py:115} INFO - [2023-01-07 01:37:23,943] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:37:24,719] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:37:24,721] {logging_mixin.py:115} INFO - [2023-01-07 01:37:24,721] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:37:24,721] {logging_mixin.py:115} INFO - [2023-01-07 01:37:24,721] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:37:24,728] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:37:24,750] {logging_mixin.py:115} INFO - [2023-01-07 01:37:24,749] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:37:24,769] {logging_mixin.py:115} INFO - [2023-01-07 01:37:24,769] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:37:24,778] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-07 01:37:54,867] {processor.py:153} INFO - Started process (PID=11275) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:37:54,868] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:37:54,869] {logging_mixin.py:115} INFO - [2023-01-07 01:37:54,869] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:37:55,633] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:37:55,635] {logging_mixin.py:115} INFO - [2023-01-07 01:37:55,634] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:37:55,635] {logging_mixin.py:115} INFO - [2023-01-07 01:37:55,635] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:37:55,642] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:37:55,664] {logging_mixin.py:115} INFO - [2023-01-07 01:37:55,664] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:37:55,683] {logging_mixin.py:115} INFO - [2023-01-07 01:37:55,683] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:37:55,692] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.830 seconds
[2023-01-07 01:38:26,305] {processor.py:153} INFO - Started process (PID=11300) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:38:26,307] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:38:26,308] {logging_mixin.py:115} INFO - [2023-01-07 01:38:26,308] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:38:27,067] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:38:27,068] {logging_mixin.py:115} INFO - [2023-01-07 01:38:27,068] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:38:27,069] {logging_mixin.py:115} INFO - [2023-01-07 01:38:27,068] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:38:27,075] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:38:27,097] {logging_mixin.py:115} INFO - [2023-01-07 01:38:27,097] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:38:27,116] {logging_mixin.py:115} INFO - [2023-01-07 01:38:27,116] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:38:27,126] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.825 seconds
[2023-01-07 01:38:57,213] {processor.py:153} INFO - Started process (PID=11317) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:38:57,214] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:38:57,215] {logging_mixin.py:115} INFO - [2023-01-07 01:38:57,215] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:38:58,247] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:38:58,249] {logging_mixin.py:115} INFO - [2023-01-07 01:38:58,249] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:38:58,249] {logging_mixin.py:115} INFO - [2023-01-07 01:38:58,249] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:38:58,256] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:38:58,278] {logging_mixin.py:115} INFO - [2023-01-07 01:38:58,278] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:38:58,298] {logging_mixin.py:115} INFO - [2023-01-07 01:38:58,298] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:38:58,307] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.099 seconds
[2023-01-07 01:39:28,383] {processor.py:153} INFO - Started process (PID=11343) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:39:28,385] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:39:28,386] {logging_mixin.py:115} INFO - [2023-01-07 01:39:28,386] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:39:29,149] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:39:29,150] {logging_mixin.py:115} INFO - [2023-01-07 01:39:29,150] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:39:29,150] {logging_mixin.py:115} INFO - [2023-01-07 01:39:29,150] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:39:29,157] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:39:29,179] {logging_mixin.py:115} INFO - [2023-01-07 01:39:29,179] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:39:29,198] {logging_mixin.py:115} INFO - [2023-01-07 01:39:29,198] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:39:29,207] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.828 seconds
[2023-01-07 01:39:59,284] {processor.py:153} INFO - Started process (PID=11367) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:39:59,285] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:39:59,286] {logging_mixin.py:115} INFO - [2023-01-07 01:39:59,286] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:40:00,045] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:40:00,047] {logging_mixin.py:115} INFO - [2023-01-07 01:40:00,046] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:40:00,047] {logging_mixin.py:115} INFO - [2023-01-07 01:40:00,047] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:40:00,054] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:40:00,076] {logging_mixin.py:115} INFO - [2023-01-07 01:40:00,075] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:40:00,095] {logging_mixin.py:115} INFO - [2023-01-07 01:40:00,095] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:40:00,104] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.825 seconds
[2023-01-07 01:40:30,389] {processor.py:153} INFO - Started process (PID=11393) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:40:30,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:40:30,392] {logging_mixin.py:115} INFO - [2023-01-07 01:40:30,392] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:40:31,182] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:40:31,183] {logging_mixin.py:115} INFO - [2023-01-07 01:40:31,183] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:40:31,184] {logging_mixin.py:115} INFO - [2023-01-07 01:40:31,184] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:40:31,190] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:40:31,220] {logging_mixin.py:115} INFO - [2023-01-07 01:40:31,219] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:40:31,248] {logging_mixin.py:115} INFO - [2023-01-07 01:40:31,248] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:40:31,261] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.876 seconds
[2023-01-07 01:41:01,375] {processor.py:153} INFO - Started process (PID=11411) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:41:01,375] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:41:01,376] {logging_mixin.py:115} INFO - [2023-01-07 01:41:01,376] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:41:02,148] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:41:02,150] {logging_mixin.py:115} INFO - [2023-01-07 01:41:02,150] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:41:02,150] {logging_mixin.py:115} INFO - [2023-01-07 01:41:02,150] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:41:02,157] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:41:02,179] {logging_mixin.py:115} INFO - [2023-01-07 01:41:02,178] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:41:02,200] {logging_mixin.py:115} INFO - [2023-01-07 01:41:02,200] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:41:02,210] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-07 01:41:32,308] {processor.py:153} INFO - Started process (PID=11436) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:41:32,310] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:41:32,310] {logging_mixin.py:115} INFO - [2023-01-07 01:41:32,310] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:41:33,077] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:41:33,078] {logging_mixin.py:115} INFO - [2023-01-07 01:41:33,078] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:41:33,079] {logging_mixin.py:115} INFO - [2023-01-07 01:41:33,079] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:41:33,086] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:41:33,107] {logging_mixin.py:115} INFO - [2023-01-07 01:41:33,107] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:41:33,126] {logging_mixin.py:115} INFO - [2023-01-07 01:41:33,126] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:41:33,135] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.831 seconds
[2023-01-07 01:42:03,226] {processor.py:153} INFO - Started process (PID=11462) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:42:03,227] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:42:03,228] {logging_mixin.py:115} INFO - [2023-01-07 01:42:03,227] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:42:04,011] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:42:04,012] {logging_mixin.py:115} INFO - [2023-01-07 01:42:04,012] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:42:04,013] {logging_mixin.py:115} INFO - [2023-01-07 01:42:04,013] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:42:04,019] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:42:04,041] {logging_mixin.py:115} INFO - [2023-01-07 01:42:04,041] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:42:04,076] {logging_mixin.py:115} INFO - [2023-01-07 01:42:04,076] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:42:04,090] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.869 seconds
[2023-01-07 01:42:34,193] {processor.py:153} INFO - Started process (PID=11487) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:42:34,194] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:42:34,194] {logging_mixin.py:115} INFO - [2023-01-07 01:42:34,194] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:42:34,977] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:42:34,978] {logging_mixin.py:115} INFO - [2023-01-07 01:42:34,978] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:42:34,979] {logging_mixin.py:115} INFO - [2023-01-07 01:42:34,978] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:42:34,985] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:42:35,007] {logging_mixin.py:115} INFO - [2023-01-07 01:42:35,007] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:42:35,026] {logging_mixin.py:115} INFO - [2023-01-07 01:42:35,026] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:42:35,036] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.848 seconds
[2023-01-07 01:43:05,125] {processor.py:153} INFO - Started process (PID=11505) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:43:05,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:43:05,126] {logging_mixin.py:115} INFO - [2023-01-07 01:43:05,126] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:43:05,918] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:43:05,919] {logging_mixin.py:115} INFO - [2023-01-07 01:43:05,919] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:43:05,920] {logging_mixin.py:115} INFO - [2023-01-07 01:43:05,920] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:43:05,926] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:43:05,949] {logging_mixin.py:115} INFO - [2023-01-07 01:43:05,948] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:43:05,968] {logging_mixin.py:115} INFO - [2023-01-07 01:43:05,968] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:43:05,977] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.857 seconds
[2023-01-07 01:43:36,065] {processor.py:153} INFO - Started process (PID=11530) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:43:36,068] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:43:36,069] {logging_mixin.py:115} INFO - [2023-01-07 01:43:36,069] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:43:36,896] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:43:36,897] {logging_mixin.py:115} INFO - [2023-01-07 01:43:36,897] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:43:36,897] {logging_mixin.py:115} INFO - [2023-01-07 01:43:36,897] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:43:36,904] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:43:36,926] {logging_mixin.py:115} INFO - [2023-01-07 01:43:36,926] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:43:36,945] {logging_mixin.py:115} INFO - [2023-01-07 01:43:36,945] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:43:36,954] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.893 seconds
[2023-01-07 01:44:07,044] {processor.py:153} INFO - Started process (PID=11555) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:44:07,044] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:44:07,045] {logging_mixin.py:115} INFO - [2023-01-07 01:44:07,045] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:44:07,823] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:44:07,824] {logging_mixin.py:115} INFO - [2023-01-07 01:44:07,824] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:44:07,825] {logging_mixin.py:115} INFO - [2023-01-07 01:44:07,824] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:44:07,831] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:44:07,853] {logging_mixin.py:115} INFO - [2023-01-07 01:44:07,853] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:44:07,872] {logging_mixin.py:115} INFO - [2023-01-07 01:44:07,872] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:44:07,881] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.842 seconds
[2023-01-07 01:44:38,463] {processor.py:153} INFO - Started process (PID=11579) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:44:38,464] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:44:38,465] {logging_mixin.py:115} INFO - [2023-01-07 01:44:38,464] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:44:39,229] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:44:39,231] {logging_mixin.py:115} INFO - [2023-01-07 01:44:39,231] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:44:39,231] {logging_mixin.py:115} INFO - [2023-01-07 01:44:39,231] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:44:39,238] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:44:39,259] {logging_mixin.py:115} INFO - [2023-01-07 01:44:39,259] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:44:39,278] {logging_mixin.py:115} INFO - [2023-01-07 01:44:39,278] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:44:39,287] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.829 seconds
[2023-01-07 01:45:09,388] {processor.py:153} INFO - Started process (PID=11597) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:45:09,389] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:45:09,390] {logging_mixin.py:115} INFO - [2023-01-07 01:45:09,390] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:45:10,196] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:45:10,198] {logging_mixin.py:115} INFO - [2023-01-07 01:45:10,198] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:45:10,198] {logging_mixin.py:115} INFO - [2023-01-07 01:45:10,198] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:45:10,205] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:45:10,227] {logging_mixin.py:115} INFO - [2023-01-07 01:45:10,227] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:45:10,247] {logging_mixin.py:115} INFO - [2023-01-07 01:45:10,247] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:45:10,256] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.872 seconds
[2023-01-07 01:45:40,347] {processor.py:153} INFO - Started process (PID=11622) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:45:40,348] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:45:40,349] {logging_mixin.py:115} INFO - [2023-01-07 01:45:40,348] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:45:41,131] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:45:41,133] {logging_mixin.py:115} INFO - [2023-01-07 01:45:41,133] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:45:41,133] {logging_mixin.py:115} INFO - [2023-01-07 01:45:41,133] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:45:41,140] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:45:41,163] {logging_mixin.py:115} INFO - [2023-01-07 01:45:41,163] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:45:41,183] {logging_mixin.py:115} INFO - [2023-01-07 01:45:41,183] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:45:41,192] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.850 seconds
[2023-01-07 01:46:11,283] {processor.py:153} INFO - Started process (PID=11647) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:46:11,284] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:46:11,284] {logging_mixin.py:115} INFO - [2023-01-07 01:46:11,284] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:46:12,040] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:46:12,041] {logging_mixin.py:115} INFO - [2023-01-07 01:46:12,041] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:46:12,042] {logging_mixin.py:115} INFO - [2023-01-07 01:46:12,041] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:46:12,048] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:46:12,070] {logging_mixin.py:115} INFO - [2023-01-07 01:46:12,070] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:46:12,090] {logging_mixin.py:115} INFO - [2023-01-07 01:46:12,090] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:46:12,102] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.823 seconds
[2023-01-07 01:46:42,521] {processor.py:153} INFO - Started process (PID=11671) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:46:42,523] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:46:42,523] {logging_mixin.py:115} INFO - [2023-01-07 01:46:42,523] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:46:43,309] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:46:43,311] {logging_mixin.py:115} INFO - [2023-01-07 01:46:43,311] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:46:43,311] {logging_mixin.py:115} INFO - [2023-01-07 01:46:43,311] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:46:43,318] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:46:43,340] {logging_mixin.py:115} INFO - [2023-01-07 01:46:43,340] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:46:43,360] {logging_mixin.py:115} INFO - [2023-01-07 01:46:43,360] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:46:43,369] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.853 seconds
[2023-01-07 01:47:13,459] {processor.py:153} INFO - Started process (PID=11690) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:47:13,460] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:47:13,461] {logging_mixin.py:115} INFO - [2023-01-07 01:47:13,461] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:47:14,429] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:47:14,431] {logging_mixin.py:115} INFO - [2023-01-07 01:47:14,431] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:47:14,431] {logging_mixin.py:115} INFO - [2023-01-07 01:47:14,431] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:47:14,442] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:47:14,473] {logging_mixin.py:115} INFO - [2023-01-07 01:47:14,472] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:47:14,501] {logging_mixin.py:115} INFO - [2023-01-07 01:47:14,501] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:47:14,513] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.059 seconds
[2023-01-07 01:47:44,579] {processor.py:153} INFO - Started process (PID=11715) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:47:44,579] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:47:44,580] {logging_mixin.py:115} INFO - [2023-01-07 01:47:44,580] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:47:45,399] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:47:45,401] {logging_mixin.py:115} INFO - [2023-01-07 01:47:45,401] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:47:45,401] {logging_mixin.py:115} INFO - [2023-01-07 01:47:45,401] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:47:45,408] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:47:45,430] {logging_mixin.py:115} INFO - [2023-01-07 01:47:45,430] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:47:45,450] {logging_mixin.py:115} INFO - [2023-01-07 01:47:45,450] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:47:45,459] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.885 seconds
[2023-01-07 01:48:15,505] {processor.py:153} INFO - Started process (PID=11741) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:48:15,506] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:48:15,506] {logging_mixin.py:115} INFO - [2023-01-07 01:48:15,506] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:48:16,348] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:48:16,349] {logging_mixin.py:115} INFO - [2023-01-07 01:48:16,349] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:48:16,350] {logging_mixin.py:115} INFO - [2023-01-07 01:48:16,349] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:48:16,356] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:48:16,379] {logging_mixin.py:115} INFO - [2023-01-07 01:48:16,379] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:48:16,399] {logging_mixin.py:115} INFO - [2023-01-07 01:48:16,399] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:48:16,408] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.908 seconds
[2023-01-07 01:48:46,447] {processor.py:153} INFO - Started process (PID=11766) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:48:46,448] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:48:46,448] {logging_mixin.py:115} INFO - [2023-01-07 01:48:46,448] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:48:47,206] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:48:47,207] {logging_mixin.py:115} INFO - [2023-01-07 01:48:47,207] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:48:47,207] {logging_mixin.py:115} INFO - [2023-01-07 01:48:47,207] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:48:47,214] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:48:47,235] {logging_mixin.py:115} INFO - [2023-01-07 01:48:47,235] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:48:47,255] {logging_mixin.py:115} INFO - [2023-01-07 01:48:47,255] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:48:47,264] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.822 seconds
[2023-01-07 01:49:17,364] {processor.py:153} INFO - Started process (PID=11790) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:49:17,365] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:49:17,366] {logging_mixin.py:115} INFO - [2023-01-07 01:49:17,366] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:49:18,150] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:49:18,151] {logging_mixin.py:115} INFO - [2023-01-07 01:49:18,151] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:49:18,151] {logging_mixin.py:115} INFO - [2023-01-07 01:49:18,151] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:49:18,158] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:49:18,187] {logging_mixin.py:115} INFO - [2023-01-07 01:49:18,187] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:49:18,215] {logging_mixin.py:115} INFO - [2023-01-07 01:49:18,215] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:49:18,227] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.868 seconds
[2023-01-07 01:49:48,320] {processor.py:153} INFO - Started process (PID=11809) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:49:48,321] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:49:48,322] {logging_mixin.py:115} INFO - [2023-01-07 01:49:48,321] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:49:49,148] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:49:49,149] {logging_mixin.py:115} INFO - [2023-01-07 01:49:49,149] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:49:49,150] {logging_mixin.py:115} INFO - [2023-01-07 01:49:49,149] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:49:49,156] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:49:49,179] {logging_mixin.py:115} INFO - [2023-01-07 01:49:49,179] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:49:49,199] {logging_mixin.py:115} INFO - [2023-01-07 01:49:49,199] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:49:49,209] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.894 seconds
[2023-01-07 01:50:19,304] {processor.py:153} INFO - Started process (PID=11835) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:50:19,305] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:50:19,305] {logging_mixin.py:115} INFO - [2023-01-07 01:50:19,305] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:50:20,066] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:50:20,068] {logging_mixin.py:115} INFO - [2023-01-07 01:50:20,068] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:50:20,069] {logging_mixin.py:115} INFO - [2023-01-07 01:50:20,069] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:50:20,076] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:50:20,097] {logging_mixin.py:115} INFO - [2023-01-07 01:50:20,097] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:50:20,122] {logging_mixin.py:115} INFO - [2023-01-07 01:50:20,122] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:50:20,131] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.832 seconds
[2023-01-07 01:50:50,226] {processor.py:153} INFO - Started process (PID=11860) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:50:50,227] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:50:50,227] {logging_mixin.py:115} INFO - [2023-01-07 01:50:50,227] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:50:51,021] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:50:51,022] {logging_mixin.py:115} INFO - [2023-01-07 01:50:51,022] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:50:51,023] {logging_mixin.py:115} INFO - [2023-01-07 01:50:51,022] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:50:51,029] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:50:51,051] {logging_mixin.py:115} INFO - [2023-01-07 01:50:51,051] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:50:51,070] {logging_mixin.py:115} INFO - [2023-01-07 01:50:51,070] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:50:51,079] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.858 seconds
[2023-01-07 01:51:21,167] {processor.py:153} INFO - Started process (PID=11885) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:51:21,168] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:51:21,169] {logging_mixin.py:115} INFO - [2023-01-07 01:51:21,169] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:51:22,189] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:51:22,190] {logging_mixin.py:115} INFO - [2023-01-07 01:51:22,190] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:51:22,191] {logging_mixin.py:115} INFO - [2023-01-07 01:51:22,191] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:51:22,202] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:51:22,234] {logging_mixin.py:115} INFO - [2023-01-07 01:51:22,234] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:51:22,262] {logging_mixin.py:115} INFO - [2023-01-07 01:51:22,262] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:51:22,274] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.111 seconds
[2023-01-07 01:51:52,347] {processor.py:153} INFO - Started process (PID=11903) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:51:52,348] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:51:52,348] {logging_mixin.py:115} INFO - [2023-01-07 01:51:52,348] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:51:53,159] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:51:53,160] {logging_mixin.py:115} INFO - [2023-01-07 01:51:53,160] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:51:53,161] {logging_mixin.py:115} INFO - [2023-01-07 01:51:53,161] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:51:53,167] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:51:53,190] {logging_mixin.py:115} INFO - [2023-01-07 01:51:53,189] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:51:53,209] {logging_mixin.py:115} INFO - [2023-01-07 01:51:53,209] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:51:53,218] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.877 seconds
[2023-01-07 01:52:23,282] {processor.py:153} INFO - Started process (PID=11928) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:52:23,283] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:52:23,284] {logging_mixin.py:115} INFO - [2023-01-07 01:52:23,284] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:52:24,045] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:52:24,046] {logging_mixin.py:115} INFO - [2023-01-07 01:52:24,046] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:52:24,047] {logging_mixin.py:115} INFO - [2023-01-07 01:52:24,047] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:52:24,053] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:52:24,075] {logging_mixin.py:115} INFO - [2023-01-07 01:52:24,075] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:52:24,094] {logging_mixin.py:115} INFO - [2023-01-07 01:52:24,094] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:52:24,105] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.827 seconds
[2023-01-07 01:52:54,174] {processor.py:153} INFO - Started process (PID=11954) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:52:54,175] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:52:54,175] {logging_mixin.py:115} INFO - [2023-01-07 01:52:54,175] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:52:54,939] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:52:54,940] {logging_mixin.py:115} INFO - [2023-01-07 01:52:54,940] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:52:54,941] {logging_mixin.py:115} INFO - [2023-01-07 01:52:54,940] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:52:54,947] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:52:54,969] {logging_mixin.py:115} INFO - [2023-01-07 01:52:54,969] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:52:54,989] {logging_mixin.py:115} INFO - [2023-01-07 01:52:54,989] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:52:54,998] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.829 seconds
[2023-01-07 01:53:25,385] {processor.py:153} INFO - Started process (PID=11981) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:53:25,386] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:53:25,387] {logging_mixin.py:115} INFO - [2023-01-07 01:53:25,387] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:53:26,192] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:53:26,193] {logging_mixin.py:115} INFO - [2023-01-07 01:53:26,193] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:53:26,194] {logging_mixin.py:115} INFO - [2023-01-07 01:53:26,194] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:53:26,200] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:53:26,223] {logging_mixin.py:115} INFO - [2023-01-07 01:53:26,222] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:53:26,242] {logging_mixin.py:115} INFO - [2023-01-07 01:53:26,242] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:53:26,251] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.870 seconds
[2023-01-07 01:53:56,446] {processor.py:153} INFO - Started process (PID=11999) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:53:56,446] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:53:56,447] {logging_mixin.py:115} INFO - [2023-01-07 01:53:56,447] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:53:57,239] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:53:57,240] {logging_mixin.py:115} INFO - [2023-01-07 01:53:57,240] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:53:57,241] {logging_mixin.py:115} INFO - [2023-01-07 01:53:57,240] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:53:57,247] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:53:57,270] {logging_mixin.py:115} INFO - [2023-01-07 01:53:57,269] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:53:57,289] {logging_mixin.py:115} INFO - [2023-01-07 01:53:57,289] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:53:57,298] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.856 seconds
[2023-01-07 01:54:27,386] {processor.py:153} INFO - Started process (PID=12026) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:54:27,387] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:54:27,388] {logging_mixin.py:115} INFO - [2023-01-07 01:54:27,388] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:54:28,199] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:54:28,200] {logging_mixin.py:115} INFO - [2023-01-07 01:54:28,200] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:54:28,200] {logging_mixin.py:115} INFO - [2023-01-07 01:54:28,200] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:54:28,207] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:54:28,232] {logging_mixin.py:115} INFO - [2023-01-07 01:54:28,232] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:54:28,252] {logging_mixin.py:115} INFO - [2023-01-07 01:54:28,252] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:54:28,261] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.880 seconds
[2023-01-07 01:54:58,356] {processor.py:153} INFO - Started process (PID=12051) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:54:58,359] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:54:58,359] {logging_mixin.py:115} INFO - [2023-01-07 01:54:58,359] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:54:59,111] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:54:59,112] {logging_mixin.py:115} INFO - [2023-01-07 01:54:59,112] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:54:59,113] {logging_mixin.py:115} INFO - [2023-01-07 01:54:59,113] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:54:59,119] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:54:59,141] {logging_mixin.py:115} INFO - [2023-01-07 01:54:59,141] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:54:59,160] {logging_mixin.py:115} INFO - [2023-01-07 01:54:59,160] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:54:59,169] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.817 seconds
[2023-01-07 01:55:29,270] {processor.py:153} INFO - Started process (PID=12075) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:55:29,271] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:55:29,272] {logging_mixin.py:115} INFO - [2023-01-07 01:55:29,272] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:55:30,033] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:55:30,035] {logging_mixin.py:115} INFO - [2023-01-07 01:55:30,034] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:55:30,035] {logging_mixin.py:115} INFO - [2023-01-07 01:55:30,035] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:55:30,042] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:55:30,063] {logging_mixin.py:115} INFO - [2023-01-07 01:55:30,063] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:55:30,082] {logging_mixin.py:115} INFO - [2023-01-07 01:55:30,082] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:55:30,092] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.827 seconds
[2023-01-07 01:56:00,194] {processor.py:153} INFO - Started process (PID=12092) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:56:00,196] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:56:00,197] {logging_mixin.py:115} INFO - [2023-01-07 01:56:00,196] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:56:01,053] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:56:01,055] {logging_mixin.py:115} INFO - [2023-01-07 01:56:01,054] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:56:01,055] {logging_mixin.py:115} INFO - [2023-01-07 01:56:01,055] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:56:01,062] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:56:01,084] {logging_mixin.py:115} INFO - [2023-01-07 01:56:01,084] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:56:01,104] {logging_mixin.py:115} INFO - [2023-01-07 01:56:01,104] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:56:01,113] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.924 seconds
[2023-01-07 01:56:31,207] {processor.py:153} INFO - Started process (PID=12117) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:56:31,208] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:56:31,208] {logging_mixin.py:115} INFO - [2023-01-07 01:56:31,208] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:56:31,975] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:56:31,976] {logging_mixin.py:115} INFO - [2023-01-07 01:56:31,976] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:56:31,977] {logging_mixin.py:115} INFO - [2023-01-07 01:56:31,977] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:56:31,984] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:56:32,005] {logging_mixin.py:115} INFO - [2023-01-07 01:56:32,005] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:56:32,025] {logging_mixin.py:115} INFO - [2023-01-07 01:56:32,025] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:56:32,034] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.831 seconds
[2023-01-07 01:57:02,125] {processor.py:153} INFO - Started process (PID=12142) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:57:02,126] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:57:02,127] {logging_mixin.py:115} INFO - [2023-01-07 01:57:02,127] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:57:02,892] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:57:02,893] {logging_mixin.py:115} INFO - [2023-01-07 01:57:02,893] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:57:02,893] {logging_mixin.py:115} INFO - [2023-01-07 01:57:02,893] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:57:02,900] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:57:02,922] {logging_mixin.py:115} INFO - [2023-01-07 01:57:02,922] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:57:02,942] {logging_mixin.py:115} INFO - [2023-01-07 01:57:02,941] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:57:02,951] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.830 seconds
[2023-01-07 01:57:33,034] {processor.py:153} INFO - Started process (PID=12167) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:57:33,035] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:57:33,035] {logging_mixin.py:115} INFO - [2023-01-07 01:57:33,035] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:57:33,806] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:57:33,807] {logging_mixin.py:115} INFO - [2023-01-07 01:57:33,807] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:57:33,808] {logging_mixin.py:115} INFO - [2023-01-07 01:57:33,807] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:57:33,814] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:57:33,843] {logging_mixin.py:115} INFO - [2023-01-07 01:57:33,843] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:57:33,863] {logging_mixin.py:115} INFO - [2023-01-07 01:57:33,863] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:57:33,873] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.843 seconds
[2023-01-07 01:58:03,944] {processor.py:153} INFO - Started process (PID=12185) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:58:03,945] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:58:03,946] {logging_mixin.py:115} INFO - [2023-01-07 01:58:03,945] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:58:04,744] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:58:04,745] {logging_mixin.py:115} INFO - [2023-01-07 01:58:04,745] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:58:04,746] {logging_mixin.py:115} INFO - [2023-01-07 01:58:04,745] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:58:04,753] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:58:04,775] {logging_mixin.py:115} INFO - [2023-01-07 01:58:04,775] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:58:04,794] {logging_mixin.py:115} INFO - [2023-01-07 01:58:04,794] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:58:04,803] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.864 seconds
[2023-01-07 01:58:34,871] {processor.py:153} INFO - Started process (PID=12208) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:58:34,872] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:58:34,873] {logging_mixin.py:115} INFO - [2023-01-07 01:58:34,873] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:58:35,653] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:58:35,654] {logging_mixin.py:115} INFO - [2023-01-07 01:58:35,654] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:58:35,655] {logging_mixin.py:115} INFO - [2023-01-07 01:58:35,655] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:58:35,661] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:58:35,684] {logging_mixin.py:115} INFO - [2023-01-07 01:58:35,684] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:58:35,703] {logging_mixin.py:115} INFO - [2023-01-07 01:58:35,703] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:58:35,712] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.846 seconds
[2023-01-07 01:59:05,778] {processor.py:153} INFO - Started process (PID=12233) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:59:05,779] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:59:05,780] {logging_mixin.py:115} INFO - [2023-01-07 01:59:05,780] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:59:06,616] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:59:06,617] {logging_mixin.py:115} INFO - [2023-01-07 01:59:06,617] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:59:06,618] {logging_mixin.py:115} INFO - [2023-01-07 01:59:06,617] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:59:06,625] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:59:06,655] {logging_mixin.py:115} INFO - [2023-01-07 01:59:06,655] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:59:06,688] {logging_mixin.py:115} INFO - [2023-01-07 01:59:06,688] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:59:06,700] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.927 seconds
[2023-01-07 01:59:36,773] {processor.py:153} INFO - Started process (PID=12257) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:59:36,775] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 01:59:36,775] {logging_mixin.py:115} INFO - [2023-01-07 01:59:36,775] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:59:37,555] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 01:59:37,556] {logging_mixin.py:115} INFO - [2023-01-07 01:59:37,556] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 01:59:37,557] {logging_mixin.py:115} INFO - [2023-01-07 01:59:37,557] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 01:59:37,563] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 01:59:37,587] {logging_mixin.py:115} INFO - [2023-01-07 01:59:37,586] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 01:59:37,606] {logging_mixin.py:115} INFO - [2023-01-07 01:59:37,606] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 01:59:37,615] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.846 seconds
[2023-01-07 02:00:07,680] {processor.py:153} INFO - Started process (PID=12275) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:00:07,680] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:00:07,681] {logging_mixin.py:115} INFO - [2023-01-07 02:00:07,681] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:00:08,464] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:00:08,465] {logging_mixin.py:115} INFO - [2023-01-07 02:00:08,465] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:00:08,466] {logging_mixin.py:115} INFO - [2023-01-07 02:00:08,466] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:00:08,473] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:00:08,494] {logging_mixin.py:115} INFO - [2023-01-07 02:00:08,494] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:00:08,514] {logging_mixin.py:115} INFO - [2023-01-07 02:00:08,514] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:00:08,523] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.848 seconds
[2023-01-07 02:00:38,610] {processor.py:153} INFO - Started process (PID=12298) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:00:38,611] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:00:38,611] {logging_mixin.py:115} INFO - [2023-01-07 02:00:38,611] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:00:39,411] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:00:39,412] {logging_mixin.py:115} INFO - [2023-01-07 02:00:39,412] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:00:39,413] {logging_mixin.py:115} INFO - [2023-01-07 02:00:39,412] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:00:39,419] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:00:39,441] {logging_mixin.py:115} INFO - [2023-01-07 02:00:39,441] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:00:39,460] {logging_mixin.py:115} INFO - [2023-01-07 02:00:39,460] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:00:39,470] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.865 seconds
[2023-01-07 02:01:09,588] {processor.py:153} INFO - Started process (PID=12324) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:01:09,588] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:01:09,589] {logging_mixin.py:115} INFO - [2023-01-07 02:01:09,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:01:10,341] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:01:10,343] {logging_mixin.py:115} INFO - [2023-01-07 02:01:10,343] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:01:10,343] {logging_mixin.py:115} INFO - [2023-01-07 02:01:10,343] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:01:10,350] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:01:10,372] {logging_mixin.py:115} INFO - [2023-01-07 02:01:10,371] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:01:10,392] {logging_mixin.py:115} INFO - [2023-01-07 02:01:10,392] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:01:10,401] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.818 seconds
[2023-01-07 02:01:40,495] {processor.py:153} INFO - Started process (PID=12349) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:01:40,498] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:01:40,499] {logging_mixin.py:115} INFO - [2023-01-07 02:01:40,499] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:01:41,270] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:01:41,272] {logging_mixin.py:115} INFO - [2023-01-07 02:01:41,272] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:01:41,272] {logging_mixin.py:115} INFO - [2023-01-07 02:01:41,272] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:01:41,279] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:01:41,301] {logging_mixin.py:115} INFO - [2023-01-07 02:01:41,301] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:01:41,320] {logging_mixin.py:115} INFO - [2023-01-07 02:01:41,320] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:01:41,330] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.839 seconds
[2023-01-07 02:02:11,677] {processor.py:153} INFO - Started process (PID=12368) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:02:11,678] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:02:11,679] {logging_mixin.py:115} INFO - [2023-01-07 02:02:11,679] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:02:12,501] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:02:12,502] {logging_mixin.py:115} INFO - [2023-01-07 02:02:12,502] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:02:12,502] {logging_mixin.py:115} INFO - [2023-01-07 02:02:12,502] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:02:12,509] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:02:12,531] {logging_mixin.py:115} INFO - [2023-01-07 02:02:12,531] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:02:12,552] {logging_mixin.py:115} INFO - [2023-01-07 02:02:12,552] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:02:12,561] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.890 seconds
[2023-01-07 02:02:42,661] {processor.py:153} INFO - Started process (PID=12393) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:02:42,662] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:02:42,663] {logging_mixin.py:115} INFO - [2023-01-07 02:02:42,663] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:02:43,422] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:02:43,423] {logging_mixin.py:115} INFO - [2023-01-07 02:02:43,423] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:02:43,424] {logging_mixin.py:115} INFO - [2023-01-07 02:02:43,424] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:02:43,430] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:02:43,452] {logging_mixin.py:115} INFO - [2023-01-07 02:02:43,452] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:02:43,472] {logging_mixin.py:115} INFO - [2023-01-07 02:02:43,472] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:02:43,481] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.824 seconds
[2023-01-07 02:03:13,572] {processor.py:153} INFO - Started process (PID=12418) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:03:13,573] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:03:13,574] {logging_mixin.py:115} INFO - [2023-01-07 02:03:13,574] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:03:14,341] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:03:14,342] {logging_mixin.py:115} INFO - [2023-01-07 02:03:14,342] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:03:14,343] {logging_mixin.py:115} INFO - [2023-01-07 02:03:14,343] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:03:14,349] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:03:14,372] {logging_mixin.py:115} INFO - [2023-01-07 02:03:14,371] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:03:14,392] {logging_mixin.py:115} INFO - [2023-01-07 02:03:14,392] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:03:14,401] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.833 seconds
[2023-01-07 02:03:44,767] {processor.py:153} INFO - Started process (PID=12443) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:03:44,768] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:03:44,769] {logging_mixin.py:115} INFO - [2023-01-07 02:03:44,769] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:03:45,539] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:03:45,540] {logging_mixin.py:115} INFO - [2023-01-07 02:03:45,540] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:03:45,541] {logging_mixin.py:115} INFO - [2023-01-07 02:03:45,540] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:03:45,547] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:03:45,569] {logging_mixin.py:115} INFO - [2023-01-07 02:03:45,569] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:03:45,588] {logging_mixin.py:115} INFO - [2023-01-07 02:03:45,588] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:03:45,598] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.836 seconds
[2023-01-07 02:04:15,833] {processor.py:153} INFO - Started process (PID=12460) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:04:15,833] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:04:15,834] {logging_mixin.py:115} INFO - [2023-01-07 02:04:15,834] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:04:16,644] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:04:16,646] {logging_mixin.py:115} INFO - [2023-01-07 02:04:16,646] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:04:16,646] {logging_mixin.py:115} INFO - [2023-01-07 02:04:16,646] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:04:16,653] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:04:16,675] {logging_mixin.py:115} INFO - [2023-01-07 02:04:16,675] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:04:16,695] {logging_mixin.py:115} INFO - [2023-01-07 02:04:16,695] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:04:16,705] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.877 seconds
[2023-01-07 02:04:46,806] {processor.py:153} INFO - Started process (PID=12485) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:04:46,807] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:04:46,808] {logging_mixin.py:115} INFO - [2023-01-07 02:04:46,808] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:04:47,577] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:04:47,578] {logging_mixin.py:115} INFO - [2023-01-07 02:04:47,578] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:04:47,578] {logging_mixin.py:115} INFO - [2023-01-07 02:04:47,578] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:04:47,585] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:04:47,611] {logging_mixin.py:115} INFO - [2023-01-07 02:04:47,611] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:04:47,632] {logging_mixin.py:115} INFO - [2023-01-07 02:04:47,631] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:04:47,642] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-07 02:05:17,735] {processor.py:153} INFO - Started process (PID=12510) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:05:17,737] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:05:17,737] {logging_mixin.py:115} INFO - [2023-01-07 02:05:17,737] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:05:18,506] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:05:18,507] {logging_mixin.py:115} INFO - [2023-01-07 02:05:18,507] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:05:18,508] {logging_mixin.py:115} INFO - [2023-01-07 02:05:18,507] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:05:18,514] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:05:18,543] {logging_mixin.py:115} INFO - [2023-01-07 02:05:18,543] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:05:18,566] {logging_mixin.py:115} INFO - [2023-01-07 02:05:18,566] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:05:18,576] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.845 seconds
[2023-01-07 02:05:48,681] {processor.py:153} INFO - Started process (PID=12535) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:05:48,682] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:05:48,682] {logging_mixin.py:115} INFO - [2023-01-07 02:05:48,682] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:05:49,442] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:05:49,443] {logging_mixin.py:115} INFO - [2023-01-07 02:05:49,443] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:05:49,444] {logging_mixin.py:115} INFO - [2023-01-07 02:05:49,443] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:05:49,450] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:05:49,472] {logging_mixin.py:115} INFO - [2023-01-07 02:05:49,472] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:05:49,491] {logging_mixin.py:115} INFO - [2023-01-07 02:05:49,491] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:05:49,500] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.824 seconds
[2023-01-07 02:06:19,590] {processor.py:153} INFO - Started process (PID=12560) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:06:19,591] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:06:19,592] {logging_mixin.py:115} INFO - [2023-01-07 02:06:19,592] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:06:20,386] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:06:20,388] {logging_mixin.py:115} INFO - [2023-01-07 02:06:20,388] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:06:20,389] {logging_mixin.py:115} INFO - [2023-01-07 02:06:20,388] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:06:20,399] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:06:20,432] {logging_mixin.py:115} INFO - [2023-01-07 02:06:20,432] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:06:20,456] {logging_mixin.py:115} INFO - [2023-01-07 02:06:20,456] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:06:20,467] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.882 seconds
[2023-01-07 02:06:50,905] {processor.py:153} INFO - Started process (PID=12579) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:06:50,906] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:06:50,908] {logging_mixin.py:115} INFO - [2023-01-07 02:06:50,908] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:06:51,826] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:06:51,828] {logging_mixin.py:115} INFO - [2023-01-07 02:06:51,828] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:06:51,829] {logging_mixin.py:115} INFO - [2023-01-07 02:06:51,828] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:06:51,840] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:06:51,869] {logging_mixin.py:115} INFO - [2023-01-07 02:06:51,869] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:06:51,899] {logging_mixin.py:115} INFO - [2023-01-07 02:06:51,899] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:06:51,911] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.010 seconds
[2023-01-07 02:07:21,981] {processor.py:153} INFO - Started process (PID=12604) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:07:21,982] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:07:21,984] {logging_mixin.py:115} INFO - [2023-01-07 02:07:21,984] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:07:22,762] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:07:22,764] {logging_mixin.py:115} INFO - [2023-01-07 02:07:22,764] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:07:22,764] {logging_mixin.py:115} INFO - [2023-01-07 02:07:22,764] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:07:22,771] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:07:22,798] {logging_mixin.py:115} INFO - [2023-01-07 02:07:22,798] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:07:22,820] {logging_mixin.py:115} INFO - [2023-01-07 02:07:22,820] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:07:22,829] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.853 seconds
[2023-01-07 02:07:52,929] {processor.py:153} INFO - Started process (PID=12629) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:07:52,931] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:07:52,933] {logging_mixin.py:115} INFO - [2023-01-07 02:07:52,933] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:07:53,722] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:07:53,723] {logging_mixin.py:115} INFO - [2023-01-07 02:07:53,723] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:07:53,723] {logging_mixin.py:115} INFO - [2023-01-07 02:07:53,723] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:07:53,730] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:07:53,751] {logging_mixin.py:115} INFO - [2023-01-07 02:07:53,751] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:07:53,770] {logging_mixin.py:115} INFO - [2023-01-07 02:07:53,770] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:07:53,779] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.854 seconds
[2023-01-07 02:08:23,872] {processor.py:153} INFO - Started process (PID=12653) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:08:23,874] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:08:23,876] {logging_mixin.py:115} INFO - [2023-01-07 02:08:23,876] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:08:24,665] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:08:24,666] {logging_mixin.py:115} INFO - [2023-01-07 02:08:24,666] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:08:24,667] {logging_mixin.py:115} INFO - [2023-01-07 02:08:24,666] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:08:24,673] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:08:24,695] {logging_mixin.py:115} INFO - [2023-01-07 02:08:24,695] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:08:24,720] {logging_mixin.py:115} INFO - [2023-01-07 02:08:24,719] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:08:24,731] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.864 seconds
[2023-01-07 02:08:54,825] {processor.py:153} INFO - Started process (PID=12671) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:08:54,825] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:08:54,827] {logging_mixin.py:115} INFO - [2023-01-07 02:08:54,827] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:08:55,600] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:08:55,601] {logging_mixin.py:115} INFO - [2023-01-07 02:08:55,601] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:08:55,602] {logging_mixin.py:115} INFO - [2023-01-07 02:08:55,601] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:08:55,608] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:08:55,632] {logging_mixin.py:115} INFO - [2023-01-07 02:08:55,631] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:08:55,651] {logging_mixin.py:115} INFO - [2023-01-07 02:08:55,651] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:08:55,660] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.840 seconds
[2023-01-07 02:09:25,752] {processor.py:153} INFO - Started process (PID=12696) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:09:25,753] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:09:25,755] {logging_mixin.py:115} INFO - [2023-01-07 02:09:25,755] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:09:26,516] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:09:26,517] {logging_mixin.py:115} INFO - [2023-01-07 02:09:26,517] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:09:26,517] {logging_mixin.py:115} INFO - [2023-01-07 02:09:26,517] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:09:26,524] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:09:26,546] {logging_mixin.py:115} INFO - [2023-01-07 02:09:26,546] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:09:26,566] {logging_mixin.py:115} INFO - [2023-01-07 02:09:26,566] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:09:26,575] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.828 seconds
[2023-01-07 02:09:56,674] {processor.py:153} INFO - Started process (PID=12721) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:09:56,674] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:09:56,676] {logging_mixin.py:115} INFO - [2023-01-07 02:09:56,676] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:09:57,457] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:09:57,458] {logging_mixin.py:115} INFO - [2023-01-07 02:09:57,458] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:09:57,459] {logging_mixin.py:115} INFO - [2023-01-07 02:09:57,458] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:09:57,465] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:09:57,488] {logging_mixin.py:115} INFO - [2023-01-07 02:09:57,488] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:09:57,508] {logging_mixin.py:115} INFO - [2023-01-07 02:09:57,508] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:09:57,517] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.848 seconds
[2023-01-07 02:10:27,615] {processor.py:153} INFO - Started process (PID=12747) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:10:27,617] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:10:27,619] {logging_mixin.py:115} INFO - [2023-01-07 02:10:27,618] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:10:28,367] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:10:28,369] {logging_mixin.py:115} INFO - [2023-01-07 02:10:28,368] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:10:28,369] {logging_mixin.py:115} INFO - [2023-01-07 02:10:28,369] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:10:28,378] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:10:28,401] {logging_mixin.py:115} INFO - [2023-01-07 02:10:28,401] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:10:28,420] {logging_mixin.py:115} INFO - [2023-01-07 02:10:28,420] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:10:28,430] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.819 seconds
[2023-01-07 02:10:58,500] {processor.py:153} INFO - Started process (PID=12765) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:10:58,501] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:10:58,501] {logging_mixin.py:115} INFO - [2023-01-07 02:10:58,501] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:10:59,270] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:10:59,271] {logging_mixin.py:115} INFO - [2023-01-07 02:10:59,271] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:10:59,271] {logging_mixin.py:115} INFO - [2023-01-07 02:10:59,271] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:10:59,278] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:10:59,302] {logging_mixin.py:115} INFO - [2023-01-07 02:10:59,302] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:10:59,322] {logging_mixin.py:115} INFO - [2023-01-07 02:10:59,322] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:10:59,331] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.836 seconds
[2023-01-07 02:11:29,406] {processor.py:153} INFO - Started process (PID=12790) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:11:29,407] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:11:29,408] {logging_mixin.py:115} INFO - [2023-01-07 02:11:29,408] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:11:30,224] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:11:30,225] {logging_mixin.py:115} INFO - [2023-01-07 02:11:30,225] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:11:30,226] {logging_mixin.py:115} INFO - [2023-01-07 02:11:30,226] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:11:30,232] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:11:30,255] {logging_mixin.py:115} INFO - [2023-01-07 02:11:30,255] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:11:30,276] {logging_mixin.py:115} INFO - [2023-01-07 02:11:30,275] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:11:30,285] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.883 seconds
[2023-01-07 02:12:00,354] {processor.py:153} INFO - Started process (PID=12815) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:12:00,355] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:12:00,356] {logging_mixin.py:115} INFO - [2023-01-07 02:12:00,356] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:12:01,124] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:12:01,126] {logging_mixin.py:115} INFO - [2023-01-07 02:12:01,126] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:12:01,126] {logging_mixin.py:115} INFO - [2023-01-07 02:12:01,126] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:12:01,133] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:12:01,153] {logging_mixin.py:115} INFO - [2023-01-07 02:12:01,153] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:12:01,172] {logging_mixin.py:115} INFO - [2023-01-07 02:12:01,172] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:12:01,181] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.832 seconds
[2023-01-07 02:12:31,248] {processor.py:153} INFO - Started process (PID=12840) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:12:31,248] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:12:31,249] {logging_mixin.py:115} INFO - [2023-01-07 02:12:31,249] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:12:32,005] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:12:32,006] {logging_mixin.py:115} INFO - [2023-01-07 02:12:32,006] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:12:32,007] {logging_mixin.py:115} INFO - [2023-01-07 02:12:32,007] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:12:32,013] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:12:32,035] {logging_mixin.py:115} INFO - [2023-01-07 02:12:32,035] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:12:32,054] {logging_mixin.py:115} INFO - [2023-01-07 02:12:32,054] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:12:32,063] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.820 seconds
[2023-01-07 02:13:02,128] {processor.py:153} INFO - Started process (PID=12858) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:13:02,129] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:13:02,130] {logging_mixin.py:115} INFO - [2023-01-07 02:13:02,130] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:13:02,993] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:13:02,994] {logging_mixin.py:115} INFO - [2023-01-07 02:13:02,994] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:13:02,995] {logging_mixin.py:115} INFO - [2023-01-07 02:13:02,995] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:13:03,006] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:13:03,035] {logging_mixin.py:115} INFO - [2023-01-07 02:13:03,035] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:13:03,064] {logging_mixin.py:115} INFO - [2023-01-07 02:13:03,063] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:13:03,075] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.952 seconds
[2023-01-07 02:13:33,147] {processor.py:153} INFO - Started process (PID=12883) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:13:33,148] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:13:33,148] {logging_mixin.py:115} INFO - [2023-01-07 02:13:33,148] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:13:33,918] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:13:33,919] {logging_mixin.py:115} INFO - [2023-01-07 02:13:33,919] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:13:33,920] {logging_mixin.py:115} INFO - [2023-01-07 02:13:33,920] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:13:33,926] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:13:33,948] {logging_mixin.py:115} INFO - [2023-01-07 02:13:33,948] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:13:33,967] {logging_mixin.py:115} INFO - [2023-01-07 02:13:33,967] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:13:33,977] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.835 seconds
[2023-01-07 02:14:04,070] {processor.py:153} INFO - Started process (PID=12907) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:14:04,071] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:14:04,072] {logging_mixin.py:115} INFO - [2023-01-07 02:14:04,072] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:14:04,841] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:14:04,842] {logging_mixin.py:115} INFO - [2023-01-07 02:14:04,842] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:14:04,843] {logging_mixin.py:115} INFO - [2023-01-07 02:14:04,842] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:14:04,849] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:14:04,870] {logging_mixin.py:115} INFO - [2023-01-07 02:14:04,869] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:14:04,889] {logging_mixin.py:115} INFO - [2023-01-07 02:14:04,889] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:14:04,898] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.833 seconds
[2023-01-07 02:14:34,992] {processor.py:153} INFO - Started process (PID=12932) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:14:34,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:14:34,994] {logging_mixin.py:115} INFO - [2023-01-07 02:14:34,994] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:14:35,797] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:14:35,798] {logging_mixin.py:115} INFO - [2023-01-07 02:14:35,798] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:14:35,799] {logging_mixin.py:115} INFO - [2023-01-07 02:14:35,799] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:14:35,806] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:14:35,826] {logging_mixin.py:115} INFO - [2023-01-07 02:14:35,826] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:14:35,846] {logging_mixin.py:115} INFO - [2023-01-07 02:14:35,846] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:14:35,855] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.869 seconds
[2023-01-07 02:15:05,954] {processor.py:153} INFO - Started process (PID=12951) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:15:05,955] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:15:05,955] {logging_mixin.py:115} INFO - [2023-01-07 02:15:05,955] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:15:06,734] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:15:06,735] {logging_mixin.py:115} INFO - [2023-01-07 02:15:06,735] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:15:06,736] {logging_mixin.py:115} INFO - [2023-01-07 02:15:06,736] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:15:06,742] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:15:06,770] {logging_mixin.py:115} INFO - [2023-01-07 02:15:06,770] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:15:06,798] {logging_mixin.py:115} INFO - [2023-01-07 02:15:06,798] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:15:06,808] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.858 seconds
[2023-01-07 02:15:36,899] {processor.py:153} INFO - Started process (PID=12977) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:15:36,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:15:36,901] {logging_mixin.py:115} INFO - [2023-01-07 02:15:36,901] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:15:37,674] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:15:37,675] {logging_mixin.py:115} INFO - [2023-01-07 02:15:37,675] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:15:37,675] {logging_mixin.py:115} INFO - [2023-01-07 02:15:37,675] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:15:37,682] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:15:37,703] {logging_mixin.py:115} INFO - [2023-01-07 02:15:37,703] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:15:37,722] {logging_mixin.py:115} INFO - [2023-01-07 02:15:37,722] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:15:37,731] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.837 seconds
[2023-01-07 02:16:07,818] {processor.py:153} INFO - Started process (PID=13003) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:16:07,819] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:16:07,819] {logging_mixin.py:115} INFO - [2023-01-07 02:16:07,819] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:16:08,673] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:16:08,674] {logging_mixin.py:115} INFO - [2023-01-07 02:16:08,674] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:16:08,675] {logging_mixin.py:115} INFO - [2023-01-07 02:16:08,674] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:16:08,681] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:16:08,703] {logging_mixin.py:115} INFO - [2023-01-07 02:16:08,702] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:16:08,724] {logging_mixin.py:115} INFO - [2023-01-07 02:16:08,724] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:16:08,736] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.922 seconds
[2023-01-07 02:16:38,829] {processor.py:153} INFO - Started process (PID=13029) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:16:38,830] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:16:38,831] {logging_mixin.py:115} INFO - [2023-01-07 02:16:38,831] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:16:39,602] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:16:39,603] {logging_mixin.py:115} INFO - [2023-01-07 02:16:39,603] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:16:39,604] {logging_mixin.py:115} INFO - [2023-01-07 02:16:39,603] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:16:39,611] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:16:39,634] {logging_mixin.py:115} INFO - [2023-01-07 02:16:39,633] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:16:39,659] {logging_mixin.py:115} INFO - [2023-01-07 02:16:39,659] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:16:39,670] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.846 seconds
[2023-01-07 02:17:09,749] {processor.py:153} INFO - Started process (PID=13047) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:17:09,750] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:17:09,751] {logging_mixin.py:115} INFO - [2023-01-07 02:17:09,751] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:17:10,625] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:17:10,627] {logging_mixin.py:115} INFO - [2023-01-07 02:17:10,626] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:17:10,627] {logging_mixin.py:115} INFO - [2023-01-07 02:17:10,627] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:17:10,634] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:17:10,655] {logging_mixin.py:115} INFO - [2023-01-07 02:17:10,655] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:17:10,675] {logging_mixin.py:115} INFO - [2023-01-07 02:17:10,675] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:17:10,684] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.940 seconds
[2023-01-07 02:17:41,187] {processor.py:153} INFO - Started process (PID=13070) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:17:41,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:17:41,188] {logging_mixin.py:115} INFO - [2023-01-07 02:17:41,188] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:17:41,995] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:17:41,996] {logging_mixin.py:115} INFO - [2023-01-07 02:17:41,996] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:17:41,996] {logging_mixin.py:115} INFO - [2023-01-07 02:17:41,996] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:17:42,003] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:17:42,024] {logging_mixin.py:115} INFO - [2023-01-07 02:17:42,024] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:17:42,044] {logging_mixin.py:115} INFO - [2023-01-07 02:17:42,044] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:17:42,054] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.872 seconds
[2023-01-07 02:18:12,147] {processor.py:153} INFO - Started process (PID=13095) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:18:12,148] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:18:12,148] {logging_mixin.py:115} INFO - [2023-01-07 02:18:12,148] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:18:12,926] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:18:12,927] {logging_mixin.py:115} INFO - [2023-01-07 02:18:12,927] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:18:12,928] {logging_mixin.py:115} INFO - [2023-01-07 02:18:12,928] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:18:12,934] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:18:12,956] {logging_mixin.py:115} INFO - [2023-01-07 02:18:12,955] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:18:12,975] {logging_mixin.py:115} INFO - [2023-01-07 02:18:12,975] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:18:12,984] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.842 seconds
[2023-01-07 02:18:43,079] {processor.py:153} INFO - Started process (PID=13119) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:18:43,080] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 02:18:43,080] {logging_mixin.py:115} INFO - [2023-01-07 02:18:43,080] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:18:43,843] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 02:18:43,845] {logging_mixin.py:115} INFO - [2023-01-07 02:18:43,845] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 02:18:43,845] {logging_mixin.py:115} INFO - [2023-01-07 02:18:43,845] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 02:18:43,852] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 02:18:43,873] {logging_mixin.py:115} INFO - [2023-01-07 02:18:43,872] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 02:18:43,892] {logging_mixin.py:115} INFO - [2023-01-07 02:18:43,892] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 02:18:43,901] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.827 seconds
[2023-01-07 21:09:06,615] {processor.py:153} INFO - Started process (PID=34) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:09:06,619] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:09:06,620] {logging_mixin.py:115} INFO - [2023-01-07 21:09:06,619] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:09:10,420] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:09:10,422] {logging_mixin.py:115} INFO - [2023-01-07 21:09:10,422] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:09:10,423] {logging_mixin.py:115} INFO - [2023-01-07 21:09:10,422] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:09:10,436] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:09:10,471] {logging_mixin.py:115} INFO - [2023-01-07 21:09:10,471] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:09:10,503] {logging_mixin.py:115} INFO - [2023-01-07 21:09:10,503] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:09:10,543] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 3.933 seconds
[2023-01-07 21:09:40,632] {processor.py:153} INFO - Started process (PID=61) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:09:40,636] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:09:40,637] {logging_mixin.py:115} INFO - [2023-01-07 21:09:40,637] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:09:41,673] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:09:41,674] {logging_mixin.py:115} INFO - [2023-01-07 21:09:41,674] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:09:41,675] {logging_mixin.py:115} INFO - [2023-01-07 21:09:41,674] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:09:41,682] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:09:41,703] {logging_mixin.py:115} INFO - [2023-01-07 21:09:41,702] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:09:41,725] {logging_mixin.py:115} INFO - [2023-01-07 21:09:41,725] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:09:41,734] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.107 seconds
[2023-01-07 21:10:11,812] {processor.py:153} INFO - Started process (PID=85) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:10:11,812] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:10:11,813] {logging_mixin.py:115} INFO - [2023-01-07 21:10:11,813] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:10:12,637] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:10:12,639] {logging_mixin.py:115} INFO - [2023-01-07 21:10:12,639] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:10:12,639] {logging_mixin.py:115} INFO - [2023-01-07 21:10:12,639] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:10:12,646] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:10:12,674] {logging_mixin.py:115} INFO - [2023-01-07 21:10:12,674] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:10:12,703] {logging_mixin.py:115} INFO - [2023-01-07 21:10:12,703] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:10:12,712] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.904 seconds
[2023-01-07 21:10:42,886] {processor.py:153} INFO - Started process (PID=103) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:10:42,888] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:10:42,889] {logging_mixin.py:115} INFO - [2023-01-07 21:10:42,889] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:10:43,711] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:10:43,713] {logging_mixin.py:115} INFO - [2023-01-07 21:10:43,713] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:10:43,713] {logging_mixin.py:115} INFO - [2023-01-07 21:10:43,713] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:10:43,720] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:10:43,742] {logging_mixin.py:115} INFO - [2023-01-07 21:10:43,742] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:10:43,763] {logging_mixin.py:115} INFO - [2023-01-07 21:10:43,763] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:10:43,773] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.890 seconds
[2023-01-07 21:11:13,964] {processor.py:153} INFO - Started process (PID=128) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:11:13,965] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:11:13,965] {logging_mixin.py:115} INFO - [2023-01-07 21:11:13,965] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:11:14,878] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:11:14,879] {logging_mixin.py:115} INFO - [2023-01-07 21:11:14,879] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:11:14,880] {logging_mixin.py:115} INFO - [2023-01-07 21:11:14,879] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:11:14,886] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:11:14,908] {logging_mixin.py:115} INFO - [2023-01-07 21:11:14,908] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:11:14,928] {logging_mixin.py:115} INFO - [2023-01-07 21:11:14,928] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:11:14,937] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.978 seconds
[2023-01-07 21:11:45,255] {processor.py:153} INFO - Started process (PID=153) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:11:45,259] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:11:45,260] {logging_mixin.py:115} INFO - [2023-01-07 21:11:45,260] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:11:46,070] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:11:46,072] {logging_mixin.py:115} INFO - [2023-01-07 21:11:46,071] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:11:46,072] {logging_mixin.py:115} INFO - [2023-01-07 21:11:46,072] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:11:46,079] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:11:46,101] {logging_mixin.py:115} INFO - [2023-01-07 21:11:46,101] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:11:46,125] {logging_mixin.py:115} INFO - [2023-01-07 21:11:46,125] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:11:46,136] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.886 seconds
[2023-01-07 21:12:16,235] {processor.py:153} INFO - Started process (PID=179) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:12:16,239] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:12:16,239] {logging_mixin.py:115} INFO - [2023-01-07 21:12:16,239] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:12:17,037] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:12:17,038] {logging_mixin.py:115} INFO - [2023-01-07 21:12:17,038] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:12:17,039] {logging_mixin.py:115} INFO - [2023-01-07 21:12:17,038] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:12:17,045] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:12:17,067] {logging_mixin.py:115} INFO - [2023-01-07 21:12:17,067] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:12:17,087] {logging_mixin.py:115} INFO - [2023-01-07 21:12:17,087] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:12:17,097] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.867 seconds
[2023-01-07 21:12:47,198] {processor.py:153} INFO - Started process (PID=198) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:12:47,199] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:12:47,199] {logging_mixin.py:115} INFO - [2023-01-07 21:12:47,199] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:12:48,126] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:12:48,128] {logging_mixin.py:115} INFO - [2023-01-07 21:12:48,128] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:12:48,129] {logging_mixin.py:115} INFO - [2023-01-07 21:12:48,128] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:12:48,142] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:12:48,175] {logging_mixin.py:115} INFO - [2023-01-07 21:12:48,174] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:12:48,213] {logging_mixin.py:115} INFO - [2023-01-07 21:12:48,213] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:12:48,233] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.040 seconds
[2023-01-07 21:13:18,351] {processor.py:153} INFO - Started process (PID=222) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:13:18,352] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:13:18,353] {logging_mixin.py:115} INFO - [2023-01-07 21:13:18,353] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:13:19,169] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:13:19,171] {logging_mixin.py:115} INFO - [2023-01-07 21:13:19,171] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:13:19,171] {logging_mixin.py:115} INFO - [2023-01-07 21:13:19,171] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:13:19,178] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:13:19,206] {logging_mixin.py:115} INFO - [2023-01-07 21:13:19,205] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:13:19,233] {logging_mixin.py:115} INFO - [2023-01-07 21:13:19,233] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:13:19,245] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.899 seconds
[2023-01-07 21:13:49,780] {processor.py:153} INFO - Started process (PID=248) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:13:49,781] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:13:49,782] {logging_mixin.py:115} INFO - [2023-01-07 21:13:49,782] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:13:50,580] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:13:50,582] {logging_mixin.py:115} INFO - [2023-01-07 21:13:50,582] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:13:50,582] {logging_mixin.py:115} INFO - [2023-01-07 21:13:50,582] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:13:50,589] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:13:50,611] {logging_mixin.py:115} INFO - [2023-01-07 21:13:50,611] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:13:50,631] {logging_mixin.py:115} INFO - [2023-01-07 21:13:50,631] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:13:50,641] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.865 seconds
[2023-01-07 21:14:20,749] {processor.py:153} INFO - Started process (PID=272) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:14:20,749] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:14:20,750] {logging_mixin.py:115} INFO - [2023-01-07 21:14:20,750] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:14:21,868] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:14:21,870] {logging_mixin.py:115} INFO - [2023-01-07 21:14:21,870] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:14:21,870] {logging_mixin.py:115} INFO - [2023-01-07 21:14:21,870] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:14:21,877] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:14:21,905] {logging_mixin.py:115} INFO - [2023-01-07 21:14:21,905] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:14:21,934] {logging_mixin.py:115} INFO - [2023-01-07 21:14:21,934] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:14:21,946] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.202 seconds
[2023-01-07 21:14:52,045] {processor.py:153} INFO - Started process (PID=290) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:14:52,046] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:14:52,046] {logging_mixin.py:115} INFO - [2023-01-07 21:14:52,046] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:14:52,868] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:14:52,869] {logging_mixin.py:115} INFO - [2023-01-07 21:14:52,869] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:14:52,870] {logging_mixin.py:115} INFO - [2023-01-07 21:14:52,870] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:14:52,877] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:14:52,899] {logging_mixin.py:115} INFO - [2023-01-07 21:14:52,899] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:14:52,920] {logging_mixin.py:115} INFO - [2023-01-07 21:14:52,920] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:14:52,930] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.889 seconds
[2023-01-07 21:15:23,275] {processor.py:153} INFO - Started process (PID=316) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:15:23,276] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:15:23,277] {logging_mixin.py:115} INFO - [2023-01-07 21:15:23,277] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:15:24,119] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:15:24,121] {logging_mixin.py:115} INFO - [2023-01-07 21:15:24,121] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:15:24,121] {logging_mixin.py:115} INFO - [2023-01-07 21:15:24,121] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:15:24,128] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:15:24,150] {logging_mixin.py:115} INFO - [2023-01-07 21:15:24,150] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:15:24,171] {logging_mixin.py:115} INFO - [2023-01-07 21:15:24,171] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:15:24,180] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.909 seconds
[2023-01-07 21:15:54,351] {processor.py:153} INFO - Started process (PID=343) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:15:54,354] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:15:54,354] {logging_mixin.py:115} INFO - [2023-01-07 21:15:54,354] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:15:55,244] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:15:55,246] {logging_mixin.py:115} INFO - [2023-01-07 21:15:55,245] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:15:55,246] {logging_mixin.py:115} INFO - [2023-01-07 21:15:55,246] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:15:55,253] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:15:55,275] {logging_mixin.py:115} INFO - [2023-01-07 21:15:55,275] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:15:55,295] {logging_mixin.py:115} INFO - [2023-01-07 21:15:55,295] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:15:55,305] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.958 seconds
[2023-01-07 21:16:25,434] {processor.py:153} INFO - Started process (PID=367) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:16:25,435] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:16:25,436] {logging_mixin.py:115} INFO - [2023-01-07 21:16:25,435] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:16:26,441] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:16:26,442] {logging_mixin.py:115} INFO - [2023-01-07 21:16:26,442] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:16:26,443] {logging_mixin.py:115} INFO - [2023-01-07 21:16:26,442] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:16:26,450] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:16:26,481] {logging_mixin.py:115} INFO - [2023-01-07 21:16:26,480] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:16:26,507] {logging_mixin.py:115} INFO - [2023-01-07 21:16:26,507] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:16:26,517] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.089 seconds
[2023-01-07 21:16:56,613] {processor.py:153} INFO - Started process (PID=386) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:16:56,614] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:16:56,615] {logging_mixin.py:115} INFO - [2023-01-07 21:16:56,614] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:16:57,489] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:16:57,491] {logging_mixin.py:115} INFO - [2023-01-07 21:16:57,491] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:16:57,492] {logging_mixin.py:115} INFO - [2023-01-07 21:16:57,491] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:16:57,503] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:16:57,534] {logging_mixin.py:115} INFO - [2023-01-07 21:16:57,533] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:16:57,563] {logging_mixin.py:115} INFO - [2023-01-07 21:16:57,563] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:16:57,576] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.968 seconds
[2023-01-07 21:17:27,881] {processor.py:153} INFO - Started process (PID=412) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:17:27,882] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:17:27,883] {logging_mixin.py:115} INFO - [2023-01-07 21:17:27,883] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:17:28,857] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:17:28,858] {logging_mixin.py:115} INFO - [2023-01-07 21:17:28,858] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:17:28,859] {logging_mixin.py:115} INFO - [2023-01-07 21:17:28,859] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:17:28,871] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:17:28,901] {logging_mixin.py:115} INFO - [2023-01-07 21:17:28,901] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:17:28,931] {logging_mixin.py:115} INFO - [2023-01-07 21:17:28,931] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:17:28,944] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.067 seconds
[2023-01-07 21:17:59,045] {processor.py:153} INFO - Started process (PID=437) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:17:59,046] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:17:59,046] {logging_mixin.py:115} INFO - [2023-01-07 21:17:59,046] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:17:59,845] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:17:59,847] {logging_mixin.py:115} INFO - [2023-01-07 21:17:59,847] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:17:59,847] {logging_mixin.py:115} INFO - [2023-01-07 21:17:59,847] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:17:59,854] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:17:59,876] {logging_mixin.py:115} INFO - [2023-01-07 21:17:59,875] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:17:59,896] {logging_mixin.py:115} INFO - [2023-01-07 21:17:59,895] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:17:59,905] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.864 seconds
[2023-01-07 21:18:30,005] {processor.py:153} INFO - Started process (PID=462) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:18:30,007] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:18:30,007] {logging_mixin.py:115} INFO - [2023-01-07 21:18:30,007] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:18:30,825] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:18:30,827] {logging_mixin.py:115} INFO - [2023-01-07 21:18:30,827] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:18:30,827] {logging_mixin.py:115} INFO - [2023-01-07 21:18:30,827] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:18:30,834] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:18:30,863] {logging_mixin.py:115} INFO - [2023-01-07 21:18:30,863] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:18:30,883] {logging_mixin.py:115} INFO - [2023-01-07 21:18:30,883] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:18:30,893] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.893 seconds
[2023-01-07 21:19:00,983] {processor.py:153} INFO - Started process (PID=480) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:19:00,985] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:19:00,985] {logging_mixin.py:115} INFO - [2023-01-07 21:19:00,985] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:19:01,900] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:19:01,902] {logging_mixin.py:115} INFO - [2023-01-07 21:19:01,901] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:19:01,902] {logging_mixin.py:115} INFO - [2023-01-07 21:19:01,902] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:19:01,913] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:19:01,943] {logging_mixin.py:115} INFO - [2023-01-07 21:19:01,942] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:19:01,972] {logging_mixin.py:115} INFO - [2023-01-07 21:19:01,972] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:19:01,984] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.005 seconds
[2023-01-07 21:19:32,075] {processor.py:153} INFO - Started process (PID=507) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:19:32,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:19:32,076] {logging_mixin.py:115} INFO - [2023-01-07 21:19:32,076] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:19:32,870] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:19:32,871] {logging_mixin.py:115} INFO - [2023-01-07 21:19:32,871] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:19:32,872] {logging_mixin.py:115} INFO - [2023-01-07 21:19:32,872] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:19:32,879] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:19:32,901] {logging_mixin.py:115} INFO - [2023-01-07 21:19:32,900] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:19:32,921] {logging_mixin.py:115} INFO - [2023-01-07 21:19:32,921] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:19:32,931] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.861 seconds
[2023-01-07 21:20:02,997] {processor.py:153} INFO - Started process (PID=532) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:20:02,998] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:20:02,999] {logging_mixin.py:115} INFO - [2023-01-07 21:20:02,999] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:20:03,803] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:20:03,804] {logging_mixin.py:115} INFO - [2023-01-07 21:20:03,804] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:20:03,805] {logging_mixin.py:115} INFO - [2023-01-07 21:20:03,804] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:20:03,811] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:20:03,835] {logging_mixin.py:115} INFO - [2023-01-07 21:20:03,835] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:20:03,856] {logging_mixin.py:115} INFO - [2023-01-07 21:20:03,856] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:20:03,866] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.873 seconds
[2023-01-07 21:20:33,937] {processor.py:153} INFO - Started process (PID=556) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:20:33,938] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:20:33,939] {logging_mixin.py:115} INFO - [2023-01-07 21:20:33,938] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:20:34,739] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:20:34,740] {logging_mixin.py:115} INFO - [2023-01-07 21:20:34,740] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:20:34,741] {logging_mixin.py:115} INFO - [2023-01-07 21:20:34,741] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:20:34,750] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:20:34,771] {logging_mixin.py:115} INFO - [2023-01-07 21:20:34,771] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:20:34,792] {logging_mixin.py:115} INFO - [2023-01-07 21:20:34,791] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:20:34,801] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.869 seconds
[2023-01-07 21:21:04,840] {processor.py:153} INFO - Started process (PID=574) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:21:04,841] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:21:04,842] {logging_mixin.py:115} INFO - [2023-01-07 21:21:04,842] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:21:05,662] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:21:05,663] {logging_mixin.py:115} INFO - [2023-01-07 21:21:05,663] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:21:05,663] {logging_mixin.py:115} INFO - [2023-01-07 21:21:05,663] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:21:05,671] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:21:05,693] {logging_mixin.py:115} INFO - [2023-01-07 21:21:05,692] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:21:05,717] {logging_mixin.py:115} INFO - [2023-01-07 21:21:05,717] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:21:05,726] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.891 seconds
[2023-01-07 21:21:35,920] {processor.py:153} INFO - Started process (PID=599) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:21:35,921] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:21:35,921] {logging_mixin.py:115} INFO - [2023-01-07 21:21:35,921] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:21:36,745] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:21:36,746] {logging_mixin.py:115} INFO - [2023-01-07 21:21:36,746] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:21:36,747] {logging_mixin.py:115} INFO - [2023-01-07 21:21:36,746] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:21:36,753] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:21:36,775] {logging_mixin.py:115} INFO - [2023-01-07 21:21:36,775] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:21:36,795] {logging_mixin.py:115} INFO - [2023-01-07 21:21:36,795] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:21:36,805] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.889 seconds
[2023-01-07 21:22:06,904] {processor.py:153} INFO - Started process (PID=624) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:22:06,905] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:22:06,906] {logging_mixin.py:115} INFO - [2023-01-07 21:22:06,906] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:22:07,710] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:22:07,711] {logging_mixin.py:115} INFO - [2023-01-07 21:22:07,711] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:22:07,712] {logging_mixin.py:115} INFO - [2023-01-07 21:22:07,712] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:22:07,719] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:22:07,740] {logging_mixin.py:115} INFO - [2023-01-07 21:22:07,740] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:22:07,760] {logging_mixin.py:115} INFO - [2023-01-07 21:22:07,760] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:22:07,769] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.870 seconds
[2023-01-07 21:22:37,869] {processor.py:153} INFO - Started process (PID=650) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:22:37,872] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:22:37,873] {logging_mixin.py:115} INFO - [2023-01-07 21:22:37,873] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:22:38,696] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:22:38,697] {logging_mixin.py:115} INFO - [2023-01-07 21:22:38,697] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:22:38,698] {logging_mixin.py:115} INFO - [2023-01-07 21:22:38,697] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:22:38,704] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:22:38,726] {logging_mixin.py:115} INFO - [2023-01-07 21:22:38,725] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:22:38,746] {logging_mixin.py:115} INFO - [2023-01-07 21:22:38,745] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:22:38,755] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.892 seconds
[2023-01-07 21:23:08,850] {processor.py:153} INFO - Started process (PID=668) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:23:08,851] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:23:08,852] {logging_mixin.py:115} INFO - [2023-01-07 21:23:08,851] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:23:09,674] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:23:09,676] {logging_mixin.py:115} INFO - [2023-01-07 21:23:09,675] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:23:09,676] {logging_mixin.py:115} INFO - [2023-01-07 21:23:09,676] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:23:09,683] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:23:09,704] {logging_mixin.py:115} INFO - [2023-01-07 21:23:09,704] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:23:09,724] {logging_mixin.py:115} INFO - [2023-01-07 21:23:09,724] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:23:09,733] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.887 seconds
[2023-01-07 21:23:39,826] {processor.py:153} INFO - Started process (PID=693) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:23:39,829] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:23:39,829] {logging_mixin.py:115} INFO - [2023-01-07 21:23:39,829] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:23:40,649] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:23:40,650] {logging_mixin.py:115} INFO - [2023-01-07 21:23:40,650] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:23:40,651] {logging_mixin.py:115} INFO - [2023-01-07 21:23:40,651] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:23:40,658] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:23:40,681] {logging_mixin.py:115} INFO - [2023-01-07 21:23:40,681] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:23:40,701] {logging_mixin.py:115} INFO - [2023-01-07 21:23:40,701] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:23:40,710] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.889 seconds
[2023-01-07 21:24:10,803] {processor.py:153} INFO - Started process (PID=717) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:24:10,803] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:24:10,804] {logging_mixin.py:115} INFO - [2023-01-07 21:24:10,804] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:24:11,601] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:24:11,602] {logging_mixin.py:115} INFO - [2023-01-07 21:24:11,602] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:24:11,603] {logging_mixin.py:115} INFO - [2023-01-07 21:24:11,602] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:24:11,609] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:24:11,631] {logging_mixin.py:115} INFO - [2023-01-07 21:24:11,631] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:24:11,652] {logging_mixin.py:115} INFO - [2023-01-07 21:24:11,652] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:24:11,661] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.864 seconds
[2023-01-07 21:24:41,763] {processor.py:153} INFO - Started process (PID=742) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:24:41,766] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:24:41,767] {logging_mixin.py:115} INFO - [2023-01-07 21:24:41,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:24:42,761] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:24:42,763] {logging_mixin.py:115} INFO - [2023-01-07 21:24:42,763] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:24:42,763] {logging_mixin.py:115} INFO - [2023-01-07 21:24:42,763] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:24:42,770] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:24:42,798] {logging_mixin.py:115} INFO - [2023-01-07 21:24:42,798] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:24:42,826] {logging_mixin.py:115} INFO - [2023-01-07 21:24:42,826] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:24:42,838] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.081 seconds
[2023-01-07 21:25:12,906] {processor.py:153} INFO - Started process (PID=760) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:25:12,907] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:25:12,908] {logging_mixin.py:115} INFO - [2023-01-07 21:25:12,908] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:25:13,710] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:25:13,712] {logging_mixin.py:115} INFO - [2023-01-07 21:25:13,712] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:25:13,712] {logging_mixin.py:115} INFO - [2023-01-07 21:25:13,712] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:25:13,719] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:25:13,741] {logging_mixin.py:115} INFO - [2023-01-07 21:25:13,741] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:25:13,761] {logging_mixin.py:115} INFO - [2023-01-07 21:25:13,761] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:25:13,770] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.869 seconds
[2023-01-07 21:25:43,871] {processor.py:153} INFO - Started process (PID=785) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:25:43,873] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:25:43,874] {logging_mixin.py:115} INFO - [2023-01-07 21:25:43,874] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:25:44,669] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:25:44,670] {logging_mixin.py:115} INFO - [2023-01-07 21:25:44,670] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:25:44,671] {logging_mixin.py:115} INFO - [2023-01-07 21:25:44,670] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:25:44,677] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:25:44,699] {logging_mixin.py:115} INFO - [2023-01-07 21:25:44,699] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:25:44,719] {logging_mixin.py:115} INFO - [2023-01-07 21:25:44,719] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:25:44,729] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.862 seconds
[2023-01-07 21:26:14,826] {processor.py:153} INFO - Started process (PID=810) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:26:14,827] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:26:14,828] {logging_mixin.py:115} INFO - [2023-01-07 21:26:14,828] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:26:15,660] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:26:15,661] {logging_mixin.py:115} INFO - [2023-01-07 21:26:15,661] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:26:15,661] {logging_mixin.py:115} INFO - [2023-01-07 21:26:15,661] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:26:15,668] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:26:15,690] {logging_mixin.py:115} INFO - [2023-01-07 21:26:15,690] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:26:15,710] {logging_mixin.py:115} INFO - [2023-01-07 21:26:15,710] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:26:15,719] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.898 seconds
[2023-01-07 21:26:45,812] {processor.py:153} INFO - Started process (PID=829) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:26:45,814] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:26:45,814] {logging_mixin.py:115} INFO - [2023-01-07 21:26:45,814] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:26:46,623] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:26:46,624] {logging_mixin.py:115} INFO - [2023-01-07 21:26:46,624] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:26:46,624] {logging_mixin.py:115} INFO - [2023-01-07 21:26:46,624] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:26:46,631] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:26:46,653] {logging_mixin.py:115} INFO - [2023-01-07 21:26:46,653] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:26:46,673] {logging_mixin.py:115} INFO - [2023-01-07 21:26:46,673] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:26:46,683] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.875 seconds
[2023-01-07 21:27:17,008] {processor.py:153} INFO - Started process (PID=854) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:27:17,009] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:27:17,009] {logging_mixin.py:115} INFO - [2023-01-07 21:27:17,009] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:27:17,807] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:27:17,808] {logging_mixin.py:115} INFO - [2023-01-07 21:27:17,808] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:27:17,809] {logging_mixin.py:115} INFO - [2023-01-07 21:27:17,808] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:27:17,816] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:27:17,838] {logging_mixin.py:115} INFO - [2023-01-07 21:27:17,837] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:27:17,858] {logging_mixin.py:115} INFO - [2023-01-07 21:27:17,858] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:27:17,868] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.864 seconds
[2023-01-07 21:27:47,959] {processor.py:153} INFO - Started process (PID=880) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:27:47,961] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:27:47,961] {logging_mixin.py:115} INFO - [2023-01-07 21:27:47,961] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:27:48,768] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:27:48,770] {logging_mixin.py:115} INFO - [2023-01-07 21:27:48,770] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:27:48,770] {logging_mixin.py:115} INFO - [2023-01-07 21:27:48,770] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:27:48,777] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:27:48,799] {logging_mixin.py:115} INFO - [2023-01-07 21:27:48,799] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:27:48,819] {logging_mixin.py:115} INFO - [2023-01-07 21:27:48,819] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:27:48,828] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.873 seconds
[2023-01-07 21:28:18,921] {processor.py:153} INFO - Started process (PID=908) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:28:18,922] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:28:18,923] {logging_mixin.py:115} INFO - [2023-01-07 21:28:18,922] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:28:19,744] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:28:19,745] {logging_mixin.py:115} INFO - [2023-01-07 21:28:19,745] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:28:19,745] {logging_mixin.py:115} INFO - [2023-01-07 21:28:19,745] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:28:19,752] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:28:19,773] {logging_mixin.py:115} INFO - [2023-01-07 21:28:19,773] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:28:19,793] {logging_mixin.py:115} INFO - [2023-01-07 21:28:19,793] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:28:19,802] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.886 seconds
[2023-01-07 21:28:49,895] {processor.py:153} INFO - Started process (PID=926) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:28:49,896] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:28:49,897] {logging_mixin.py:115} INFO - [2023-01-07 21:28:49,897] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:28:50,697] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:28:50,698] {logging_mixin.py:115} INFO - [2023-01-07 21:28:50,698] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:28:50,699] {logging_mixin.py:115} INFO - [2023-01-07 21:28:50,699] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:28:50,706] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:28:50,728] {logging_mixin.py:115} INFO - [2023-01-07 21:28:50,727] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:28:50,748] {logging_mixin.py:115} INFO - [2023-01-07 21:28:50,748] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:28:50,758] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.867 seconds
[2023-01-07 21:29:21,148] {processor.py:153} INFO - Started process (PID=951) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:29:21,149] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:29:21,149] {logging_mixin.py:115} INFO - [2023-01-07 21:29:21,149] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:29:21,958] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:29:21,959] {logging_mixin.py:115} INFO - [2023-01-07 21:29:21,959] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:29:21,960] {logging_mixin.py:115} INFO - [2023-01-07 21:29:21,960] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:29:21,967] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:29:21,989] {logging_mixin.py:115} INFO - [2023-01-07 21:29:21,988] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:29:22,009] {logging_mixin.py:115} INFO - [2023-01-07 21:29:22,009] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:29:22,018] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.875 seconds
[2023-01-07 21:32:54,708] {processor.py:153} INFO - Started process (PID=34) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:32:54,709] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:32:54,710] {logging_mixin.py:115} INFO - [2023-01-07 21:32:54,710] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:32:58,251] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:32:58,252] {logging_mixin.py:115} INFO - [2023-01-07 21:32:58,252] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:32:58,253] {logging_mixin.py:115} INFO - [2023-01-07 21:32:58,252] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:32:58,263] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:32:58,292] {logging_mixin.py:115} INFO - [2023-01-07 21:32:58,291] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:32:58,321] {logging_mixin.py:115} INFO - [2023-01-07 21:32:58,321] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:32:58,334] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 3.647 seconds
[2023-01-07 21:33:28,436] {processor.py:153} INFO - Started process (PID=59) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:33:28,437] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:33:28,438] {logging_mixin.py:115} INFO - [2023-01-07 21:33:28,438] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:33:29,460] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:33:29,461] {logging_mixin.py:115} INFO - [2023-01-07 21:33:29,461] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:33:29,462] {logging_mixin.py:115} INFO - [2023-01-07 21:33:29,461] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:33:29,468] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:33:29,491] {logging_mixin.py:115} INFO - [2023-01-07 21:33:29,491] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:33:29,511] {logging_mixin.py:115} INFO - [2023-01-07 21:33:29,511] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:33:29,521] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.089 seconds
[2023-01-07 21:33:59,619] {processor.py:153} INFO - Started process (PID=84) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:33:59,620] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:33:59,621] {logging_mixin.py:115} INFO - [2023-01-07 21:33:59,621] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:34:00,750] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:34:00,752] {logging_mixin.py:115} INFO - [2023-01-07 21:34:00,752] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:34:00,753] {logging_mixin.py:115} INFO - [2023-01-07 21:34:00,753] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:34:00,765] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:34:00,796] {logging_mixin.py:115} INFO - [2023-01-07 21:34:00,795] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:34:00,834] {logging_mixin.py:115} INFO - [2023-01-07 21:34:00,834] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:34:00,847] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.234 seconds
[2023-01-07 21:34:30,947] {processor.py:153} INFO - Started process (PID=101) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:34:30,950] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:34:30,951] {logging_mixin.py:115} INFO - [2023-01-07 21:34:30,951] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:34:31,764] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:34:31,765] {logging_mixin.py:115} INFO - [2023-01-07 21:34:31,765] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:34:31,765] {logging_mixin.py:115} INFO - [2023-01-07 21:34:31,765] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:34:31,772] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:34:31,794] {logging_mixin.py:115} INFO - [2023-01-07 21:34:31,793] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:34:31,818] {logging_mixin.py:115} INFO - [2023-01-07 21:34:31,818] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:34:31,828] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.886 seconds
[2023-01-07 21:35:01,927] {processor.py:153} INFO - Started process (PID=126) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:35:01,930] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:35:01,931] {logging_mixin.py:115} INFO - [2023-01-07 21:35:01,931] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:35:02,837] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:35:02,838] {logging_mixin.py:115} INFO - [2023-01-07 21:35:02,838] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:35:02,839] {logging_mixin.py:115} INFO - [2023-01-07 21:35:02,838] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:35:02,846] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:35:02,868] {logging_mixin.py:115} INFO - [2023-01-07 21:35:02,868] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:35:02,888] {logging_mixin.py:115} INFO - [2023-01-07 21:35:02,888] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:35:02,898] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.975 seconds
[2023-01-07 21:35:33,254] {processor.py:153} INFO - Started process (PID=151) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:35:33,255] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:35:33,256] {logging_mixin.py:115} INFO - [2023-01-07 21:35:33,256] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:35:34,094] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:35:34,095] {logging_mixin.py:115} INFO - [2023-01-07 21:35:34,095] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:35:34,096] {logging_mixin.py:115} INFO - [2023-01-07 21:35:34,095] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:35:34,102] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:35:34,131] {logging_mixin.py:115} INFO - [2023-01-07 21:35:34,130] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:35:34,156] {logging_mixin.py:115} INFO - [2023-01-07 21:35:34,156] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:35:34,166] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.917 seconds
[2023-01-07 21:36:04,492] {processor.py:153} INFO - Started process (PID=177) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:36:04,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:36:04,494] {logging_mixin.py:115} INFO - [2023-01-07 21:36:04,494] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:36:05,714] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:36:05,716] {logging_mixin.py:115} INFO - [2023-01-07 21:36:05,716] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:36:05,717] {logging_mixin.py:115} INFO - [2023-01-07 21:36:05,716] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:36:05,728] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:36:05,759] {logging_mixin.py:115} INFO - [2023-01-07 21:36:05,759] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:36:05,791] {logging_mixin.py:115} INFO - [2023-01-07 21:36:05,791] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:36:05,805] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.317 seconds
[2023-01-07 21:36:35,918] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:36:35,919] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:36:35,920] {logging_mixin.py:115} INFO - [2023-01-07 21:36:35,920] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:36:37,051] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:36:37,053] {logging_mixin.py:115} INFO - [2023-01-07 21:36:37,053] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:36:37,054] {logging_mixin.py:115} INFO - [2023-01-07 21:36:37,053] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:36:37,065] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:36:37,094] {logging_mixin.py:115} INFO - [2023-01-07 21:36:37,093] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:36:37,122] {logging_mixin.py:115} INFO - [2023-01-07 21:36:37,122] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:36:37,136] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.224 seconds
[2023-01-07 21:37:07,240] {processor.py:153} INFO - Started process (PID=219) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:37:07,241] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:37:07,242] {logging_mixin.py:115} INFO - [2023-01-07 21:37:07,241] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:37:08,073] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:37:08,075] {logging_mixin.py:115} INFO - [2023-01-07 21:37:08,075] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:37:08,076] {logging_mixin.py:115} INFO - [2023-01-07 21:37:08,075] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:37:08,087] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:37:08,110] {logging_mixin.py:115} INFO - [2023-01-07 21:37:08,110] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:37:08,130] {logging_mixin.py:115} INFO - [2023-01-07 21:37:08,130] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:37:08,140] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.904 seconds
[2023-01-07 21:37:38,403] {processor.py:153} INFO - Started process (PID=244) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:37:38,406] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:37:38,406] {logging_mixin.py:115} INFO - [2023-01-07 21:37:38,406] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:37:39,215] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:37:39,216] {logging_mixin.py:115} INFO - [2023-01-07 21:37:39,216] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:37:39,217] {logging_mixin.py:115} INFO - [2023-01-07 21:37:39,217] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:37:39,224] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:37:39,246] {logging_mixin.py:115} INFO - [2023-01-07 21:37:39,246] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:37:39,267] {logging_mixin.py:115} INFO - [2023-01-07 21:37:39,266] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:37:39,276] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.877 seconds
[2023-01-07 21:38:09,383] {processor.py:153} INFO - Started process (PID=263) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:38:09,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:38:09,385] {logging_mixin.py:115} INFO - [2023-01-07 21:38:09,385] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:38:10,662] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:38:10,664] {logging_mixin.py:115} INFO - [2023-01-07 21:38:10,664] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:38:10,670] {logging_mixin.py:115} INFO - [2023-01-07 21:38:10,670] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:38:10,689] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:38:10,742] {logging_mixin.py:115} INFO - [2023-01-07 21:38:10,742] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:38:10,785] {logging_mixin.py:115} INFO - [2023-01-07 21:38:10,785] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:38:10,814] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.435 seconds
[2023-01-07 21:38:40,924] {processor.py:153} INFO - Started process (PID=292) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:38:40,925] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:38:40,926] {logging_mixin.py:115} INFO - [2023-01-07 21:38:40,926] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:38:41,744] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:38:41,745] {logging_mixin.py:115} INFO - [2023-01-07 21:38:41,745] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:38:41,746] {logging_mixin.py:115} INFO - [2023-01-07 21:38:41,745] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:38:41,753] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:38:41,776] {logging_mixin.py:115} INFO - [2023-01-07 21:38:41,776] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:38:41,801] {logging_mixin.py:115} INFO - [2023-01-07 21:38:41,801] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:38:41,810] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.890 seconds
[2023-01-07 21:39:12,017] {processor.py:153} INFO - Started process (PID=317) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:39:12,018] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:39:12,019] {logging_mixin.py:115} INFO - [2023-01-07 21:39:12,019] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:39:12,837] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:39:12,838] {logging_mixin.py:115} INFO - [2023-01-07 21:39:12,838] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:39:12,838] {logging_mixin.py:115} INFO - [2023-01-07 21:39:12,838] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:39:12,845] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:39:12,867] {logging_mixin.py:115} INFO - [2023-01-07 21:39:12,866] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:39:12,887] {logging_mixin.py:115} INFO - [2023-01-07 21:39:12,887] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:39:12,896] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.884 seconds
[2023-01-07 21:39:42,993] {processor.py:153} INFO - Started process (PID=342) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:39:42,994] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:39:42,995] {logging_mixin.py:115} INFO - [2023-01-07 21:39:42,995] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:39:43,919] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:39:43,920] {logging_mixin.py:115} INFO - [2023-01-07 21:39:43,920] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:39:43,921] {logging_mixin.py:115} INFO - [2023-01-07 21:39:43,921] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:39:43,928] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:39:43,949] {logging_mixin.py:115} INFO - [2023-01-07 21:39:43,949] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:39:43,969] {logging_mixin.py:115} INFO - [2023-01-07 21:39:43,969] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:39:43,978] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.991 seconds
[2023-01-07 21:39:51,016] {processor.py:153} INFO - Started process (PID=346) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:39:51,017] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:39:51,018] {logging_mixin.py:115} INFO - [2023-01-07 21:39:51,017] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:39:51,826] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:39:51,827] {logging_mixin.py:115} INFO - [2023-01-07 21:39:51,827] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:39:51,828] {logging_mixin.py:115} INFO - [2023-01-07 21:39:51,828] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:39:51,835] {logging_mixin.py:115} INFO - [2023-01-07 21:39:51,834] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 91, in <module>
    trigger_dbt_cloud_job_run = DbtCloudRunJobOperator(
NameError: name 'DbtCloudRunJobOperator' is not defined
[2023-01-07 21:39:51,835] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:39:51,853] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-07 21:40:22,053] {processor.py:153} INFO - Started process (PID=372) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:40:22,054] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:40:22,055] {logging_mixin.py:115} INFO - [2023-01-07 21:40:22,055] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:40:22,872] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:40:22,873] {logging_mixin.py:115} INFO - [2023-01-07 21:40:22,873] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:40:22,874] {logging_mixin.py:115} INFO - [2023-01-07 21:40:22,873] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:40:22,881] {logging_mixin.py:115} INFO - [2023-01-07 21:40:22,880] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 91, in <module>
    trigger_dbt_cloud_job_run = DbtCloudRunJobOperator(
NameError: name 'DbtCloudRunJobOperator' is not defined
[2023-01-07 21:40:22,881] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:40:22,899] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.851 seconds
[2023-01-07 21:40:53,145] {processor.py:153} INFO - Started process (PID=397) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:40:53,147] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:40:53,147] {logging_mixin.py:115} INFO - [2023-01-07 21:40:53,147] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:40:53,942] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:40:53,944] {logging_mixin.py:115} INFO - [2023-01-07 21:40:53,944] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:40:53,944] {logging_mixin.py:115} INFO - [2023-01-07 21:40:53,944] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:40:53,951] {logging_mixin.py:115} INFO - [2023-01-07 21:40:53,951] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 91, in <module>
    trigger_dbt_cloud_job_run = DbtCloudRunJobOperator(
NameError: name 'DbtCloudRunJobOperator' is not defined
[2023-01-07 21:40:53,951] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:40:53,969] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.828 seconds
[2023-01-07 21:41:24,063] {processor.py:153} INFO - Started process (PID=415) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:41:24,064] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:41:24,065] {logging_mixin.py:115} INFO - [2023-01-07 21:41:24,064] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:41:25,068] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:41:25,070] {logging_mixin.py:115} INFO - [2023-01-07 21:41:25,070] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:41:25,070] {logging_mixin.py:115} INFO - [2023-01-07 21:41:25,070] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:41:25,083] {logging_mixin.py:115} INFO - [2023-01-07 21:41:25,083] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 91, in <module>
    trigger_dbt_cloud_job_run = DbtCloudRunJobOperator(
NameError: name 'DbtCloudRunJobOperator' is not defined
[2023-01-07 21:41:25,084] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:41:25,107] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.048 seconds
[2023-01-07 21:41:56,137] {processor.py:153} INFO - Started process (PID=441) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:41:56,141] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:41:56,142] {logging_mixin.py:115} INFO - [2023-01-07 21:41:56,141] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:41:56,948] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:41:56,949] {logging_mixin.py:115} INFO - [2023-01-07 21:41:56,949] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:41:56,950] {logging_mixin.py:115} INFO - [2023-01-07 21:41:56,949] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:41:56,956] {logging_mixin.py:115} INFO - [2023-01-07 21:41:56,956] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 91, in <module>
    trigger_dbt_cloud_job_run = DbtCloudRunJobOperator(
NameError: name 'DbtCloudRunJobOperator' is not defined
[2023-01-07 21:41:56,956] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:41:56,974] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.842 seconds
[2023-01-07 21:42:12,175] {processor.py:153} INFO - Started process (PID=460) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:42:12,176] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:42:12,177] {logging_mixin.py:115} INFO - [2023-01-07 21:42:12,176] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:42:12,179] {logging_mixin.py:115} INFO - [2023-01-07 21:42:12,179] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 846, in exec_module
  File "<frozen importlib._bootstrap_external>", line 983, in get_code
  File "<frozen importlib._bootstrap_external>", line 913, in source_to_code
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18
    from apache-airflow-providers-dbt-cloud import DbtCloudRunJobOperator
               ^
SyntaxError: invalid syntax
[2023-01-07 21:42:12,180] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:42:12,202] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.032 seconds
[2023-01-07 21:42:42,240] {processor.py:153} INFO - Started process (PID=477) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:42:42,243] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:42:42,244] {logging_mixin.py:115} INFO - [2023-01-07 21:42:42,244] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:42:42,247] {logging_mixin.py:115} INFO - [2023-01-07 21:42:42,246] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 846, in exec_module
  File "<frozen importlib._bootstrap_external>", line 983, in get_code
  File "<frozen importlib._bootstrap_external>", line 913, in source_to_code
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18
    from apache-airflow-providers-dbt-cloud import DbtCloudRunJobOperator
               ^
SyntaxError: invalid syntax
[2023-01-07 21:42:42,247] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:42:42,270] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.036 seconds
[2023-01-07 21:43:02,339] {processor.py:153} INFO - Started process (PID=493) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:43:02,340] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:43:02,340] {logging_mixin.py:115} INFO - [2023-01-07 21:43:02,340] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:43:03,162] {logging_mixin.py:115} INFO - [2023-01-07 21:43:03,161] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:43:03,163] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:43:03,193] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.859 seconds
[2023-01-07 21:43:33,295] {processor.py:153} INFO - Started process (PID=518) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:43:33,296] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:43:33,297] {logging_mixin.py:115} INFO - [2023-01-07 21:43:33,297] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:43:34,098] {logging_mixin.py:115} INFO - [2023-01-07 21:43:34,097] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:43:34,099] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:43:34,115] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.826 seconds
[2023-01-07 21:44:04,212] {processor.py:153} INFO - Started process (PID=543) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:44:04,214] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:44:04,214] {logging_mixin.py:115} INFO - [2023-01-07 21:44:04,214] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:44:05,143] {logging_mixin.py:115} INFO - [2023-01-07 21:44:05,142] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:44:05,143] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:44:05,160] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.954 seconds
[2023-01-07 21:44:35,264] {processor.py:153} INFO - Started process (PID=561) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:44:35,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:44:35,265] {logging_mixin.py:115} INFO - [2023-01-07 21:44:35,265] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:44:36,070] {logging_mixin.py:115} INFO - [2023-01-07 21:44:36,069] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:44:36,070] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:44:36,087] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.828 seconds
[2023-01-07 21:45:06,176] {processor.py:153} INFO - Started process (PID=586) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:45:06,177] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:45:06,178] {logging_mixin.py:115} INFO - [2023-01-07 21:45:06,178] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:45:06,967] {logging_mixin.py:115} INFO - [2023-01-07 21:45:06,966] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:45:06,968] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:45:06,985] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.814 seconds
[2023-01-07 21:45:37,066] {processor.py:153} INFO - Started process (PID=610) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:45:37,067] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:45:37,068] {logging_mixin.py:115} INFO - [2023-01-07 21:45:37,068] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:45:37,863] {logging_mixin.py:115} INFO - [2023-01-07 21:45:37,862] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:45:37,864] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:45:37,886] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.824 seconds
[2023-01-07 21:46:07,958] {processor.py:153} INFO - Started process (PID=628) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:46:07,959] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:46:07,960] {logging_mixin.py:115} INFO - [2023-01-07 21:46:07,960] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:46:08,773] {logging_mixin.py:115} INFO - [2023-01-07 21:46:08,772] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:46:08,773] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:46:08,791] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.837 seconds
[2023-01-07 21:46:38,867] {processor.py:153} INFO - Started process (PID=653) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:46:38,867] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:46:38,868] {logging_mixin.py:115} INFO - [2023-01-07 21:46:38,868] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:46:39,663] {logging_mixin.py:115} INFO - [2023-01-07 21:46:39,663] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:46:39,664] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:46:39,680] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.818 seconds
[2023-01-07 21:47:09,755] {processor.py:153} INFO - Started process (PID=678) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:47:09,756] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:47:09,757] {logging_mixin.py:115} INFO - [2023-01-07 21:47:09,757] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:47:10,570] {logging_mixin.py:115} INFO - [2023-01-07 21:47:10,568] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:47:10,570] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:47:10,592] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.842 seconds
[2023-01-07 21:47:40,676] {processor.py:153} INFO - Started process (PID=703) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:47:40,677] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:47:40,677] {logging_mixin.py:115} INFO - [2023-01-07 21:47:40,677] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:47:41,500] {logging_mixin.py:115} INFO - [2023-01-07 21:47:41,499] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:47:41,501] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:47:41,518] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.846 seconds
[2023-01-07 21:48:11,587] {processor.py:153} INFO - Started process (PID=721) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:48:11,588] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:48:11,589] {logging_mixin.py:115} INFO - [2023-01-07 21:48:11,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:48:12,382] {logging_mixin.py:115} INFO - [2023-01-07 21:48:12,381] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:48:12,383] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:48:12,400] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.818 seconds
[2023-01-07 21:48:42,471] {processor.py:153} INFO - Started process (PID=748) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:48:42,471] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:48:42,472] {logging_mixin.py:115} INFO - [2023-01-07 21:48:42,472] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:48:43,286] {logging_mixin.py:115} INFO - [2023-01-07 21:48:43,285] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:48:43,286] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:48:43,307] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-07 21:49:13,401] {processor.py:153} INFO - Started process (PID=773) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:49:13,403] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:49:13,403] {logging_mixin.py:115} INFO - [2023-01-07 21:49:13,403] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:49:14,202] {logging_mixin.py:115} INFO - [2023-01-07 21:49:14,202] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:49:14,203] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:49:14,220] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.823 seconds
[2023-01-07 21:49:44,298] {processor.py:153} INFO - Started process (PID=798) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:49:44,299] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:49:44,300] {logging_mixin.py:115} INFO - [2023-01-07 21:49:44,300] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:49:45,240] {logging_mixin.py:115} INFO - [2023-01-07 21:49:45,239] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:49:45,240] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:49:45,258] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.964 seconds
[2023-01-07 21:50:15,358] {processor.py:153} INFO - Started process (PID=817) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:50:15,360] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:50:15,360] {logging_mixin.py:115} INFO - [2023-01-07 21:50:15,360] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:50:16,159] {logging_mixin.py:115} INFO - [2023-01-07 21:50:16,158] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:50:16,159] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:50:16,176] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.823 seconds
[2023-01-07 21:50:46,643] {processor.py:153} INFO - Started process (PID=842) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:50:46,643] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:50:46,644] {logging_mixin.py:115} INFO - [2023-01-07 21:50:46,644] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:50:47,415] {logging_mixin.py:115} INFO - [2023-01-07 21:50:47,414] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:50:47,415] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:50:47,432] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.794 seconds
[2023-01-07 21:51:17,514] {processor.py:153} INFO - Started process (PID=868) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:51:17,515] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:51:17,516] {logging_mixin.py:115} INFO - [2023-01-07 21:51:17,516] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:51:18,307] {logging_mixin.py:115} INFO - [2023-01-07 21:51:18,306] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:51:18,308] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:51:18,325] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.817 seconds
[2023-01-07 21:51:48,399] {processor.py:153} INFO - Started process (PID=887) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:51:48,400] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:51:48,400] {logging_mixin.py:115} INFO - [2023-01-07 21:51:48,400] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:51:49,244] {logging_mixin.py:115} INFO - [2023-01-07 21:51:49,243] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:51:49,244] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:51:49,262] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.868 seconds
[2023-01-07 21:52:19,340] {processor.py:153} INFO - Started process (PID=912) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:52:19,341] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:52:19,342] {logging_mixin.py:115} INFO - [2023-01-07 21:52:19,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:52:20,135] {logging_mixin.py:115} INFO - [2023-01-07 21:52:20,134] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:52:20,135] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:52:20,156] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.822 seconds
[2023-01-07 21:52:50,241] {processor.py:153} INFO - Started process (PID=939) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:52:50,242] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:52:50,242] {logging_mixin.py:115} INFO - [2023-01-07 21:52:50,242] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:52:51,121] {logging_mixin.py:115} INFO - [2023-01-07 21:52:51,120] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:52:51,121] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:52:51,139] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.903 seconds
[2023-01-07 21:53:21,213] {processor.py:153} INFO - Started process (PID=963) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:53:21,213] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:53:21,214] {logging_mixin.py:115} INFO - [2023-01-07 21:53:21,214] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:53:22,083] {logging_mixin.py:115} INFO - [2023-01-07 21:53:22,082] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:53:22,083] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:53:22,101] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.893 seconds
[2023-01-07 21:53:52,170] {processor.py:153} INFO - Started process (PID=981) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:53:52,170] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:53:52,171] {logging_mixin.py:115} INFO - [2023-01-07 21:53:52,171] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:53:52,985] {logging_mixin.py:115} INFO - [2023-01-07 21:53:52,984] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:53:52,985] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:53:53,004] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.839 seconds
[2023-01-07 21:54:23,086] {processor.py:153} INFO - Started process (PID=1006) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:54:23,087] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:54:23,088] {logging_mixin.py:115} INFO - [2023-01-07 21:54:23,088] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:54:23,930] {logging_mixin.py:115} INFO - [2023-01-07 21:54:23,929] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:54:23,931] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:54:23,952] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.871 seconds
[2023-01-07 21:54:54,024] {processor.py:153} INFO - Started process (PID=1032) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:54:54,025] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:54:54,026] {logging_mixin.py:115} INFO - [2023-01-07 21:54:54,026] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:54:54,836] {logging_mixin.py:115} INFO - [2023-01-07 21:54:54,835] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:54:54,836] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:54:54,853] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.834 seconds
[2023-01-07 21:55:24,916] {processor.py:153} INFO - Started process (PID=1056) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:55:24,917] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:55:24,918] {logging_mixin.py:115} INFO - [2023-01-07 21:55:24,918] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:55:25,871] {logging_mixin.py:115} INFO - [2023-01-07 21:55:25,870] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:55:25,871] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:55:25,893] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.982 seconds
[2023-01-07 21:55:55,947] {processor.py:153} INFO - Started process (PID=1074) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:55:55,948] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:55:55,949] {logging_mixin.py:115} INFO - [2023-01-07 21:55:55,949] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:55:56,768] {logging_mixin.py:115} INFO - [2023-01-07 21:55:56,767] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 18, in <module>
    from airflow.providers.dbt.cloud import DbtCloudRunJobOperator
ImportError: cannot import name 'DbtCloudRunJobOperator' from 'airflow.providers.dbt.cloud' (/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/dbt/cloud/__init__.py)
[2023-01-07 21:55:56,768] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:55:56,786] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.844 seconds
[2023-01-07 21:56:02,834] {processor.py:153} INFO - Started process (PID=1085) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:56:02,835] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:56:02,836] {logging_mixin.py:115} INFO - [2023-01-07 21:56:02,836] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:56:03,794] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:56:03,795] {logging_mixin.py:115} INFO - [2023-01-07 21:56:03,795] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:56:03,796] {logging_mixin.py:115} INFO - [2023-01-07 21:56:03,796] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:56:03,803] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:56:03,861] {logging_mixin.py:115} INFO - [2023-01-07 21:56:03,860] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:56:03,880] {logging_mixin.py:115} INFO - [2023-01-07 21:56:03,880] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:56:03,894] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.064 seconds
[2023-01-07 21:56:33,972] {processor.py:153} INFO - Started process (PID=1109) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:56:33,974] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:56:33,974] {logging_mixin.py:115} INFO - [2023-01-07 21:56:33,974] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:56:34,809] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:56:34,811] {logging_mixin.py:115} INFO - [2023-01-07 21:56:34,811] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:56:34,811] {logging_mixin.py:115} INFO - [2023-01-07 21:56:34,811] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:56:34,819] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:56:34,841] {logging_mixin.py:115} INFO - [2023-01-07 21:56:34,841] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:56:34,861] {logging_mixin.py:115} INFO - [2023-01-07 21:56:34,861] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:56:34,871] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.903 seconds
[2023-01-07 21:57:04,973] {processor.py:153} INFO - Started process (PID=1127) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:57:04,973] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:57:04,974] {logging_mixin.py:115} INFO - [2023-01-07 21:57:04,974] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:57:05,781] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:57:05,782] {logging_mixin.py:115} INFO - [2023-01-07 21:57:05,782] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:57:05,783] {logging_mixin.py:115} INFO - [2023-01-07 21:57:05,782] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:57:05,790] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:57:05,814] {logging_mixin.py:115} INFO - [2023-01-07 21:57:05,813] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:57:05,835] {logging_mixin.py:115} INFO - [2023-01-07 21:57:05,835] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:57:05,846] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.878 seconds
[2023-01-07 21:57:35,945] {processor.py:153} INFO - Started process (PID=1152) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:57:35,949] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:57:35,950] {logging_mixin.py:115} INFO - [2023-01-07 21:57:35,950] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:57:36,752] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:57:36,753] {logging_mixin.py:115} INFO - [2023-01-07 21:57:36,753] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:57:36,753] {logging_mixin.py:115} INFO - [2023-01-07 21:57:36,753] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:57:36,760] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:57:36,783] {logging_mixin.py:115} INFO - [2023-01-07 21:57:36,783] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:57:36,803] {logging_mixin.py:115} INFO - [2023-01-07 21:57:36,803] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:57:36,813] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.873 seconds
[2023-01-07 21:58:07,148] {processor.py:153} INFO - Started process (PID=1177) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:58:07,149] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:58:07,150] {logging_mixin.py:115} INFO - [2023-01-07 21:58:07,150] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:58:07,970] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:58:07,971] {logging_mixin.py:115} INFO - [2023-01-07 21:58:07,971] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:58:07,972] {logging_mixin.py:115} INFO - [2023-01-07 21:58:07,972] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:58:07,979] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:58:08,001] {logging_mixin.py:115} INFO - [2023-01-07 21:58:08,001] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:58:08,021] {logging_mixin.py:115} INFO - [2023-01-07 21:58:08,021] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:58:08,032] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.888 seconds
[2023-01-07 21:58:38,127] {processor.py:153} INFO - Started process (PID=1203) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:58:38,127] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:58:38,128] {logging_mixin.py:115} INFO - [2023-01-07 21:58:38,128] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:58:38,961] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:58:38,962] {logging_mixin.py:115} INFO - [2023-01-07 21:58:38,962] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:58:38,962] {logging_mixin.py:115} INFO - [2023-01-07 21:58:38,962] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:58:38,970] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:58:39,002] {logging_mixin.py:115} INFO - [2023-01-07 21:58:39,001] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:58:39,031] {logging_mixin.py:115} INFO - [2023-01-07 21:58:39,031] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:58:39,047] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.925 seconds
[2023-01-07 21:59:09,142] {processor.py:153} INFO - Started process (PID=1222) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:59:09,143] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:59:09,144] {logging_mixin.py:115} INFO - [2023-01-07 21:59:09,144] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:59:09,968] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:59:09,970] {logging_mixin.py:115} INFO - [2023-01-07 21:59:09,970] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:59:09,970] {logging_mixin.py:115} INFO - [2023-01-07 21:59:09,970] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:59:09,978] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:59:10,000] {logging_mixin.py:115} INFO - [2023-01-07 21:59:10,000] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:59:10,020] {logging_mixin.py:115} INFO - [2023-01-07 21:59:10,020] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:59:10,031] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.894 seconds
[2023-01-07 21:59:40,131] {processor.py:153} INFO - Started process (PID=1247) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:59:40,132] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 21:59:40,132] {logging_mixin.py:115} INFO - [2023-01-07 21:59:40,132] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:59:40,958] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 21:59:40,960] {logging_mixin.py:115} INFO - [2023-01-07 21:59:40,960] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 21:59:40,960] {logging_mixin.py:115} INFO - [2023-01-07 21:59:40,960] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 21:59:40,967] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 21:59:40,998] {logging_mixin.py:115} INFO - [2023-01-07 21:59:40,998] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 21:59:41,019] {logging_mixin.py:115} INFO - [2023-01-07 21:59:41,019] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 21:59:41,030] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.904 seconds
[2023-01-07 22:00:11,395] {processor.py:153} INFO - Started process (PID=1272) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:00:11,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:00:11,396] {logging_mixin.py:115} INFO - [2023-01-07 22:00:11,396] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:00:12,200] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:00:12,201] {logging_mixin.py:115} INFO - [2023-01-07 22:00:12,201] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:00:12,201] {logging_mixin.py:115} INFO - [2023-01-07 22:00:12,201] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:00:12,209] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:00:12,231] {logging_mixin.py:115} INFO - [2023-01-07 22:00:12,231] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:00:12,252] {logging_mixin.py:115} INFO - [2023-01-07 22:00:12,252] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:00:12,263] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.872 seconds
[2023-01-07 22:00:42,360] {processor.py:153} INFO - Started process (PID=1297) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:00:42,360] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:00:42,361] {logging_mixin.py:115} INFO - [2023-01-07 22:00:42,361] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:00:43,255] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:00:43,257] {logging_mixin.py:115} INFO - [2023-01-07 22:00:43,257] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:00:43,257] {logging_mixin.py:115} INFO - [2023-01-07 22:00:43,257] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:00:43,269] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:00:43,301] {logging_mixin.py:115} INFO - [2023-01-07 22:00:43,301] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:00:43,332] {logging_mixin.py:115} INFO - [2023-01-07 22:00:43,332] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:00:43,347] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.992 seconds
[2023-01-07 22:01:13,457] {processor.py:153} INFO - Started process (PID=1316) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:01:13,459] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:01:13,460] {logging_mixin.py:115} INFO - [2023-01-07 22:01:13,460] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:01:14,326] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:01:14,327] {logging_mixin.py:115} INFO - [2023-01-07 22:01:14,327] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:01:14,327] {logging_mixin.py:115} INFO - [2023-01-07 22:01:14,327] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:01:14,335] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:01:14,359] {logging_mixin.py:115} INFO - [2023-01-07 22:01:14,359] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:01:14,380] {logging_mixin.py:115} INFO - [2023-01-07 22:01:14,380] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:01:14,391] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.939 seconds
[2023-01-07 22:01:44,495] {processor.py:153} INFO - Started process (PID=1342) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:01:44,496] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:01:44,497] {logging_mixin.py:115} INFO - [2023-01-07 22:01:44,497] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:01:45,304] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:01:45,305] {logging_mixin.py:115} INFO - [2023-01-07 22:01:45,305] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:01:45,306] {logging_mixin.py:115} INFO - [2023-01-07 22:01:45,305] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:01:45,313] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:01:45,336] {logging_mixin.py:115} INFO - [2023-01-07 22:01:45,335] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:01:45,356] {logging_mixin.py:115} INFO - [2023-01-07 22:01:45,356] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:01:45,367] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.877 seconds
[2023-01-07 22:02:15,558] {processor.py:153} INFO - Started process (PID=1366) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:02:15,559] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:02:15,560] {logging_mixin.py:115} INFO - [2023-01-07 22:02:15,560] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:02:16,357] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:02:16,358] {logging_mixin.py:115} INFO - [2023-01-07 22:02:16,358] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:02:16,359] {logging_mixin.py:115} INFO - [2023-01-07 22:02:16,358] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:02:16,366] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:02:16,388] {logging_mixin.py:115} INFO - [2023-01-07 22:02:16,388] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:02:16,409] {logging_mixin.py:115} INFO - [2023-01-07 22:02:16,408] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:02:16,419] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.866 seconds
[2023-01-07 22:02:46,499] {processor.py:153} INFO - Started process (PID=1385) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:02:46,499] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:02:46,500] {logging_mixin.py:115} INFO - [2023-01-07 22:02:46,500] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:02:47,376] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:02:47,378] {logging_mixin.py:115} INFO - [2023-01-07 22:02:47,378] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:02:47,378] {logging_mixin.py:115} INFO - [2023-01-07 22:02:47,378] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:02:47,389] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:02:47,412] {logging_mixin.py:115} INFO - [2023-01-07 22:02:47,412] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:02:47,433] {logging_mixin.py:115} INFO - [2023-01-07 22:02:47,433] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:02:47,444] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.950 seconds
[2023-01-07 22:03:17,525] {processor.py:153} INFO - Started process (PID=1412) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:03:17,526] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:03:17,527] {logging_mixin.py:115} INFO - [2023-01-07 22:03:17,527] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:03:18,347] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:03:18,348] {logging_mixin.py:115} INFO - [2023-01-07 22:03:18,348] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:03:18,348] {logging_mixin.py:115} INFO - [2023-01-07 22:03:18,348] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:03:18,356] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:03:18,379] {logging_mixin.py:115} INFO - [2023-01-07 22:03:18,379] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:03:18,400] {logging_mixin.py:115} INFO - [2023-01-07 22:03:18,400] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:03:18,412] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.892 seconds
[2023-01-07 22:03:48,977] {processor.py:153} INFO - Started process (PID=1436) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:03:48,978] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:03:48,979] {logging_mixin.py:115} INFO - [2023-01-07 22:03:48,979] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:03:49,790] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:03:49,791] {logging_mixin.py:115} INFO - [2023-01-07 22:03:49,791] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:03:49,791] {logging_mixin.py:115} INFO - [2023-01-07 22:03:49,791] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:03:49,799] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:03:49,822] {logging_mixin.py:115} INFO - [2023-01-07 22:03:49,822] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:03:49,842] {logging_mixin.py:115} INFO - [2023-01-07 22:03:49,842] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:03:49,853] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.881 seconds
[2023-01-07 22:04:19,955] {processor.py:153} INFO - Started process (PID=1461) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:04:19,957] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:04:19,958] {logging_mixin.py:115} INFO - [2023-01-07 22:04:19,958] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:04:21,072] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:04:21,074] {logging_mixin.py:115} INFO - [2023-01-07 22:04:21,074] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:04:21,075] {logging_mixin.py:115} INFO - [2023-01-07 22:04:21,075] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:04:21,087] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:04:21,118] {logging_mixin.py:115} INFO - [2023-01-07 22:04:21,117] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:04:21,141] {logging_mixin.py:115} INFO - [2023-01-07 22:04:21,141] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:04:21,153] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.203 seconds
[2023-01-07 22:04:51,228] {processor.py:153} INFO - Started process (PID=1479) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:04:51,228] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:04:51,229] {logging_mixin.py:115} INFO - [2023-01-07 22:04:51,229] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:04:52,043] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:04:52,045] {logging_mixin.py:115} INFO - [2023-01-07 22:04:52,045] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:04:52,045] {logging_mixin.py:115} INFO - [2023-01-07 22:04:52,045] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:04:52,052] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:04:52,075] {logging_mixin.py:115} INFO - [2023-01-07 22:04:52,075] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:04:52,095] {logging_mixin.py:115} INFO - [2023-01-07 22:04:52,095] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:04:52,106] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.883 seconds
[2023-01-07 22:05:22,214] {processor.py:153} INFO - Started process (PID=1505) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:05:22,216] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:05:22,217] {logging_mixin.py:115} INFO - [2023-01-07 22:05:22,217] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:05:23,015] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:05:23,016] {logging_mixin.py:115} INFO - [2023-01-07 22:05:23,016] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:05:23,017] {logging_mixin.py:115} INFO - [2023-01-07 22:05:23,016] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:05:23,024] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:05:23,047] {logging_mixin.py:115} INFO - [2023-01-07 22:05:23,047] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:05:23,068] {logging_mixin.py:115} INFO - [2023-01-07 22:05:23,068] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:05:23,079] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.871 seconds
[2023-01-07 22:05:53,324] {processor.py:153} INFO - Started process (PID=1531) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:05:53,326] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:05:53,327] {logging_mixin.py:115} INFO - [2023-01-07 22:05:53,327] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:05:54,175] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:05:54,176] {logging_mixin.py:115} INFO - [2023-01-07 22:05:54,176] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:05:54,176] {logging_mixin.py:115} INFO - [2023-01-07 22:05:54,176] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:05:54,184] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:05:54,208] {logging_mixin.py:115} INFO - [2023-01-07 22:05:54,207] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:05:54,228] {logging_mixin.py:115} INFO - [2023-01-07 22:05:54,228] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:05:54,239] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.921 seconds
[2023-01-07 22:06:24,342] {processor.py:153} INFO - Started process (PID=1550) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:06:24,343] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:06:24,344] {logging_mixin.py:115} INFO - [2023-01-07 22:06:24,344] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:06:25,361] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:06:25,362] {logging_mixin.py:115} INFO - [2023-01-07 22:06:25,362] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:06:25,363] {logging_mixin.py:115} INFO - [2023-01-07 22:06:25,362] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:06:25,370] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:06:25,393] {logging_mixin.py:115} INFO - [2023-01-07 22:06:25,393] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:06:25,414] {logging_mixin.py:115} INFO - [2023-01-07 22:06:25,414] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:06:25,426] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.090 seconds
[2023-01-07 22:06:55,505] {processor.py:153} INFO - Started process (PID=1575) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:06:55,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:06:55,509] {logging_mixin.py:115} INFO - [2023-01-07 22:06:55,509] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:06:56,312] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:06:56,313] {logging_mixin.py:115} INFO - [2023-01-07 22:06:56,313] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:06:56,314] {logging_mixin.py:115} INFO - [2023-01-07 22:06:56,313] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:06:56,321] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:06:56,343] {logging_mixin.py:115} INFO - [2023-01-07 22:06:56,343] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:06:56,363] {logging_mixin.py:115} INFO - [2023-01-07 22:06:56,363] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:06:56,373] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.873 seconds
[2023-01-07 22:07:26,475] {processor.py:153} INFO - Started process (PID=1601) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:07:26,476] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:07:26,477] {logging_mixin.py:115} INFO - [2023-01-07 22:07:26,477] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:07:27,271] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:07:27,272] {logging_mixin.py:115} INFO - [2023-01-07 22:07:27,272] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:07:27,273] {logging_mixin.py:115} INFO - [2023-01-07 22:07:27,272] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:07:27,280] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:07:27,302] {logging_mixin.py:115} INFO - [2023-01-07 22:07:27,302] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:07:27,322] {logging_mixin.py:115} INFO - [2023-01-07 22:07:27,322] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:07:27,333] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.863 seconds
[2023-01-07 22:07:57,658] {processor.py:153} INFO - Started process (PID=1625) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:07:57,659] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:07:57,659] {logging_mixin.py:115} INFO - [2023-01-07 22:07:57,659] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:07:58,446] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:07:58,447] {logging_mixin.py:115} INFO - [2023-01-07 22:07:58,447] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:07:58,448] {logging_mixin.py:115} INFO - [2023-01-07 22:07:58,448] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:07:58,455] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:07:58,484] {logging_mixin.py:115} INFO - [2023-01-07 22:07:58,484] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:07:58,505] {logging_mixin.py:115} INFO - [2023-01-07 22:07:58,504] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:07:58,515] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.862 seconds
[2023-01-07 22:08:28,935] {processor.py:153} INFO - Started process (PID=1643) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:08:28,936] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:08:28,936] {logging_mixin.py:115} INFO - [2023-01-07 22:08:28,936] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:08:29,808] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:08:29,810] {logging_mixin.py:115} INFO - [2023-01-07 22:08:29,810] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:08:29,811] {logging_mixin.py:115} INFO - [2023-01-07 22:08:29,810] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:08:29,823] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:08:29,854] {logging_mixin.py:115} INFO - [2023-01-07 22:08:29,853] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:08:29,883] {logging_mixin.py:115} INFO - [2023-01-07 22:08:29,883] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:08:29,897] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.967 seconds
[2023-01-07 22:09:00,004] {processor.py:153} INFO - Started process (PID=1669) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:09:00,005] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:09:00,005] {logging_mixin.py:115} INFO - [2023-01-07 22:09:00,005] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:09:00,820] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:09:00,821] {logging_mixin.py:115} INFO - [2023-01-07 22:09:00,821] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:09:00,821] {logging_mixin.py:115} INFO - [2023-01-07 22:09:00,821] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:09:00,828] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:09:00,851] {logging_mixin.py:115} INFO - [2023-01-07 22:09:00,851] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:09:00,872] {logging_mixin.py:115} INFO - [2023-01-07 22:09:00,871] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:09:00,882] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.883 seconds
[2023-01-07 22:09:30,985] {processor.py:153} INFO - Started process (PID=1695) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:09:30,986] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:09:30,986] {logging_mixin.py:115} INFO - [2023-01-07 22:09:30,986] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:09:31,793] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:09:31,794] {logging_mixin.py:115} INFO - [2023-01-07 22:09:31,794] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:09:31,795] {logging_mixin.py:115} INFO - [2023-01-07 22:09:31,794] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:09:31,802] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:09:31,825] {logging_mixin.py:115} INFO - [2023-01-07 22:09:31,824] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:09:31,845] {logging_mixin.py:115} INFO - [2023-01-07 22:09:31,845] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:09:31,857] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.877 seconds
[2023-01-07 22:10:02,078] {processor.py:153} INFO - Started process (PID=1721) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:10:02,079] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:10:02,080] {logging_mixin.py:115} INFO - [2023-01-07 22:10:02,080] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:10:03,074] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:10:03,075] {logging_mixin.py:115} INFO - [2023-01-07 22:10:03,075] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:10:03,075] {logging_mixin.py:115} INFO - [2023-01-07 22:10:03,075] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:10:03,082] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:10:03,105] {logging_mixin.py:115} INFO - [2023-01-07 22:10:03,104] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:10:03,126] {logging_mixin.py:115} INFO - [2023-01-07 22:10:03,126] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:10:03,137] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.065 seconds
[2023-01-07 22:10:33,205] {processor.py:153} INFO - Started process (PID=1740) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:10:33,206] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:10:33,206] {logging_mixin.py:115} INFO - [2023-01-07 22:10:33,206] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:10:34,008] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:10:34,009] {logging_mixin.py:115} INFO - [2023-01-07 22:10:34,009] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:10:34,010] {logging_mixin.py:115} INFO - [2023-01-07 22:10:34,009] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:10:34,017] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:10:34,040] {logging_mixin.py:115} INFO - [2023-01-07 22:10:34,039] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:10:34,059] {logging_mixin.py:115} INFO - [2023-01-07 22:10:34,059] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:10:34,070] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.870 seconds
[2023-01-07 22:11:04,155] {processor.py:153} INFO - Started process (PID=1764) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:11:04,156] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:11:04,157] {logging_mixin.py:115} INFO - [2023-01-07 22:11:04,157] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:11:04,954] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:11:04,955] {logging_mixin.py:115} INFO - [2023-01-07 22:11:04,955] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:11:04,955] {logging_mixin.py:115} INFO - [2023-01-07 22:11:04,955] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:11:04,963] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:11:04,985] {logging_mixin.py:115} INFO - [2023-01-07 22:11:04,985] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:11:05,006] {logging_mixin.py:115} INFO - [2023-01-07 22:11:05,006] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:11:05,016] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.866 seconds
[2023-01-07 22:11:35,114] {processor.py:153} INFO - Started process (PID=1789) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:11:35,116] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:11:35,116] {logging_mixin.py:115} INFO - [2023-01-07 22:11:35,116] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:11:35,968] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:11:35,970] {logging_mixin.py:115} INFO - [2023-01-07 22:11:35,970] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:11:35,971] {logging_mixin.py:115} INFO - [2023-01-07 22:11:35,970] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:11:35,978] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:11:36,000] {logging_mixin.py:115} INFO - [2023-01-07 22:11:36,000] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:11:36,021] {logging_mixin.py:115} INFO - [2023-01-07 22:11:36,021] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:11:36,032] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.924 seconds
[2023-01-07 22:12:06,132] {processor.py:153} INFO - Started process (PID=1813) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:12:06,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:12:06,134] {logging_mixin.py:115} INFO - [2023-01-07 22:12:06,134] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:12:07,014] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:12:07,016] {logging_mixin.py:115} INFO - [2023-01-07 22:12:07,015] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:12:07,016] {logging_mixin.py:115} INFO - [2023-01-07 22:12:07,016] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:12:07,023] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:12:07,045] {logging_mixin.py:115} INFO - [2023-01-07 22:12:07,045] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:12:07,066] {logging_mixin.py:115} INFO - [2023-01-07 22:12:07,066] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:12:07,077] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.951 seconds
[2023-01-07 22:12:37,176] {processor.py:153} INFO - Started process (PID=1831) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:12:37,178] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:12:37,179] {logging_mixin.py:115} INFO - [2023-01-07 22:12:37,178] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:12:37,996] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:12:37,997] {logging_mixin.py:115} INFO - [2023-01-07 22:12:37,997] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:12:37,998] {logging_mixin.py:115} INFO - [2023-01-07 22:12:37,997] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:12:38,005] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:12:38,028] {logging_mixin.py:115} INFO - [2023-01-07 22:12:38,027] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:12:38,048] {logging_mixin.py:115} INFO - [2023-01-07 22:12:38,048] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:12:38,058] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.889 seconds
[2023-01-07 22:13:08,164] {processor.py:153} INFO - Started process (PID=1856) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:13:08,165] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:13:08,165] {logging_mixin.py:115} INFO - [2023-01-07 22:13:08,165] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:13:09,126] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:13:09,128] {logging_mixin.py:115} INFO - [2023-01-07 22:13:09,127] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:13:09,128] {logging_mixin.py:115} INFO - [2023-01-07 22:13:09,128] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:13:09,135] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:13:09,158] {logging_mixin.py:115} INFO - [2023-01-07 22:13:09,158] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:13:09,181] {logging_mixin.py:115} INFO - [2023-01-07 22:13:09,181] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:13:09,198] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.040 seconds
[2023-01-07 22:13:39,289] {processor.py:153} INFO - Started process (PID=1882) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:13:39,290] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:13:39,291] {logging_mixin.py:115} INFO - [2023-01-07 22:13:39,291] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:13:40,152] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:13:40,154] {logging_mixin.py:115} INFO - [2023-01-07 22:13:40,154] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:13:40,154] {logging_mixin.py:115} INFO - [2023-01-07 22:13:40,154] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:13:40,161] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:13:40,190] {logging_mixin.py:115} INFO - [2023-01-07 22:13:40,190] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:13:40,217] {logging_mixin.py:115} INFO - [2023-01-07 22:13:40,217] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:13:40,233] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.949 seconds
[2023-01-07 22:14:10,336] {processor.py:153} INFO - Started process (PID=1906) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:14:10,340] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:14:10,341] {logging_mixin.py:115} INFO - [2023-01-07 22:14:10,341] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:14:11,509] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:14:11,511] {logging_mixin.py:115} INFO - [2023-01-07 22:14:11,511] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:14:11,511] {logging_mixin.py:115} INFO - [2023-01-07 22:14:11,511] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:14:11,518] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:14:11,541] {logging_mixin.py:115} INFO - [2023-01-07 22:14:11,541] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:14:11,561] {logging_mixin.py:115} INFO - [2023-01-07 22:14:11,561] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:14:11,572] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.247 seconds
[2023-01-07 22:14:41,640] {processor.py:153} INFO - Started process (PID=1926) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:14:41,642] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:14:41,643] {logging_mixin.py:115} INFO - [2023-01-07 22:14:41,642] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:14:42,731] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:14:42,732] {logging_mixin.py:115} INFO - [2023-01-07 22:14:42,732] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:14:42,733] {logging_mixin.py:115} INFO - [2023-01-07 22:14:42,733] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:14:42,740] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:14:42,763] {logging_mixin.py:115} INFO - [2023-01-07 22:14:42,762] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:14:42,783] {logging_mixin.py:115} INFO - [2023-01-07 22:14:42,783] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:14:42,794] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.159 seconds
[2023-01-07 22:15:12,868] {processor.py:153} INFO - Started process (PID=1952) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:15:12,869] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:15:12,870] {logging_mixin.py:115} INFO - [2023-01-07 22:15:12,870] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:15:13,666] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:15:13,667] {logging_mixin.py:115} INFO - [2023-01-07 22:15:13,667] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:15:13,668] {logging_mixin.py:115} INFO - [2023-01-07 22:15:13,668] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:15:13,675] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:15:13,698] {logging_mixin.py:115} INFO - [2023-01-07 22:15:13,698] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:15:13,718] {logging_mixin.py:115} INFO - [2023-01-07 22:15:13,718] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:15:13,729] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.866 seconds
[2023-01-07 22:15:43,763] {processor.py:153} INFO - Started process (PID=1977) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:15:43,765] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:15:43,766] {logging_mixin.py:115} INFO - [2023-01-07 22:15:43,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:15:44,576] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:15:44,577] {logging_mixin.py:115} INFO - [2023-01-07 22:15:44,577] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:15:44,578] {logging_mixin.py:115} INFO - [2023-01-07 22:15:44,577] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:15:44,585] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:15:44,607] {logging_mixin.py:115} INFO - [2023-01-07 22:15:44,607] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:15:44,627] {logging_mixin.py:115} INFO - [2023-01-07 22:15:44,627] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:15:44,638] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.880 seconds
[2023-01-07 22:16:14,735] {processor.py:153} INFO - Started process (PID=2001) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:16:14,737] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:16:14,738] {logging_mixin.py:115} INFO - [2023-01-07 22:16:14,738] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:16:15,588] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:16:15,589] {logging_mixin.py:115} INFO - [2023-01-07 22:16:15,589] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:16:15,590] {logging_mixin.py:115} INFO - [2023-01-07 22:16:15,589] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:16:15,597] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:16:15,659] {logging_mixin.py:115} INFO - [2023-01-07 22:16:15,658] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:16:15,689] {logging_mixin.py:115} INFO - [2023-01-07 22:16:15,689] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:16:15,703] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.973 seconds
[2023-01-07 22:16:45,857] {processor.py:153} INFO - Started process (PID=2019) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:16:45,858] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:16:45,859] {logging_mixin.py:115} INFO - [2023-01-07 22:16:45,858] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:16:46,675] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:16:46,676] {logging_mixin.py:115} INFO - [2023-01-07 22:16:46,676] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:16:46,677] {logging_mixin.py:115} INFO - [2023-01-07 22:16:46,676] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:16:46,684] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:16:46,706] {logging_mixin.py:115} INFO - [2023-01-07 22:16:46,706] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:16:46,726] {logging_mixin.py:115} INFO - [2023-01-07 22:16:46,726] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:16:46,737] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.885 seconds
[2023-01-07 22:17:17,327] {processor.py:153} INFO - Started process (PID=2044) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:17:17,328] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:17:17,329] {logging_mixin.py:115} INFO - [2023-01-07 22:17:17,329] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:17:18,270] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:17:18,271] {logging_mixin.py:115} INFO - [2023-01-07 22:17:18,271] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:17:18,272] {logging_mixin.py:115} INFO - [2023-01-07 22:17:18,271] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:17:18,279] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:17:18,301] {logging_mixin.py:115} INFO - [2023-01-07 22:17:18,301] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:17:18,321] {logging_mixin.py:115} INFO - [2023-01-07 22:17:18,321] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:17:18,332] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.010 seconds
[2023-01-07 22:17:48,435] {processor.py:153} INFO - Started process (PID=2070) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:17:48,435] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:17:48,436] {logging_mixin.py:115} INFO - [2023-01-07 22:17:48,436] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:17:49,419] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:17:49,420] {logging_mixin.py:115} INFO - [2023-01-07 22:17:49,420] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:17:49,421] {logging_mixin.py:115} INFO - [2023-01-07 22:17:49,420] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:17:49,429] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:17:49,452] {logging_mixin.py:115} INFO - [2023-01-07 22:17:49,452] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:17:49,472] {logging_mixin.py:115} INFO - [2023-01-07 22:17:49,472] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:17:49,483] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.053 seconds
[2023-01-07 22:18:19,595] {processor.py:153} INFO - Started process (PID=2095) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:18:19,595] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:18:19,596] {logging_mixin.py:115} INFO - [2023-01-07 22:18:19,596] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:18:20,563] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:18:20,565] {logging_mixin.py:115} INFO - [2023-01-07 22:18:20,565] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:18:20,565] {logging_mixin.py:115} INFO - [2023-01-07 22:18:20,565] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:18:20,572] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:18:20,597] {logging_mixin.py:115} INFO - [2023-01-07 22:18:20,597] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:18:20,617] {logging_mixin.py:115} INFO - [2023-01-07 22:18:20,617] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:18:20,628] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.038 seconds
[2023-01-07 22:18:50,730] {processor.py:153} INFO - Started process (PID=2112) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:18:50,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:18:50,732] {logging_mixin.py:115} INFO - [2023-01-07 22:18:50,732] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:18:51,682] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:18:51,684] {logging_mixin.py:115} INFO - [2023-01-07 22:18:51,684] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:18:51,685] {logging_mixin.py:115} INFO - [2023-01-07 22:18:51,684] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:18:51,697] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:18:51,732] {logging_mixin.py:115} INFO - [2023-01-07 22:18:51,732] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:18:51,762] {logging_mixin.py:115} INFO - [2023-01-07 22:18:51,761] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:18:51,775] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.050 seconds
[2023-01-07 22:19:21,874] {processor.py:153} INFO - Started process (PID=2138) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:19:21,875] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:19:21,875] {logging_mixin.py:115} INFO - [2023-01-07 22:19:21,875] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:19:22,807] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:19:22,809] {logging_mixin.py:115} INFO - [2023-01-07 22:19:22,808] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:19:22,809] {logging_mixin.py:115} INFO - [2023-01-07 22:19:22,809] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:19:22,816] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:19:22,838] {logging_mixin.py:115} INFO - [2023-01-07 22:19:22,838] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:19:22,858] {logging_mixin.py:115} INFO - [2023-01-07 22:19:22,858] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:19:22,869] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.999 seconds
[2023-01-07 22:19:52,962] {processor.py:153} INFO - Started process (PID=2165) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:19:52,963] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:19:52,964] {logging_mixin.py:115} INFO - [2023-01-07 22:19:52,964] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:19:53,790] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:19:53,791] {logging_mixin.py:115} INFO - [2023-01-07 22:19:53,791] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:19:53,792] {logging_mixin.py:115} INFO - [2023-01-07 22:19:53,792] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:19:53,801] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:19:53,823] {logging_mixin.py:115} INFO - [2023-01-07 22:19:53,823] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:19:53,843] {logging_mixin.py:115} INFO - [2023-01-07 22:19:53,843] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:19:53,854] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.896 seconds
[2023-01-07 22:20:24,260] {processor.py:153} INFO - Started process (PID=2190) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:20:24,269] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:20:24,270] {logging_mixin.py:115} INFO - [2023-01-07 22:20:24,270] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:20:25,095] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:20:25,096] {logging_mixin.py:115} INFO - [2023-01-07 22:20:25,096] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:20:25,097] {logging_mixin.py:115} INFO - [2023-01-07 22:20:25,097] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:20:25,104] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:20:25,127] {logging_mixin.py:115} INFO - [2023-01-07 22:20:25,127] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:20:25,147] {logging_mixin.py:115} INFO - [2023-01-07 22:20:25,147] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:20:25,157] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.905 seconds
[2023-01-07 22:20:55,335] {processor.py:153} INFO - Started process (PID=2208) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:20:55,337] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:20:55,337] {logging_mixin.py:115} INFO - [2023-01-07 22:20:55,337] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:20:56,261] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:20:56,262] {logging_mixin.py:115} INFO - [2023-01-07 22:20:56,262] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:20:56,263] {logging_mixin.py:115} INFO - [2023-01-07 22:20:56,263] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:20:56,275] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:20:56,306] {logging_mixin.py:115} INFO - [2023-01-07 22:20:56,306] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:20:56,335] {logging_mixin.py:115} INFO - [2023-01-07 22:20:56,335] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:20:56,349] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.019 seconds
[2023-01-07 22:21:26,454] {processor.py:153} INFO - Started process (PID=2234) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:21:26,455] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:21:26,456] {logging_mixin.py:115} INFO - [2023-01-07 22:21:26,456] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:21:27,275] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:21:27,276] {logging_mixin.py:115} INFO - [2023-01-07 22:21:27,276] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:21:27,276] {logging_mixin.py:115} INFO - [2023-01-07 22:21:27,276] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:21:27,284] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:21:27,306] {logging_mixin.py:115} INFO - [2023-01-07 22:21:27,306] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:21:27,326] {logging_mixin.py:115} INFO - [2023-01-07 22:21:27,326] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:21:27,337] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.888 seconds
[2023-01-07 22:21:57,429] {processor.py:153} INFO - Started process (PID=2259) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:21:57,431] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:21:57,431] {logging_mixin.py:115} INFO - [2023-01-07 22:21:57,431] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:21:58,277] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:21:58,278] {logging_mixin.py:115} INFO - [2023-01-07 22:21:58,278] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:21:58,279] {logging_mixin.py:115} INFO - [2023-01-07 22:21:58,279] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:21:58,286] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:21:58,316] {logging_mixin.py:115} INFO - [2023-01-07 22:21:58,316] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:21:58,345] {logging_mixin.py:115} INFO - [2023-01-07 22:21:58,345] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:21:58,360] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.936 seconds
[2023-01-07 22:22:28,833] {processor.py:153} INFO - Started process (PID=2284) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:22:28,834] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:22:28,834] {logging_mixin.py:115} INFO - [2023-01-07 22:22:28,834] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:22:29,640] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:22:29,641] {logging_mixin.py:115} INFO - [2023-01-07 22:22:29,641] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:22:29,642] {logging_mixin.py:115} INFO - [2023-01-07 22:22:29,642] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:22:29,649] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:22:29,671] {logging_mixin.py:115} INFO - [2023-01-07 22:22:29,671] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:22:29,691] {logging_mixin.py:115} INFO - [2023-01-07 22:22:29,691] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:22:29,702] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.873 seconds
[2023-01-07 22:22:59,809] {processor.py:153} INFO - Started process (PID=2301) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:22:59,810] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:22:59,811] {logging_mixin.py:115} INFO - [2023-01-07 22:22:59,811] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:23:00,842] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:23:00,843] {logging_mixin.py:115} INFO - [2023-01-07 22:23:00,843] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:23:00,844] {logging_mixin.py:115} INFO - [2023-01-07 22:23:00,844] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:23:00,851] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:23:00,874] {logging_mixin.py:115} INFO - [2023-01-07 22:23:00,874] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:23:00,895] {logging_mixin.py:115} INFO - [2023-01-07 22:23:00,895] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:23:00,906] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.102 seconds
[2023-01-07 22:23:31,010] {processor.py:153} INFO - Started process (PID=2326) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:23:31,012] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:23:31,012] {logging_mixin.py:115} INFO - [2023-01-07 22:23:31,012] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:23:31,823] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:23:31,825] {logging_mixin.py:115} INFO - [2023-01-07 22:23:31,825] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:23:31,825] {logging_mixin.py:115} INFO - [2023-01-07 22:23:31,825] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:23:31,833] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:23:31,855] {logging_mixin.py:115} INFO - [2023-01-07 22:23:31,855] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:23:31,875] {logging_mixin.py:115} INFO - [2023-01-07 22:23:31,875] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:23:31,887] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.881 seconds
[2023-01-07 22:24:01,981] {processor.py:153} INFO - Started process (PID=2350) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:24:01,982] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:24:01,983] {logging_mixin.py:115} INFO - [2023-01-07 22:24:01,982] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:24:02,809] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:24:02,810] {logging_mixin.py:115} INFO - [2023-01-07 22:24:02,810] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:24:02,810] {logging_mixin.py:115} INFO - [2023-01-07 22:24:02,810] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:24:02,818] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:24:02,840] {logging_mixin.py:115} INFO - [2023-01-07 22:24:02,840] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:24:02,864] {logging_mixin.py:115} INFO - [2023-01-07 22:24:02,864] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:24:02,880] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.904 seconds
[2023-01-07 22:24:33,233] {processor.py:153} INFO - Started process (PID=2374) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:24:33,234] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:24:33,234] {logging_mixin.py:115} INFO - [2023-01-07 22:24:33,234] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:24:34,032] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:24:34,033] {logging_mixin.py:115} INFO - [2023-01-07 22:24:34,033] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:24:34,034] {logging_mixin.py:115} INFO - [2023-01-07 22:24:34,033] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:24:34,041] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:24:34,063] {logging_mixin.py:115} INFO - [2023-01-07 22:24:34,063] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:24:34,083] {logging_mixin.py:115} INFO - [2023-01-07 22:24:34,083] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:24:34,093] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.864 seconds
[2023-01-07 22:25:04,186] {processor.py:153} INFO - Started process (PID=2392) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:25:04,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:25:04,188] {logging_mixin.py:115} INFO - [2023-01-07 22:25:04,188] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:25:05,218] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:25:05,220] {logging_mixin.py:115} INFO - [2023-01-07 22:25:05,220] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:25:05,221] {logging_mixin.py:115} INFO - [2023-01-07 22:25:05,220] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:25:05,233] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:25:05,264] {logging_mixin.py:115} INFO - [2023-01-07 22:25:05,264] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:25:05,298] {logging_mixin.py:115} INFO - [2023-01-07 22:25:05,298] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:25:05,313] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.132 seconds
[2023-01-07 22:25:35,427] {processor.py:153} INFO - Started process (PID=2417) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:25:35,428] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:25:35,429] {logging_mixin.py:115} INFO - [2023-01-07 22:25:35,429] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:25:36,297] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:25:36,298] {logging_mixin.py:115} INFO - [2023-01-07 22:25:36,298] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:25:36,299] {logging_mixin.py:115} INFO - [2023-01-07 22:25:36,298] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:25:36,306] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:25:36,336] {logging_mixin.py:115} INFO - [2023-01-07 22:25:36,335] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:25:36,365] {logging_mixin.py:115} INFO - [2023-01-07 22:25:36,365] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:25:36,380] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.958 seconds
[2023-01-07 22:26:06,647] {processor.py:153} INFO - Started process (PID=2441) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:26:06,652] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:26:06,652] {logging_mixin.py:115} INFO - [2023-01-07 22:26:06,652] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:26:07,528] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:26:07,529] {logging_mixin.py:115} INFO - [2023-01-07 22:26:07,529] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:26:07,529] {logging_mixin.py:115} INFO - [2023-01-07 22:26:07,529] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:26:07,537] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:26:07,560] {logging_mixin.py:115} INFO - [2023-01-07 22:26:07,559] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:26:07,580] {logging_mixin.py:115} INFO - [2023-01-07 22:26:07,580] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:26:07,591] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.948 seconds
[2023-01-07 22:26:37,789] {processor.py:153} INFO - Started process (PID=2467) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:26:37,789] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:26:37,790] {logging_mixin.py:115} INFO - [2023-01-07 22:26:37,790] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:26:38,587] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:26:38,589] {logging_mixin.py:115} INFO - [2023-01-07 22:26:38,589] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:26:38,589] {logging_mixin.py:115} INFO - [2023-01-07 22:26:38,589] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:26:38,596] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:26:38,619] {logging_mixin.py:115} INFO - [2023-01-07 22:26:38,618] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:26:38,638] {logging_mixin.py:115} INFO - [2023-01-07 22:26:38,638] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:26:38,649] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.866 seconds
[2023-01-07 22:27:08,746] {processor.py:153} INFO - Started process (PID=2486) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:27:08,748] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:27:08,748] {logging_mixin.py:115} INFO - [2023-01-07 22:27:08,748] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:27:09,696] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:27:09,698] {logging_mixin.py:115} INFO - [2023-01-07 22:27:09,698] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:27:09,698] {logging_mixin.py:115} INFO - [2023-01-07 22:27:09,698] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:27:09,710] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:27:09,735] {logging_mixin.py:115} INFO - [2023-01-07 22:27:09,735] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:27:09,757] {logging_mixin.py:115} INFO - [2023-01-07 22:27:09,757] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:27:09,768] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.026 seconds
[2023-01-07 22:27:39,869] {processor.py:153} INFO - Started process (PID=2512) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:27:39,869] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:27:39,870] {logging_mixin.py:115} INFO - [2023-01-07 22:27:39,870] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:27:40,679] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:27:40,680] {logging_mixin.py:115} INFO - [2023-01-07 22:27:40,680] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:27:40,680] {logging_mixin.py:115} INFO - [2023-01-07 22:27:40,680] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:27:40,688] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:27:40,710] {logging_mixin.py:115} INFO - [2023-01-07 22:27:40,710] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:27:40,730] {logging_mixin.py:115} INFO - [2023-01-07 22:27:40,730] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:27:40,741] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.877 seconds
[2023-01-07 22:28:10,852] {processor.py:153} INFO - Started process (PID=2538) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:28:10,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:28:10,856] {logging_mixin.py:115} INFO - [2023-01-07 22:28:10,856] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:28:11,657] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:28:11,658] {logging_mixin.py:115} INFO - [2023-01-07 22:28:11,658] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:28:11,659] {logging_mixin.py:115} INFO - [2023-01-07 22:28:11,658] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:28:11,666] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:28:11,695] {logging_mixin.py:115} INFO - [2023-01-07 22:28:11,695] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:28:11,716] {logging_mixin.py:115} INFO - [2023-01-07 22:28:11,716] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:28:11,726] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.879 seconds
[2023-01-07 22:28:41,816] {processor.py:153} INFO - Started process (PID=2563) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:28:41,817] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:28:41,818] {logging_mixin.py:115} INFO - [2023-01-07 22:28:41,818] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:28:42,629] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:28:42,630] {logging_mixin.py:115} INFO - [2023-01-07 22:28:42,630] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:28:42,631] {logging_mixin.py:115} INFO - [2023-01-07 22:28:42,630] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:28:42,638] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:28:42,667] {logging_mixin.py:115} INFO - [2023-01-07 22:28:42,667] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:28:42,698] {logging_mixin.py:115} INFO - [2023-01-07 22:28:42,698] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:28:42,710] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.898 seconds
[2023-01-07 22:29:13,159] {processor.py:153} INFO - Started process (PID=2580) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:29:13,159] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:29:13,160] {logging_mixin.py:115} INFO - [2023-01-07 22:29:13,160] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:29:14,174] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:29:14,176] {logging_mixin.py:115} INFO - [2023-01-07 22:29:14,175] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:29:14,176] {logging_mixin.py:115} INFO - [2023-01-07 22:29:14,176] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:29:14,183] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:29:14,205] {logging_mixin.py:115} INFO - [2023-01-07 22:29:14,205] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:29:14,228] {logging_mixin.py:115} INFO - [2023-01-07 22:29:14,228] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:29:14,237] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.083 seconds
[2023-01-07 22:29:44,267] {processor.py:153} INFO - Started process (PID=2605) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:29:44,268] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:29:44,268] {logging_mixin.py:115} INFO - [2023-01-07 22:29:44,268] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:29:45,070] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:29:45,072] {logging_mixin.py:115} INFO - [2023-01-07 22:29:45,072] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:29:45,072] {logging_mixin.py:115} INFO - [2023-01-07 22:29:45,072] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:29:45,080] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:29:45,102] {logging_mixin.py:115} INFO - [2023-01-07 22:29:45,102] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:29:45,123] {logging_mixin.py:115} INFO - [2023-01-07 22:29:45,123] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:29:45,132] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.870 seconds
[2023-01-07 22:30:15,228] {processor.py:153} INFO - Started process (PID=2630) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:30:15,230] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:30:15,230] {logging_mixin.py:115} INFO - [2023-01-07 22:30:15,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:30:16,050] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:30:16,051] {logging_mixin.py:115} INFO - [2023-01-07 22:30:16,051] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:30:16,051] {logging_mixin.py:115} INFO - [2023-01-07 22:30:16,051] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:30:16,059] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:30:16,083] {logging_mixin.py:115} INFO - [2023-01-07 22:30:16,083] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:30:16,106] {logging_mixin.py:115} INFO - [2023-01-07 22:30:16,106] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:30:16,116] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.892 seconds
[2023-01-07 22:30:46,208] {processor.py:153} INFO - Started process (PID=2656) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:30:46,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:30:46,211] {logging_mixin.py:115} INFO - [2023-01-07 22:30:46,211] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:30:47,071] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:30:47,072] {logging_mixin.py:115} INFO - [2023-01-07 22:30:47,072] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:30:47,073] {logging_mixin.py:115} INFO - [2023-01-07 22:30:47,073] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:30:47,081] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:30:47,102] {logging_mixin.py:115} INFO - [2023-01-07 22:30:47,102] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:30:47,123] {logging_mixin.py:115} INFO - [2023-01-07 22:30:47,123] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:30:47,132] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.929 seconds
[2023-01-07 22:31:17,385] {processor.py:153} INFO - Started process (PID=2675) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:31:17,386] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:31:17,387] {logging_mixin.py:115} INFO - [2023-01-07 22:31:17,387] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:31:18,201] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:31:18,202] {logging_mixin.py:115} INFO - [2023-01-07 22:31:18,202] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:31:18,203] {logging_mixin.py:115} INFO - [2023-01-07 22:31:18,203] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:31:18,210] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:31:18,232] {logging_mixin.py:115} INFO - [2023-01-07 22:31:18,232] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:31:18,254] {logging_mixin.py:115} INFO - [2023-01-07 22:31:18,254] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:31:18,264] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.883 seconds
[2023-01-07 22:31:48,469] {processor.py:153} INFO - Started process (PID=2700) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:31:48,472] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:31:48,473] {logging_mixin.py:115} INFO - [2023-01-07 22:31:48,473] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:31:49,303] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:31:49,304] {logging_mixin.py:115} INFO - [2023-01-07 22:31:49,304] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:31:49,304] {logging_mixin.py:115} INFO - [2023-01-07 22:31:49,304] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:31:49,311] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:31:49,334] {logging_mixin.py:115} INFO - [2023-01-07 22:31:49,333] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:31:49,355] {logging_mixin.py:115} INFO - [2023-01-07 22:31:49,355] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:31:49,364] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.899 seconds
[2023-01-07 22:32:19,466] {processor.py:153} INFO - Started process (PID=2725) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:32:19,467] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:32:19,468] {logging_mixin.py:115} INFO - [2023-01-07 22:32:19,468] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:32:20,299] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:32:20,301] {logging_mixin.py:115} INFO - [2023-01-07 22:32:20,301] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:32:20,301] {logging_mixin.py:115} INFO - [2023-01-07 22:32:20,301] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:32:20,309] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:32:20,334] {logging_mixin.py:115} INFO - [2023-01-07 22:32:20,334] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:32:20,358] {logging_mixin.py:115} INFO - [2023-01-07 22:32:20,358] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:32:20,368] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.906 seconds
[2023-01-07 22:32:50,651] {processor.py:153} INFO - Started process (PID=2751) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:32:50,653] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:32:50,654] {logging_mixin.py:115} INFO - [2023-01-07 22:32:50,654] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:32:51,550] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:32:51,552] {logging_mixin.py:115} INFO - [2023-01-07 22:32:51,552] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:32:51,552] {logging_mixin.py:115} INFO - [2023-01-07 22:32:51,552] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:32:51,559] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:32:51,584] {logging_mixin.py:115} INFO - [2023-01-07 22:32:51,583] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:32:51,606] {logging_mixin.py:115} INFO - [2023-01-07 22:32:51,605] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:32:51,615] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.969 seconds
[2023-01-07 22:33:21,758] {processor.py:153} INFO - Started process (PID=2769) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:33:21,759] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:33:21,759] {logging_mixin.py:115} INFO - [2023-01-07 22:33:21,759] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:33:22,621] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:33:22,622] {logging_mixin.py:115} INFO - [2023-01-07 22:33:22,622] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:33:22,623] {logging_mixin.py:115} INFO - [2023-01-07 22:33:22,622] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:33:22,630] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:33:22,652] {logging_mixin.py:115} INFO - [2023-01-07 22:33:22,652] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:33:22,673] {logging_mixin.py:115} INFO - [2023-01-07 22:33:22,673] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:33:22,683] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.930 seconds
[2023-01-07 22:33:52,850] {processor.py:153} INFO - Started process (PID=2795) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:33:52,851] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:33:52,852] {logging_mixin.py:115} INFO - [2023-01-07 22:33:52,852] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:33:53,658] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:33:53,659] {logging_mixin.py:115} INFO - [2023-01-07 22:33:53,659] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:33:53,660] {logging_mixin.py:115} INFO - [2023-01-07 22:33:53,660] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:33:53,667] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:33:53,689] {logging_mixin.py:115} INFO - [2023-01-07 22:33:53,689] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:33:53,711] {logging_mixin.py:115} INFO - [2023-01-07 22:33:53,710] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:33:53,720] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.874 seconds
[2023-01-07 22:34:23,815] {processor.py:153} INFO - Started process (PID=2820) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:34:23,816] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:34:23,817] {logging_mixin.py:115} INFO - [2023-01-07 22:34:23,816] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:34:24,934] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:34:24,936] {logging_mixin.py:115} INFO - [2023-01-07 22:34:24,936] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:34:24,937] {logging_mixin.py:115} INFO - [2023-01-07 22:34:24,936] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:34:24,945] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:34:24,968] {logging_mixin.py:115} INFO - [2023-01-07 22:34:24,967] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:34:24,989] {logging_mixin.py:115} INFO - [2023-01-07 22:34:24,989] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:34:24,998] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.187 seconds
[2023-01-07 22:34:55,035] {processor.py:153} INFO - Started process (PID=2838) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:34:55,036] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:34:55,037] {logging_mixin.py:115} INFO - [2023-01-07 22:34:55,037] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:34:56,166] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:34:56,168] {logging_mixin.py:115} INFO - [2023-01-07 22:34:56,168] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:34:56,169] {logging_mixin.py:115} INFO - [2023-01-07 22:34:56,168] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:34:56,181] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:34:56,212] {logging_mixin.py:115} INFO - [2023-01-07 22:34:56,212] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:34:56,243] {logging_mixin.py:115} INFO - [2023-01-07 22:34:56,243] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:34:56,256] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.225 seconds
[2023-01-07 22:35:26,362] {processor.py:153} INFO - Started process (PID=2863) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:35:26,362] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:35:26,363] {logging_mixin.py:115} INFO - [2023-01-07 22:35:26,363] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:35:27,160] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:35:27,162] {logging_mixin.py:115} INFO - [2023-01-07 22:35:27,162] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:35:27,162] {logging_mixin.py:115} INFO - [2023-01-07 22:35:27,162] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:35:27,169] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:35:27,192] {logging_mixin.py:115} INFO - [2023-01-07 22:35:27,192] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:35:27,214] {logging_mixin.py:115} INFO - [2023-01-07 22:35:27,214] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:35:27,223] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.866 seconds
[2023-01-07 22:35:57,319] {processor.py:153} INFO - Started process (PID=2888) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:35:57,320] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:35:57,321] {logging_mixin.py:115} INFO - [2023-01-07 22:35:57,321] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:35:58,171] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:35:58,172] {logging_mixin.py:115} INFO - [2023-01-07 22:35:58,172] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:35:58,173] {logging_mixin.py:115} INFO - [2023-01-07 22:35:58,172] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:35:58,180] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:35:58,202] {logging_mixin.py:115} INFO - [2023-01-07 22:35:58,202] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:35:58,223] {logging_mixin.py:115} INFO - [2023-01-07 22:35:58,223] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:35:58,232] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.918 seconds
[2023-01-07 22:36:28,572] {processor.py:153} INFO - Started process (PID=2913) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:36:28,573] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:36:28,574] {logging_mixin.py:115} INFO - [2023-01-07 22:36:28,573] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:36:29,380] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:36:29,382] {logging_mixin.py:115} INFO - [2023-01-07 22:36:29,382] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:36:29,382] {logging_mixin.py:115} INFO - [2023-01-07 22:36:29,382] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:36:29,389] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:36:29,412] {logging_mixin.py:115} INFO - [2023-01-07 22:36:29,412] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:36:29,434] {logging_mixin.py:115} INFO - [2023-01-07 22:36:29,433] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:36:29,443] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.876 seconds
[2023-01-07 22:36:59,540] {processor.py:153} INFO - Started process (PID=2931) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:36:59,541] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:36:59,542] {logging_mixin.py:115} INFO - [2023-01-07 22:36:59,542] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:37:00,407] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:37:00,409] {logging_mixin.py:115} INFO - [2023-01-07 22:37:00,409] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:37:00,412] {logging_mixin.py:115} INFO - [2023-01-07 22:37:00,410] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:37:00,424] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:37:00,455] {logging_mixin.py:115} INFO - [2023-01-07 22:37:00,454] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:37:00,488] {logging_mixin.py:115} INFO - [2023-01-07 22:37:00,488] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:37:00,504] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.968 seconds
[2023-01-07 22:37:30,592] {processor.py:153} INFO - Started process (PID=2956) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:37:30,593] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:37:30,593] {logging_mixin.py:115} INFO - [2023-01-07 22:37:30,593] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:37:31,423] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:37:31,424] {logging_mixin.py:115} INFO - [2023-01-07 22:37:31,424] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:37:31,425] {logging_mixin.py:115} INFO - [2023-01-07 22:37:31,425] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:37:31,432] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:37:31,455] {logging_mixin.py:115} INFO - [2023-01-07 22:37:31,455] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:37:31,477] {logging_mixin.py:115} INFO - [2023-01-07 22:37:31,476] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:37:31,486] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.899 seconds
[2023-01-07 22:38:02,165] {processor.py:153} INFO - Started process (PID=2982) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:38:02,167] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:38:02,167] {logging_mixin.py:115} INFO - [2023-01-07 22:38:02,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:38:02,979] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:38:02,980] {logging_mixin.py:115} INFO - [2023-01-07 22:38:02,980] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:38:02,981] {logging_mixin.py:115} INFO - [2023-01-07 22:38:02,980] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:38:02,988] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:38:03,010] {logging_mixin.py:115} INFO - [2023-01-07 22:38:03,010] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:38:03,038] {logging_mixin.py:115} INFO - [2023-01-07 22:38:03,038] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:38:03,048] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.887 seconds
[2023-01-07 22:38:33,329] {processor.py:153} INFO - Started process (PID=3006) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:38:33,333] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:38:33,334] {logging_mixin.py:115} INFO - [2023-01-07 22:38:33,334] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:38:34,213] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:38:34,214] {logging_mixin.py:115} INFO - [2023-01-07 22:38:34,214] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:38:34,215] {logging_mixin.py:115} INFO - [2023-01-07 22:38:34,215] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:38:34,222] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:38:34,249] {logging_mixin.py:115} INFO - [2023-01-07 22:38:34,248] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:38:34,277] {logging_mixin.py:115} INFO - [2023-01-07 22:38:34,277] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:38:34,287] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.963 seconds
[2023-01-07 22:39:04,412] {processor.py:153} INFO - Started process (PID=3023) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:39:04,413] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:39:04,414] {logging_mixin.py:115} INFO - [2023-01-07 22:39:04,414] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:39:05,367] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:39:05,368] {logging_mixin.py:115} INFO - [2023-01-07 22:39:05,368] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:39:05,369] {logging_mixin.py:115} INFO - [2023-01-07 22:39:05,369] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:39:05,381] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:39:05,411] {logging_mixin.py:115} INFO - [2023-01-07 22:39:05,410] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:39:05,443] {logging_mixin.py:115} INFO - [2023-01-07 22:39:05,443] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:39:05,455] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.049 seconds
[2023-01-07 22:39:35,547] {processor.py:153} INFO - Started process (PID=3047) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:39:35,549] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:39:35,550] {logging_mixin.py:115} INFO - [2023-01-07 22:39:35,550] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:39:36,361] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:39:36,363] {logging_mixin.py:115} INFO - [2023-01-07 22:39:36,363] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:39:36,363] {logging_mixin.py:115} INFO - [2023-01-07 22:39:36,363] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:39:36,371] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:39:36,394] {logging_mixin.py:115} INFO - [2023-01-07 22:39:36,394] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:39:36,416] {logging_mixin.py:115} INFO - [2023-01-07 22:39:36,416] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:39:36,425] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.883 seconds
[2023-01-07 22:40:06,503] {processor.py:153} INFO - Started process (PID=3072) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:40:06,505] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:40:06,505] {logging_mixin.py:115} INFO - [2023-01-07 22:40:06,505] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:40:07,298] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:40:07,299] {logging_mixin.py:115} INFO - [2023-01-07 22:40:07,299] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:40:07,300] {logging_mixin.py:115} INFO - [2023-01-07 22:40:07,300] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:40:07,307] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:40:07,335] {logging_mixin.py:115} INFO - [2023-01-07 22:40:07,335] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:40:07,362] {logging_mixin.py:115} INFO - [2023-01-07 22:40:07,362] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:40:07,372] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.873 seconds
[2023-01-07 22:40:37,446] {processor.py:153} INFO - Started process (PID=3097) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:40:37,448] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:40:37,449] {logging_mixin.py:115} INFO - [2023-01-07 22:40:37,449] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:40:38,562] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:40:38,564] {logging_mixin.py:115} INFO - [2023-01-07 22:40:38,564] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:40:38,565] {logging_mixin.py:115} INFO - [2023-01-07 22:40:38,564] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:40:38,575] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:40:38,605] {logging_mixin.py:115} INFO - [2023-01-07 22:40:38,604] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:40:38,635] {logging_mixin.py:115} INFO - [2023-01-07 22:40:38,635] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:40:38,648] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.207 seconds
[2023-01-07 22:41:08,725] {processor.py:153} INFO - Started process (PID=3117) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:41:08,726] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:41:08,726] {logging_mixin.py:115} INFO - [2023-01-07 22:41:08,726] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:41:09,536] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:41:09,537] {logging_mixin.py:115} INFO - [2023-01-07 22:41:09,537] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:41:09,538] {logging_mixin.py:115} INFO - [2023-01-07 22:41:09,538] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:41:09,545] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:41:09,568] {logging_mixin.py:115} INFO - [2023-01-07 22:41:09,567] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:41:09,589] {logging_mixin.py:115} INFO - [2023-01-07 22:41:09,589] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:41:09,599] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.880 seconds
[2023-01-07 22:41:39,675] {processor.py:153} INFO - Started process (PID=3143) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:41:39,676] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:41:39,677] {logging_mixin.py:115} INFO - [2023-01-07 22:41:39,677] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:41:40,501] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:41:40,502] {logging_mixin.py:115} INFO - [2023-01-07 22:41:40,502] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:41:40,502] {logging_mixin.py:115} INFO - [2023-01-07 22:41:40,502] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:41:40,509] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:41:40,532] {logging_mixin.py:115} INFO - [2023-01-07 22:41:40,531] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:41:40,553] {logging_mixin.py:115} INFO - [2023-01-07 22:41:40,553] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:41:40,563] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.893 seconds
[2023-01-07 22:42:10,637] {processor.py:153} INFO - Started process (PID=3169) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:42:10,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:42:10,641] {logging_mixin.py:115} INFO - [2023-01-07 22:42:10,640] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:42:11,420] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:42:11,421] {logging_mixin.py:115} INFO - [2023-01-07 22:42:11,421] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:42:11,422] {logging_mixin.py:115} INFO - [2023-01-07 22:42:11,421] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:42:11,429] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:42:11,451] {logging_mixin.py:115} INFO - [2023-01-07 22:42:11,451] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:42:11,477] {logging_mixin.py:115} INFO - [2023-01-07 22:42:11,477] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:42:11,489] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.856 seconds
[2023-01-07 22:42:41,536] {processor.py:153} INFO - Started process (PID=3188) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:42:41,537] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:42:41,538] {logging_mixin.py:115} INFO - [2023-01-07 22:42:41,538] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:42:42,344] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:42:42,345] {logging_mixin.py:115} INFO - [2023-01-07 22:42:42,345] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:42:42,346] {logging_mixin.py:115} INFO - [2023-01-07 22:42:42,345] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:42:42,353] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:42:42,375] {logging_mixin.py:115} INFO - [2023-01-07 22:42:42,375] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:42:42,398] {logging_mixin.py:115} INFO - [2023-01-07 22:42:42,398] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:42:42,410] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.878 seconds
[2023-01-07 22:43:12,641] {processor.py:153} INFO - Started process (PID=3214) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:43:12,642] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:43:12,642] {logging_mixin.py:115} INFO - [2023-01-07 22:43:12,642] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:43:13,439] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:43:13,440] {logging_mixin.py:115} INFO - [2023-01-07 22:43:13,440] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:43:13,441] {logging_mixin.py:115} INFO - [2023-01-07 22:43:13,441] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:43:13,448] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:43:13,471] {logging_mixin.py:115} INFO - [2023-01-07 22:43:13,471] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:43:13,492] {logging_mixin.py:115} INFO - [2023-01-07 22:43:13,492] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:43:13,501] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.865 seconds
[2023-01-07 22:43:43,595] {processor.py:153} INFO - Started process (PID=3241) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:43:43,596] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:43:43,597] {logging_mixin.py:115} INFO - [2023-01-07 22:43:43,597] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:43:44,385] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:43:44,387] {logging_mixin.py:115} INFO - [2023-01-07 22:43:44,387] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:43:44,387] {logging_mixin.py:115} INFO - [2023-01-07 22:43:44,387] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:43:44,394] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:43:44,417] {logging_mixin.py:115} INFO - [2023-01-07 22:43:44,416] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:43:44,438] {logging_mixin.py:115} INFO - [2023-01-07 22:43:44,438] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:43:44,447] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.857 seconds
[2023-01-07 22:44:14,540] {processor.py:153} INFO - Started process (PID=3266) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:44:14,541] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:44:14,541] {logging_mixin.py:115} INFO - [2023-01-07 22:44:14,541] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:44:15,330] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:44:15,331] {logging_mixin.py:115} INFO - [2023-01-07 22:44:15,331] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:44:15,331] {logging_mixin.py:115} INFO - [2023-01-07 22:44:15,331] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:44:15,338] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:44:15,361] {logging_mixin.py:115} INFO - [2023-01-07 22:44:15,361] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:44:15,383] {logging_mixin.py:115} INFO - [2023-01-07 22:44:15,382] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:44:15,392] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.857 seconds
[2023-01-07 22:44:45,482] {processor.py:153} INFO - Started process (PID=3284) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:44:45,483] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:44:45,484] {logging_mixin.py:115} INFO - [2023-01-07 22:44:45,484] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:44:46,319] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:44:46,320] {logging_mixin.py:115} INFO - [2023-01-07 22:44:46,320] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:44:46,321] {logging_mixin.py:115} INFO - [2023-01-07 22:44:46,320] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:44:46,328] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:44:46,351] {logging_mixin.py:115} INFO - [2023-01-07 22:44:46,351] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:44:46,374] {logging_mixin.py:115} INFO - [2023-01-07 22:44:46,373] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:44:46,383] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.907 seconds
[2023-01-07 22:45:16,798] {processor.py:153} INFO - Started process (PID=3310) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:45:16,802] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:45:16,803] {logging_mixin.py:115} INFO - [2023-01-07 22:45:16,803] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:45:17,596] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:45:17,597] {logging_mixin.py:115} INFO - [2023-01-07 22:45:17,597] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:45:17,598] {logging_mixin.py:115} INFO - [2023-01-07 22:45:17,598] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:45:17,610] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:45:17,658] {logging_mixin.py:115} INFO - [2023-01-07 22:45:17,658] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:45:17,684] {logging_mixin.py:115} INFO - [2023-01-07 22:45:17,684] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:45:17,694] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.901 seconds
[2023-01-07 22:45:47,940] {processor.py:153} INFO - Started process (PID=3337) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:45:47,941] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:45:47,942] {logging_mixin.py:115} INFO - [2023-01-07 22:45:47,942] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:45:48,739] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:45:48,740] {logging_mixin.py:115} INFO - [2023-01-07 22:45:48,740] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:45:48,740] {logging_mixin.py:115} INFO - [2023-01-07 22:45:48,740] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:45:48,747] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:45:48,770] {logging_mixin.py:115} INFO - [2023-01-07 22:45:48,770] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:45:48,791] {logging_mixin.py:115} INFO - [2023-01-07 22:45:48,791] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:45:48,801] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.865 seconds
[2023-01-07 22:46:18,898] {processor.py:153} INFO - Started process (PID=3362) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:46:18,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:46:18,900] {logging_mixin.py:115} INFO - [2023-01-07 22:46:18,900] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:46:19,711] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:46:19,712] {logging_mixin.py:115} INFO - [2023-01-07 22:46:19,712] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:46:19,713] {logging_mixin.py:115} INFO - [2023-01-07 22:46:19,712] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:46:19,721] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:46:19,743] {logging_mixin.py:115} INFO - [2023-01-07 22:46:19,743] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:46:19,768] {logging_mixin.py:115} INFO - [2023-01-07 22:46:19,768] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:46:19,778] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.886 seconds
[2023-01-07 22:46:49,871] {processor.py:153} INFO - Started process (PID=3380) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:46:49,872] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:46:49,873] {logging_mixin.py:115} INFO - [2023-01-07 22:46:49,872] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:46:50,723] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:46:50,724] {logging_mixin.py:115} INFO - [2023-01-07 22:46:50,724] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:46:50,725] {logging_mixin.py:115} INFO - [2023-01-07 22:46:50,724] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:46:50,732] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:46:50,755] {logging_mixin.py:115} INFO - [2023-01-07 22:46:50,754] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:46:50,777] {logging_mixin.py:115} INFO - [2023-01-07 22:46:50,776] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:46:50,786] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.920 seconds
[2023-01-07 22:47:21,080] {processor.py:153} INFO - Started process (PID=3406) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:47:21,081] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:47:21,082] {logging_mixin.py:115} INFO - [2023-01-07 22:47:21,081] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:47:21,899] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:47:21,900] {logging_mixin.py:115} INFO - [2023-01-07 22:47:21,900] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:47:21,901] {logging_mixin.py:115} INFO - [2023-01-07 22:47:21,900] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:47:21,908] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:47:21,930] {logging_mixin.py:115} INFO - [2023-01-07 22:47:21,930] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:47:21,951] {logging_mixin.py:115} INFO - [2023-01-07 22:47:21,951] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:47:21,960] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.885 seconds
[2023-01-07 22:47:52,054] {processor.py:153} INFO - Started process (PID=3431) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:47:52,055] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:47:52,055] {logging_mixin.py:115} INFO - [2023-01-07 22:47:52,055] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:47:52,858] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:47:52,860] {logging_mixin.py:115} INFO - [2023-01-07 22:47:52,860] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:47:52,860] {logging_mixin.py:115} INFO - [2023-01-07 22:47:52,860] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:47:52,867] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:47:52,889] {logging_mixin.py:115} INFO - [2023-01-07 22:47:52,889] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:47:52,910] {logging_mixin.py:115} INFO - [2023-01-07 22:47:52,910] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:47:52,919] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.870 seconds
[2023-01-07 22:48:23,028] {processor.py:153} INFO - Started process (PID=3456) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:48:23,029] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:48:23,030] {logging_mixin.py:115} INFO - [2023-01-07 22:48:23,030] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:48:23,827] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:48:23,828] {logging_mixin.py:115} INFO - [2023-01-07 22:48:23,828] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:48:23,828] {logging_mixin.py:115} INFO - [2023-01-07 22:48:23,828] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:48:23,835] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:48:23,858] {logging_mixin.py:115} INFO - [2023-01-07 22:48:23,858] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:48:23,879] {logging_mixin.py:115} INFO - [2023-01-07 22:48:23,879] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:48:23,888] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.865 seconds
[2023-01-07 22:48:53,982] {processor.py:153} INFO - Started process (PID=3476) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:48:53,983] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:48:53,983] {logging_mixin.py:115} INFO - [2023-01-07 22:48:53,983] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:48:54,793] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:48:54,794] {logging_mixin.py:115} INFO - [2023-01-07 22:48:54,794] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:48:54,795] {logging_mixin.py:115} INFO - [2023-01-07 22:48:54,794] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:48:54,802] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:48:54,825] {logging_mixin.py:115} INFO - [2023-01-07 22:48:54,825] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:48:54,846] {logging_mixin.py:115} INFO - [2023-01-07 22:48:54,846] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:48:54,855] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.878 seconds
[2023-01-07 22:49:25,224] {processor.py:153} INFO - Started process (PID=3503) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:49:25,225] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:49:25,226] {logging_mixin.py:115} INFO - [2023-01-07 22:49:25,226] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:49:26,053] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:49:26,054] {logging_mixin.py:115} INFO - [2023-01-07 22:49:26,054] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:49:26,055] {logging_mixin.py:115} INFO - [2023-01-07 22:49:26,054] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:49:26,062] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:49:26,084] {logging_mixin.py:115} INFO - [2023-01-07 22:49:26,083] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:49:26,105] {logging_mixin.py:115} INFO - [2023-01-07 22:49:26,105] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:49:26,115] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.895 seconds
[2023-01-07 22:49:56,208] {processor.py:153} INFO - Started process (PID=3528) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:49:56,208] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:49:56,209] {logging_mixin.py:115} INFO - [2023-01-07 22:49:56,209] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:49:57,005] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:49:57,006] {logging_mixin.py:115} INFO - [2023-01-07 22:49:57,006] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:49:57,007] {logging_mixin.py:115} INFO - [2023-01-07 22:49:57,007] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:49:57,014] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:49:57,036] {logging_mixin.py:115} INFO - [2023-01-07 22:49:57,036] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:49:57,058] {logging_mixin.py:115} INFO - [2023-01-07 22:49:57,057] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:49:57,067] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.864 seconds
[2023-01-07 22:50:27,158] {processor.py:153} INFO - Started process (PID=3554) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:50:27,161] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:50:27,161] {logging_mixin.py:115} INFO - [2023-01-07 22:50:27,161] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:50:27,969] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:50:27,970] {logging_mixin.py:115} INFO - [2023-01-07 22:50:27,970] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:50:27,971] {logging_mixin.py:115} INFO - [2023-01-07 22:50:27,971] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:50:27,978] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:50:28,000] {logging_mixin.py:115} INFO - [2023-01-07 22:50:28,000] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:50:28,021] {logging_mixin.py:115} INFO - [2023-01-07 22:50:28,021] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:50:28,030] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.877 seconds
[2023-01-07 22:50:58,128] {processor.py:153} INFO - Started process (PID=3572) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:50:58,129] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:50:58,130] {logging_mixin.py:115} INFO - [2023-01-07 22:50:58,130] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:50:58,957] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:50:58,958] {logging_mixin.py:115} INFO - [2023-01-07 22:50:58,958] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:50:58,959] {logging_mixin.py:115} INFO - [2023-01-07 22:50:58,959] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:50:58,966] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:50:58,996] {logging_mixin.py:115} INFO - [2023-01-07 22:50:58,995] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:50:59,021] {logging_mixin.py:115} INFO - [2023-01-07 22:50:59,021] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:50:59,030] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.907 seconds
[2023-01-07 22:51:29,354] {processor.py:153} INFO - Started process (PID=3597) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:51:29,355] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:51:29,355] {logging_mixin.py:115} INFO - [2023-01-07 22:51:29,355] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:51:30,147] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:51:30,148] {logging_mixin.py:115} INFO - [2023-01-07 22:51:30,148] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:51:30,149] {logging_mixin.py:115} INFO - [2023-01-07 22:51:30,148] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:51:30,156] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:51:30,179] {logging_mixin.py:115} INFO - [2023-01-07 22:51:30,178] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:51:30,200] {logging_mixin.py:115} INFO - [2023-01-07 22:51:30,200] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:51:30,209] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.860 seconds
[2023-01-07 22:52:00,303] {processor.py:153} INFO - Started process (PID=3621) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:52:00,304] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:52:00,305] {logging_mixin.py:115} INFO - [2023-01-07 22:52:00,305] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:52:01,141] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:52:01,143] {logging_mixin.py:115} INFO - [2023-01-07 22:52:01,143] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:52:01,144] {logging_mixin.py:115} INFO - [2023-01-07 22:52:01,143] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:52:01,154] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:52:01,178] {logging_mixin.py:115} INFO - [2023-01-07 22:52:01,178] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:52:01,201] {logging_mixin.py:115} INFO - [2023-01-07 22:52:01,201] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:52:01,210] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.911 seconds
[2023-01-07 22:52:31,306] {processor.py:153} INFO - Started process (PID=3644) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:52:31,307] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:52:31,308] {logging_mixin.py:115} INFO - [2023-01-07 22:52:31,307] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:52:32,174] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:52:32,175] {logging_mixin.py:115} INFO - [2023-01-07 22:52:32,175] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:52:32,176] {logging_mixin.py:115} INFO - [2023-01-07 22:52:32,176] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:52:32,183] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:52:32,206] {logging_mixin.py:115} INFO - [2023-01-07 22:52:32,205] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:52:32,231] {logging_mixin.py:115} INFO - [2023-01-07 22:52:32,231] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:52:32,240] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.940 seconds
[2023-01-07 22:53:02,527] {processor.py:153} INFO - Started process (PID=3662) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:53:02,527] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:53:02,528] {logging_mixin.py:115} INFO - [2023-01-07 22:53:02,528] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:53:03,316] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:53:03,317] {logging_mixin.py:115} INFO - [2023-01-07 22:53:03,317] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:53:03,317] {logging_mixin.py:115} INFO - [2023-01-07 22:53:03,317] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:53:03,324] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:53:03,347] {logging_mixin.py:115} INFO - [2023-01-07 22:53:03,346] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:53:03,368] {logging_mixin.py:115} INFO - [2023-01-07 22:53:03,368] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:53:03,377] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.855 seconds
[2023-01-07 22:53:33,612] {processor.py:153} INFO - Started process (PID=3687) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:53:33,613] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:53:33,614] {logging_mixin.py:115} INFO - [2023-01-07 22:53:33,614] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:53:34,401] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:53:34,402] {logging_mixin.py:115} INFO - [2023-01-07 22:53:34,402] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:53:34,402] {logging_mixin.py:115} INFO - [2023-01-07 22:53:34,402] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:53:34,410] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:53:34,438] {logging_mixin.py:115} INFO - [2023-01-07 22:53:34,438] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:53:34,462] {logging_mixin.py:115} INFO - [2023-01-07 22:53:34,462] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:53:34,471] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.864 seconds
[2023-01-07 22:54:04,572] {processor.py:153} INFO - Started process (PID=3712) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:54:04,573] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:54:04,573] {logging_mixin.py:115} INFO - [2023-01-07 22:54:04,573] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:54:05,481] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:54:05,482] {logging_mixin.py:115} INFO - [2023-01-07 22:54:05,482] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:54:05,483] {logging_mixin.py:115} INFO - [2023-01-07 22:54:05,483] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:54:05,490] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:54:05,513] {logging_mixin.py:115} INFO - [2023-01-07 22:54:05,513] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:54:05,535] {logging_mixin.py:115} INFO - [2023-01-07 22:54:05,535] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:54:05,545] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.977 seconds
[2023-01-07 22:54:35,717] {processor.py:153} INFO - Started process (PID=3737) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:54:35,718] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:54:35,719] {logging_mixin.py:115} INFO - [2023-01-07 22:54:35,719] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:54:36,597] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:54:36,598] {logging_mixin.py:115} INFO - [2023-01-07 22:54:36,598] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:54:36,599] {logging_mixin.py:115} INFO - [2023-01-07 22:54:36,598] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:54:36,606] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:54:36,629] {logging_mixin.py:115} INFO - [2023-01-07 22:54:36,629] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:54:36,650] {logging_mixin.py:115} INFO - [2023-01-07 22:54:36,650] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-07 22:54:36,659] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.947 seconds
[2023-01-07 22:55:06,735] {processor.py:153} INFO - Started process (PID=3754) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:55:06,738] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:55:06,738] {logging_mixin.py:115} INFO - [2023-01-07 22:55:06,738] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:55:07,611] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:55:07,612] {logging_mixin.py:115} INFO - [2023-01-07 22:55:07,612] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:55:07,612] {logging_mixin.py:115} INFO - [2023-01-07 22:55:07,612] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:55:07,620] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:55:07,643] {logging_mixin.py:115} INFO - [2023-01-07 22:55:07,642] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:55:07,671] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.941 seconds
[2023-01-07 22:55:37,759] {processor.py:153} INFO - Started process (PID=3779) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:55:37,760] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:55:37,760] {logging_mixin.py:115} INFO - [2023-01-07 22:55:37,760] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:55:38,573] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:55:38,574] {logging_mixin.py:115} INFO - [2023-01-07 22:55:38,574] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:55:38,575] {logging_mixin.py:115} INFO - [2023-01-07 22:55:38,574] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:55:38,582] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:55:38,605] {logging_mixin.py:115} INFO - [2023-01-07 22:55:38,604] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:55:38,626] {logging_mixin.py:115} INFO - [2023-01-07 22:55:38,626] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 22:55:38,636] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.882 seconds
[2023-01-07 22:56:08,870] {processor.py:153} INFO - Started process (PID=3804) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:56:08,873] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:56:08,874] {logging_mixin.py:115} INFO - [2023-01-07 22:56:08,874] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:56:09,671] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:56:09,673] {logging_mixin.py:115} INFO - [2023-01-07 22:56:09,672] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:56:09,673] {logging_mixin.py:115} INFO - [2023-01-07 22:56:09,673] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:56:09,680] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:56:09,703] {logging_mixin.py:115} INFO - [2023-01-07 22:56:09,702] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:56:09,724] {logging_mixin.py:115} INFO - [2023-01-07 22:56:09,724] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 22:56:09,734] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.868 seconds
[2023-01-07 22:56:39,834] {processor.py:153} INFO - Started process (PID=3829) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:56:39,835] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:56:39,836] {logging_mixin.py:115} INFO - [2023-01-07 22:56:39,836] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:56:40,756] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:56:40,758] {logging_mixin.py:115} INFO - [2023-01-07 22:56:40,758] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:56:40,758] {logging_mixin.py:115} INFO - [2023-01-07 22:56:40,758] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:56:40,765] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:56:40,789] {logging_mixin.py:115} INFO - [2023-01-07 22:56:40,789] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:56:40,810] {logging_mixin.py:115} INFO - [2023-01-07 22:56:40,810] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 22:56:40,819] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.991 seconds
[2023-01-07 22:57:10,868] {processor.py:153} INFO - Started process (PID=3847) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:57:10,869] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:57:10,870] {logging_mixin.py:115} INFO - [2023-01-07 22:57:10,870] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:57:11,772] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:57:11,773] {logging_mixin.py:115} INFO - [2023-01-07 22:57:11,773] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:57:11,774] {logging_mixin.py:115} INFO - [2023-01-07 22:57:11,774] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:57:11,786] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:57:11,817] {logging_mixin.py:115} INFO - [2023-01-07 22:57:11,817] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:57:11,849] {logging_mixin.py:115} INFO - [2023-01-07 22:57:11,848] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 22:57:11,862] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.999 seconds
[2023-01-07 22:57:41,970] {processor.py:153} INFO - Started process (PID=3872) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:57:41,971] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:57:41,971] {logging_mixin.py:115} INFO - [2023-01-07 22:57:41,971] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:57:42,774] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:57:42,775] {logging_mixin.py:115} INFO - [2023-01-07 22:57:42,775] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:57:42,775] {logging_mixin.py:115} INFO - [2023-01-07 22:57:42,775] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:57:42,782] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:57:42,805] {logging_mixin.py:115} INFO - [2023-01-07 22:57:42,805] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:57:42,826] {logging_mixin.py:115} INFO - [2023-01-07 22:57:42,826] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 22:57:42,835] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.871 seconds
[2023-01-07 22:58:13,089] {processor.py:153} INFO - Started process (PID=3897) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:58:13,089] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:58:13,091] {logging_mixin.py:115} INFO - [2023-01-07 22:58:13,091] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:58:13,891] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:58:13,893] {logging_mixin.py:115} INFO - [2023-01-07 22:58:13,892] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:58:13,893] {logging_mixin.py:115} INFO - [2023-01-07 22:58:13,893] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:58:13,900] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:58:13,923] {logging_mixin.py:115} INFO - [2023-01-07 22:58:13,923] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:58:13,945] {logging_mixin.py:115} INFO - [2023-01-07 22:58:13,944] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 22:58:13,954] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.870 seconds
[2023-01-07 22:58:44,047] {processor.py:153} INFO - Started process (PID=3922) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:58:44,049] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:58:44,049] {logging_mixin.py:115} INFO - [2023-01-07 22:58:44,049] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:58:44,890] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:58:44,892] {logging_mixin.py:115} INFO - [2023-01-07 22:58:44,891] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:58:44,892] {logging_mixin.py:115} INFO - [2023-01-07 22:58:44,892] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:58:44,899] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:58:44,922] {logging_mixin.py:115} INFO - [2023-01-07 22:58:44,922] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:58:44,943] {logging_mixin.py:115} INFO - [2023-01-07 22:58:44,943] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 22:58:44,953] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.911 seconds
[2023-01-07 22:59:15,193] {processor.py:153} INFO - Started process (PID=3941) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:59:15,194] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:59:15,195] {logging_mixin.py:115} INFO - [2023-01-07 22:59:15,195] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:59:16,019] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:59:16,020] {logging_mixin.py:115} INFO - [2023-01-07 22:59:16,020] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:59:16,020] {logging_mixin.py:115} INFO - [2023-01-07 22:59:16,020] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:59:16,028] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:59:16,052] {logging_mixin.py:115} INFO - [2023-01-07 22:59:16,052] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:59:16,074] {logging_mixin.py:115} INFO - [2023-01-07 22:59:16,074] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 22:59:16,083] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.895 seconds
[2023-01-07 22:59:46,263] {processor.py:153} INFO - Started process (PID=3967) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:59:46,264] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 22:59:46,265] {logging_mixin.py:115} INFO - [2023-01-07 22:59:46,265] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:59:47,055] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 22:59:47,056] {logging_mixin.py:115} INFO - [2023-01-07 22:59:47,056] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 22:59:47,056] {logging_mixin.py:115} INFO - [2023-01-07 22:59:47,056] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 22:59:47,063] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 22:59:47,090] {logging_mixin.py:115} INFO - [2023-01-07 22:59:47,090] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 22:59:47,112] {logging_mixin.py:115} INFO - [2023-01-07 22:59:47,111] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 22:59:47,121] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.863 seconds
[2023-01-07 23:00:17,199] {processor.py:153} INFO - Started process (PID=3991) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:00:17,201] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:00:17,202] {logging_mixin.py:115} INFO - [2023-01-07 23:00:17,201] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:00:17,991] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:00:17,992] {logging_mixin.py:115} INFO - [2023-01-07 23:00:17,992] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:00:17,993] {logging_mixin.py:115} INFO - [2023-01-07 23:00:17,992] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:00:18,000] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:00:18,022] {logging_mixin.py:115} INFO - [2023-01-07 23:00:18,022] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:00:18,044] {logging_mixin.py:115} INFO - [2023-01-07 23:00:18,044] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:00:18,053] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.859 seconds
[2023-01-07 23:00:48,699] {processor.py:153} INFO - Started process (PID=4016) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:00:48,699] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:00:48,700] {logging_mixin.py:115} INFO - [2023-01-07 23:00:48,700] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:00:49,664] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:00:49,666] {logging_mixin.py:115} INFO - [2023-01-07 23:00:49,666] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:00:49,666] {logging_mixin.py:115} INFO - [2023-01-07 23:00:49,666] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:00:49,673] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:00:49,697] {logging_mixin.py:115} INFO - [2023-01-07 23:00:49,697] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:00:49,719] {logging_mixin.py:115} INFO - [2023-01-07 23:00:49,719] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:00:49,729] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.036 seconds
[2023-01-07 23:01:19,764] {processor.py:153} INFO - Started process (PID=4033) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:01:19,765] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:01:19,765] {logging_mixin.py:115} INFO - [2023-01-07 23:01:19,765] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:01:20,593] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:01:20,594] {logging_mixin.py:115} INFO - [2023-01-07 23:01:20,594] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:01:20,595] {logging_mixin.py:115} INFO - [2023-01-07 23:01:20,595] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:01:20,602] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:01:20,632] {logging_mixin.py:115} INFO - [2023-01-07 23:01:20,632] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:01:20,657] {logging_mixin.py:115} INFO - [2023-01-07 23:01:20,657] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:01:20,667] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.908 seconds
[2023-01-07 23:01:50,864] {processor.py:153} INFO - Started process (PID=4057) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:01:50,865] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:01:50,865] {logging_mixin.py:115} INFO - [2023-01-07 23:01:50,865] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:01:51,681] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:01:51,683] {logging_mixin.py:115} INFO - [2023-01-07 23:01:51,683] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:01:51,684] {logging_mixin.py:115} INFO - [2023-01-07 23:01:51,683] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:01:51,691] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:01:51,720] {logging_mixin.py:115} INFO - [2023-01-07 23:01:51,719] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:01:51,746] {logging_mixin.py:115} INFO - [2023-01-07 23:01:51,746] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:01:51,755] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.897 seconds
[2023-01-07 23:02:21,950] {processor.py:153} INFO - Started process (PID=4082) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:02:21,951] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:02:21,952] {logging_mixin.py:115} INFO - [2023-01-07 23:02:21,952] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:02:22,750] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:02:22,752] {logging_mixin.py:115} INFO - [2023-01-07 23:02:22,752] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:02:22,752] {logging_mixin.py:115} INFO - [2023-01-07 23:02:22,752] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:02:22,760] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:02:22,783] {logging_mixin.py:115} INFO - [2023-01-07 23:02:22,783] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:02:22,804] {logging_mixin.py:115} INFO - [2023-01-07 23:02:22,804] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:02:22,817] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.872 seconds
[2023-01-07 23:02:52,914] {processor.py:153} INFO - Started process (PID=4106) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:02:52,917] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:02:52,918] {logging_mixin.py:115} INFO - [2023-01-07 23:02:52,918] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:02:53,746] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:02:53,747] {logging_mixin.py:115} INFO - [2023-01-07 23:02:53,747] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:02:53,748] {logging_mixin.py:115} INFO - [2023-01-07 23:02:53,748] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:02:53,755] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:02:53,785] {logging_mixin.py:115} INFO - [2023-01-07 23:02:53,785] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:02:53,817] {logging_mixin.py:115} INFO - [2023-01-07 23:02:53,816] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:02:53,828] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.919 seconds
[2023-01-07 23:03:23,952] {processor.py:153} INFO - Started process (PID=4125) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:03:23,953] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:03:23,953] {logging_mixin.py:115} INFO - [2023-01-07 23:03:23,953] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:03:24,787] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:03:24,788] {logging_mixin.py:115} INFO - [2023-01-07 23:03:24,788] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:03:24,789] {logging_mixin.py:115} INFO - [2023-01-07 23:03:24,789] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:03:24,802] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:03:24,825] {logging_mixin.py:115} INFO - [2023-01-07 23:03:24,825] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:03:24,847] {logging_mixin.py:115} INFO - [2023-01-07 23:03:24,847] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:03:24,857] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.909 seconds
[2023-01-07 23:03:55,117] {processor.py:153} INFO - Started process (PID=4152) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:03:55,119] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:03:55,119] {logging_mixin.py:115} INFO - [2023-01-07 23:03:55,119] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:03:55,934] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:03:55,935] {logging_mixin.py:115} INFO - [2023-01-07 23:03:55,935] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:03:55,935] {logging_mixin.py:115} INFO - [2023-01-07 23:03:55,935] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:03:55,942] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:03:55,965] {logging_mixin.py:115} INFO - [2023-01-07 23:03:55,964] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:03:55,986] {logging_mixin.py:115} INFO - [2023-01-07 23:03:55,986] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:03:55,995] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.883 seconds
[2023-01-07 23:04:26,092] {processor.py:153} INFO - Started process (PID=4177) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:04:26,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:04:26,096] {logging_mixin.py:115} INFO - [2023-01-07 23:04:26,096] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:04:26,919] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:04:26,920] {logging_mixin.py:115} INFO - [2023-01-07 23:04:26,920] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:04:26,921] {logging_mixin.py:115} INFO - [2023-01-07 23:04:26,921] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:04:26,928] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:04:26,951] {logging_mixin.py:115} INFO - [2023-01-07 23:04:26,951] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:04:26,972] {logging_mixin.py:115} INFO - [2023-01-07 23:04:26,972] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:04:26,982] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.895 seconds
[2023-01-07 23:04:57,067] {processor.py:153} INFO - Started process (PID=4202) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:04:57,068] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:04:57,069] {logging_mixin.py:115} INFO - [2023-01-07 23:04:57,069] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:04:58,078] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:04:58,080] {logging_mixin.py:115} INFO - [2023-01-07 23:04:58,080] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:04:58,081] {logging_mixin.py:115} INFO - [2023-01-07 23:04:58,081] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:04:58,092] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:04:58,121] {logging_mixin.py:115} INFO - [2023-01-07 23:04:58,120] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:04:58,150] {logging_mixin.py:115} INFO - [2023-01-07 23:04:58,150] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:04:58,166] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.104 seconds
[2023-01-07 23:05:28,229] {processor.py:153} INFO - Started process (PID=4221) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:05:28,230] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:05:28,231] {logging_mixin.py:115} INFO - [2023-01-07 23:05:28,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:05:29,044] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:05:29,046] {logging_mixin.py:115} INFO - [2023-01-07 23:05:29,046] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:05:29,046] {logging_mixin.py:115} INFO - [2023-01-07 23:05:29,046] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:05:29,053] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:05:29,076] {logging_mixin.py:115} INFO - [2023-01-07 23:05:29,075] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:05:29,097] {logging_mixin.py:115} INFO - [2023-01-07 23:05:29,096] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:05:29,106] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.882 seconds
[2023-01-07 23:05:59,315] {processor.py:153} INFO - Started process (PID=4247) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:05:59,316] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:05:59,316] {logging_mixin.py:115} INFO - [2023-01-07 23:05:59,316] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:06:00,128] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:06:00,129] {logging_mixin.py:115} INFO - [2023-01-07 23:06:00,129] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:06:00,130] {logging_mixin.py:115} INFO - [2023-01-07 23:06:00,130] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:06:00,137] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:06:00,160] {logging_mixin.py:115} INFO - [2023-01-07 23:06:00,160] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:06:00,181] {logging_mixin.py:115} INFO - [2023-01-07 23:06:00,181] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:06:00,190] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.880 seconds
[2023-01-07 23:06:30,396] {processor.py:153} INFO - Started process (PID=4270) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:06:30,397] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:06:30,398] {logging_mixin.py:115} INFO - [2023-01-07 23:06:30,398] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:06:31,216] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:06:31,217] {logging_mixin.py:115} INFO - [2023-01-07 23:06:31,217] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:06:31,218] {logging_mixin.py:115} INFO - [2023-01-07 23:06:31,218] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:06:31,225] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:06:31,249] {logging_mixin.py:115} INFO - [2023-01-07 23:06:31,248] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:06:31,270] {logging_mixin.py:115} INFO - [2023-01-07 23:06:31,270] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:06:31,280] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.890 seconds
[2023-01-07 23:07:01,481] {processor.py:153} INFO - Started process (PID=4288) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:07:01,482] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:07:01,483] {logging_mixin.py:115} INFO - [2023-01-07 23:07:01,483] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:07:02,402] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:07:02,403] {logging_mixin.py:115} INFO - [2023-01-07 23:07:02,403] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:07:02,404] {logging_mixin.py:115} INFO - [2023-01-07 23:07:02,404] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:07:02,411] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:07:02,435] {logging_mixin.py:115} INFO - [2023-01-07 23:07:02,434] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:07:02,457] {logging_mixin.py:115} INFO - [2023-01-07 23:07:02,457] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:07:02,467] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.990 seconds
[2023-01-07 23:07:32,549] {processor.py:153} INFO - Started process (PID=4313) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:07:32,551] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:07:32,551] {logging_mixin.py:115} INFO - [2023-01-07 23:07:32,551] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:07:33,415] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:07:33,417] {logging_mixin.py:115} INFO - [2023-01-07 23:07:33,417] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:07:33,418] {logging_mixin.py:115} INFO - [2023-01-07 23:07:33,418] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:07:33,428] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:07:33,467] {logging_mixin.py:115} INFO - [2023-01-07 23:07:33,467] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:07:33,491] {logging_mixin.py:115} INFO - [2023-01-07 23:07:33,490] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:07:33,500] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.956 seconds
[2023-01-07 23:08:03,633] {processor.py:153} INFO - Started process (PID=4338) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:08:03,633] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:08:03,634] {logging_mixin.py:115} INFO - [2023-01-07 23:08:03,634] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:08:04,556] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:08:04,557] {logging_mixin.py:115} INFO - [2023-01-07 23:08:04,557] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:08:04,558] {logging_mixin.py:115} INFO - [2023-01-07 23:08:04,557] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:08:04,565] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:08:04,588] {logging_mixin.py:115} INFO - [2023-01-07 23:08:04,587] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:08:04,610] {logging_mixin.py:115} INFO - [2023-01-07 23:08:04,610] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:08:04,619] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.991 seconds
[2023-01-07 23:08:34,718] {processor.py:153} INFO - Started process (PID=4364) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:08:34,719] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:08:34,720] {logging_mixin.py:115} INFO - [2023-01-07 23:08:34,720] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:08:35,529] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:08:35,530] {logging_mixin.py:115} INFO - [2023-01-07 23:08:35,530] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:08:35,530] {logging_mixin.py:115} INFO - [2023-01-07 23:08:35,530] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:08:35,538] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:08:35,560] {logging_mixin.py:115} INFO - [2023-01-07 23:08:35,560] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:08:35,583] {logging_mixin.py:115} INFO - [2023-01-07 23:08:35,582] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:08:35,592] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.879 seconds
[2023-01-07 23:09:05,708] {processor.py:153} INFO - Started process (PID=4381) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:09:05,709] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:09:05,709] {logging_mixin.py:115} INFO - [2023-01-07 23:09:05,709] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:09:06,660] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:09:06,662] {logging_mixin.py:115} INFO - [2023-01-07 23:09:06,662] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:09:06,663] {logging_mixin.py:115} INFO - [2023-01-07 23:09:06,662] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:09:06,674] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:09:06,698] {logging_mixin.py:115} INFO - [2023-01-07 23:09:06,698] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:09:06,728] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.025 seconds
[2023-01-07 23:09:36,786] {processor.py:153} INFO - Started process (PID=4407) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:09:36,787] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:09:36,787] {logging_mixin.py:115} INFO - [2023-01-07 23:09:36,787] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:09:37,602] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:09:37,604] {logging_mixin.py:115} INFO - [2023-01-07 23:09:37,604] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:09:37,604] {logging_mixin.py:115} INFO - [2023-01-07 23:09:37,604] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:09:37,612] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:09:37,634] {logging_mixin.py:115} INFO - [2023-01-07 23:09:37,634] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:09:37,656] {logging_mixin.py:115} INFO - [2023-01-07 23:09:37,655] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:09:37,665] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.883 seconds
[2023-01-07 23:10:07,862] {processor.py:153} INFO - Started process (PID=4432) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:10:07,863] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:10:07,864] {logging_mixin.py:115} INFO - [2023-01-07 23:10:07,863] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:10:08,664] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:10:08,665] {logging_mixin.py:115} INFO - [2023-01-07 23:10:08,665] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:10:08,666] {logging_mixin.py:115} INFO - [2023-01-07 23:10:08,666] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:10:08,673] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:10:08,695] {logging_mixin.py:115} INFO - [2023-01-07 23:10:08,695] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:10:08,717] {logging_mixin.py:115} INFO - [2023-01-07 23:10:08,717] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:10:08,727] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.870 seconds
[2023-01-07 23:10:39,197] {processor.py:153} INFO - Started process (PID=4456) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:10:39,199] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:10:39,199] {logging_mixin.py:115} INFO - [2023-01-07 23:10:39,199] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:10:40,037] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:10:40,038] {logging_mixin.py:115} INFO - [2023-01-07 23:10:40,038] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:10:40,038] {logging_mixin.py:115} INFO - [2023-01-07 23:10:40,038] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:10:40,046] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:10:40,069] {logging_mixin.py:115} INFO - [2023-01-07 23:10:40,069] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:10:40,091] {logging_mixin.py:115} INFO - [2023-01-07 23:10:40,091] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:10:40,101] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.908 seconds
[2023-01-07 23:11:10,199] {processor.py:153} INFO - Started process (PID=4474) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:11:10,200] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:11:10,200] {logging_mixin.py:115} INFO - [2023-01-07 23:11:10,200] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:11:11,064] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:11:11,066] {logging_mixin.py:115} INFO - [2023-01-07 23:11:11,066] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:11:11,067] {logging_mixin.py:115} INFO - [2023-01-07 23:11:11,067] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:11:11,081] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:11:11,114] {logging_mixin.py:115} INFO - [2023-01-07 23:11:11,114] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:11:11,145] {logging_mixin.py:115} INFO - [2023-01-07 23:11:11,145] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:11:11,158] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.964 seconds
[2023-01-07 23:11:41,311] {processor.py:153} INFO - Started process (PID=4499) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:11:41,312] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:11:41,312] {logging_mixin.py:115} INFO - [2023-01-07 23:11:41,312] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:11:42,142] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:11:42,144] {logging_mixin.py:115} INFO - [2023-01-07 23:11:42,144] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:11:42,144] {logging_mixin.py:115} INFO - [2023-01-07 23:11:42,144] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:11:42,151] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:11:42,174] {logging_mixin.py:115} INFO - [2023-01-07 23:11:42,174] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:11:42,196] {logging_mixin.py:115} INFO - [2023-01-07 23:11:42,196] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:11:42,205] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.898 seconds
[2023-01-07 23:12:12,390] {processor.py:153} INFO - Started process (PID=4525) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:12:12,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:12:12,392] {logging_mixin.py:115} INFO - [2023-01-07 23:12:12,392] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:12:13,228] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:12:13,229] {logging_mixin.py:115} INFO - [2023-01-07 23:12:13,229] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:12:13,230] {logging_mixin.py:115} INFO - [2023-01-07 23:12:13,230] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:12:13,242] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:12:13,265] {logging_mixin.py:115} INFO - [2023-01-07 23:12:13,265] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:12:13,294] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.910 seconds
[2023-01-07 23:12:43,475] {processor.py:153} INFO - Started process (PID=4550) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:12:43,475] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:12:43,476] {logging_mixin.py:115} INFO - [2023-01-07 23:12:43,476] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:12:44,275] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:12:44,277] {logging_mixin.py:115} INFO - [2023-01-07 23:12:44,277] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:12:44,277] {logging_mixin.py:115} INFO - [2023-01-07 23:12:44,277] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:12:44,284] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:12:44,308] {logging_mixin.py:115} INFO - [2023-01-07 23:12:44,308] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:12:44,337] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.867 seconds
[2023-01-07 23:13:14,567] {processor.py:153} INFO - Started process (PID=4568) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:13:14,568] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:13:14,569] {logging_mixin.py:115} INFO - [2023-01-07 23:13:14,569] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:13:15,364] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:13:15,365] {logging_mixin.py:115} INFO - [2023-01-07 23:13:15,365] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:13:15,366] {logging_mixin.py:115} INFO - [2023-01-07 23:13:15,366] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:13:15,373] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:13:15,395] {logging_mixin.py:115} INFO - [2023-01-07 23:13:15,395] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:13:15,424] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.861 seconds
[2023-01-07 23:13:45,521] {processor.py:153} INFO - Started process (PID=4593) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:13:45,522] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:13:45,522] {logging_mixin.py:115} INFO - [2023-01-07 23:13:45,522] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:13:46,332] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:13:46,333] {logging_mixin.py:115} INFO - [2023-01-07 23:13:46,333] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:13:46,334] {logging_mixin.py:115} INFO - [2023-01-07 23:13:46,333] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:13:46,341] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:13:46,363] {logging_mixin.py:115} INFO - [2023-01-07 23:13:46,363] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:13:46,392] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.876 seconds
[2023-01-07 23:14:16,662] {processor.py:153} INFO - Started process (PID=4617) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:14:16,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:14:16,666] {logging_mixin.py:115} INFO - [2023-01-07 23:14:16,666] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:14:17,469] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:14:17,471] {logging_mixin.py:115} INFO - [2023-01-07 23:14:17,470] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:14:17,471] {logging_mixin.py:115} INFO - [2023-01-07 23:14:17,471] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:14:17,478] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:14:17,501] {logging_mixin.py:115} INFO - [2023-01-07 23:14:17,500] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:14:17,529] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.872 seconds
[2023-01-07 23:14:47,739] {processor.py:153} INFO - Started process (PID=4642) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:14:47,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:14:47,741] {logging_mixin.py:115} INFO - [2023-01-07 23:14:47,741] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:14:48,533] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:14:48,535] {logging_mixin.py:115} INFO - [2023-01-07 23:14:48,534] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:14:48,535] {logging_mixin.py:115} INFO - [2023-01-07 23:14:48,535] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:14:48,542] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:14:48,564] {logging_mixin.py:115} INFO - [2023-01-07 23:14:48,564] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:14:48,593] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.858 seconds
[2023-01-07 23:15:18,691] {processor.py:153} INFO - Started process (PID=4660) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:15:18,692] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:15:18,693] {logging_mixin.py:115} INFO - [2023-01-07 23:15:18,693] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:15:19,551] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:15:19,552] {logging_mixin.py:115} INFO - [2023-01-07 23:15:19,552] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:15:19,553] {logging_mixin.py:115} INFO - [2023-01-07 23:15:19,552] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:15:19,561] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:15:19,584] {logging_mixin.py:115} INFO - [2023-01-07 23:15:19,584] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:15:19,613] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.927 seconds
[2023-01-07 23:15:49,708] {processor.py:153} INFO - Started process (PID=4684) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:15:49,708] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:15:49,709] {logging_mixin.py:115} INFO - [2023-01-07 23:15:49,709] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:15:50,536] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:15:50,537] {logging_mixin.py:115} INFO - [2023-01-07 23:15:50,537] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:15:50,538] {logging_mixin.py:115} INFO - [2023-01-07 23:15:50,537] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:15:50,545] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:15:50,567] {logging_mixin.py:115} INFO - [2023-01-07 23:15:50,567] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:15:50,595] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.892 seconds
[2023-01-07 23:16:20,927] {processor.py:153} INFO - Started process (PID=4710) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:16:20,927] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:16:20,928] {logging_mixin.py:115} INFO - [2023-01-07 23:16:20,928] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:16:21,762] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:16:21,764] {logging_mixin.py:115} INFO - [2023-01-07 23:16:21,763] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:16:21,764] {logging_mixin.py:115} INFO - [2023-01-07 23:16:21,764] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:16:21,771] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:16:21,794] {logging_mixin.py:115} INFO - [2023-01-07 23:16:21,794] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:16:21,823] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.901 seconds
[2023-01-07 23:16:52,005] {processor.py:153} INFO - Started process (PID=4735) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:16:52,006] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:16:52,007] {logging_mixin.py:115} INFO - [2023-01-07 23:16:52,007] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:16:52,804] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:16:52,805] {logging_mixin.py:115} INFO - [2023-01-07 23:16:52,805] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:16:52,806] {logging_mixin.py:115} INFO - [2023-01-07 23:16:52,806] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:16:52,813] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:16:52,835] {logging_mixin.py:115} INFO - [2023-01-07 23:16:52,835] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:16:52,856] {logging_mixin.py:115} INFO - [2023-01-07 23:16:52,856] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:16:52,865] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.865 seconds
[2023-01-07 23:17:23,088] {processor.py:153} INFO - Started process (PID=4753) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:17:23,089] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:17:23,090] {logging_mixin.py:115} INFO - [2023-01-07 23:17:23,090] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:17:23,906] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:17:23,907] {logging_mixin.py:115} INFO - [2023-01-07 23:17:23,907] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:17:23,908] {logging_mixin.py:115} INFO - [2023-01-07 23:17:23,908] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:17:23,915] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:17:23,938] {logging_mixin.py:115} INFO - [2023-01-07 23:17:23,937] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:17:23,959] {logging_mixin.py:115} INFO - [2023-01-07 23:17:23,959] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:17:23,968] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.885 seconds
[2023-01-07 23:17:54,163] {processor.py:153} INFO - Started process (PID=4777) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:17:54,164] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:17:54,165] {logging_mixin.py:115} INFO - [2023-01-07 23:17:54,165] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:17:54,964] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:17:54,966] {logging_mixin.py:115} INFO - [2023-01-07 23:17:54,965] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:17:54,966] {logging_mixin.py:115} INFO - [2023-01-07 23:17:54,966] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:17:54,973] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:17:54,995] {logging_mixin.py:115} INFO - [2023-01-07 23:17:54,995] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:17:55,016] {logging_mixin.py:115} INFO - [2023-01-07 23:17:55,016] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:17:55,026] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.867 seconds
[2023-01-07 23:18:25,138] {processor.py:153} INFO - Started process (PID=4800) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:18:25,139] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:18:25,139] {logging_mixin.py:115} INFO - [2023-01-07 23:18:25,139] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:18:25,958] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:18:25,959] {logging_mixin.py:115} INFO - [2023-01-07 23:18:25,959] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:18:25,960] {logging_mixin.py:115} INFO - [2023-01-07 23:18:25,959] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:18:25,967] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:18:25,989] {logging_mixin.py:115} INFO - [2023-01-07 23:18:25,989] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:18:26,016] {logging_mixin.py:115} INFO - [2023-01-07 23:18:26,016] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:18:26,025] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.892 seconds
[2023-01-07 23:18:56,274] {processor.py:153} INFO - Started process (PID=4825) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:18:56,276] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:18:56,276] {logging_mixin.py:115} INFO - [2023-01-07 23:18:56,276] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:18:57,095] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:18:57,096] {logging_mixin.py:115} INFO - [2023-01-07 23:18:57,096] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:18:57,097] {logging_mixin.py:115} INFO - [2023-01-07 23:18:57,097] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:18:57,104] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:18:57,127] {logging_mixin.py:115} INFO - [2023-01-07 23:18:57,126] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:18:57,149] {logging_mixin.py:115} INFO - [2023-01-07 23:18:57,149] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:18:57,158] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.888 seconds
[2023-01-07 23:19:27,260] {processor.py:153} INFO - Started process (PID=4843) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:19:27,261] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:19:27,262] {logging_mixin.py:115} INFO - [2023-01-07 23:19:27,262] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:19:28,057] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:19:28,059] {logging_mixin.py:115} INFO - [2023-01-07 23:19:28,058] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:19:28,059] {logging_mixin.py:115} INFO - [2023-01-07 23:19:28,059] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:19:28,066] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:19:28,089] {logging_mixin.py:115} INFO - [2023-01-07 23:19:28,088] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:19:28,109] {logging_mixin.py:115} INFO - [2023-01-07 23:19:28,109] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:19:28,119] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.863 seconds
[2023-01-07 23:19:58,215] {processor.py:153} INFO - Started process (PID=4869) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:19:58,217] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:19:58,217] {logging_mixin.py:115} INFO - [2023-01-07 23:19:58,217] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:19:59,016] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:19:59,017] {logging_mixin.py:115} INFO - [2023-01-07 23:19:59,017] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:19:59,017] {logging_mixin.py:115} INFO - [2023-01-07 23:19:59,017] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:19:59,025] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:19:59,047] {logging_mixin.py:115} INFO - [2023-01-07 23:19:59,047] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:19:59,069] {logging_mixin.py:115} INFO - [2023-01-07 23:19:59,069] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:19:59,078] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.868 seconds
[2023-01-07 23:20:29,423] {processor.py:153} INFO - Started process (PID=4895) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:20:29,423] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:20:29,424] {logging_mixin.py:115} INFO - [2023-01-07 23:20:29,424] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:20:30,274] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:20:30,275] {logging_mixin.py:115} INFO - [2023-01-07 23:20:30,275] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:20:30,276] {logging_mixin.py:115} INFO - [2023-01-07 23:20:30,276] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:20:30,283] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:20:30,305] {logging_mixin.py:115} INFO - [2023-01-07 23:20:30,305] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:20:30,335] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.918 seconds
[2023-01-07 23:21:00,507] {processor.py:153} INFO - Started process (PID=4921) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:21:00,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:21:00,508] {logging_mixin.py:115} INFO - [2023-01-07 23:21:00,508] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:21:01,329] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:21:01,330] {logging_mixin.py:115} INFO - [2023-01-07 23:21:01,330] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:21:01,331] {logging_mixin.py:115} INFO - [2023-01-07 23:21:01,330] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:21:01,338] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:21:01,360] {logging_mixin.py:115} INFO - [2023-01-07 23:21:01,360] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:21:01,382] {logging_mixin.py:115} INFO - [2023-01-07 23:21:01,382] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:21:01,391] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.890 seconds
[2023-01-07 23:21:31,492] {processor.py:153} INFO - Started process (PID=4939) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:21:31,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:21:31,494] {logging_mixin.py:115} INFO - [2023-01-07 23:21:31,494] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:21:32,304] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:21:32,305] {logging_mixin.py:115} INFO - [2023-01-07 23:21:32,305] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:21:32,306] {logging_mixin.py:115} INFO - [2023-01-07 23:21:32,306] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:21:32,313] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:21:32,337] {logging_mixin.py:115} INFO - [2023-01-07 23:21:32,337] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:21:32,358] {logging_mixin.py:115} INFO - [2023-01-07 23:21:32,358] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:21:32,368] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.881 seconds
[2023-01-07 23:22:02,668] {processor.py:153} INFO - Started process (PID=4965) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:22:02,669] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:22:02,670] {logging_mixin.py:115} INFO - [2023-01-07 23:22:02,670] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:22:03,479] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:22:03,481] {logging_mixin.py:115} INFO - [2023-01-07 23:22:03,480] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:22:03,481] {logging_mixin.py:115} INFO - [2023-01-07 23:22:03,481] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:22:03,488] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:22:03,510] {logging_mixin.py:115} INFO - [2023-01-07 23:22:03,510] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:22:03,532] {logging_mixin.py:115} INFO - [2023-01-07 23:22:03,532] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:22:03,541] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.878 seconds
[2023-01-07 23:22:33,770] {processor.py:153} INFO - Started process (PID=4992) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:22:33,771] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:22:33,771] {logging_mixin.py:115} INFO - [2023-01-07 23:22:33,771] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:22:34,608] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:22:34,609] {logging_mixin.py:115} INFO - [2023-01-07 23:22:34,609] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:22:34,609] {logging_mixin.py:115} INFO - [2023-01-07 23:22:34,609] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:22:34,616] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:22:34,642] {logging_mixin.py:115} INFO - [2023-01-07 23:22:34,642] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:22:34,670] {logging_mixin.py:115} INFO - [2023-01-07 23:22:34,670] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:22:34,678] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.913 seconds
[2023-01-07 23:23:04,919] {processor.py:153} INFO - Started process (PID=5017) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:23:04,922] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:23:04,923] {logging_mixin.py:115} INFO - [2023-01-07 23:23:04,923] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:23:05,735] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:23:05,737] {logging_mixin.py:115} INFO - [2023-01-07 23:23:05,737] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:23:05,737] {logging_mixin.py:115} INFO - [2023-01-07 23:23:05,737] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:23:05,744] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:23:05,767] {logging_mixin.py:115} INFO - [2023-01-07 23:23:05,767] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:23:05,789] {logging_mixin.py:115} INFO - [2023-01-07 23:23:05,789] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:23:05,798] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.884 seconds
[2023-01-07 23:23:35,911] {processor.py:153} INFO - Started process (PID=5034) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:23:35,913] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:23:35,913] {logging_mixin.py:115} INFO - [2023-01-07 23:23:35,913] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:23:36,714] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:23:36,716] {logging_mixin.py:115} INFO - [2023-01-07 23:23:36,716] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:23:36,716] {logging_mixin.py:115} INFO - [2023-01-07 23:23:36,716] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:23:36,724] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:23:36,747] {logging_mixin.py:115} INFO - [2023-01-07 23:23:36,746] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:23:36,769] {logging_mixin.py:115} INFO - [2023-01-07 23:23:36,768] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:23:36,778] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.872 seconds
[2023-01-07 23:24:07,022] {processor.py:153} INFO - Started process (PID=5059) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:24:07,022] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:24:07,023] {logging_mixin.py:115} INFO - [2023-01-07 23:24:07,023] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:24:07,831] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:24:07,833] {logging_mixin.py:115} INFO - [2023-01-07 23:24:07,832] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:24:07,833] {logging_mixin.py:115} INFO - [2023-01-07 23:24:07,833] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:24:07,840] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:24:07,863] {logging_mixin.py:115} INFO - [2023-01-07 23:24:07,862] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:24:07,884] {logging_mixin.py:115} INFO - [2023-01-07 23:24:07,884] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:24:07,893] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.876 seconds
[2023-01-07 23:24:38,099] {processor.py:153} INFO - Started process (PID=5084) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:24:38,100] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:24:38,101] {logging_mixin.py:115} INFO - [2023-01-07 23:24:38,101] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:24:38,925] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:24:38,927] {logging_mixin.py:115} INFO - [2023-01-07 23:24:38,927] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:24:38,928] {logging_mixin.py:115} INFO - [2023-01-07 23:24:38,927] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:24:38,935] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:24:38,958] {logging_mixin.py:115} INFO - [2023-01-07 23:24:38,958] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:24:38,980] {logging_mixin.py:115} INFO - [2023-01-07 23:24:38,980] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:24:38,990] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.896 seconds
[2023-01-07 23:25:09,188] {processor.py:153} INFO - Started process (PID=5109) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:25:09,188] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:25:09,189] {logging_mixin.py:115} INFO - [2023-01-07 23:25:09,189] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:25:09,984] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:25:09,985] {logging_mixin.py:115} INFO - [2023-01-07 23:25:09,985] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:25:09,986] {logging_mixin.py:115} INFO - [2023-01-07 23:25:09,985] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:25:09,993] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:25:10,015] {logging_mixin.py:115} INFO - [2023-01-07 23:25:10,015] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:25:10,036] {logging_mixin.py:115} INFO - [2023-01-07 23:25:10,036] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:25:10,045] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.863 seconds
[2023-01-07 23:25:40,420] {processor.py:153} INFO - Started process (PID=5128) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:25:40,426] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:25:40,427] {logging_mixin.py:115} INFO - [2023-01-07 23:25:40,426] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:25:41,248] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:25:41,250] {logging_mixin.py:115} INFO - [2023-01-07 23:25:41,250] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:25:41,250] {logging_mixin.py:115} INFO - [2023-01-07 23:25:41,250] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:25:41,258] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:25:41,281] {logging_mixin.py:115} INFO - [2023-01-07 23:25:41,281] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:25:41,302] {logging_mixin.py:115} INFO - [2023-01-07 23:25:41,302] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:25:41,312] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.896 seconds
[2023-01-07 23:26:11,409] {processor.py:153} INFO - Started process (PID=5154) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:26:11,410] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:26:11,411] {logging_mixin.py:115} INFO - [2023-01-07 23:26:11,411] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:26:12,204] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:26:12,205] {logging_mixin.py:115} INFO - [2023-01-07 23:26:12,205] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:26:12,206] {logging_mixin.py:115} INFO - [2023-01-07 23:26:12,205] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:26:12,213] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:26:12,234] {logging_mixin.py:115} INFO - [2023-01-07 23:26:12,234] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:26:12,255] {logging_mixin.py:115} INFO - [2023-01-07 23:26:12,255] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:26:12,264] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.860 seconds
[2023-01-07 23:26:42,536] {processor.py:153} INFO - Started process (PID=5179) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:26:42,538] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:26:42,538] {logging_mixin.py:115} INFO - [2023-01-07 23:26:42,538] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:26:43,342] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:26:43,343] {logging_mixin.py:115} INFO - [2023-01-07 23:26:43,343] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:26:43,343] {logging_mixin.py:115} INFO - [2023-01-07 23:26:43,343] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:26:43,350] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:26:43,374] {logging_mixin.py:115} INFO - [2023-01-07 23:26:43,373] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:26:43,396] {logging_mixin.py:115} INFO - [2023-01-07 23:26:43,395] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:26:43,405] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.874 seconds
[2023-01-07 23:27:13,484] {processor.py:153} INFO - Started process (PID=5205) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:27:13,485] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:27:13,485] {logging_mixin.py:115} INFO - [2023-01-07 23:27:13,485] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:27:14,317] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:27:14,319] {logging_mixin.py:115} INFO - [2023-01-07 23:27:14,319] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:27:14,319] {logging_mixin.py:115} INFO - [2023-01-07 23:27:14,319] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:27:14,326] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:27:14,349] {logging_mixin.py:115} INFO - [2023-01-07 23:27:14,349] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:27:14,371] {logging_mixin.py:115} INFO - [2023-01-07 23:27:14,371] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:27:14,381] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.901 seconds
[2023-01-07 23:27:44,458] {processor.py:153} INFO - Started process (PID=5223) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:27:44,459] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:27:44,460] {logging_mixin.py:115} INFO - [2023-01-07 23:27:44,460] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:27:45,258] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:27:45,260] {logging_mixin.py:115} INFO - [2023-01-07 23:27:45,260] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:27:45,260] {logging_mixin.py:115} INFO - [2023-01-07 23:27:45,260] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:27:45,267] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:27:45,289] {logging_mixin.py:115} INFO - [2023-01-07 23:27:45,289] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:27:45,311] {logging_mixin.py:115} INFO - [2023-01-07 23:27:45,311] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:27:45,320] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.867 seconds
[2023-01-07 23:28:15,991] {processor.py:153} INFO - Started process (PID=5249) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:28:15,991] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:28:15,992] {logging_mixin.py:115} INFO - [2023-01-07 23:28:15,992] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:28:16,798] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:28:16,800] {logging_mixin.py:115} INFO - [2023-01-07 23:28:16,799] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:28:16,800] {logging_mixin.py:115} INFO - [2023-01-07 23:28:16,800] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:28:16,807] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:28:16,829] {logging_mixin.py:115} INFO - [2023-01-07 23:28:16,829] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:28:16,850] {logging_mixin.py:115} INFO - [2023-01-07 23:28:16,850] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:28:16,859] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.873 seconds
[2023-01-07 23:28:47,061] {processor.py:153} INFO - Started process (PID=5272) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:28:47,062] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:28:47,063] {logging_mixin.py:115} INFO - [2023-01-07 23:28:47,063] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:28:47,950] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:28:47,952] {logging_mixin.py:115} INFO - [2023-01-07 23:28:47,952] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:28:47,953] {logging_mixin.py:115} INFO - [2023-01-07 23:28:47,953] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:28:47,962] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:28:47,984] {logging_mixin.py:115} INFO - [2023-01-07 23:28:47,984] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:28:48,005] {logging_mixin.py:115} INFO - [2023-01-07 23:28:48,005] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:28:48,015] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.958 seconds
[2023-01-07 23:29:18,131] {processor.py:153} INFO - Started process (PID=5298) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:29:18,131] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:29:18,133] {logging_mixin.py:115} INFO - [2023-01-07 23:29:18,133] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:29:18,946] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:29:18,948] {logging_mixin.py:115} INFO - [2023-01-07 23:29:18,948] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:29:18,948] {logging_mixin.py:115} INFO - [2023-01-07 23:29:18,948] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:29:18,956] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:29:18,979] {logging_mixin.py:115} INFO - [2023-01-07 23:29:18,979] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:29:19,001] {logging_mixin.py:115} INFO - [2023-01-07 23:29:19,001] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:29:19,011] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.884 seconds
[2023-01-07 23:29:49,206] {processor.py:153} INFO - Started process (PID=5316) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:29:49,208] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:29:49,209] {logging_mixin.py:115} INFO - [2023-01-07 23:29:49,209] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:29:50,040] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:29:50,041] {logging_mixin.py:115} INFO - [2023-01-07 23:29:50,041] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:29:50,042] {logging_mixin.py:115} INFO - [2023-01-07 23:29:50,042] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:29:50,049] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:29:50,076] {logging_mixin.py:115} INFO - [2023-01-07 23:29:50,076] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:29:50,097] {logging_mixin.py:115} INFO - [2023-01-07 23:29:50,097] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:29:50,106] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.904 seconds
[2023-01-07 23:30:20,207] {processor.py:153} INFO - Started process (PID=5342) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:30:20,209] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:30:20,210] {logging_mixin.py:115} INFO - [2023-01-07 23:30:20,210] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:30:21,016] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:30:21,018] {logging_mixin.py:115} INFO - [2023-01-07 23:30:21,018] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:30:21,018] {logging_mixin.py:115} INFO - [2023-01-07 23:30:21,018] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:30:21,026] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:30:21,049] {logging_mixin.py:115} INFO - [2023-01-07 23:30:21,049] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:30:21,070] {logging_mixin.py:115} INFO - [2023-01-07 23:30:21,070] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:30:21,080] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.878 seconds
[2023-01-07 23:30:51,315] {processor.py:153} INFO - Started process (PID=5366) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:30:51,316] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:30:51,317] {logging_mixin.py:115} INFO - [2023-01-07 23:30:51,317] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:30:52,139] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:30:52,140] {logging_mixin.py:115} INFO - [2023-01-07 23:30:52,140] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:30:52,141] {logging_mixin.py:115} INFO - [2023-01-07 23:30:52,140] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:30:52,148] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:30:52,170] {logging_mixin.py:115} INFO - [2023-01-07 23:30:52,170] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:30:52,191] {logging_mixin.py:115} INFO - [2023-01-07 23:30:52,191] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:30:52,201] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.891 seconds
[2023-01-07 23:31:22,405] {processor.py:153} INFO - Started process (PID=5391) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:31:22,406] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:31:22,408] {logging_mixin.py:115} INFO - [2023-01-07 23:31:22,407] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:31:23,211] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:31:23,212] {logging_mixin.py:115} INFO - [2023-01-07 23:31:23,212] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:31:23,212] {logging_mixin.py:115} INFO - [2023-01-07 23:31:23,212] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:31:23,220] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:31:23,243] {logging_mixin.py:115} INFO - [2023-01-07 23:31:23,242] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:31:23,264] {logging_mixin.py:115} INFO - [2023-01-07 23:31:23,264] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:31:23,273] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.874 seconds
[2023-01-07 23:31:53,368] {processor.py:153} INFO - Started process (PID=5410) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:31:53,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-07 23:31:53,370] {logging_mixin.py:115} INFO - [2023-01-07 23:31:53,370] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:31:54,321] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-07 23:31:54,322] {logging_mixin.py:115} INFO - [2023-01-07 23:31:54,322] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-07 23:31:54,323] {logging_mixin.py:115} INFO - [2023-01-07 23:31:54,323] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-07 23:31:54,331] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-07 23:31:54,362] {logging_mixin.py:115} INFO - [2023-01-07 23:31:54,361] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-07 23:31:54,392] {logging_mixin.py:115} INFO - [2023-01-07 23:31:54,392] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-07T22:55:00+00:00, run_after=2023-01-08T22:55:00+00:00
[2023-01-07 23:31:54,408] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.045 seconds

[2023-01-06 00:00:28,063] {processor.py:153} INFO - Started process (PID=6830) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:00:28,063] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:00:28,064] {logging_mixin.py:115} INFO - [2023-01-06 00:00:28,064] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:00:29,052] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:00:29,054] {logging_mixin.py:115} INFO - [2023-01-06 00:00:29,053] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:00:29,054] {logging_mixin.py:115} INFO - [2023-01-06 00:00:29,054] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:00:29,061] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:00:29,086] {logging_mixin.py:115} INFO - [2023-01-06 00:00:29,086] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:00:29,108] {logging_mixin.py:115} INFO - [2023-01-06 00:00:29,108] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:00:29,119] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.061 seconds
[2023-01-06 00:00:59,191] {processor.py:153} INFO - Started process (PID=6856) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:00:59,192] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:00:59,193] {logging_mixin.py:115} INFO - [2023-01-06 00:00:59,193] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:01:00,161] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:01:00,162] {logging_mixin.py:115} INFO - [2023-01-06 00:01:00,162] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:01:00,163] {logging_mixin.py:115} INFO - [2023-01-06 00:01:00,163] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:01:00,173] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:01:00,204] {logging_mixin.py:115} INFO - [2023-01-06 00:01:00,204] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:01:00,234] {logging_mixin.py:115} INFO - [2023-01-06 00:01:00,234] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:01:00,247] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.061 seconds
[2023-01-06 00:01:30,321] {processor.py:153} INFO - Started process (PID=6879) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:01:30,324] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:01:30,325] {logging_mixin.py:115} INFO - [2023-01-06 00:01:30,325] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:01:31,246] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:01:31,248] {logging_mixin.py:115} INFO - [2023-01-06 00:01:31,247] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:01:31,248] {logging_mixin.py:115} INFO - [2023-01-06 00:01:31,248] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:01:31,255] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:01:31,278] {logging_mixin.py:115} INFO - [2023-01-06 00:01:31,277] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:01:31,298] {logging_mixin.py:115} INFO - [2023-01-06 00:01:31,298] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:01:31,309] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.994 seconds
[2023-01-06 00:02:01,389] {processor.py:153} INFO - Started process (PID=6898) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:02:01,389] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:02:01,390] {logging_mixin.py:115} INFO - [2023-01-06 00:02:01,390] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:02:02,315] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:02:02,316] {logging_mixin.py:115} INFO - [2023-01-06 00:02:02,316] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:02:02,316] {logging_mixin.py:115} INFO - [2023-01-06 00:02:02,316] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:02:02,323] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:02:02,347] {logging_mixin.py:115} INFO - [2023-01-06 00:02:02,347] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:02:02,368] {logging_mixin.py:115} INFO - [2023-01-06 00:02:02,368] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:02:02,379] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.995 seconds
[2023-01-06 00:02:32,454] {processor.py:153} INFO - Started process (PID=6923) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:02:32,456] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:02:32,456] {logging_mixin.py:115} INFO - [2023-01-06 00:02:32,456] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:02:33,384] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:02:33,385] {logging_mixin.py:115} INFO - [2023-01-06 00:02:33,385] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:02:33,386] {logging_mixin.py:115} INFO - [2023-01-06 00:02:33,385] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:02:33,393] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:02:33,417] {logging_mixin.py:115} INFO - [2023-01-06 00:02:33,416] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:02:33,439] {logging_mixin.py:115} INFO - [2023-01-06 00:02:33,438] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:02:33,449] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.999 seconds
[2023-01-06 00:03:03,527] {processor.py:153} INFO - Started process (PID=6947) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:03:03,528] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:03:03,528] {logging_mixin.py:115} INFO - [2023-01-06 00:03:03,528] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:03:04,488] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:03:04,489] {logging_mixin.py:115} INFO - [2023-01-06 00:03:04,489] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:03:04,490] {logging_mixin.py:115} INFO - [2023-01-06 00:03:04,490] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:03:04,497] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:03:04,521] {logging_mixin.py:115} INFO - [2023-01-06 00:03:04,521] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:03:04,543] {logging_mixin.py:115} INFO - [2023-01-06 00:03:04,543] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:03:04,554] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.032 seconds
[2023-01-06 00:03:34,629] {processor.py:153} INFO - Started process (PID=6972) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:03:34,630] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:03:34,630] {logging_mixin.py:115} INFO - [2023-01-06 00:03:34,630] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:03:35,632] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:03:35,633] {logging_mixin.py:115} INFO - [2023-01-06 00:03:35,633] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:03:35,634] {logging_mixin.py:115} INFO - [2023-01-06 00:03:35,633] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:03:35,640] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:03:35,663] {logging_mixin.py:115} INFO - [2023-01-06 00:03:35,663] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:03:35,684] {logging_mixin.py:115} INFO - [2023-01-06 00:03:35,684] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:03:35,694] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.069 seconds
[2023-01-06 00:04:05,777] {processor.py:153} INFO - Started process (PID=6990) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:04:05,778] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:04:05,779] {logging_mixin.py:115} INFO - [2023-01-06 00:04:05,778] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:04:06,694] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:04:06,695] {logging_mixin.py:115} INFO - [2023-01-06 00:04:06,695] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:04:06,695] {logging_mixin.py:115} INFO - [2023-01-06 00:04:06,695] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:04:06,702] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:04:06,725] {logging_mixin.py:115} INFO - [2023-01-06 00:04:06,724] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:04:06,746] {logging_mixin.py:115} INFO - [2023-01-06 00:04:06,745] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:04:06,756] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.984 seconds
[2023-01-06 00:04:36,799] {processor.py:153} INFO - Started process (PID=7015) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:04:36,800] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:04:36,801] {logging_mixin.py:115} INFO - [2023-01-06 00:04:36,801] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:04:37,716] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:04:37,718] {logging_mixin.py:115} INFO - [2023-01-06 00:04:37,718] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:04:37,718] {logging_mixin.py:115} INFO - [2023-01-06 00:04:37,718] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:04:37,725] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:04:37,747] {logging_mixin.py:115} INFO - [2023-01-06 00:04:37,747] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:04:37,768] {logging_mixin.py:115} INFO - [2023-01-06 00:04:37,768] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:04:37,777] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.983 seconds
[2023-01-06 00:05:07,835] {processor.py:153} INFO - Started process (PID=7039) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:05:07,836] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:05:07,837] {logging_mixin.py:115} INFO - [2023-01-06 00:05:07,837] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:05:08,766] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:05:08,767] {logging_mixin.py:115} INFO - [2023-01-06 00:05:08,767] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:05:08,768] {logging_mixin.py:115} INFO - [2023-01-06 00:05:08,767] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:05:08,775] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:05:08,797] {logging_mixin.py:115} INFO - [2023-01-06 00:05:08,796] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:05:08,824] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.994 seconds
[2023-01-06 00:05:38,854] {processor.py:153} INFO - Started process (PID=7064) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:05:38,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:05:38,857] {logging_mixin.py:115} INFO - [2023-01-06 00:05:38,857] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:05:39,796] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:05:39,797] {logging_mixin.py:115} INFO - [2023-01-06 00:05:39,797] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:05:39,798] {logging_mixin.py:115} INFO - [2023-01-06 00:05:39,797] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:05:39,806] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:05:39,832] {logging_mixin.py:115} INFO - [2023-01-06 00:05:39,831] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:05:39,865] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.015 seconds
[2023-01-06 00:06:09,909] {processor.py:153} INFO - Started process (PID=7081) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:06:09,913] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:06:09,915] {logging_mixin.py:115} INFO - [2023-01-06 00:06:09,915] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:06:10,853] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:06:10,855] {logging_mixin.py:115} INFO - [2023-01-06 00:06:10,855] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:06:10,855] {logging_mixin.py:115} INFO - [2023-01-06 00:06:10,855] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:06:10,862] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:06:10,885] {logging_mixin.py:115} INFO - [2023-01-06 00:06:10,885] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:06:10,912] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.008 seconds
[2023-01-06 00:06:40,941] {processor.py:153} INFO - Started process (PID=7106) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:06:40,942] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:06:40,943] {logging_mixin.py:115} INFO - [2023-01-06 00:06:40,943] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:06:41,871] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:06:41,872] {logging_mixin.py:115} INFO - [2023-01-06 00:06:41,872] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:06:41,873] {logging_mixin.py:115} INFO - [2023-01-06 00:06:41,873] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:06:41,884] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:06:41,908] {logging_mixin.py:115} INFO - [2023-01-06 00:06:41,908] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:06:41,936] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.000 seconds
[2023-01-06 00:07:11,970] {processor.py:153} INFO - Started process (PID=7130) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:07:11,977] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:07:11,979] {logging_mixin.py:115} INFO - [2023-01-06 00:07:11,979] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:07:12,913] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:07:12,914] {logging_mixin.py:115} INFO - [2023-01-06 00:07:12,914] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:07:12,915] {logging_mixin.py:115} INFO - [2023-01-06 00:07:12,915] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:07:12,922] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:07:12,944] {logging_mixin.py:115} INFO - [2023-01-06 00:07:12,944] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:07:12,971] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.006 seconds
[2023-01-06 00:07:43,041] {processor.py:153} INFO - Started process (PID=7149) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:07:43,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:07:43,043] {logging_mixin.py:115} INFO - [2023-01-06 00:07:43,043] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:07:44,207] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:07:44,209] {logging_mixin.py:115} INFO - [2023-01-06 00:07:44,209] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:07:44,210] {logging_mixin.py:115} INFO - [2023-01-06 00:07:44,209] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:07:44,221] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:07:44,252] {logging_mixin.py:115} INFO - [2023-01-06 00:07:44,252] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:07:44,289] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.253 seconds
[2023-01-06 00:08:14,367] {processor.py:153} INFO - Started process (PID=7175) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:08:14,371] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:08:14,373] {logging_mixin.py:115} INFO - [2023-01-06 00:08:14,373] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:08:15,320] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:08:15,322] {logging_mixin.py:115} INFO - [2023-01-06 00:08:15,322] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:08:15,322] {logging_mixin.py:115} INFO - [2023-01-06 00:08:15,322] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:08:15,329] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:08:15,352] {logging_mixin.py:115} INFO - [2023-01-06 00:08:15,352] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:08:15,381] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.020 seconds
[2023-01-06 00:08:45,432] {processor.py:153} INFO - Started process (PID=7200) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:08:45,432] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:08:45,434] {logging_mixin.py:115} INFO - [2023-01-06 00:08:45,434] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:08:46,343] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:08:46,344] {logging_mixin.py:115} INFO - [2023-01-06 00:08:46,344] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:08:46,345] {logging_mixin.py:115} INFO - [2023-01-06 00:08:46,344] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:08:46,352] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:08:46,377] {logging_mixin.py:115} INFO - [2023-01-06 00:08:46,376] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:08:46,406] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.979 seconds
[2023-01-06 00:09:16,495] {processor.py:153} INFO - Started process (PID=7225) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:09:16,496] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:09:16,498] {logging_mixin.py:115} INFO - [2023-01-06 00:09:16,498] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:09:17,390] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:09:17,391] {logging_mixin.py:115} INFO - [2023-01-06 00:09:17,391] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:09:17,392] {logging_mixin.py:115} INFO - [2023-01-06 00:09:17,391] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:09:17,398] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:09:17,422] {logging_mixin.py:115} INFO - [2023-01-06 00:09:17,421] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:09:17,450] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.960 seconds
[2023-01-06 00:09:47,525] {processor.py:153} INFO - Started process (PID=7244) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:09:47,526] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:09:47,528] {logging_mixin.py:115} INFO - [2023-01-06 00:09:47,528] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:09:48,432] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:09:48,434] {logging_mixin.py:115} INFO - [2023-01-06 00:09:48,434] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:09:48,434] {logging_mixin.py:115} INFO - [2023-01-06 00:09:48,434] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:09:48,441] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:09:48,464] {logging_mixin.py:115} INFO - [2023-01-06 00:09:48,463] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:09:48,493] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.972 seconds
[2023-01-06 00:10:18,566] {processor.py:153} INFO - Started process (PID=7268) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:10:18,569] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:10:18,570] {logging_mixin.py:115} INFO - [2023-01-06 00:10:18,570] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:10:19,497] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:10:19,498] {logging_mixin.py:115} INFO - [2023-01-06 00:10:19,498] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:10:19,499] {logging_mixin.py:115} INFO - [2023-01-06 00:10:19,499] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:10:19,507] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:10:19,530] {logging_mixin.py:115} INFO - [2023-01-06 00:10:19,529] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:10:19,558] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.997 seconds
[2023-01-06 00:10:49,604] {processor.py:153} INFO - Started process (PID=7292) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:10:49,605] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:10:49,606] {logging_mixin.py:115} INFO - [2023-01-06 00:10:49,606] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:10:50,546] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:10:50,547] {logging_mixin.py:115} INFO - [2023-01-06 00:10:50,547] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:10:50,548] {logging_mixin.py:115} INFO - [2023-01-06 00:10:50,547] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:10:50,555] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:10:50,581] {logging_mixin.py:115} INFO - [2023-01-06 00:10:50,581] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:10:50,611] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.012 seconds
[2023-01-06 00:11:20,710] {processor.py:153} INFO - Started process (PID=7317) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:11:20,711] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:11:20,712] {logging_mixin.py:115} INFO - [2023-01-06 00:11:20,712] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:11:21,640] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:11:21,642] {logging_mixin.py:115} INFO - [2023-01-06 00:11:21,642] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:11:21,642] {logging_mixin.py:115} INFO - [2023-01-06 00:11:21,642] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:11:21,649] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:11:21,675] {logging_mixin.py:115} INFO - [2023-01-06 00:11:21,674] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:11:21,704] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.999 seconds
[2023-01-06 00:11:51,782] {processor.py:153} INFO - Started process (PID=7334) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:11:51,782] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:11:51,783] {logging_mixin.py:115} INFO - [2023-01-06 00:11:51,783] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:11:52,740] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:11:52,741] {logging_mixin.py:115} INFO - [2023-01-06 00:11:52,741] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:11:52,742] {logging_mixin.py:115} INFO - [2023-01-06 00:11:52,741] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:11:52,749] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:11:52,771] {logging_mixin.py:115} INFO - [2023-01-06 00:11:52,771] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:11:52,799] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.022 seconds
[2023-01-06 00:12:22,863] {processor.py:153} INFO - Started process (PID=7361) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:12:22,866] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:12:22,866] {logging_mixin.py:115} INFO - [2023-01-06 00:12:22,866] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:12:23,799] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:12:23,801] {logging_mixin.py:115} INFO - [2023-01-06 00:12:23,801] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:12:23,801] {logging_mixin.py:115} INFO - [2023-01-06 00:12:23,801] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:12:23,808] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:12:23,832] {logging_mixin.py:115} INFO - [2023-01-06 00:12:23,832] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:12:23,854] {logging_mixin.py:115} INFO - [2023-01-06 00:12:23,854] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:12:23,864] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.006 seconds
[2023-01-06 00:12:53,950] {processor.py:153} INFO - Started process (PID=7386) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:12:53,951] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:12:53,951] {logging_mixin.py:115} INFO - [2023-01-06 00:12:53,951] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:12:54,874] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:12:54,876] {logging_mixin.py:115} INFO - [2023-01-06 00:12:54,875] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:12:54,876] {logging_mixin.py:115} INFO - [2023-01-06 00:12:54,876] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:12:54,883] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:12:54,906] {logging_mixin.py:115} INFO - [2023-01-06 00:12:54,906] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:12:54,930] {logging_mixin.py:115} INFO - [2023-01-06 00:12:54,930] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:12:54,943] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.998 seconds
[2023-01-06 00:13:25,021] {processor.py:153} INFO - Started process (PID=7412) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:13:25,023] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:13:25,024] {logging_mixin.py:115} INFO - [2023-01-06 00:13:25,023] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:13:26,066] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:13:26,067] {logging_mixin.py:115} INFO - [2023-01-06 00:13:26,067] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:13:26,068] {logging_mixin.py:115} INFO - [2023-01-06 00:13:26,068] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:13:26,075] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:13:26,107] {logging_mixin.py:115} INFO - [2023-01-06 00:13:26,107] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:13:26,139] {logging_mixin.py:115} INFO - [2023-01-06 00:13:26,139] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:13:26,152] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.137 seconds
[2023-01-06 00:13:56,226] {processor.py:153} INFO - Started process (PID=7430) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:13:56,227] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:13:56,228] {logging_mixin.py:115} INFO - [2023-01-06 00:13:56,228] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:13:57,182] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:13:57,183] {logging_mixin.py:115} INFO - [2023-01-06 00:13:57,183] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:13:57,184] {logging_mixin.py:115} INFO - [2023-01-06 00:13:57,184] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:13:57,191] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:13:57,215] {logging_mixin.py:115} INFO - [2023-01-06 00:13:57,214] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:13:57,236] {logging_mixin.py:115} INFO - [2023-01-06 00:13:57,236] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:13:57,246] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.025 seconds
[2023-01-06 00:14:27,306] {processor.py:153} INFO - Started process (PID=7454) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:14:27,306] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:14:27,307] {logging_mixin.py:115} INFO - [2023-01-06 00:14:27,307] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:14:28,230] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:14:28,232] {logging_mixin.py:115} INFO - [2023-01-06 00:14:28,232] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:14:28,232] {logging_mixin.py:115} INFO - [2023-01-06 00:14:28,232] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:14:28,239] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:14:28,262] {logging_mixin.py:115} INFO - [2023-01-06 00:14:28,262] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:14:28,284] {logging_mixin.py:115} INFO - [2023-01-06 00:14:28,284] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:14:28,293] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.993 seconds
[2023-01-06 00:14:58,381] {processor.py:153} INFO - Started process (PID=7479) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:14:58,383] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:14:58,384] {logging_mixin.py:115} INFO - [2023-01-06 00:14:58,383] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:14:59,365] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:14:59,367] {logging_mixin.py:115} INFO - [2023-01-06 00:14:59,366] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:14:59,367] {logging_mixin.py:115} INFO - [2023-01-06 00:14:59,367] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:14:59,374] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:14:59,404] {logging_mixin.py:115} INFO - [2023-01-06 00:14:59,404] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:14:59,435] {logging_mixin.py:115} INFO - [2023-01-06 00:14:59,434] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:14:59,446] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.071 seconds
[2023-01-06 00:15:29,531] {processor.py:153} INFO - Started process (PID=7504) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:15:29,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:15:29,533] {logging_mixin.py:115} INFO - [2023-01-06 00:15:29,533] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:15:30,477] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:15:30,479] {logging_mixin.py:115} INFO - [2023-01-06 00:15:30,479] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:15:30,479] {logging_mixin.py:115} INFO - [2023-01-06 00:15:30,479] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:15:30,486] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:15:30,511] {logging_mixin.py:115} INFO - [2023-01-06 00:15:30,510] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:15:30,533] {logging_mixin.py:115} INFO - [2023-01-06 00:15:30,533] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:15:30,543] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.018 seconds
[2023-01-06 00:16:00,617] {processor.py:153} INFO - Started process (PID=7522) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:16:00,618] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:16:00,618] {logging_mixin.py:115} INFO - [2023-01-06 00:16:00,618] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:16:01,554] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:16:01,555] {logging_mixin.py:115} INFO - [2023-01-06 00:16:01,555] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:16:01,556] {logging_mixin.py:115} INFO - [2023-01-06 00:16:01,555] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:16:01,563] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:16:01,588] {logging_mixin.py:115} INFO - [2023-01-06 00:16:01,588] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:16:01,611] {logging_mixin.py:115} INFO - [2023-01-06 00:16:01,611] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:16:01,621] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.009 seconds
[2023-01-06 00:16:31,659] {processor.py:153} INFO - Started process (PID=7547) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:16:31,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:16:31,661] {logging_mixin.py:115} INFO - [2023-01-06 00:16:31,661] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:16:32,611] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:16:32,613] {logging_mixin.py:115} INFO - [2023-01-06 00:16:32,613] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:16:32,613] {logging_mixin.py:115} INFO - [2023-01-06 00:16:32,613] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:16:32,620] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:16:32,644] {logging_mixin.py:115} INFO - [2023-01-06 00:16:32,643] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:16:32,666] {logging_mixin.py:115} INFO - [2023-01-06 00:16:32,666] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:16:32,676] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.022 seconds
[2023-01-06 00:17:02,718] {processor.py:153} INFO - Started process (PID=7570) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:17:02,720] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:17:02,720] {logging_mixin.py:115} INFO - [2023-01-06 00:17:02,720] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:17:03,658] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:17:03,660] {logging_mixin.py:115} INFO - [2023-01-06 00:17:03,660] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:17:03,661] {logging_mixin.py:115} INFO - [2023-01-06 00:17:03,660] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:17:03,668] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:17:03,692] {logging_mixin.py:115} INFO - [2023-01-06 00:17:03,692] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:17:03,715] {logging_mixin.py:115} INFO - [2023-01-06 00:17:03,715] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:17:03,725] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.012 seconds
[2023-01-06 00:17:33,765] {processor.py:153} INFO - Started process (PID=7595) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:17:33,767] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:17:33,768] {logging_mixin.py:115} INFO - [2023-01-06 00:17:33,767] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:17:34,724] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:17:34,726] {logging_mixin.py:115} INFO - [2023-01-06 00:17:34,726] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:17:34,726] {logging_mixin.py:115} INFO - [2023-01-06 00:17:34,726] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:17:34,734] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:17:34,762] {logging_mixin.py:115} INFO - [2023-01-06 00:17:34,761] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:17:34,788] {logging_mixin.py:115} INFO - [2023-01-06 00:17:34,787] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:17:34,799] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.040 seconds
[2023-01-06 00:18:04,839] {processor.py:153} INFO - Started process (PID=7614) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:18:04,839] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:18:04,840] {logging_mixin.py:115} INFO - [2023-01-06 00:18:04,840] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:18:05,770] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:18:05,772] {logging_mixin.py:115} INFO - [2023-01-06 00:18:05,771] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:18:05,772] {logging_mixin.py:115} INFO - [2023-01-06 00:18:05,772] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:18:05,779] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:18:05,802] {logging_mixin.py:115} INFO - [2023-01-06 00:18:05,802] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:18:05,823] {logging_mixin.py:115} INFO - [2023-01-06 00:18:05,823] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:18:05,833] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.999 seconds
[2023-01-06 00:18:35,929] {processor.py:153} INFO - Started process (PID=7639) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:18:35,930] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:18:35,931] {logging_mixin.py:115} INFO - [2023-01-06 00:18:35,931] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:18:36,853] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:18:36,854] {logging_mixin.py:115} INFO - [2023-01-06 00:18:36,854] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:18:36,855] {logging_mixin.py:115} INFO - [2023-01-06 00:18:36,854] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:18:36,861] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:18:36,885] {logging_mixin.py:115} INFO - [2023-01-06 00:18:36,885] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:18:36,908] {logging_mixin.py:115} INFO - [2023-01-06 00:18:36,908] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:18:36,918] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.994 seconds
[2023-01-06 00:19:07,003] {processor.py:153} INFO - Started process (PID=7664) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:19:07,003] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:19:07,004] {logging_mixin.py:115} INFO - [2023-01-06 00:19:07,004] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:19:08,066] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:19:08,068] {logging_mixin.py:115} INFO - [2023-01-06 00:19:08,068] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:19:08,068] {logging_mixin.py:115} INFO - [2023-01-06 00:19:08,068] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:19:08,076] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:19:08,106] {logging_mixin.py:115} INFO - [2023-01-06 00:19:08,106] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:19:08,137] {logging_mixin.py:115} INFO - [2023-01-06 00:19:08,137] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:19:08,149] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.152 seconds
[2023-01-06 00:19:38,227] {processor.py:153} INFO - Started process (PID=7682) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:19:38,228] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:19:38,229] {logging_mixin.py:115} INFO - [2023-01-06 00:19:38,229] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:19:39,176] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:19:39,178] {logging_mixin.py:115} INFO - [2023-01-06 00:19:39,178] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:19:39,178] {logging_mixin.py:115} INFO - [2023-01-06 00:19:39,178] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:19:39,185] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:19:39,209] {logging_mixin.py:115} INFO - [2023-01-06 00:19:39,208] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:19:39,229] {logging_mixin.py:115} INFO - [2023-01-06 00:19:39,229] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:19:39,240] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.018 seconds
[2023-01-06 00:20:09,316] {processor.py:153} INFO - Started process (PID=7707) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:20:09,317] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:20:09,318] {logging_mixin.py:115} INFO - [2023-01-06 00:20:09,318] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:20:10,260] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:20:10,261] {logging_mixin.py:115} INFO - [2023-01-06 00:20:10,261] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:20:10,262] {logging_mixin.py:115} INFO - [2023-01-06 00:20:10,261] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:20:10,269] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:20:10,294] {logging_mixin.py:115} INFO - [2023-01-06 00:20:10,293] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:20:10,316] {logging_mixin.py:115} INFO - [2023-01-06 00:20:10,316] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:20:10,326] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.015 seconds
[2023-01-06 00:20:40,399] {processor.py:153} INFO - Started process (PID=7732) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:20:40,400] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:20:40,401] {logging_mixin.py:115} INFO - [2023-01-06 00:20:40,401] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:20:41,412] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:20:41,413] {logging_mixin.py:115} INFO - [2023-01-06 00:20:41,413] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:20:41,414] {logging_mixin.py:115} INFO - [2023-01-06 00:20:41,414] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:20:41,421] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:20:41,444] {logging_mixin.py:115} INFO - [2023-01-06 00:20:41,444] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:20:41,465] {logging_mixin.py:115} INFO - [2023-01-06 00:20:41,465] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:20:41,475] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.080 seconds
[2023-01-06 00:21:11,557] {processor.py:153} INFO - Started process (PID=7756) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:21:11,558] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:21:11,559] {logging_mixin.py:115} INFO - [2023-01-06 00:21:11,559] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:21:12,525] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:21:12,526] {logging_mixin.py:115} INFO - [2023-01-06 00:21:12,526] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:21:12,526] {logging_mixin.py:115} INFO - [2023-01-06 00:21:12,526] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:21:12,534] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:21:12,563] {logging_mixin.py:115} INFO - [2023-01-06 00:21:12,563] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:21:12,585] {logging_mixin.py:115} INFO - [2023-01-06 00:21:12,585] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:21:12,596] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.045 seconds
[2023-01-06 00:21:42,674] {processor.py:153} INFO - Started process (PID=7774) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:21:42,675] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:21:42,676] {logging_mixin.py:115} INFO - [2023-01-06 00:21:42,675] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:21:43,600] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:21:43,602] {logging_mixin.py:115} INFO - [2023-01-06 00:21:43,601] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:21:43,602] {logging_mixin.py:115} INFO - [2023-01-06 00:21:43,602] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:21:43,609] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:21:43,633] {logging_mixin.py:115} INFO - [2023-01-06 00:21:43,632] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:21:43,654] {logging_mixin.py:115} INFO - [2023-01-06 00:21:43,654] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:21:43,665] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.995 seconds
[2023-01-06 00:22:13,696] {processor.py:153} INFO - Started process (PID=7799) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:22:13,698] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:22:13,699] {logging_mixin.py:115} INFO - [2023-01-06 00:22:13,698] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:22:14,682] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:22:14,683] {logging_mixin.py:115} INFO - [2023-01-06 00:22:14,683] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:22:14,684] {logging_mixin.py:115} INFO - [2023-01-06 00:22:14,684] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:22:14,691] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:22:14,714] {logging_mixin.py:115} INFO - [2023-01-06 00:22:14,713] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:22:14,734] {logging_mixin.py:115} INFO - [2023-01-06 00:22:14,734] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:22:14,745] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.053 seconds
[2023-01-06 00:22:44,819] {processor.py:153} INFO - Started process (PID=7824) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:22:44,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:22:44,821] {logging_mixin.py:115} INFO - [2023-01-06 00:22:44,821] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:22:45,746] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:22:45,748] {logging_mixin.py:115} INFO - [2023-01-06 00:22:45,748] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:22:45,748] {logging_mixin.py:115} INFO - [2023-01-06 00:22:45,748] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:22:45,755] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:22:45,780] {logging_mixin.py:115} INFO - [2023-01-06 00:22:45,779] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:22:45,806] {logging_mixin.py:115} INFO - [2023-01-06 00:22:45,806] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:22:45,818] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.004 seconds
[2023-01-06 00:23:15,890] {processor.py:153} INFO - Started process (PID=7850) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:23:15,892] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:23:15,892] {logging_mixin.py:115} INFO - [2023-01-06 00:23:15,892] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:23:16,841] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:23:16,842] {logging_mixin.py:115} INFO - [2023-01-06 00:23:16,842] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:23:16,843] {logging_mixin.py:115} INFO - [2023-01-06 00:23:16,842] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:23:16,853] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:23:16,885] {logging_mixin.py:115} INFO - [2023-01-06 00:23:16,885] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:23:16,915] {logging_mixin.py:115} INFO - [2023-01-06 00:23:16,915] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:23:16,926] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.042 seconds
[2023-01-06 00:23:46,998] {processor.py:153} INFO - Started process (PID=7868) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:23:47,000] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:23:47,000] {logging_mixin.py:115} INFO - [2023-01-06 00:23:47,000] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:23:47,989] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:23:47,991] {logging_mixin.py:115} INFO - [2023-01-06 00:23:47,991] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:23:47,992] {logging_mixin.py:115} INFO - [2023-01-06 00:23:47,991] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:23:48,003] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:23:48,035] {logging_mixin.py:115} INFO - [2023-01-06 00:23:48,034] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:23:48,066] {logging_mixin.py:115} INFO - [2023-01-06 00:23:48,066] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:23:48,078] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.085 seconds
[2023-01-06 00:24:18,158] {processor.py:153} INFO - Started process (PID=7894) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:24:18,159] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:24:18,160] {logging_mixin.py:115} INFO - [2023-01-06 00:24:18,160] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:24:19,081] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:24:19,083] {logging_mixin.py:115} INFO - [2023-01-06 00:24:19,083] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:24:19,083] {logging_mixin.py:115} INFO - [2023-01-06 00:24:19,083] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:24:19,090] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:24:19,112] {logging_mixin.py:115} INFO - [2023-01-06 00:24:19,112] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:24:19,133] {logging_mixin.py:115} INFO - [2023-01-06 00:24:19,133] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:24:19,143] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.990 seconds
[2023-01-06 00:24:49,249] {processor.py:153} INFO - Started process (PID=7919) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:24:49,249] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:24:49,250] {logging_mixin.py:115} INFO - [2023-01-06 00:24:49,250] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:24:50,215] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:24:50,216] {logging_mixin.py:115} INFO - [2023-01-06 00:24:50,216] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:24:50,217] {logging_mixin.py:115} INFO - [2023-01-06 00:24:50,216] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:24:50,223] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:24:50,247] {logging_mixin.py:115} INFO - [2023-01-06 00:24:50,246] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:24:50,268] {logging_mixin.py:115} INFO - [2023-01-06 00:24:50,267] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:24:50,277] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.033 seconds
[2023-01-06 00:25:20,365] {processor.py:153} INFO - Started process (PID=7944) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:25:20,366] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:25:20,367] {logging_mixin.py:115} INFO - [2023-01-06 00:25:20,367] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:25:21,299] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:25:21,301] {logging_mixin.py:115} INFO - [2023-01-06 00:25:21,300] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:25:21,301] {logging_mixin.py:115} INFO - [2023-01-06 00:25:21,301] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:25:21,308] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:25:21,342] {logging_mixin.py:115} INFO - [2023-01-06 00:25:21,341] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:25:21,376] {logging_mixin.py:115} INFO - [2023-01-06 00:25:21,376] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:25:21,389] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.029 seconds
[2023-01-06 00:25:51,480] {processor.py:153} INFO - Started process (PID=7962) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:25:51,481] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:25:51,482] {logging_mixin.py:115} INFO - [2023-01-06 00:25:51,482] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:25:52,424] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:25:52,425] {logging_mixin.py:115} INFO - [2023-01-06 00:25:52,425] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:25:52,426] {logging_mixin.py:115} INFO - [2023-01-06 00:25:52,425] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:25:52,433] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:25:52,455] {logging_mixin.py:115} INFO - [2023-01-06 00:25:52,455] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:25:52,477] {logging_mixin.py:115} INFO - [2023-01-06 00:25:52,476] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:25:52,487] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.013 seconds
[2023-01-06 00:26:22,561] {processor.py:153} INFO - Started process (PID=7986) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:26:22,562] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:26:22,563] {logging_mixin.py:115} INFO - [2023-01-06 00:26:22,562] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:26:23,488] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:26:23,490] {logging_mixin.py:115} INFO - [2023-01-06 00:26:23,490] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:26:23,490] {logging_mixin.py:115} INFO - [2023-01-06 00:26:23,490] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:26:23,497] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:26:23,522] {logging_mixin.py:115} INFO - [2023-01-06 00:26:23,521] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:26:23,551] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.995 seconds
[2023-01-06 00:26:53,631] {processor.py:153} INFO - Started process (PID=8009) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:26:53,632] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:26:53,633] {logging_mixin.py:115} INFO - [2023-01-06 00:26:53,633] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:26:54,570] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:26:54,572] {logging_mixin.py:115} INFO - [2023-01-06 00:26:54,571] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:26:54,572] {logging_mixin.py:115} INFO - [2023-01-06 00:26:54,572] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:26:54,579] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:26:54,607] {logging_mixin.py:115} INFO - [2023-01-06 00:26:54,606] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:26:54,635] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.009 seconds
[2023-01-06 00:27:24,703] {processor.py:153} INFO - Started process (PID=8034) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:27:24,703] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:27:24,704] {logging_mixin.py:115} INFO - [2023-01-06 00:27:24,704] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:27:25,631] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:27:25,632] {logging_mixin.py:115} INFO - [2023-01-06 00:27:25,632] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:27:25,633] {logging_mixin.py:115} INFO - [2023-01-06 00:27:25,632] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:27:25,639] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:27:25,663] {logging_mixin.py:115} INFO - [2023-01-06 00:27:25,662] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:27:25,691] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.993 seconds
[2023-01-06 00:27:44,688] {processor.py:153} INFO - Started process (PID=8045) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:27:44,689] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:27:44,690] {logging_mixin.py:115} INFO - [2023-01-06 00:27:44,690] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:27:45,662] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:27:45,663] {logging_mixin.py:115} INFO - [2023-01-06 00:27:45,663] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:27:45,664] {logging_mixin.py:115} INFO - [2023-01-06 00:27:45,663] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:27:45,672] {logging_mixin.py:115} INFO - [2023-01-06 00:27:45,670] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipeline_dag.py", line 87, in <module>
    download_btc_data_from_datalake_task >> create_cluster_dataproc_task >> submit_spark_job_task >> delete_cluster_dataproc_task
NameError: name 'download_btc_data_from_datalake_task' is not defined
[2023-01-06 00:27:45,672] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:27:45,694] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.011 seconds
[2023-01-06 00:28:15,781] {processor.py:153} INFO - Started process (PID=8072) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:28:15,784] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:28:15,784] {logging_mixin.py:115} INFO - [2023-01-06 00:28:15,784] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:28:16,697] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:28:16,698] {logging_mixin.py:115} INFO - [2023-01-06 00:28:16,698] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:28:16,699] {logging_mixin.py:115} INFO - [2023-01-06 00:28:16,698] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:28:16,706] {logging_mixin.py:115} INFO - [2023-01-06 00:28:16,705] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipeline_dag.py", line 87, in <module>
    download_btc_data_from_datalake_task >> create_cluster_dataproc_task >> submit_spark_job_task >> delete_cluster_dataproc_task
NameError: name 'download_btc_data_from_datalake_task' is not defined
[2023-01-06 00:28:16,706] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:28:16,724] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.948 seconds
[2023-01-06 00:28:47,748] {processor.py:153} INFO - Started process (PID=8098) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:28:47,749] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:28:47,750] {logging_mixin.py:115} INFO - [2023-01-06 00:28:47,750] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:28:48,747] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:28:48,749] {logging_mixin.py:115} INFO - [2023-01-06 00:28:48,749] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:28:48,749] {logging_mixin.py:115} INFO - [2023-01-06 00:28:48,749] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:28:48,756] {logging_mixin.py:115} INFO - [2023-01-06 00:28:48,756] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipeline_dag.py", line 87, in <module>
    download_btc_data_from_datalake_task >> create_cluster_dataproc_task >> submit_spark_job_task >> delete_cluster_dataproc_task
NameError: name 'download_btc_data_from_datalake_task' is not defined
[2023-01-06 00:28:48,757] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:28:48,777] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.034 seconds
[2023-01-06 00:29:00,786] {processor.py:153} INFO - Started process (PID=8108) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:29:00,786] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:29:00,787] {logging_mixin.py:115} INFO - [2023-01-06 00:29:00,787] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:29:01,756] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:29:01,757] {logging_mixin.py:115} INFO - [2023-01-06 00:29:01,757] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:29:01,758] {logging_mixin.py:115} INFO - [2023-01-06 00:29:01,757] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:29:01,765] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:29:01,826] {logging_mixin.py:115} INFO - [2023-01-06 00:29:01,826] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:29:01,860] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.079 seconds
[2023-01-06 00:29:31,906] {processor.py:153} INFO - Started process (PID=8134) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:29:31,907] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:29:31,908] {logging_mixin.py:115} INFO - [2023-01-06 00:29:31,908] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:29:32,861] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:29:32,863] {logging_mixin.py:115} INFO - [2023-01-06 00:29:32,863] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:29:32,863] {logging_mixin.py:115} INFO - [2023-01-06 00:29:32,863] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:29:32,870] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:29:32,894] {logging_mixin.py:115} INFO - [2023-01-06 00:29:32,894] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:29:32,926] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.024 seconds
[2023-01-06 00:30:02,995] {processor.py:153} INFO - Started process (PID=8152) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:30:02,996] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:30:02,997] {logging_mixin.py:115} INFO - [2023-01-06 00:30:02,997] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:30:04,070] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:30:04,072] {logging_mixin.py:115} INFO - [2023-01-06 00:30:04,072] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:30:04,072] {logging_mixin.py:115} INFO - [2023-01-06 00:30:04,072] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:30:04,080] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:30:04,105] {logging_mixin.py:115} INFO - [2023-01-06 00:30:04,105] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:30:04,135] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.144 seconds
[2023-01-06 00:30:34,212] {processor.py:153} INFO - Started process (PID=8177) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:30:34,213] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:30:34,214] {logging_mixin.py:115} INFO - [2023-01-06 00:30:34,214] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:30:35,118] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:30:35,119] {logging_mixin.py:115} INFO - [2023-01-06 00:30:35,119] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:30:35,120] {logging_mixin.py:115} INFO - [2023-01-06 00:30:35,120] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:30:35,127] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:30:35,150] {logging_mixin.py:115} INFO - [2023-01-06 00:30:35,150] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:30:35,178] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.970 seconds
[2023-01-06 00:31:05,250] {processor.py:153} INFO - Started process (PID=8202) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:31:05,252] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:31:05,252] {logging_mixin.py:115} INFO - [2023-01-06 00:31:05,252] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:31:06,220] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:31:06,221] {logging_mixin.py:115} INFO - [2023-01-06 00:31:06,221] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:31:06,221] {logging_mixin.py:115} INFO - [2023-01-06 00:31:06,221] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:31:06,228] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:31:06,252] {logging_mixin.py:115} INFO - [2023-01-06 00:31:06,251] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:31:06,280] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.034 seconds
[2023-01-06 00:31:36,330] {processor.py:153} INFO - Started process (PID=8227) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:31:36,331] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:31:36,331] {logging_mixin.py:115} INFO - [2023-01-06 00:31:36,331] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:31:37,409] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:31:37,410] {logging_mixin.py:115} INFO - [2023-01-06 00:31:37,410] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:31:37,411] {logging_mixin.py:115} INFO - [2023-01-06 00:31:37,411] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:31:37,418] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:31:37,441] {logging_mixin.py:115} INFO - [2023-01-06 00:31:37,441] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:31:37,470] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.145 seconds
[2023-01-06 00:32:07,546] {processor.py:153} INFO - Started process (PID=8246) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:32:07,548] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:32:07,549] {logging_mixin.py:115} INFO - [2023-01-06 00:32:07,549] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:32:08,588] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:32:08,590] {logging_mixin.py:115} INFO - [2023-01-06 00:32:08,590] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:32:08,590] {logging_mixin.py:115} INFO - [2023-01-06 00:32:08,590] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:32:08,597] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:32:08,621] {logging_mixin.py:115} INFO - [2023-01-06 00:32:08,620] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:32:08,649] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.107 seconds
[2023-01-06 00:32:38,720] {processor.py:153} INFO - Started process (PID=8272) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:32:38,723] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:32:38,723] {logging_mixin.py:115} INFO - [2023-01-06 00:32:38,723] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:32:39,674] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:32:39,675] {logging_mixin.py:115} INFO - [2023-01-06 00:32:39,675] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:32:39,676] {logging_mixin.py:115} INFO - [2023-01-06 00:32:39,676] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:32:39,683] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:32:39,708] {logging_mixin.py:115} INFO - [2023-01-06 00:32:39,708] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:32:39,738] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.023 seconds
[2023-01-06 00:33:09,802] {processor.py:153} INFO - Started process (PID=8296) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:33:09,803] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:33:09,803] {logging_mixin.py:115} INFO - [2023-01-06 00:33:09,803] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:33:10,731] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:33:10,732] {logging_mixin.py:115} INFO - [2023-01-06 00:33:10,732] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:33:10,733] {logging_mixin.py:115} INFO - [2023-01-06 00:33:10,733] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:33:10,741] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:33:10,765] {logging_mixin.py:115} INFO - [2023-01-06 00:33:10,765] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:33:10,792] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.995 seconds
[2023-01-06 00:33:40,865] {processor.py:153} INFO - Started process (PID=8321) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:33:40,866] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:33:40,867] {logging_mixin.py:115} INFO - [2023-01-06 00:33:40,867] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:33:41,859] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:33:41,860] {logging_mixin.py:115} INFO - [2023-01-06 00:33:41,860] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:33:41,861] {logging_mixin.py:115} INFO - [2023-01-06 00:33:41,861] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:33:41,868] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:33:41,892] {logging_mixin.py:115} INFO - [2023-01-06 00:33:41,892] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:33:41,922] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.062 seconds
[2023-01-06 00:34:11,993] {processor.py:153} INFO - Started process (PID=8338) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:34:11,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:34:11,994] {logging_mixin.py:115} INFO - [2023-01-06 00:34:11,994] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:34:13,183] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:34:13,184] {logging_mixin.py:115} INFO - [2023-01-06 00:34:13,184] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:34:13,184] {logging_mixin.py:115} INFO - [2023-01-06 00:34:13,184] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:34:13,191] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:34:13,216] {logging_mixin.py:115} INFO - [2023-01-06 00:34:13,215] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:34:13,244] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.257 seconds
[2023-01-06 00:34:43,317] {processor.py:153} INFO - Started process (PID=8362) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:34:43,319] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:34:43,319] {logging_mixin.py:115} INFO - [2023-01-06 00:34:43,319] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:34:44,265] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:34:44,266] {logging_mixin.py:115} INFO - [2023-01-06 00:34:44,266] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:34:44,267] {logging_mixin.py:115} INFO - [2023-01-06 00:34:44,266] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:34:44,274] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:34:44,297] {logging_mixin.py:115} INFO - [2023-01-06 00:34:44,297] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:34:44,328] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.015 seconds
[2023-01-06 00:35:14,401] {processor.py:153} INFO - Started process (PID=8388) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:35:14,402] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:35:14,403] {logging_mixin.py:115} INFO - [2023-01-06 00:35:14,403] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:35:15,371] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:35:15,372] {logging_mixin.py:115} INFO - [2023-01-06 00:35:15,372] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:35:15,373] {logging_mixin.py:115} INFO - [2023-01-06 00:35:15,372] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:35:15,380] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:35:15,403] {logging_mixin.py:115} INFO - [2023-01-06 00:35:15,402] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:35:15,430] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.034 seconds
[2023-01-06 00:35:45,480] {processor.py:153} INFO - Started process (PID=8413) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:35:45,481] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:35:45,482] {logging_mixin.py:115} INFO - [2023-01-06 00:35:45,481] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:35:46,460] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:35:46,461] {logging_mixin.py:115} INFO - [2023-01-06 00:35:46,461] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:35:46,462] {logging_mixin.py:115} INFO - [2023-01-06 00:35:46,461] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:35:46,470] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:35:46,503] {logging_mixin.py:115} INFO - [2023-01-06 00:35:46,502] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:35:46,563] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.087 seconds
[2023-01-06 00:36:16,646] {processor.py:153} INFO - Started process (PID=8431) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:36:16,648] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:36:16,649] {logging_mixin.py:115} INFO - [2023-01-06 00:36:16,649] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:36:17,574] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:36:17,576] {logging_mixin.py:115} INFO - [2023-01-06 00:36:17,576] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:36:17,576] {logging_mixin.py:115} INFO - [2023-01-06 00:36:17,576] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:36:17,585] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:36:17,608] {logging_mixin.py:115} INFO - [2023-01-06 00:36:17,608] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:36:17,630] {logging_mixin.py:115} INFO - [2023-01-06 00:36:17,629] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:36:17,646] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.006 seconds
[2023-01-06 00:36:47,722] {processor.py:153} INFO - Started process (PID=8456) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:36:47,723] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:36:47,724] {logging_mixin.py:115} INFO - [2023-01-06 00:36:47,724] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:36:48,645] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:36:48,647] {logging_mixin.py:115} INFO - [2023-01-06 00:36:48,647] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:36:48,647] {logging_mixin.py:115} INFO - [2023-01-06 00:36:48,647] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:36:48,654] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:36:48,677] {logging_mixin.py:115} INFO - [2023-01-06 00:36:48,677] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:36:48,698] {logging_mixin.py:115} INFO - [2023-01-06 00:36:48,698] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:36:48,709] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.992 seconds
[2023-01-06 00:37:18,788] {processor.py:153} INFO - Started process (PID=8482) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:37:18,791] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:37:18,791] {logging_mixin.py:115} INFO - [2023-01-06 00:37:18,791] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:37:19,708] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:37:19,710] {logging_mixin.py:115} INFO - [2023-01-06 00:37:19,710] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:37:19,710] {logging_mixin.py:115} INFO - [2023-01-06 00:37:19,710] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:37:19,717] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:37:19,742] {logging_mixin.py:115} INFO - [2023-01-06 00:37:19,742] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:37:19,763] {logging_mixin.py:115} INFO - [2023-01-06 00:37:19,763] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:37:19,773] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.991 seconds
[2023-01-06 00:37:49,851] {processor.py:153} INFO - Started process (PID=8507) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:37:49,853] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:37:49,854] {logging_mixin.py:115} INFO - [2023-01-06 00:37:49,854] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:37:50,810] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:37:50,812] {logging_mixin.py:115} INFO - [2023-01-06 00:37:50,812] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:37:50,813] {logging_mixin.py:115} INFO - [2023-01-06 00:37:50,812] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:37:50,821] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:37:50,845] {logging_mixin.py:115} INFO - [2023-01-06 00:37:50,845] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:37:50,871] {logging_mixin.py:115} INFO - [2023-01-06 00:37:50,871] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:37:50,884] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.039 seconds
[2023-01-06 00:38:20,966] {processor.py:153} INFO - Started process (PID=8524) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:38:20,967] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:38:20,967] {logging_mixin.py:115} INFO - [2023-01-06 00:38:20,967] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:38:21,883] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:38:21,885] {logging_mixin.py:115} INFO - [2023-01-06 00:38:21,885] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:38:21,885] {logging_mixin.py:115} INFO - [2023-01-06 00:38:21,885] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:38:21,893] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:38:21,917] {logging_mixin.py:115} INFO - [2023-01-06 00:38:21,917] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:38:21,939] {logging_mixin.py:115} INFO - [2023-01-06 00:38:21,939] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:38:21,949] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.988 seconds
[2023-01-06 00:38:52,028] {processor.py:153} INFO - Started process (PID=8550) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:38:52,030] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:38:52,030] {logging_mixin.py:115} INFO - [2023-01-06 00:38:52,030] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:38:52,963] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:38:52,965] {logging_mixin.py:115} INFO - [2023-01-06 00:38:52,964] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:38:52,965] {logging_mixin.py:115} INFO - [2023-01-06 00:38:52,965] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:38:52,972] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:38:52,995] {logging_mixin.py:115} INFO - [2023-01-06 00:38:52,994] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:38:53,016] {logging_mixin.py:115} INFO - [2023-01-06 00:38:53,016] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:38:53,027] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.003 seconds
[2023-01-06 00:39:23,099] {processor.py:153} INFO - Started process (PID=8576) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:39:23,099] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:39:23,100] {logging_mixin.py:115} INFO - [2023-01-06 00:39:23,100] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:39:24,042] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:39:24,043] {logging_mixin.py:115} INFO - [2023-01-06 00:39:24,043] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:39:24,044] {logging_mixin.py:115} INFO - [2023-01-06 00:39:24,043] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:39:24,050] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:39:24,077] {logging_mixin.py:115} INFO - [2023-01-06 00:39:24,076] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:39:24,100] {logging_mixin.py:115} INFO - [2023-01-06 00:39:24,100] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:39:24,111] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.017 seconds
[2023-01-06 00:39:54,217] {processor.py:153} INFO - Started process (PID=8601) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:39:54,218] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:39:54,219] {logging_mixin.py:115} INFO - [2023-01-06 00:39:54,219] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:39:55,352] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:39:55,353] {logging_mixin.py:115} INFO - [2023-01-06 00:39:55,353] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:39:55,354] {logging_mixin.py:115} INFO - [2023-01-06 00:39:55,354] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:39:55,361] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:39:55,384] {logging_mixin.py:115} INFO - [2023-01-06 00:39:55,384] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:39:55,405] {logging_mixin.py:115} INFO - [2023-01-06 00:39:55,405] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:39:55,415] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.211 seconds
[2023-01-06 00:40:25,503] {processor.py:153} INFO - Started process (PID=8619) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:40:25,504] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:40:25,505] {logging_mixin.py:115} INFO - [2023-01-06 00:40:25,505] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:40:26,455] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:40:26,456] {logging_mixin.py:115} INFO - [2023-01-06 00:40:26,456] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:40:26,457] {logging_mixin.py:115} INFO - [2023-01-06 00:40:26,456] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:40:26,464] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:40:26,490] {logging_mixin.py:115} INFO - [2023-01-06 00:40:26,490] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:40:26,518] {logging_mixin.py:115} INFO - [2023-01-06 00:40:26,518] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:40:26,530] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.032 seconds
[2023-01-06 00:40:56,562] {processor.py:153} INFO - Started process (PID=8643) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:40:56,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:40:56,565] {logging_mixin.py:115} INFO - [2023-01-06 00:40:56,565] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:40:57,485] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:40:57,486] {logging_mixin.py:115} INFO - [2023-01-06 00:40:57,486] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:40:57,487] {logging_mixin.py:115} INFO - [2023-01-06 00:40:57,487] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:40:57,495] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:40:57,518] {logging_mixin.py:115} INFO - [2023-01-06 00:40:57,517] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:40:57,539] {logging_mixin.py:115} INFO - [2023-01-06 00:40:57,539] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:40:57,551] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.995 seconds
[2023-01-06 00:41:27,644] {processor.py:153} INFO - Started process (PID=8669) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:41:27,646] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:41:27,647] {logging_mixin.py:115} INFO - [2023-01-06 00:41:27,646] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:41:28,603] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:41:28,604] {logging_mixin.py:115} INFO - [2023-01-06 00:41:28,604] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:41:28,605] {logging_mixin.py:115} INFO - [2023-01-06 00:41:28,604] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:41:28,612] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:41:28,643] {logging_mixin.py:115} INFO - [2023-01-06 00:41:28,643] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:41:28,675] {logging_mixin.py:115} INFO - [2023-01-06 00:41:28,675] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:41:28,689] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.050 seconds
[2023-01-06 00:41:58,725] {processor.py:153} INFO - Started process (PID=8694) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:41:58,728] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:41:58,729] {logging_mixin.py:115} INFO - [2023-01-06 00:41:58,729] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:41:59,705] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:41:59,706] {logging_mixin.py:115} INFO - [2023-01-06 00:41:59,706] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:41:59,707] {logging_mixin.py:115} INFO - [2023-01-06 00:41:59,706] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:41:59,714] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:41:59,739] {logging_mixin.py:115} INFO - [2023-01-06 00:41:59,739] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:41:59,762] {logging_mixin.py:115} INFO - [2023-01-06 00:41:59,761] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:41:59,776] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.057 seconds
[2023-01-06 00:42:29,853] {processor.py:153} INFO - Started process (PID=8714) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:42:29,854] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:42:29,855] {logging_mixin.py:115} INFO - [2023-01-06 00:42:29,855] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:42:30,799] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:42:30,800] {logging_mixin.py:115} INFO - [2023-01-06 00:42:30,800] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:42:30,801] {logging_mixin.py:115} INFO - [2023-01-06 00:42:30,801] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:42:30,808] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:42:30,831] {logging_mixin.py:115} INFO - [2023-01-06 00:42:30,831] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:42:30,853] {logging_mixin.py:115} INFO - [2023-01-06 00:42:30,853] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:42:30,865] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.017 seconds
[2023-01-06 00:43:00,939] {processor.py:153} INFO - Started process (PID=8741) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:43:00,940] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:43:00,940] {logging_mixin.py:115} INFO - [2023-01-06 00:43:00,940] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:43:01,938] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:43:01,939] {logging_mixin.py:115} INFO - [2023-01-06 00:43:01,939] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:43:01,940] {logging_mixin.py:115} INFO - [2023-01-06 00:43:01,940] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:43:01,947] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:43:01,970] {logging_mixin.py:115} INFO - [2023-01-06 00:43:01,970] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:43:01,991] {logging_mixin.py:115} INFO - [2023-01-06 00:43:01,991] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:43:02,003] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.069 seconds
[2023-01-06 00:43:32,074] {processor.py:153} INFO - Started process (PID=8765) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:43:32,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:43:32,075] {logging_mixin.py:115} INFO - [2023-01-06 00:43:32,075] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:43:33,033] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:43:33,035] {logging_mixin.py:115} INFO - [2023-01-06 00:43:33,035] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:43:33,035] {logging_mixin.py:115} INFO - [2023-01-06 00:43:33,035] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:43:33,042] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:43:33,066] {logging_mixin.py:115} INFO - [2023-01-06 00:43:33,065] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:43:33,087] {logging_mixin.py:115} INFO - [2023-01-06 00:43:33,087] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:43:33,098] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.029 seconds
[2023-01-06 00:44:03,171] {processor.py:153} INFO - Started process (PID=8789) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:44:03,172] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:44:03,173] {logging_mixin.py:115} INFO - [2023-01-06 00:44:03,173] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:44:04,149] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:44:04,150] {logging_mixin.py:115} INFO - [2023-01-06 00:44:04,150] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:44:04,151] {logging_mixin.py:115} INFO - [2023-01-06 00:44:04,151] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:44:04,158] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:44:04,181] {logging_mixin.py:115} INFO - [2023-01-06 00:44:04,181] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:44:04,202] {logging_mixin.py:115} INFO - [2023-01-06 00:44:04,202] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:44:04,214] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.049 seconds
[2023-01-06 00:44:34,288] {processor.py:153} INFO - Started process (PID=8807) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:44:34,289] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:44:34,290] {logging_mixin.py:115} INFO - [2023-01-06 00:44:34,290] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:44:35,225] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:44:35,227] {logging_mixin.py:115} INFO - [2023-01-06 00:44:35,227] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:44:35,228] {logging_mixin.py:115} INFO - [2023-01-06 00:44:35,228] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:44:35,237] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:44:35,261] {logging_mixin.py:115} INFO - [2023-01-06 00:44:35,261] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:44:35,284] {logging_mixin.py:115} INFO - [2023-01-06 00:44:35,284] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:44:35,296] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.012 seconds
[2023-01-06 00:45:05,369] {processor.py:153} INFO - Started process (PID=8833) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:45:05,371] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:45:05,372] {logging_mixin.py:115} INFO - [2023-01-06 00:45:05,372] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:45:06,293] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:45:06,294] {logging_mixin.py:115} INFO - [2023-01-06 00:45:06,294] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:45:06,294] {logging_mixin.py:115} INFO - [2023-01-06 00:45:06,294] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:45:06,301] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:45:06,324] {logging_mixin.py:115} INFO - [2023-01-06 00:45:06,324] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:45:06,345] {logging_mixin.py:115} INFO - [2023-01-06 00:45:06,345] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:45:06,357] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.992 seconds
[2023-01-06 00:45:36,433] {processor.py:153} INFO - Started process (PID=8859) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:45:36,433] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:45:36,434] {logging_mixin.py:115} INFO - [2023-01-06 00:45:36,434] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:45:37,394] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:45:37,396] {logging_mixin.py:115} INFO - [2023-01-06 00:45:37,395] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:45:37,396] {logging_mixin.py:115} INFO - [2023-01-06 00:45:37,396] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:45:37,404] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:45:37,426] {logging_mixin.py:115} INFO - [2023-01-06 00:45:37,426] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:45:37,447] {logging_mixin.py:115} INFO - [2023-01-06 00:45:37,447] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:45:37,458] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.031 seconds
[2023-01-06 00:46:07,533] {processor.py:153} INFO - Started process (PID=8878) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:46:07,534] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:46:07,535] {logging_mixin.py:115} INFO - [2023-01-06 00:46:07,535] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:46:08,466] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:46:08,467] {logging_mixin.py:115} INFO - [2023-01-06 00:46:08,467] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:46:08,468] {logging_mixin.py:115} INFO - [2023-01-06 00:46:08,467] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:46:08,475] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:46:08,499] {logging_mixin.py:115} INFO - [2023-01-06 00:46:08,499] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:46:08,521] {logging_mixin.py:115} INFO - [2023-01-06 00:46:08,521] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:46:08,534] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.007 seconds
[2023-01-06 00:46:38,607] {processor.py:153} INFO - Started process (PID=8903) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:46:38,608] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:46:38,609] {logging_mixin.py:115} INFO - [2023-01-06 00:46:38,609] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:46:39,535] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:46:39,536] {logging_mixin.py:115} INFO - [2023-01-06 00:46:39,536] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:46:39,537] {logging_mixin.py:115} INFO - [2023-01-06 00:46:39,536] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:46:39,544] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:46:39,568] {logging_mixin.py:115} INFO - [2023-01-06 00:46:39,567] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:46:39,594] {logging_mixin.py:115} INFO - [2023-01-06 00:46:39,593] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:46:39,606] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.004 seconds
[2023-01-06 00:47:09,681] {processor.py:153} INFO - Started process (PID=8928) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:47:09,681] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:47:09,682] {logging_mixin.py:115} INFO - [2023-01-06 00:47:09,682] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:47:10,642] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:47:10,644] {logging_mixin.py:115} INFO - [2023-01-06 00:47:10,644] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:47:10,645] {logging_mixin.py:115} INFO - [2023-01-06 00:47:10,644] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:47:10,657] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:47:10,687] {logging_mixin.py:115} INFO - [2023-01-06 00:47:10,686] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:47:10,714] {logging_mixin.py:115} INFO - [2023-01-06 00:47:10,714] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:47:10,725] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.051 seconds
[2023-01-06 00:47:40,803] {processor.py:153} INFO - Started process (PID=8954) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:47:40,807] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:47:40,808] {logging_mixin.py:115} INFO - [2023-01-06 00:47:40,808] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:47:41,838] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:47:41,839] {logging_mixin.py:115} INFO - [2023-01-06 00:47:41,839] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:47:41,840] {logging_mixin.py:115} INFO - [2023-01-06 00:47:41,840] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:47:41,847] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:47:41,872] {logging_mixin.py:115} INFO - [2023-01-06 00:47:41,872] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:47:41,893] {logging_mixin.py:115} INFO - [2023-01-06 00:47:41,892] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:47:41,904] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.105 seconds
[2023-01-06 00:48:11,977] {processor.py:153} INFO - Started process (PID=8972) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:48:11,979] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:48:11,979] {logging_mixin.py:115} INFO - [2023-01-06 00:48:11,979] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:48:12,930] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:48:12,931] {logging_mixin.py:115} INFO - [2023-01-06 00:48:12,931] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:48:12,932] {logging_mixin.py:115} INFO - [2023-01-06 00:48:12,931] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:48:12,939] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:48:12,962] {logging_mixin.py:115} INFO - [2023-01-06 00:48:12,961] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:48:12,983] {logging_mixin.py:115} INFO - [2023-01-06 00:48:12,983] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:48:12,994] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.021 seconds
[2023-01-06 00:48:43,030] {processor.py:153} INFO - Started process (PID=8998) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:48:43,031] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:48:43,032] {logging_mixin.py:115} INFO - [2023-01-06 00:48:43,031] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:48:43,963] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:48:43,965] {logging_mixin.py:115} INFO - [2023-01-06 00:48:43,965] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:48:43,965] {logging_mixin.py:115} INFO - [2023-01-06 00:48:43,965] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:48:43,972] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:48:43,996] {logging_mixin.py:115} INFO - [2023-01-06 00:48:43,996] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:48:44,017] {logging_mixin.py:115} INFO - [2023-01-06 00:48:44,017] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:48:44,028] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.003 seconds
[2023-01-06 00:49:14,099] {processor.py:153} INFO - Started process (PID=9022) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:49:14,100] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:49:14,100] {logging_mixin.py:115} INFO - [2023-01-06 00:49:14,100] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:49:15,017] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:49:15,019] {logging_mixin.py:115} INFO - [2023-01-06 00:49:15,018] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:49:15,019] {logging_mixin.py:115} INFO - [2023-01-06 00:49:15,019] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:49:15,026] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:49:15,050] {logging_mixin.py:115} INFO - [2023-01-06 00:49:15,050] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:49:15,071] {logging_mixin.py:115} INFO - [2023-01-06 00:49:15,071] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:49:15,083] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.988 seconds
[2023-01-06 00:49:45,147] {processor.py:153} INFO - Started process (PID=9047) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:49:45,148] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:49:45,149] {logging_mixin.py:115} INFO - [2023-01-06 00:49:45,149] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:49:46,118] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:49:46,120] {logging_mixin.py:115} INFO - [2023-01-06 00:49:46,120] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:49:46,120] {logging_mixin.py:115} INFO - [2023-01-06 00:49:46,120] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:49:46,127] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:49:46,156] {logging_mixin.py:115} INFO - [2023-01-06 00:49:46,156] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:49:46,185] {logging_mixin.py:115} INFO - [2023-01-06 00:49:46,185] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:49:46,200] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.058 seconds
[2023-01-06 00:50:16,274] {processor.py:153} INFO - Started process (PID=9065) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:50:16,276] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:50:16,277] {logging_mixin.py:115} INFO - [2023-01-06 00:50:16,277] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:50:17,271] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:50:17,273] {logging_mixin.py:115} INFO - [2023-01-06 00:50:17,272] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:50:17,273] {logging_mixin.py:115} INFO - [2023-01-06 00:50:17,273] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:50:17,284] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:50:17,309] {logging_mixin.py:115} INFO - [2023-01-06 00:50:17,309] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:50:17,330] {logging_mixin.py:115} INFO - [2023-01-06 00:50:17,330] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:50:17,341] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.072 seconds
[2023-01-06 00:50:47,414] {processor.py:153} INFO - Started process (PID=9088) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:50:47,415] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:50:47,416] {logging_mixin.py:115} INFO - [2023-01-06 00:50:47,416] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:50:48,344] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:50:48,346] {logging_mixin.py:115} INFO - [2023-01-06 00:50:48,346] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:50:48,346] {logging_mixin.py:115} INFO - [2023-01-06 00:50:48,346] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:50:48,353] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:50:48,377] {logging_mixin.py:115} INFO - [2023-01-06 00:50:48,376] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:50:48,399] {logging_mixin.py:115} INFO - [2023-01-06 00:50:48,399] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:50:48,411] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.002 seconds
[2023-01-06 00:51:18,485] {processor.py:153} INFO - Started process (PID=9114) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:51:18,486] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:51:18,487] {logging_mixin.py:115} INFO - [2023-01-06 00:51:18,486] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:51:19,436] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:51:19,437] {logging_mixin.py:115} INFO - [2023-01-06 00:51:19,437] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:51:19,438] {logging_mixin.py:115} INFO - [2023-01-06 00:51:19,438] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:51:19,445] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:51:19,468] {logging_mixin.py:115} INFO - [2023-01-06 00:51:19,468] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:51:19,491] {logging_mixin.py:115} INFO - [2023-01-06 00:51:19,491] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:51:19,503] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.024 seconds
[2023-01-06 00:51:49,574] {processor.py:153} INFO - Started process (PID=9139) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:51:49,576] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:51:49,576] {logging_mixin.py:115} INFO - [2023-01-06 00:51:49,576] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:51:50,645] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:51:50,647] {logging_mixin.py:115} INFO - [2023-01-06 00:51:50,646] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:51:50,647] {logging_mixin.py:115} INFO - [2023-01-06 00:51:50,647] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:51:50,654] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:51:50,684] {logging_mixin.py:115} INFO - [2023-01-06 00:51:50,684] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:51:50,706] {logging_mixin.py:115} INFO - [2023-01-06 00:51:50,706] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:51:50,718] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.148 seconds
[2023-01-06 00:52:20,797] {processor.py:153} INFO - Started process (PID=9157) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:52:20,799] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:52:20,800] {logging_mixin.py:115} INFO - [2023-01-06 00:52:20,800] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:52:21,725] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:52:21,727] {logging_mixin.py:115} INFO - [2023-01-06 00:52:21,727] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:52:21,728] {logging_mixin.py:115} INFO - [2023-01-06 00:52:21,727] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:52:21,735] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:52:21,760] {logging_mixin.py:115} INFO - [2023-01-06 00:52:21,759] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:52:21,781] {logging_mixin.py:115} INFO - [2023-01-06 00:52:21,781] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:52:21,794] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.002 seconds
[2023-01-06 00:52:51,866] {processor.py:153} INFO - Started process (PID=9184) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:52:51,868] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:52:51,868] {logging_mixin.py:115} INFO - [2023-01-06 00:52:51,868] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:52:52,767] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:52:52,768] {logging_mixin.py:115} INFO - [2023-01-06 00:52:52,768] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:52:52,769] {logging_mixin.py:115} INFO - [2023-01-06 00:52:52,768] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:52:52,775] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:52:52,800] {logging_mixin.py:115} INFO - [2023-01-06 00:52:52,799] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:52:52,821] {logging_mixin.py:115} INFO - [2023-01-06 00:52:52,821] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:52:52,833] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.971 seconds
[2023-01-06 00:53:22,907] {processor.py:153} INFO - Started process (PID=9208) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:53:22,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:53:22,909] {logging_mixin.py:115} INFO - [2023-01-06 00:53:22,908] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:53:23,815] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:53:23,817] {logging_mixin.py:115} INFO - [2023-01-06 00:53:23,817] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:53:23,817] {logging_mixin.py:115} INFO - [2023-01-06 00:53:23,817] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:53:23,825] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:53:23,849] {logging_mixin.py:115} INFO - [2023-01-06 00:53:23,849] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:53:23,871] {logging_mixin.py:115} INFO - [2023-01-06 00:53:23,871] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:53:23,883] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.981 seconds
[2023-01-06 00:53:53,955] {processor.py:153} INFO - Started process (PID=9233) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:53:53,956] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:53:53,957] {logging_mixin.py:115} INFO - [2023-01-06 00:53:53,957] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:53:54,883] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:53:54,884] {logging_mixin.py:115} INFO - [2023-01-06 00:53:54,884] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:53:54,885] {logging_mixin.py:115} INFO - [2023-01-06 00:53:54,884] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:53:54,892] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:53:54,920] {logging_mixin.py:115} INFO - [2023-01-06 00:53:54,919] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:53:54,943] {logging_mixin.py:115} INFO - [2023-01-06 00:53:54,943] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:53:54,957] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.007 seconds
[2023-01-06 00:54:25,034] {processor.py:153} INFO - Started process (PID=9252) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:54:25,034] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:54:25,035] {logging_mixin.py:115} INFO - [2023-01-06 00:54:25,035] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:54:25,976] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:54:25,978] {logging_mixin.py:115} INFO - [2023-01-06 00:54:25,978] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:54:25,978] {logging_mixin.py:115} INFO - [2023-01-06 00:54:25,978] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:54:25,985] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:54:26,010] {logging_mixin.py:115} INFO - [2023-01-06 00:54:26,009] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:54:26,032] {logging_mixin.py:115} INFO - [2023-01-06 00:54:26,032] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:54:26,043] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.014 seconds
[2023-01-06 00:54:56,118] {processor.py:153} INFO - Started process (PID=9277) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:54:56,120] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:54:56,120] {logging_mixin.py:115} INFO - [2023-01-06 00:54:56,120] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:54:57,045] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:54:57,047] {logging_mixin.py:115} INFO - [2023-01-06 00:54:57,047] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:54:57,047] {logging_mixin.py:115} INFO - [2023-01-06 00:54:57,047] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:54:57,054] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:54:57,077] {logging_mixin.py:115} INFO - [2023-01-06 00:54:57,077] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:54:57,098] {logging_mixin.py:115} INFO - [2023-01-06 00:54:57,098] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:54:57,110] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.997 seconds
[2023-01-06 00:55:27,184] {processor.py:153} INFO - Started process (PID=9302) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:55:27,185] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:55:27,185] {logging_mixin.py:115} INFO - [2023-01-06 00:55:27,185] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:55:28,090] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:55:28,091] {logging_mixin.py:115} INFO - [2023-01-06 00:55:28,091] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:55:28,091] {logging_mixin.py:115} INFO - [2023-01-06 00:55:28,091] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:55:28,098] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:55:28,122] {logging_mixin.py:115} INFO - [2023-01-06 00:55:28,121] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:55:28,142] {logging_mixin.py:115} INFO - [2023-01-06 00:55:28,142] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:55:28,153] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.975 seconds
[2023-01-06 00:55:58,248] {processor.py:153} INFO - Started process (PID=9327) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:55:58,249] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:55:58,250] {logging_mixin.py:115} INFO - [2023-01-06 00:55:58,250] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:55:59,378] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:55:59,380] {logging_mixin.py:115} INFO - [2023-01-06 00:55:59,380] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:55:59,381] {logging_mixin.py:115} INFO - [2023-01-06 00:55:59,381] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:55:59,393] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:55:59,425] {logging_mixin.py:115} INFO - [2023-01-06 00:55:59,424] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:55:59,455] {logging_mixin.py:115} INFO - [2023-01-06 00:55:59,455] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:55:59,469] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.228 seconds
[2023-01-06 00:56:29,547] {processor.py:153} INFO - Started process (PID=9346) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:56:29,547] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:56:29,548] {logging_mixin.py:115} INFO - [2023-01-06 00:56:29,548] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:56:30,512] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:56:30,514] {logging_mixin.py:115} INFO - [2023-01-06 00:56:30,514] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:56:30,514] {logging_mixin.py:115} INFO - [2023-01-06 00:56:30,514] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:56:30,521] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:56:30,546] {logging_mixin.py:115} INFO - [2023-01-06 00:56:30,546] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:56:30,568] {logging_mixin.py:115} INFO - [2023-01-06 00:56:30,568] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:56:30,579] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.039 seconds
[2023-01-06 00:57:00,654] {processor.py:153} INFO - Started process (PID=9370) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:57:00,655] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:57:00,656] {logging_mixin.py:115} INFO - [2023-01-06 00:57:00,656] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:57:01,586] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:57:01,588] {logging_mixin.py:115} INFO - [2023-01-06 00:57:01,588] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:57:01,588] {logging_mixin.py:115} INFO - [2023-01-06 00:57:01,588] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:57:01,595] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:57:01,618] {logging_mixin.py:115} INFO - [2023-01-06 00:57:01,618] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:57:01,640] {logging_mixin.py:115} INFO - [2023-01-06 00:57:01,640] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:57:01,652] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.003 seconds
[2023-01-06 00:57:31,716] {processor.py:153} INFO - Started process (PID=9395) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:57:31,717] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:57:31,718] {logging_mixin.py:115} INFO - [2023-01-06 00:57:31,718] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:57:32,670] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:57:32,671] {logging_mixin.py:115} INFO - [2023-01-06 00:57:32,671] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:57:32,672] {logging_mixin.py:115} INFO - [2023-01-06 00:57:32,672] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:57:32,679] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:57:32,703] {logging_mixin.py:115} INFO - [2023-01-06 00:57:32,703] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:57:32,724] {logging_mixin.py:115} INFO - [2023-01-06 00:57:32,724] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:57:32,736] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.026 seconds
[2023-01-06 00:58:02,815] {processor.py:153} INFO - Started process (PID=9420) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:58:02,816] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:58:02,817] {logging_mixin.py:115} INFO - [2023-01-06 00:58:02,817] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:58:03,741] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:58:03,743] {logging_mixin.py:115} INFO - [2023-01-06 00:58:03,743] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:58:03,743] {logging_mixin.py:115} INFO - [2023-01-06 00:58:03,743] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:58:03,750] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:58:03,774] {logging_mixin.py:115} INFO - [2023-01-06 00:58:03,773] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:58:03,795] {logging_mixin.py:115} INFO - [2023-01-06 00:58:03,795] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:58:03,807] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.997 seconds
[2023-01-06 00:58:33,877] {processor.py:153} INFO - Started process (PID=9438) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:58:33,878] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:58:33,879] {logging_mixin.py:115} INFO - [2023-01-06 00:58:33,879] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:58:34,780] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:58:34,782] {logging_mixin.py:115} INFO - [2023-01-06 00:58:34,782] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:58:34,782] {logging_mixin.py:115} INFO - [2023-01-06 00:58:34,782] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:58:34,789] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:58:34,812] {logging_mixin.py:115} INFO - [2023-01-06 00:58:34,812] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:58:34,836] {logging_mixin.py:115} INFO - [2023-01-06 00:58:34,835] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:58:34,848] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.977 seconds
[2023-01-06 00:59:04,884] {processor.py:153} INFO - Started process (PID=9462) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:59:04,885] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:59:04,886] {logging_mixin.py:115} INFO - [2023-01-06 00:59:04,886] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:59:05,848] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:59:05,849] {logging_mixin.py:115} INFO - [2023-01-06 00:59:05,849] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:59:05,850] {logging_mixin.py:115} INFO - [2023-01-06 00:59:05,849] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:59:05,857] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:59:05,882] {logging_mixin.py:115} INFO - [2023-01-06 00:59:05,882] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:59:05,904] {logging_mixin.py:115} INFO - [2023-01-06 00:59:05,904] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:59:05,917] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.039 seconds
[2023-01-06 00:59:35,987] {processor.py:153} INFO - Started process (PID=9486) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:59:35,988] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:59:35,988] {logging_mixin.py:115} INFO - [2023-01-06 00:59:35,988] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:59:36,886] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:59:36,887] {logging_mixin.py:115} INFO - [2023-01-06 00:59:36,887] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:59:36,888] {logging_mixin.py:115} INFO - [2023-01-06 00:59:36,888] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:59:36,895] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 00:59:36,918] {logging_mixin.py:115} INFO - [2023-01-06 00:59:36,918] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:59:36,940] {logging_mixin.py:115} INFO - [2023-01-06 00:59:36,940] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 00:59:36,952] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.970 seconds
[2023-01-06 01:00:07,028] {processor.py:153} INFO - Started process (PID=9512) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:00:07,029] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:00:07,030] {logging_mixin.py:115} INFO - [2023-01-06 01:00:07,030] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:00:07,979] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:00:07,980] {logging_mixin.py:115} INFO - [2023-01-06 01:00:07,980] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:00:07,980] {logging_mixin.py:115} INFO - [2023-01-06 01:00:07,980] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:00:07,988] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:00:08,011] {logging_mixin.py:115} INFO - [2023-01-06 01:00:08,010] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:00:08,038] {logging_mixin.py:115} INFO - [2023-01-06 01:00:08,038] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:00:08,049] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.027 seconds
[2023-01-06 01:00:38,082] {processor.py:153} INFO - Started process (PID=9530) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:00:38,084] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:00:38,085] {logging_mixin.py:115} INFO - [2023-01-06 01:00:38,084] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:00:39,021] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:00:39,022] {logging_mixin.py:115} INFO - [2023-01-06 01:00:39,022] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:00:39,023] {logging_mixin.py:115} INFO - [2023-01-06 01:00:39,022] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:00:39,031] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:00:39,054] {logging_mixin.py:115} INFO - [2023-01-06 01:00:39,053] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:00:39,074] {logging_mixin.py:115} INFO - [2023-01-06 01:00:39,074] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:00:39,085] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.009 seconds
[2023-01-06 01:01:09,180] {processor.py:153} INFO - Started process (PID=9555) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:01:09,181] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:01:09,182] {logging_mixin.py:115} INFO - [2023-01-06 01:01:09,182] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:01:10,115] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:01:10,117] {logging_mixin.py:115} INFO - [2023-01-06 01:01:10,117] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:01:10,117] {logging_mixin.py:115} INFO - [2023-01-06 01:01:10,117] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:01:10,125] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:01:10,150] {logging_mixin.py:115} INFO - [2023-01-06 01:01:10,149] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:01:10,171] {logging_mixin.py:115} INFO - [2023-01-06 01:01:10,171] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:01:10,183] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.009 seconds
[2023-01-06 01:01:40,261] {processor.py:153} INFO - Started process (PID=9580) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:01:40,262] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:01:40,263] {logging_mixin.py:115} INFO - [2023-01-06 01:01:40,263] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:01:41,245] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:01:41,246] {logging_mixin.py:115} INFO - [2023-01-06 01:01:41,246] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:01:41,246] {logging_mixin.py:115} INFO - [2023-01-06 01:01:41,246] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:01:41,254] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:01:41,277] {logging_mixin.py:115} INFO - [2023-01-06 01:01:41,277] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:01:41,299] {logging_mixin.py:115} INFO - [2023-01-06 01:01:41,299] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:01:41,312] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.057 seconds
[2023-01-06 01:02:11,383] {processor.py:153} INFO - Started process (PID=9598) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:02:11,385] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:02:11,386] {logging_mixin.py:115} INFO - [2023-01-06 01:02:11,386] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:02:12,363] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:02:12,365] {logging_mixin.py:115} INFO - [2023-01-06 01:02:12,365] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:02:12,366] {logging_mixin.py:115} INFO - [2023-01-06 01:02:12,366] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:02:12,377] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:02:12,402] {logging_mixin.py:115} INFO - [2023-01-06 01:02:12,402] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:02:12,423] {logging_mixin.py:115} INFO - [2023-01-06 01:02:12,423] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:02:12,435] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.056 seconds
[2023-01-06 01:02:42,509] {processor.py:153} INFO - Started process (PID=9624) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:02:42,510] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:02:42,511] {logging_mixin.py:115} INFO - [2023-01-06 01:02:42,511] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:02:43,468] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:02:43,469] {logging_mixin.py:115} INFO - [2023-01-06 01:02:43,469] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:02:43,470] {logging_mixin.py:115} INFO - [2023-01-06 01:02:43,470] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:02:43,477] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:02:43,500] {logging_mixin.py:115} INFO - [2023-01-06 01:02:43,500] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:02:43,522] {logging_mixin.py:115} INFO - [2023-01-06 01:02:43,522] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:02:43,534] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.030 seconds
[2023-01-06 01:03:13,605] {processor.py:153} INFO - Started process (PID=9648) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:03:13,606] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:03:13,606] {logging_mixin.py:115} INFO - [2023-01-06 01:03:13,606] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:03:14,569] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:03:14,570] {logging_mixin.py:115} INFO - [2023-01-06 01:03:14,570] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:03:14,571] {logging_mixin.py:115} INFO - [2023-01-06 01:03:14,571] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:03:14,578] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:03:14,601] {logging_mixin.py:115} INFO - [2023-01-06 01:03:14,601] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:03:14,622] {logging_mixin.py:115} INFO - [2023-01-06 01:03:14,622] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:03:14,634] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.034 seconds
[2023-01-06 01:03:44,715] {processor.py:153} INFO - Started process (PID=9672) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:03:44,717] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:03:44,718] {logging_mixin.py:115} INFO - [2023-01-06 01:03:44,717] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:03:45,788] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:03:45,789] {logging_mixin.py:115} INFO - [2023-01-06 01:03:45,789] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:03:45,790] {logging_mixin.py:115} INFO - [2023-01-06 01:03:45,789] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:03:45,797] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:03:45,822] {logging_mixin.py:115} INFO - [2023-01-06 01:03:45,822] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:03:45,845] {logging_mixin.py:115} INFO - [2023-01-06 01:03:45,845] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:03:45,857] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.148 seconds
[2023-01-06 01:04:15,938] {processor.py:153} INFO - Started process (PID=9692) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:04:15,939] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:04:15,940] {logging_mixin.py:115} INFO - [2023-01-06 01:04:15,940] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:04:16,928] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:04:16,930] {logging_mixin.py:115} INFO - [2023-01-06 01:04:16,930] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:04:16,930] {logging_mixin.py:115} INFO - [2023-01-06 01:04:16,930] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:04:16,938] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:04:16,963] {logging_mixin.py:115} INFO - [2023-01-06 01:04:16,962] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:04:16,985] {logging_mixin.py:115} INFO - [2023-01-06 01:04:16,985] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:04:16,996] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.064 seconds
[2023-01-06 01:04:47,079] {processor.py:153} INFO - Started process (PID=9718) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:04:47,083] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:04:47,084] {logging_mixin.py:115} INFO - [2023-01-06 01:04:47,084] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:04:48,064] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:04:48,066] {logging_mixin.py:115} INFO - [2023-01-06 01:04:48,066] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:04:48,066] {logging_mixin.py:115} INFO - [2023-01-06 01:04:48,066] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:04:48,074] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:04:48,096] {logging_mixin.py:115} INFO - [2023-01-06 01:04:48,096] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:04:48,117] {logging_mixin.py:115} INFO - [2023-01-06 01:04:48,117] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:04:48,128] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.055 seconds
[2023-01-06 01:05:18,214] {processor.py:153} INFO - Started process (PID=9743) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:05:18,215] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:05:18,216] {logging_mixin.py:115} INFO - [2023-01-06 01:05:18,216] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:05:19,133] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:05:19,134] {logging_mixin.py:115} INFO - [2023-01-06 01:05:19,134] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:05:19,135] {logging_mixin.py:115} INFO - [2023-01-06 01:05:19,135] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:05:19,142] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:05:19,165] {logging_mixin.py:115} INFO - [2023-01-06 01:05:19,165] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:05:19,186] {logging_mixin.py:115} INFO - [2023-01-06 01:05:19,186] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:05:19,198] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.989 seconds
[2023-01-06 01:05:49,295] {processor.py:153} INFO - Started process (PID=9768) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:05:49,296] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:05:49,297] {logging_mixin.py:115} INFO - [2023-01-06 01:05:49,297] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:05:50,254] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:05:50,255] {logging_mixin.py:115} INFO - [2023-01-06 01:05:50,255] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:05:50,256] {logging_mixin.py:115} INFO - [2023-01-06 01:05:50,256] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:05:50,263] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:05:50,294] {logging_mixin.py:115} INFO - [2023-01-06 01:05:50,294] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:05:50,323] {logging_mixin.py:115} INFO - [2023-01-06 01:05:50,323] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:05:50,337] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.046 seconds
[2023-01-06 01:06:20,414] {processor.py:153} INFO - Started process (PID=9787) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:06:20,415] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:06:20,416] {logging_mixin.py:115} INFO - [2023-01-06 01:06:20,416] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:06:21,392] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:06:21,394] {logging_mixin.py:115} INFO - [2023-01-06 01:06:21,394] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:06:21,395] {logging_mixin.py:115} INFO - [2023-01-06 01:06:21,394] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:06:21,407] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:06:21,438] {logging_mixin.py:115} INFO - [2023-01-06 01:06:21,437] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:06:21,472] {logging_mixin.py:115} INFO - [2023-01-06 01:06:21,471] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:06:21,487] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.079 seconds
[2023-01-06 01:06:51,565] {processor.py:153} INFO - Started process (PID=9812) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:06:51,566] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:06:51,567] {logging_mixin.py:115} INFO - [2023-01-06 01:06:51,567] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:06:52,499] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:06:52,500] {logging_mixin.py:115} INFO - [2023-01-06 01:06:52,500] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:06:52,501] {logging_mixin.py:115} INFO - [2023-01-06 01:06:52,501] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:06:52,508] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:06:52,532] {logging_mixin.py:115} INFO - [2023-01-06 01:06:52,532] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:06:52,554] {logging_mixin.py:115} INFO - [2023-01-06 01:06:52,554] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:06:52,566] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.006 seconds
[2023-01-06 01:07:22,601] {processor.py:153} INFO - Started process (PID=9837) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:07:22,603] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:07:22,603] {logging_mixin.py:115} INFO - [2023-01-06 01:07:22,603] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:07:23,512] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:07:23,513] {logging_mixin.py:115} INFO - [2023-01-06 01:07:23,513] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:07:23,514] {logging_mixin.py:115} INFO - [2023-01-06 01:07:23,513] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:07:23,521] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:07:23,544] {logging_mixin.py:115} INFO - [2023-01-06 01:07:23,544] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:07:23,565] {logging_mixin.py:115} INFO - [2023-01-06 01:07:23,564] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:07:23,578] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.983 seconds
[2023-01-06 01:07:53,663] {processor.py:153} INFO - Started process (PID=9862) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:07:53,664] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:07:53,665] {logging_mixin.py:115} INFO - [2023-01-06 01:07:53,665] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:07:54,606] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:07:54,607] {logging_mixin.py:115} INFO - [2023-01-06 01:07:54,607] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:07:54,608] {logging_mixin.py:115} INFO - [2023-01-06 01:07:54,608] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:07:54,615] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:07:54,648] {logging_mixin.py:115} INFO - [2023-01-06 01:07:54,647] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:07:54,681] {logging_mixin.py:115} INFO - [2023-01-06 01:07:54,681] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:07:54,693] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.035 seconds
[2023-01-06 01:08:24,765] {processor.py:153} INFO - Started process (PID=9881) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:08:24,767] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:08:24,767] {logging_mixin.py:115} INFO - [2023-01-06 01:08:24,767] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:08:25,689] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:08:25,690] {logging_mixin.py:115} INFO - [2023-01-06 01:08:25,690] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:08:25,690] {logging_mixin.py:115} INFO - [2023-01-06 01:08:25,690] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:08:25,697] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:08:25,720] {logging_mixin.py:115} INFO - [2023-01-06 01:08:25,720] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:08:25,742] {logging_mixin.py:115} INFO - [2023-01-06 01:08:25,742] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:08:25,754] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.993 seconds
[2023-01-06 01:08:55,796] {processor.py:153} INFO - Started process (PID=9907) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:08:55,797] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:08:55,797] {logging_mixin.py:115} INFO - [2023-01-06 01:08:55,797] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:08:56,734] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:08:56,736] {logging_mixin.py:115} INFO - [2023-01-06 01:08:56,736] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:08:56,737] {logging_mixin.py:115} INFO - [2023-01-06 01:08:56,736] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:08:56,744] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:08:56,768] {logging_mixin.py:115} INFO - [2023-01-06 01:08:56,767] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:08:56,789] {logging_mixin.py:115} INFO - [2023-01-06 01:08:56,789] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:08:56,801] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.010 seconds
[2023-01-06 01:09:26,899] {processor.py:153} INFO - Started process (PID=9933) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:09:26,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:09:26,901] {logging_mixin.py:115} INFO - [2023-01-06 01:09:26,901] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:09:27,827] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:09:27,829] {logging_mixin.py:115} INFO - [2023-01-06 01:09:27,829] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:09:27,829] {logging_mixin.py:115} INFO - [2023-01-06 01:09:27,829] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:09:27,836] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:09:27,865] {logging_mixin.py:115} INFO - [2023-01-06 01:09:27,865] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:09:27,888] {logging_mixin.py:115} INFO - [2023-01-06 01:09:27,888] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:09:27,902] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.007 seconds
[2023-01-06 01:09:57,971] {processor.py:153} INFO - Started process (PID=9957) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:09:57,972] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:09:57,973] {logging_mixin.py:115} INFO - [2023-01-06 01:09:57,973] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:09:58,947] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:09:58,949] {logging_mixin.py:115} INFO - [2023-01-06 01:09:58,948] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:09:58,949] {logging_mixin.py:115} INFO - [2023-01-06 01:09:58,949] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:09:58,956] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:09:58,981] {logging_mixin.py:115} INFO - [2023-01-06 01:09:58,981] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:09:59,002] {logging_mixin.py:115} INFO - [2023-01-06 01:09:59,002] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:09:59,014] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.048 seconds
[2023-01-06 01:10:29,086] {processor.py:153} INFO - Started process (PID=9977) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:10:29,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:10:29,088] {logging_mixin.py:115} INFO - [2023-01-06 01:10:29,088] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:10:30,006] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:10:30,007] {logging_mixin.py:115} INFO - [2023-01-06 01:10:30,007] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:10:30,008] {logging_mixin.py:115} INFO - [2023-01-06 01:10:30,007] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:10:30,015] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:10:30,038] {logging_mixin.py:115} INFO - [2023-01-06 01:10:30,038] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:10:30,060] {logging_mixin.py:115} INFO - [2023-01-06 01:10:30,060] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:10:30,072] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.990 seconds
[2023-01-06 01:11:00,150] {processor.py:153} INFO - Started process (PID=10002) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:11:00,150] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:11:00,151] {logging_mixin.py:115} INFO - [2023-01-06 01:11:00,151] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:11:01,096] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:11:01,098] {logging_mixin.py:115} INFO - [2023-01-06 01:11:01,098] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:11:01,098] {logging_mixin.py:115} INFO - [2023-01-06 01:11:01,098] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:11:01,105] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:11:01,129] {logging_mixin.py:115} INFO - [2023-01-06 01:11:01,128] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:11:01,150] {logging_mixin.py:115} INFO - [2023-01-06 01:11:01,150] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:11:01,162] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.017 seconds
[2023-01-06 01:11:31,236] {processor.py:153} INFO - Started process (PID=10028) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:11:31,237] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:11:31,238] {logging_mixin.py:115} INFO - [2023-01-06 01:11:31,238] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:11:32,196] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:11:32,198] {logging_mixin.py:115} INFO - [2023-01-06 01:11:32,198] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:11:32,198] {logging_mixin.py:115} INFO - [2023-01-06 01:11:32,198] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:11:32,205] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:11:32,229] {logging_mixin.py:115} INFO - [2023-01-06 01:11:32,229] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:11:32,250] {logging_mixin.py:115} INFO - [2023-01-06 01:11:32,250] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:11:32,261] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.030 seconds
[2023-01-06 01:12:02,340] {processor.py:153} INFO - Started process (PID=10053) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:12:02,341] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:12:02,342] {logging_mixin.py:115} INFO - [2023-01-06 01:12:02,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:12:03,309] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:12:03,311] {logging_mixin.py:115} INFO - [2023-01-06 01:12:03,311] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:12:03,311] {logging_mixin.py:115} INFO - [2023-01-06 01:12:03,311] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:12:03,318] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:12:03,346] {logging_mixin.py:115} INFO - [2023-01-06 01:12:03,346] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:12:03,368] {logging_mixin.py:115} INFO - [2023-01-06 01:12:03,368] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:12:03,379] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.044 seconds
[2023-01-06 01:12:33,450] {processor.py:153} INFO - Started process (PID=10071) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:12:33,452] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:12:33,452] {logging_mixin.py:115} INFO - [2023-01-06 01:12:33,452] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:12:34,378] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:12:34,379] {logging_mixin.py:115} INFO - [2023-01-06 01:12:34,379] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:12:34,380] {logging_mixin.py:115} INFO - [2023-01-06 01:12:34,379] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:12:34,387] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:12:34,410] {logging_mixin.py:115} INFO - [2023-01-06 01:12:34,409] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:12:34,439] {logging_mixin.py:115} INFO - [2023-01-06 01:12:34,439] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:12:34,453] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.007 seconds
[2023-01-06 01:13:04,490] {processor.py:153} INFO - Started process (PID=10097) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:13:04,492] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:13:04,492] {logging_mixin.py:115} INFO - [2023-01-06 01:13:04,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:13:05,446] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:13:05,447] {logging_mixin.py:115} INFO - [2023-01-06 01:13:05,447] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:13:05,448] {logging_mixin.py:115} INFO - [2023-01-06 01:13:05,448] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:13:05,457] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:13:05,481] {logging_mixin.py:115} INFO - [2023-01-06 01:13:05,480] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:13:05,503] {logging_mixin.py:115} INFO - [2023-01-06 01:13:05,503] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:13:05,514] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.030 seconds
[2023-01-06 01:13:35,606] {processor.py:153} INFO - Started process (PID=10123) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:13:35,607] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:13:35,608] {logging_mixin.py:115} INFO - [2023-01-06 01:13:35,607] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:13:36,547] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:13:36,548] {logging_mixin.py:115} INFO - [2023-01-06 01:13:36,548] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:13:36,549] {logging_mixin.py:115} INFO - [2023-01-06 01:13:36,549] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:13:36,556] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:13:36,591] {logging_mixin.py:115} INFO - [2023-01-06 01:13:36,591] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:13:36,613] {logging_mixin.py:115} INFO - [2023-01-06 01:13:36,613] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:13:36,624] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.023 seconds
[2023-01-06 01:14:06,693] {processor.py:153} INFO - Started process (PID=10141) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:14:06,695] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:14:06,696] {logging_mixin.py:115} INFO - [2023-01-06 01:14:06,696] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:14:07,707] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:14:07,708] {logging_mixin.py:115} INFO - [2023-01-06 01:14:07,708] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:14:07,709] {logging_mixin.py:115} INFO - [2023-01-06 01:14:07,708] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:14:07,716] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:14:07,739] {logging_mixin.py:115} INFO - [2023-01-06 01:14:07,738] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:14:07,760] {logging_mixin.py:115} INFO - [2023-01-06 01:14:07,760] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:14:07,771] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.084 seconds
[2023-01-06 01:14:37,847] {processor.py:153} INFO - Started process (PID=10166) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:14:37,849] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:14:37,850] {logging_mixin.py:115} INFO - [2023-01-06 01:14:37,850] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:14:38,831] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:14:38,833] {logging_mixin.py:115} INFO - [2023-01-06 01:14:38,832] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:14:38,833] {logging_mixin.py:115} INFO - [2023-01-06 01:14:38,833] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:14:38,840] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:14:38,865] {logging_mixin.py:115} INFO - [2023-01-06 01:14:38,865] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:14:38,888] {logging_mixin.py:115} INFO - [2023-01-06 01:14:38,888] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:14:38,900] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.058 seconds
[2023-01-06 01:15:09,928] {processor.py:153} INFO - Started process (PID=10190) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:15:09,929] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:15:09,929] {logging_mixin.py:115} INFO - [2023-01-06 01:15:09,929] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:15:10,873] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:15:10,875] {logging_mixin.py:115} INFO - [2023-01-06 01:15:10,875] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:15:10,875] {logging_mixin.py:115} INFO - [2023-01-06 01:15:10,875] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:15:10,883] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:15:10,906] {logging_mixin.py:115} INFO - [2023-01-06 01:15:10,906] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:15:10,929] {logging_mixin.py:115} INFO - [2023-01-06 01:15:10,929] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:15:10,941] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.017 seconds
[2023-01-06 01:15:41,015] {processor.py:153} INFO - Started process (PID=10215) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:15:41,018] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:15:41,019] {logging_mixin.py:115} INFO - [2023-01-06 01:15:41,018] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:15:41,974] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:15:41,976] {logging_mixin.py:115} INFO - [2023-01-06 01:15:41,976] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:15:41,977] {logging_mixin.py:115} INFO - [2023-01-06 01:15:41,977] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:15:41,985] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:15:42,013] {logging_mixin.py:115} INFO - [2023-01-06 01:15:42,013] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:15:42,036] {logging_mixin.py:115} INFO - [2023-01-06 01:15:42,036] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:15:42,046] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.037 seconds
[2023-01-06 01:16:12,119] {processor.py:153} INFO - Started process (PID=10240) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:16:12,119] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:16:12,120] {logging_mixin.py:115} INFO - [2023-01-06 01:16:12,120] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:16:13,131] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:16:13,133] {logging_mixin.py:115} INFO - [2023-01-06 01:16:13,133] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:16:13,134] {logging_mixin.py:115} INFO - [2023-01-06 01:16:13,133] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:16:13,144] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:16:13,172] {logging_mixin.py:115} INFO - [2023-01-06 01:16:13,172] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:16:13,196] {logging_mixin.py:115} INFO - [2023-01-06 01:16:13,196] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:16:13,209] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.095 seconds
[2023-01-06 01:16:43,279] {processor.py:153} INFO - Started process (PID=10257) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:16:43,280] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:16:43,281] {logging_mixin.py:115} INFO - [2023-01-06 01:16:43,281] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:16:44,306] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:16:44,307] {logging_mixin.py:115} INFO - [2023-01-06 01:16:44,307] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:16:44,307] {logging_mixin.py:115} INFO - [2023-01-06 01:16:44,307] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:16:44,314] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:16:44,342] {logging_mixin.py:115} INFO - [2023-01-06 01:16:44,341] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:16:44,368] {logging_mixin.py:115} INFO - [2023-01-06 01:16:44,367] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:16:44,379] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.105 seconds
[2023-01-06 01:17:14,453] {processor.py:153} INFO - Started process (PID=10281) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:17:14,455] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:17:14,455] {logging_mixin.py:115} INFO - [2023-01-06 01:17:14,455] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:17:15,417] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:17:15,418] {logging_mixin.py:115} INFO - [2023-01-06 01:17:15,418] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:17:15,419] {logging_mixin.py:115} INFO - [2023-01-06 01:17:15,419] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:17:15,427] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:17:15,451] {logging_mixin.py:115} INFO - [2023-01-06 01:17:15,451] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:17:15,474] {logging_mixin.py:115} INFO - [2023-01-06 01:17:15,474] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:17:15,484] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.037 seconds
[2023-01-06 01:17:45,560] {processor.py:153} INFO - Started process (PID=10306) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:17:45,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:17:45,563] {logging_mixin.py:115} INFO - [2023-01-06 01:17:45,563] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:17:46,497] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:17:46,498] {logging_mixin.py:115} INFO - [2023-01-06 01:17:46,498] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:17:46,499] {logging_mixin.py:115} INFO - [2023-01-06 01:17:46,498] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:17:46,506] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:17:46,529] {logging_mixin.py:115} INFO - [2023-01-06 01:17:46,529] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:17:46,552] {logging_mixin.py:115} INFO - [2023-01-06 01:17:46,552] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:17:46,562] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.007 seconds
[2023-01-06 01:18:16,617] {processor.py:153} INFO - Started process (PID=10324) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:18:16,618] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:18:16,619] {logging_mixin.py:115} INFO - [2023-01-06 01:18:16,619] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:18:17,596] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:18:17,597] {logging_mixin.py:115} INFO - [2023-01-06 01:18:17,597] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:18:17,598] {logging_mixin.py:115} INFO - [2023-01-06 01:18:17,597] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:18:17,605] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:18:17,631] {logging_mixin.py:115} INFO - [2023-01-06 01:18:17,631] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:18:17,655] {logging_mixin.py:115} INFO - [2023-01-06 01:18:17,655] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:18:17,665] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.053 seconds
[2023-01-06 01:18:47,750] {processor.py:153} INFO - Started process (PID=10349) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:18:47,751] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:18:47,752] {logging_mixin.py:115} INFO - [2023-01-06 01:18:47,752] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:18:48,687] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:18:48,689] {logging_mixin.py:115} INFO - [2023-01-06 01:18:48,689] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:18:48,690] {logging_mixin.py:115} INFO - [2023-01-06 01:18:48,689] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:18:48,697] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:18:48,722] {logging_mixin.py:115} INFO - [2023-01-06 01:18:48,722] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:18:48,746] {logging_mixin.py:115} INFO - [2023-01-06 01:18:48,746] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:18:48,757] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.012 seconds
[2023-01-06 01:19:18,830] {processor.py:153} INFO - Started process (PID=10374) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:19:18,831] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:19:18,831] {logging_mixin.py:115} INFO - [2023-01-06 01:19:18,831] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:19:19,804] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:19:19,806] {logging_mixin.py:115} INFO - [2023-01-06 01:19:19,805] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:19:19,806] {logging_mixin.py:115} INFO - [2023-01-06 01:19:19,806] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:19:19,813] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:19:19,838] {logging_mixin.py:115} INFO - [2023-01-06 01:19:19,838] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:19:19,861] {logging_mixin.py:115} INFO - [2023-01-06 01:19:19,861] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:19:19,872] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.047 seconds
[2023-01-06 01:19:49,930] {processor.py:153} INFO - Started process (PID=10399) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:19:49,934] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:19:49,935] {logging_mixin.py:115} INFO - [2023-01-06 01:19:49,935] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:19:50,890] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:19:50,892] {logging_mixin.py:115} INFO - [2023-01-06 01:19:50,892] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:19:50,892] {logging_mixin.py:115} INFO - [2023-01-06 01:19:50,892] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:19:50,900] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:19:50,931] {logging_mixin.py:115} INFO - [2023-01-06 01:19:50,931] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:19:50,962] {logging_mixin.py:115} INFO - [2023-01-06 01:19:50,962] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:19:50,973] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.048 seconds
[2023-01-06 01:20:21,047] {processor.py:153} INFO - Started process (PID=10418) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:20:21,047] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:20:21,048] {logging_mixin.py:115} INFO - [2023-01-06 01:20:21,048] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:20:22,015] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:20:22,017] {logging_mixin.py:115} INFO - [2023-01-06 01:20:22,017] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:20:22,018] {logging_mixin.py:115} INFO - [2023-01-06 01:20:22,017] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:20:22,025] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:20:22,059] {logging_mixin.py:115} INFO - [2023-01-06 01:20:22,058] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:20:22,085] {logging_mixin.py:115} INFO - [2023-01-06 01:20:22,085] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:20:22,096] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.054 seconds
[2023-01-06 01:20:53,131] {processor.py:153} INFO - Started process (PID=10443) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:20:53,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:20:53,133] {logging_mixin.py:115} INFO - [2023-01-06 01:20:53,133] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:20:54,110] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:20:54,112] {logging_mixin.py:115} INFO - [2023-01-06 01:20:54,112] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:20:54,112] {logging_mixin.py:115} INFO - [2023-01-06 01:20:54,112] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:20:54,120] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:20:54,144] {logging_mixin.py:115} INFO - [2023-01-06 01:20:54,143] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:20:54,166] {logging_mixin.py:115} INFO - [2023-01-06 01:20:54,166] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:20:54,176] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.049 seconds
[2023-01-06 01:21:24,248] {processor.py:153} INFO - Started process (PID=10468) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:21:24,250] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:21:24,250] {logging_mixin.py:115} INFO - [2023-01-06 01:21:24,250] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:21:25,188] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:21:25,190] {logging_mixin.py:115} INFO - [2023-01-06 01:21:25,189] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:21:25,190] {logging_mixin.py:115} INFO - [2023-01-06 01:21:25,190] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:21:25,197] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:21:25,221] {logging_mixin.py:115} INFO - [2023-01-06 01:21:25,220] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:21:25,244] {logging_mixin.py:115} INFO - [2023-01-06 01:21:25,244] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 01:21:25,254] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.011 seconds
[2023-01-06 01:21:55,322] {processor.py:153} INFO - Started process (PID=10492) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:21:55,322] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:21:55,323] {logging_mixin.py:115} INFO - [2023-01-06 01:21:55,323] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:21:56,286] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:21:56,287] {logging_mixin.py:115} INFO - [2023-01-06 01:21:56,287] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:21:56,288] {logging_mixin.py:115} INFO - [2023-01-06 01:21:56,288] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:21:56,295] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:21:56,319] {logging_mixin.py:115} INFO - [2023-01-06 01:21:56,319] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:21:56,353] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.036 seconds
[2023-01-06 01:22:26,426] {processor.py:153} INFO - Started process (PID=10510) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:22:26,427] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:22:26,428] {logging_mixin.py:115} INFO - [2023-01-06 01:22:26,427] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:22:27,513] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:22:27,515] {logging_mixin.py:115} INFO - [2023-01-06 01:22:27,515] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:22:27,516] {logging_mixin.py:115} INFO - [2023-01-06 01:22:27,515] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:22:27,528] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:22:27,566] {logging_mixin.py:115} INFO - [2023-01-06 01:22:27,566] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:22:27,608] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.187 seconds
[2023-01-06 01:22:57,687] {processor.py:153} INFO - Started process (PID=10533) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:22:57,688] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:22:57,689] {logging_mixin.py:115} INFO - [2023-01-06 01:22:57,689] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:22:58,660] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:22:58,661] {logging_mixin.py:115} INFO - [2023-01-06 01:22:58,661] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:22:58,662] {logging_mixin.py:115} INFO - [2023-01-06 01:22:58,661] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:22:58,668] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:22:58,691] {logging_mixin.py:115} INFO - [2023-01-06 01:22:58,691] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:22:58,720] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.038 seconds
[2023-01-06 01:23:28,751] {processor.py:153} INFO - Started process (PID=10558) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:23:28,752] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:23:28,753] {logging_mixin.py:115} INFO - [2023-01-06 01:23:28,753] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:23:29,674] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:23:29,675] {logging_mixin.py:115} INFO - [2023-01-06 01:23:29,675] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:23:29,676] {logging_mixin.py:115} INFO - [2023-01-06 01:23:29,676] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:23:29,683] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:23:29,705] {logging_mixin.py:115} INFO - [2023-01-06 01:23:29,705] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:23:29,734] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.988 seconds
[2023-01-06 01:23:59,787] {processor.py:153} INFO - Started process (PID=10582) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:23:59,790] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:23:59,791] {logging_mixin.py:115} INFO - [2023-01-06 01:23:59,791] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:24:00,760] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:24:00,762] {logging_mixin.py:115} INFO - [2023-01-06 01:24:00,762] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:24:00,762] {logging_mixin.py:115} INFO - [2023-01-06 01:24:00,762] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:24:00,770] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:24:00,808] {logging_mixin.py:115} INFO - [2023-01-06 01:24:00,807] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:24:00,840] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.058 seconds
[2023-01-06 01:24:30,907] {processor.py:153} INFO - Started process (PID=10601) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:24:30,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:24:30,909] {logging_mixin.py:115} INFO - [2023-01-06 01:24:30,909] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:24:31,818] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:24:31,819] {logging_mixin.py:115} INFO - [2023-01-06 01:24:31,819] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:24:31,820] {logging_mixin.py:115} INFO - [2023-01-06 01:24:31,819] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:24:31,826] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:24:31,849] {logging_mixin.py:115} INFO - [2023-01-06 01:24:31,849] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:24:31,879] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.977 seconds
[2023-01-06 01:25:01,952] {processor.py:153} INFO - Started process (PID=10626) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:25:01,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:25:01,954] {logging_mixin.py:115} INFO - [2023-01-06 01:25:01,954] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:25:02,913] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:25:02,915] {logging_mixin.py:115} INFO - [2023-01-06 01:25:02,915] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:25:02,915] {logging_mixin.py:115} INFO - [2023-01-06 01:25:02,915] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:25:02,922] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:25:02,946] {logging_mixin.py:115} INFO - [2023-01-06 01:25:02,946] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:25:02,979] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.032 seconds
[2023-01-06 01:25:33,062] {processor.py:153} INFO - Started process (PID=10651) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:25:33,063] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:25:33,064] {logging_mixin.py:115} INFO - [2023-01-06 01:25:33,064] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:25:33,993] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:25:33,994] {logging_mixin.py:115} INFO - [2023-01-06 01:25:33,994] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:25:33,995] {logging_mixin.py:115} INFO - [2023-01-06 01:25:33,995] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:25:34,002] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:25:34,024] {logging_mixin.py:115} INFO - [2023-01-06 01:25:34,024] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:25:34,053] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-06 01:26:04,102] {processor.py:153} INFO - Started process (PID=10675) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:26:04,107] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:26:04,109] {logging_mixin.py:115} INFO - [2023-01-06 01:26:04,109] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:26:05,066] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:26:05,068] {logging_mixin.py:115} INFO - [2023-01-06 01:26:05,068] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:26:05,068] {logging_mixin.py:115} INFO - [2023-01-06 01:26:05,068] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:26:05,075] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:26:05,102] {logging_mixin.py:115} INFO - [2023-01-06 01:26:05,101] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:26:05,132] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.035 seconds
[2023-01-06 01:26:35,205] {processor.py:153} INFO - Started process (PID=10693) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:26:35,206] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:26:35,207] {logging_mixin.py:115} INFO - [2023-01-06 01:26:35,207] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:26:36,146] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:26:36,147] {logging_mixin.py:115} INFO - [2023-01-06 01:26:36,147] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:26:36,148] {logging_mixin.py:115} INFO - [2023-01-06 01:26:36,148] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:26:36,157] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:26:36,182] {logging_mixin.py:115} INFO - [2023-01-06 01:26:36,182] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:26:36,213] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.013 seconds
[2023-01-06 01:27:06,260] {processor.py:153} INFO - Started process (PID=10719) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:27:06,261] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:27:06,262] {logging_mixin.py:115} INFO - [2023-01-06 01:27:06,262] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:27:07,195] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:27:07,196] {logging_mixin.py:115} INFO - [2023-01-06 01:27:07,196] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:27:07,197] {logging_mixin.py:115} INFO - [2023-01-06 01:27:07,196] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:27:07,204] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:27:07,226] {logging_mixin.py:115} INFO - [2023-01-06 01:27:07,225] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:27:07,254] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.000 seconds
[2023-01-06 01:27:37,343] {processor.py:153} INFO - Started process (PID=10744) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:27:37,345] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:27:37,346] {logging_mixin.py:115} INFO - [2023-01-06 01:27:37,346] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:27:38,268] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:27:38,270] {logging_mixin.py:115} INFO - [2023-01-06 01:27:38,270] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:27:38,271] {logging_mixin.py:115} INFO - [2023-01-06 01:27:38,270] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:27:38,282] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:27:38,306] {logging_mixin.py:115} INFO - [2023-01-06 01:27:38,306] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:27:38,339] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.001 seconds
[2023-01-06 01:28:08,436] {processor.py:153} INFO - Started process (PID=10770) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:28:08,436] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:28:08,438] {logging_mixin.py:115} INFO - [2023-01-06 01:28:08,438] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:28:09,744] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:28:09,745] {logging_mixin.py:115} INFO - [2023-01-06 01:28:09,745] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:28:09,745] {logging_mixin.py:115} INFO - [2023-01-06 01:28:09,745] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:28:09,752] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:28:09,775] {logging_mixin.py:115} INFO - [2023-01-06 01:28:09,775] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:28:09,806] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.376 seconds
[2023-01-06 01:28:39,879] {processor.py:153} INFO - Started process (PID=10789) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:28:39,880] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:28:39,882] {logging_mixin.py:115} INFO - [2023-01-06 01:28:39,882] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:28:40,835] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:28:40,836] {logging_mixin.py:115} INFO - [2023-01-06 01:28:40,836] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:28:40,837] {logging_mixin.py:115} INFO - [2023-01-06 01:28:40,836] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:28:40,844] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:28:40,867] {logging_mixin.py:115} INFO - [2023-01-06 01:28:40,866] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:28:40,896] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.022 seconds
[2023-01-06 01:29:10,968] {processor.py:153} INFO - Started process (PID=10813) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:29:10,969] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:29:10,970] {logging_mixin.py:115} INFO - [2023-01-06 01:29:10,970] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:29:11,930] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:29:11,932] {logging_mixin.py:115} INFO - [2023-01-06 01:29:11,932] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:29:11,932] {logging_mixin.py:115} INFO - [2023-01-06 01:29:11,932] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:29:11,939] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:29:11,962] {logging_mixin.py:115} INFO - [2023-01-06 01:29:11,961] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:29:11,991] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.028 seconds
[2023-01-06 01:29:42,084] {processor.py:153} INFO - Started process (PID=10838) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:29:42,085] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:29:42,086] {logging_mixin.py:115} INFO - [2023-01-06 01:29:42,086] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:29:43,080] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:29:43,081] {logging_mixin.py:115} INFO - [2023-01-06 01:29:43,081] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:29:43,082] {logging_mixin.py:115} INFO - [2023-01-06 01:29:43,081] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:29:43,089] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:29:43,117] {logging_mixin.py:115} INFO - [2023-01-06 01:29:43,116] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:29:43,146] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.067 seconds
[2023-01-06 01:30:13,219] {processor.py:153} INFO - Started process (PID=10863) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:30:13,220] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:30:13,222] {logging_mixin.py:115} INFO - [2023-01-06 01:30:13,222] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:30:14,204] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:30:14,205] {logging_mixin.py:115} INFO - [2023-01-06 01:30:14,205] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:30:14,206] {logging_mixin.py:115} INFO - [2023-01-06 01:30:14,206] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:30:14,213] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:30:14,235] {logging_mixin.py:115} INFO - [2023-01-06 01:30:14,235] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:30:14,264] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.050 seconds
[2023-01-06 01:30:44,333] {processor.py:153} INFO - Started process (PID=10881) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:30:44,335] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:30:44,336] {logging_mixin.py:115} INFO - [2023-01-06 01:30:44,336] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:30:45,254] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:30:45,255] {logging_mixin.py:115} INFO - [2023-01-06 01:30:45,255] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:30:45,256] {logging_mixin.py:115} INFO - [2023-01-06 01:30:45,256] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:30:45,263] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:30:45,286] {logging_mixin.py:115} INFO - [2023-01-06 01:30:45,285] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:30:45,314] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.986 seconds
[2023-01-06 01:31:15,395] {processor.py:153} INFO - Started process (PID=10905) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:31:15,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:31:15,397] {logging_mixin.py:115} INFO - [2023-01-06 01:31:15,396] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:31:16,315] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:31:16,317] {logging_mixin.py:115} INFO - [2023-01-06 01:31:16,317] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:31:16,317] {logging_mixin.py:115} INFO - [2023-01-06 01:31:16,317] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:31:16,324] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:31:16,347] {logging_mixin.py:115} INFO - [2023-01-06 01:31:16,347] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:31:16,377] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.987 seconds
[2023-01-06 01:31:46,480] {processor.py:153} INFO - Started process (PID=10930) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:31:46,482] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:31:46,482] {logging_mixin.py:115} INFO - [2023-01-06 01:31:46,482] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:31:47,420] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:31:47,421] {logging_mixin.py:115} INFO - [2023-01-06 01:31:47,421] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:31:47,422] {logging_mixin.py:115} INFO - [2023-01-06 01:31:47,422] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:31:47,430] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:31:47,453] {logging_mixin.py:115} INFO - [2023-01-06 01:31:47,452] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:31:47,483] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.008 seconds
[2023-01-06 01:32:17,557] {processor.py:153} INFO - Started process (PID=10955) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:32:17,557] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:32:17,558] {logging_mixin.py:115} INFO - [2023-01-06 01:32:17,558] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:32:18,598] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:32:18,600] {logging_mixin.py:115} INFO - [2023-01-06 01:32:18,600] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:32:18,600] {logging_mixin.py:115} INFO - [2023-01-06 01:32:18,600] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:32:18,608] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:32:18,632] {logging_mixin.py:115} INFO - [2023-01-06 01:32:18,631] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:32:18,661] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.109 seconds
[2023-01-06 01:32:48,733] {processor.py:153} INFO - Started process (PID=10973) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:32:48,735] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:32:48,735] {logging_mixin.py:115} INFO - [2023-01-06 01:32:48,735] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:32:49,716] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:32:49,717] {logging_mixin.py:115} INFO - [2023-01-06 01:32:49,717] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:32:49,718] {logging_mixin.py:115} INFO - [2023-01-06 01:32:49,718] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:32:49,725] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:32:49,749] {logging_mixin.py:115} INFO - [2023-01-06 01:32:49,749] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:32:49,779] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.052 seconds
[2023-01-06 01:33:19,851] {processor.py:153} INFO - Started process (PID=10999) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:33:19,852] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:33:19,853] {logging_mixin.py:115} INFO - [2023-01-06 01:33:19,852] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:33:20,758] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:33:20,759] {logging_mixin.py:115} INFO - [2023-01-06 01:33:20,759] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:33:20,760] {logging_mixin.py:115} INFO - [2023-01-06 01:33:20,759] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:33:20,766] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:33:20,790] {logging_mixin.py:115} INFO - [2023-01-06 01:33:20,789] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:33:20,819] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.973 seconds
[2023-01-06 01:33:51,813] {processor.py:153} INFO - Started process (PID=11024) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:33:51,814] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:33:51,815] {logging_mixin.py:115} INFO - [2023-01-06 01:33:51,815] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:33:52,736] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:33:52,738] {logging_mixin.py:115} INFO - [2023-01-06 01:33:52,738] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:33:52,738] {logging_mixin.py:115} INFO - [2023-01-06 01:33:52,738] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:33:52,745] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:33:52,770] {logging_mixin.py:115} INFO - [2023-01-06 01:33:52,769] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:33:52,800] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.991 seconds
[2023-01-06 01:34:22,830] {processor.py:153} INFO - Started process (PID=11048) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:34:22,831] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:34:22,832] {logging_mixin.py:115} INFO - [2023-01-06 01:34:22,832] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:34:23,781] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:34:23,782] {logging_mixin.py:115} INFO - [2023-01-06 01:34:23,782] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:34:23,783] {logging_mixin.py:115} INFO - [2023-01-06 01:34:23,782] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:34:23,790] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:34:23,815] {logging_mixin.py:115} INFO - [2023-01-06 01:34:23,815] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:34:23,849] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.024 seconds
[2023-01-06 01:34:53,919] {processor.py:153} INFO - Started process (PID=11066) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:34:53,920] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:34:53,921] {logging_mixin.py:115} INFO - [2023-01-06 01:34:53,921] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:34:54,857] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:34:54,859] {logging_mixin.py:115} INFO - [2023-01-06 01:34:54,859] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:34:54,859] {logging_mixin.py:115} INFO - [2023-01-06 01:34:54,859] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:34:54,867] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:34:54,889] {logging_mixin.py:115} INFO - [2023-01-06 01:34:54,889] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:34:54,920] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.005 seconds
[2023-01-06 01:35:25,007] {processor.py:153} INFO - Started process (PID=11093) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:35:25,008] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:35:25,009] {logging_mixin.py:115} INFO - [2023-01-06 01:35:25,009] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:35:25,989] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:35:25,990] {logging_mixin.py:115} INFO - [2023-01-06 01:35:25,990] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:35:25,991] {logging_mixin.py:115} INFO - [2023-01-06 01:35:25,990] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:35:25,998] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:35:26,024] {logging_mixin.py:115} INFO - [2023-01-06 01:35:26,024] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:35:26,068] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.066 seconds
[2023-01-06 01:35:56,148] {processor.py:153} INFO - Started process (PID=11118) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:35:56,149] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:35:56,150] {logging_mixin.py:115} INFO - [2023-01-06 01:35:56,150] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:35:57,109] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:35:57,110] {logging_mixin.py:115} INFO - [2023-01-06 01:35:57,110] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:35:57,111] {logging_mixin.py:115} INFO - [2023-01-06 01:35:57,111] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:35:57,118] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:35:57,142] {logging_mixin.py:115} INFO - [2023-01-06 01:35:57,141] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:35:57,177] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.034 seconds
[2023-01-06 01:36:27,253] {processor.py:153} INFO - Started process (PID=11141) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:36:27,254] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:36:27,255] {logging_mixin.py:115} INFO - [2023-01-06 01:36:27,255] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:36:28,268] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:36:28,269] {logging_mixin.py:115} INFO - [2023-01-06 01:36:28,269] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:36:28,271] {logging_mixin.py:115} INFO - [2023-01-06 01:36:28,271] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:36:28,279] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:36:28,306] {logging_mixin.py:115} INFO - [2023-01-06 01:36:28,306] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:36:28,338] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.092 seconds
[2023-01-06 01:36:58,413] {processor.py:153} INFO - Started process (PID=11161) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:36:58,415] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:36:58,415] {logging_mixin.py:115} INFO - [2023-01-06 01:36:58,415] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:36:59,366] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:36:59,367] {logging_mixin.py:115} INFO - [2023-01-06 01:36:59,367] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:36:59,368] {logging_mixin.py:115} INFO - [2023-01-06 01:36:59,368] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:36:59,375] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:36:59,399] {logging_mixin.py:115} INFO - [2023-01-06 01:36:59,399] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:36:59,430] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.021 seconds
[2023-01-06 01:37:29,499] {processor.py:153} INFO - Started process (PID=11186) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:37:29,500] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:37:29,501] {logging_mixin.py:115} INFO - [2023-01-06 01:37:29,501] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:37:30,420] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:37:30,421] {logging_mixin.py:115} INFO - [2023-01-06 01:37:30,421] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:37:30,422] {logging_mixin.py:115} INFO - [2023-01-06 01:37:30,421] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:37:30,429] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:37:30,452] {logging_mixin.py:115} INFO - [2023-01-06 01:37:30,451] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:37:30,481] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.987 seconds
[2023-01-06 01:38:00,559] {processor.py:153} INFO - Started process (PID=11211) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:38:00,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:38:00,561] {logging_mixin.py:115} INFO - [2023-01-06 01:38:00,561] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:38:01,485] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:38:01,486] {logging_mixin.py:115} INFO - [2023-01-06 01:38:01,486] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:38:01,487] {logging_mixin.py:115} INFO - [2023-01-06 01:38:01,487] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:38:01,494] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:38:01,520] {logging_mixin.py:115} INFO - [2023-01-06 01:38:01,520] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:38:01,551] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.997 seconds
[2023-01-06 01:38:31,624] {processor.py:153} INFO - Started process (PID=11229) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:38:31,625] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:38:31,626] {logging_mixin.py:115} INFO - [2023-01-06 01:38:31,626] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:38:32,604] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:38:32,605] {logging_mixin.py:115} INFO - [2023-01-06 01:38:32,605] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:38:32,606] {logging_mixin.py:115} INFO - [2023-01-06 01:38:32,605] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:38:32,614] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:38:32,646] {logging_mixin.py:115} INFO - [2023-01-06 01:38:32,645] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:38:32,686] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.068 seconds
[2023-01-06 01:39:02,764] {processor.py:153} INFO - Started process (PID=11256) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:39:02,766] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:39:02,766] {logging_mixin.py:115} INFO - [2023-01-06 01:39:02,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:39:03,693] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:39:03,695] {logging_mixin.py:115} INFO - [2023-01-06 01:39:03,695] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:39:03,696] {logging_mixin.py:115} INFO - [2023-01-06 01:39:03,695] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:39:03,703] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:39:03,727] {logging_mixin.py:115} INFO - [2023-01-06 01:39:03,726] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:39:03,757] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.998 seconds
[2023-01-06 01:39:33,820] {processor.py:153} INFO - Started process (PID=11281) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:39:33,820] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:39:33,821] {logging_mixin.py:115} INFO - [2023-01-06 01:39:33,821] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:39:34,750] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:39:34,751] {logging_mixin.py:115} INFO - [2023-01-06 01:39:34,751] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:39:34,752] {logging_mixin.py:115} INFO - [2023-01-06 01:39:34,752] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:39:34,761] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:39:34,783] {logging_mixin.py:115} INFO - [2023-01-06 01:39:34,783] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:39:34,812] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.998 seconds
[2023-01-06 01:40:04,880] {processor.py:153} INFO - Started process (PID=11306) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:40:04,881] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:40:04,882] {logging_mixin.py:115} INFO - [2023-01-06 01:40:04,882] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:40:05,851] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:40:05,852] {logging_mixin.py:115} INFO - [2023-01-06 01:40:05,852] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:40:05,853] {logging_mixin.py:115} INFO - [2023-01-06 01:40:05,853] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:40:05,860] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:40:05,883] {logging_mixin.py:115} INFO - [2023-01-06 01:40:05,883] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:40:05,911] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.037 seconds
[2023-01-06 01:40:35,981] {processor.py:153} INFO - Started process (PID=11324) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:40:35,982] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:40:35,983] {logging_mixin.py:115} INFO - [2023-01-06 01:40:35,983] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:40:36,907] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:40:36,908] {logging_mixin.py:115} INFO - [2023-01-06 01:40:36,908] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:40:36,909] {logging_mixin.py:115} INFO - [2023-01-06 01:40:36,908] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:40:36,916] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:40:36,938] {logging_mixin.py:115} INFO - [2023-01-06 01:40:36,938] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:40:36,972] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.995 seconds
[2023-01-06 01:41:07,056] {processor.py:153} INFO - Started process (PID=11351) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:41:07,059] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:41:07,060] {logging_mixin.py:115} INFO - [2023-01-06 01:41:07,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:41:07,988] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:41:07,989] {logging_mixin.py:115} INFO - [2023-01-06 01:41:07,989] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:41:07,990] {logging_mixin.py:115} INFO - [2023-01-06 01:41:07,989] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:41:07,998] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:41:08,022] {logging_mixin.py:115} INFO - [2023-01-06 01:41:08,021] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:41:08,051] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.000 seconds
[2023-01-06 01:41:38,092] {processor.py:153} INFO - Started process (PID=11377) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:41:38,092] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:41:38,093] {logging_mixin.py:115} INFO - [2023-01-06 01:41:38,093] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:41:39,032] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:41:39,034] {logging_mixin.py:115} INFO - [2023-01-06 01:41:39,034] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:41:39,034] {logging_mixin.py:115} INFO - [2023-01-06 01:41:39,034] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:41:39,041] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:41:39,065] {logging_mixin.py:115} INFO - [2023-01-06 01:41:39,064] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:41:39,094] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.007 seconds
[2023-01-06 01:42:09,187] {processor.py:153} INFO - Started process (PID=11402) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:42:09,189] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:42:09,189] {logging_mixin.py:115} INFO - [2023-01-06 01:42:09,189] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:42:10,132] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:42:10,134] {logging_mixin.py:115} INFO - [2023-01-06 01:42:10,134] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:42:10,134] {logging_mixin.py:115} INFO - [2023-01-06 01:42:10,134] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:42:10,141] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:42:10,164] {logging_mixin.py:115} INFO - [2023-01-06 01:42:10,164] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:42:10,194] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.011 seconds
[2023-01-06 01:42:40,286] {processor.py:153} INFO - Started process (PID=11420) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:42:40,287] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:42:40,287] {logging_mixin.py:115} INFO - [2023-01-06 01:42:40,287] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:42:41,231] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:42:41,232] {logging_mixin.py:115} INFO - [2023-01-06 01:42:41,232] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:42:41,233] {logging_mixin.py:115} INFO - [2023-01-06 01:42:41,233] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:42:41,240] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:42:41,264] {logging_mixin.py:115} INFO - [2023-01-06 01:42:41,263] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:42:41,295] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.014 seconds
[2023-01-06 01:43:11,327] {processor.py:153} INFO - Started process (PID=11444) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:43:11,328] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:43:11,328] {logging_mixin.py:115} INFO - [2023-01-06 01:43:11,328] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:43:12,268] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:43:12,269] {logging_mixin.py:115} INFO - [2023-01-06 01:43:12,269] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:43:12,270] {logging_mixin.py:115} INFO - [2023-01-06 01:43:12,270] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:43:12,277] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:43:12,302] {logging_mixin.py:115} INFO - [2023-01-06 01:43:12,302] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:43:12,333] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.011 seconds
[2023-01-06 01:43:42,404] {processor.py:153} INFO - Started process (PID=11469) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:43:42,404] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:43:42,405] {logging_mixin.py:115} INFO - [2023-01-06 01:43:42,405] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:43:43,318] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:43:43,320] {logging_mixin.py:115} INFO - [2023-01-06 01:43:43,320] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:43:43,320] {logging_mixin.py:115} INFO - [2023-01-06 01:43:43,320] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:43:43,327] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:43:43,350] {logging_mixin.py:115} INFO - [2023-01-06 01:43:43,350] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:43:43,380] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.981 seconds
[2023-01-06 01:44:13,420] {processor.py:153} INFO - Started process (PID=11494) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:44:13,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:44:13,422] {logging_mixin.py:115} INFO - [2023-01-06 01:44:13,422] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:44:14,510] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:44:14,511] {logging_mixin.py:115} INFO - [2023-01-06 01:44:14,511] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:44:14,512] {logging_mixin.py:115} INFO - [2023-01-06 01:44:14,512] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:44:14,519] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:44:14,544] {logging_mixin.py:115} INFO - [2023-01-06 01:44:14,543] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:44:14,577] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.163 seconds
[2023-01-06 01:44:44,656] {processor.py:153} INFO - Started process (PID=11512) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:44:44,657] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:44:44,658] {logging_mixin.py:115} INFO - [2023-01-06 01:44:44,658] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:44:45,607] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:44:45,608] {logging_mixin.py:115} INFO - [2023-01-06 01:44:45,608] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:44:45,609] {logging_mixin.py:115} INFO - [2023-01-06 01:44:45,608] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:44:45,616] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:44:45,639] {logging_mixin.py:115} INFO - [2023-01-06 01:44:45,639] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:44:45,670] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.020 seconds
[2023-01-06 01:45:15,738] {processor.py:153} INFO - Started process (PID=11538) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:45:15,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:45:15,740] {logging_mixin.py:115} INFO - [2023-01-06 01:45:15,740] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:45:16,654] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:45:16,655] {logging_mixin.py:115} INFO - [2023-01-06 01:45:16,655] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:45:16,656] {logging_mixin.py:115} INFO - [2023-01-06 01:45:16,656] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:45:16,663] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:45:16,685] {logging_mixin.py:115} INFO - [2023-01-06 01:45:16,685] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:45:16,714] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.981 seconds
[2023-01-06 01:45:46,783] {processor.py:153} INFO - Started process (PID=11561) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:45:46,783] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:45:46,784] {logging_mixin.py:115} INFO - [2023-01-06 01:45:46,784] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:45:47,721] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:45:47,723] {logging_mixin.py:115} INFO - [2023-01-06 01:45:47,723] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:45:47,723] {logging_mixin.py:115} INFO - [2023-01-06 01:45:47,723] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:45:47,730] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:45:47,758] {logging_mixin.py:115} INFO - [2023-01-06 01:45:47,758] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:45:47,790] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.012 seconds
[2023-01-06 01:46:17,861] {processor.py:153} INFO - Started process (PID=11586) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:46:17,862] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:46:17,863] {logging_mixin.py:115} INFO - [2023-01-06 01:46:17,863] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:46:18,808] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:46:18,809] {logging_mixin.py:115} INFO - [2023-01-06 01:46:18,809] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:46:18,810] {logging_mixin.py:115} INFO - [2023-01-06 01:46:18,809] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:46:18,817] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:46:18,839] {logging_mixin.py:115} INFO - [2023-01-06 01:46:18,839] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:46:18,869] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.013 seconds
[2023-01-06 01:46:48,941] {processor.py:153} INFO - Started process (PID=11604) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:46:48,942] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:46:48,942] {logging_mixin.py:115} INFO - [2023-01-06 01:46:48,942] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:46:49,863] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:46:49,864] {logging_mixin.py:115} INFO - [2023-01-06 01:46:49,864] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:46:49,865] {logging_mixin.py:115} INFO - [2023-01-06 01:46:49,864] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:46:49,872] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:46:49,894] {logging_mixin.py:115} INFO - [2023-01-06 01:46:49,893] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:46:49,923] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.988 seconds
[2023-01-06 01:47:20,004] {processor.py:153} INFO - Started process (PID=11631) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:47:20,005] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:47:20,006] {logging_mixin.py:115} INFO - [2023-01-06 01:47:20,006] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:47:20,944] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:47:20,945] {logging_mixin.py:115} INFO - [2023-01-06 01:47:20,945] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:47:20,946] {logging_mixin.py:115} INFO - [2023-01-06 01:47:20,946] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:47:20,954] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:47:20,979] {logging_mixin.py:115} INFO - [2023-01-06 01:47:20,979] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:47:21,008] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.010 seconds
[2023-01-06 01:47:51,088] {processor.py:153} INFO - Started process (PID=11656) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:47:51,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:47:51,089] {logging_mixin.py:115} INFO - [2023-01-06 01:47:51,089] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:47:52,017] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:47:52,018] {logging_mixin.py:115} INFO - [2023-01-06 01:47:52,018] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:47:52,019] {logging_mixin.py:115} INFO - [2023-01-06 01:47:52,019] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:47:52,026] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:47:52,049] {logging_mixin.py:115} INFO - [2023-01-06 01:47:52,049] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:47:52,078] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.995 seconds
[2023-01-06 01:48:22,112] {processor.py:153} INFO - Started process (PID=11681) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:48:22,114] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:48:22,115] {logging_mixin.py:115} INFO - [2023-01-06 01:48:22,115] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:48:23,095] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:48:23,096] {logging_mixin.py:115} INFO - [2023-01-06 01:48:23,096] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:48:23,097] {logging_mixin.py:115} INFO - [2023-01-06 01:48:23,096] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:48:23,104] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:48:23,128] {logging_mixin.py:115} INFO - [2023-01-06 01:48:23,128] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:48:23,159] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.051 seconds
[2023-01-06 01:48:53,227] {processor.py:153} INFO - Started process (PID=11699) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:48:53,229] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:48:53,229] {logging_mixin.py:115} INFO - [2023-01-06 01:48:53,229] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:48:54,202] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:48:54,203] {logging_mixin.py:115} INFO - [2023-01-06 01:48:54,203] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:48:54,204] {logging_mixin.py:115} INFO - [2023-01-06 01:48:54,203] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:48:54,211] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:48:54,234] {logging_mixin.py:115} INFO - [2023-01-06 01:48:54,233] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:48:54,264] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.041 seconds
[2023-01-06 01:49:24,333] {processor.py:153} INFO - Started process (PID=11724) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:49:24,334] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:49:24,334] {logging_mixin.py:115} INFO - [2023-01-06 01:49:24,334] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:49:25,322] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:49:25,323] {logging_mixin.py:115} INFO - [2023-01-06 01:49:25,323] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:49:25,324] {logging_mixin.py:115} INFO - [2023-01-06 01:49:25,323] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:49:25,331] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:49:25,354] {logging_mixin.py:115} INFO - [2023-01-06 01:49:25,353] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:49:25,383] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.055 seconds
[2023-01-06 01:49:55,484] {processor.py:153} INFO - Started process (PID=11749) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:49:55,485] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:49:55,486] {logging_mixin.py:115} INFO - [2023-01-06 01:49:55,486] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:49:56,497] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:49:56,499] {logging_mixin.py:115} INFO - [2023-01-06 01:49:56,499] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:49:56,500] {logging_mixin.py:115} INFO - [2023-01-06 01:49:56,500] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:49:56,509] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:49:56,533] {logging_mixin.py:115} INFO - [2023-01-06 01:49:56,533] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:49:56,564] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.087 seconds
[2023-01-06 01:50:26,635] {processor.py:153} INFO - Started process (PID=11774) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:50:26,636] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:50:26,637] {logging_mixin.py:115} INFO - [2023-01-06 01:50:26,636] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:50:27,733] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:50:27,735] {logging_mixin.py:115} INFO - [2023-01-06 01:50:27,735] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:50:27,736] {logging_mixin.py:115} INFO - [2023-01-06 01:50:27,735] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:50:27,747] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:50:27,779] {logging_mixin.py:115} INFO - [2023-01-06 01:50:27,778] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:50:27,817] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.186 seconds
[2023-01-06 01:50:57,887] {processor.py:153} INFO - Started process (PID=11793) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:50:57,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:50:57,891] {logging_mixin.py:115} INFO - [2023-01-06 01:50:57,890] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:50:58,830] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:50:58,831] {logging_mixin.py:115} INFO - [2023-01-06 01:50:58,831] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:50:58,832] {logging_mixin.py:115} INFO - [2023-01-06 01:50:58,831] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:50:58,839] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:50:58,862] {logging_mixin.py:115} INFO - [2023-01-06 01:50:58,862] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:50:58,894] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.011 seconds
[2023-01-06 01:51:28,964] {processor.py:153} INFO - Started process (PID=11818) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:51:28,965] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:51:28,966] {logging_mixin.py:115} INFO - [2023-01-06 01:51:28,966] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:51:29,898] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:51:29,900] {logging_mixin.py:115} INFO - [2023-01-06 01:51:29,899] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:51:29,900] {logging_mixin.py:115} INFO - [2023-01-06 01:51:29,900] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:51:29,907] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:51:29,934] {logging_mixin.py:115} INFO - [2023-01-06 01:51:29,934] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:51:29,964] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.005 seconds
[2023-01-06 01:52:00,061] {processor.py:153} INFO - Started process (PID=11843) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:52:00,062] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:52:00,062] {logging_mixin.py:115} INFO - [2023-01-06 01:52:00,062] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:52:01,027] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:52:01,029] {logging_mixin.py:115} INFO - [2023-01-06 01:52:01,029] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:52:01,030] {logging_mixin.py:115} INFO - [2023-01-06 01:52:01,029] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:52:01,041] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:52:01,064] {logging_mixin.py:115} INFO - [2023-01-06 01:52:01,064] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:52:01,093] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.037 seconds
[2023-01-06 01:52:31,165] {processor.py:153} INFO - Started process (PID=11861) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:52:31,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:52:31,167] {logging_mixin.py:115} INFO - [2023-01-06 01:52:31,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:52:32,135] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:52:32,137] {logging_mixin.py:115} INFO - [2023-01-06 01:52:32,137] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:52:32,138] {logging_mixin.py:115} INFO - [2023-01-06 01:52:32,138] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:52:32,150] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:52:32,176] {logging_mixin.py:115} INFO - [2023-01-06 01:52:32,175] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:52:32,206] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.046 seconds
[2023-01-06 01:53:02,279] {processor.py:153} INFO - Started process (PID=11886) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:53:02,280] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:53:02,281] {logging_mixin.py:115} INFO - [2023-01-06 01:53:02,281] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:53:03,321] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:53:03,322] {logging_mixin.py:115} INFO - [2023-01-06 01:53:03,322] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:53:03,323] {logging_mixin.py:115} INFO - [2023-01-06 01:53:03,323] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:53:03,330] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:53:03,353] {logging_mixin.py:115} INFO - [2023-01-06 01:53:03,353] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:53:03,382] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.109 seconds
[2023-01-06 01:53:33,458] {processor.py:153} INFO - Started process (PID=11911) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:53:33,459] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:53:33,460] {logging_mixin.py:115} INFO - [2023-01-06 01:53:33,460] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:53:34,410] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:53:34,411] {logging_mixin.py:115} INFO - [2023-01-06 01:53:34,411] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:53:34,412] {logging_mixin.py:115} INFO - [2023-01-06 01:53:34,412] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:53:34,419] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:53:34,443] {logging_mixin.py:115} INFO - [2023-01-06 01:53:34,442] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:53:34,473] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.020 seconds
[2023-01-06 01:54:04,522] {processor.py:153} INFO - Started process (PID=11937) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:54:04,526] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:54:04,526] {logging_mixin.py:115} INFO - [2023-01-06 01:54:04,526] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:54:05,475] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:54:05,477] {logging_mixin.py:115} INFO - [2023-01-06 01:54:05,476] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:54:05,477] {logging_mixin.py:115} INFO - [2023-01-06 01:54:05,477] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:54:05,484] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:54:05,508] {logging_mixin.py:115} INFO - [2023-01-06 01:54:05,508] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:54:05,540] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.023 seconds
[2023-01-06 01:54:35,617] {processor.py:153} INFO - Started process (PID=11955) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:54:35,618] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:54:35,619] {logging_mixin.py:115} INFO - [2023-01-06 01:54:35,619] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:54:36,679] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:54:36,681] {logging_mixin.py:115} INFO - [2023-01-06 01:54:36,681] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:54:36,681] {logging_mixin.py:115} INFO - [2023-01-06 01:54:36,681] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:54:36,694] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:54:36,728] {logging_mixin.py:115} INFO - [2023-01-06 01:54:36,727] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:54:36,773] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.160 seconds
[2023-01-06 01:55:06,854] {processor.py:153} INFO - Started process (PID=11981) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:55:06,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:55:06,856] {logging_mixin.py:115} INFO - [2023-01-06 01:55:06,856] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:55:07,815] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:55:07,816] {logging_mixin.py:115} INFO - [2023-01-06 01:55:07,816] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:55:07,817] {logging_mixin.py:115} INFO - [2023-01-06 01:55:07,817] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:55:07,824] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:55:07,848] {logging_mixin.py:115} INFO - [2023-01-06 01:55:07,848] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:55:07,878] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.029 seconds
[2023-01-06 01:55:37,947] {processor.py:153} INFO - Started process (PID=12008) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:55:37,948] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:55:37,949] {logging_mixin.py:115} INFO - [2023-01-06 01:55:37,949] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:55:38,864] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:55:38,865] {logging_mixin.py:115} INFO - [2023-01-06 01:55:38,865] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:55:38,866] {logging_mixin.py:115} INFO - [2023-01-06 01:55:38,866] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:55:38,873] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:55:38,896] {logging_mixin.py:115} INFO - [2023-01-06 01:55:38,896] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:55:38,926] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.984 seconds
[2023-01-06 01:56:09,034] {processor.py:153} INFO - Started process (PID=12035) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:56:09,034] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:56:09,037] {logging_mixin.py:115} INFO - [2023-01-06 01:56:09,036] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:56:09,972] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:56:09,973] {logging_mixin.py:115} INFO - [2023-01-06 01:56:09,973] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:56:09,974] {logging_mixin.py:115} INFO - [2023-01-06 01:56:09,973] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:56:09,981] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:56:10,004] {logging_mixin.py:115} INFO - [2023-01-06 01:56:10,004] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:56:10,035] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.007 seconds
[2023-01-06 01:56:40,114] {processor.py:153} INFO - Started process (PID=12053) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:56:40,116] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:56:40,118] {logging_mixin.py:115} INFO - [2023-01-06 01:56:40,118] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:56:41,042] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:56:41,044] {logging_mixin.py:115} INFO - [2023-01-06 01:56:41,043] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:56:41,044] {logging_mixin.py:115} INFO - [2023-01-06 01:56:41,044] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:56:41,053] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:56:41,097] {logging_mixin.py:115} INFO - [2023-01-06 01:56:41,097] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:56:41,143] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.034 seconds
[2023-01-06 01:57:11,234] {processor.py:153} INFO - Started process (PID=12079) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:57:11,236] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:57:11,238] {logging_mixin.py:115} INFO - [2023-01-06 01:57:11,238] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:57:12,221] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:57:12,222] {logging_mixin.py:115} INFO - [2023-01-06 01:57:12,222] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:57:12,223] {logging_mixin.py:115} INFO - [2023-01-06 01:57:12,223] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:57:12,230] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:57:12,253] {logging_mixin.py:115} INFO - [2023-01-06 01:57:12,253] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:57:12,284] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.054 seconds
[2023-01-06 01:57:42,368] {processor.py:153} INFO - Started process (PID=12104) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:57:42,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:57:42,371] {logging_mixin.py:115} INFO - [2023-01-06 01:57:42,371] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:57:43,312] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:57:43,313] {logging_mixin.py:115} INFO - [2023-01-06 01:57:43,313] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:57:43,314] {logging_mixin.py:115} INFO - [2023-01-06 01:57:43,313] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:57:43,321] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:57:43,347] {logging_mixin.py:115} INFO - [2023-01-06 01:57:43,347] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:57:43,378] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.015 seconds
[2023-01-06 01:58:13,448] {processor.py:153} INFO - Started process (PID=12128) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:58:13,450] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:58:13,452] {logging_mixin.py:115} INFO - [2023-01-06 01:58:13,452] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:58:14,396] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:58:14,397] {logging_mixin.py:115} INFO - [2023-01-06 01:58:14,397] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:58:14,398] {logging_mixin.py:115} INFO - [2023-01-06 01:58:14,398] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:58:14,405] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:58:14,430] {logging_mixin.py:115} INFO - [2023-01-06 01:58:14,429] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:58:14,460] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.016 seconds
[2023-01-06 01:58:44,530] {processor.py:153} INFO - Started process (PID=12147) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:58:44,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:58:44,534] {logging_mixin.py:115} INFO - [2023-01-06 01:58:44,534] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:58:45,543] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:58:45,545] {logging_mixin.py:115} INFO - [2023-01-06 01:58:45,545] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:58:45,546] {logging_mixin.py:115} INFO - [2023-01-06 01:58:45,546] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:58:45,555] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:58:45,579] {logging_mixin.py:115} INFO - [2023-01-06 01:58:45,578] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:58:45,608] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.083 seconds
[2023-01-06 01:59:15,686] {processor.py:153} INFO - Started process (PID=12173) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:59:15,688] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:59:15,690] {logging_mixin.py:115} INFO - [2023-01-06 01:59:15,690] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:59:16,607] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:59:16,609] {logging_mixin.py:115} INFO - [2023-01-06 01:59:16,608] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:59:16,609] {logging_mixin.py:115} INFO - [2023-01-06 01:59:16,609] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:59:16,616] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:59:16,639] {logging_mixin.py:115} INFO - [2023-01-06 01:59:16,639] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:59:16,669] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.988 seconds
[2023-01-06 01:59:46,744] {processor.py:153} INFO - Started process (PID=12198) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:59:46,745] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:59:46,747] {logging_mixin.py:115} INFO - [2023-01-06 01:59:46,747] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:59:47,662] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:59:47,663] {logging_mixin.py:115} INFO - [2023-01-06 01:59:47,663] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:59:47,663] {logging_mixin.py:115} INFO - [2023-01-06 01:59:47,663] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:59:47,671] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 01:59:47,696] {logging_mixin.py:115} INFO - [2023-01-06 01:59:47,695] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:59:47,727] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.988 seconds
[2023-01-06 02:00:17,806] {processor.py:153} INFO - Started process (PID=12223) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:00:17,807] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:00:17,809] {logging_mixin.py:115} INFO - [2023-01-06 02:00:17,809] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:00:18,954] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:00:18,956] {logging_mixin.py:115} INFO - [2023-01-06 02:00:18,956] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:00:18,957] {logging_mixin.py:115} INFO - [2023-01-06 02:00:18,956] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:00:18,968] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:00:18,993] {logging_mixin.py:115} INFO - [2023-01-06 02:00:18,993] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:00:19,023] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.222 seconds
[2023-01-06 02:00:49,127] {processor.py:153} INFO - Started process (PID=12241) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:00:49,128] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:00:49,128] {logging_mixin.py:115} INFO - [2023-01-06 02:00:49,128] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:00:50,058] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:00:50,060] {logging_mixin.py:115} INFO - [2023-01-06 02:00:50,059] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:00:50,060] {logging_mixin.py:115} INFO - [2023-01-06 02:00:50,060] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:00:50,067] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:00:50,091] {logging_mixin.py:115} INFO - [2023-01-06 02:00:50,091] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:00:50,122] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.999 seconds
[2023-01-06 02:01:20,168] {processor.py:153} INFO - Started process (PID=12266) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:01:20,169] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:01:20,170] {logging_mixin.py:115} INFO - [2023-01-06 02:01:20,170] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:01:21,091] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:01:21,092] {logging_mixin.py:115} INFO - [2023-01-06 02:01:21,092] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:01:21,093] {logging_mixin.py:115} INFO - [2023-01-06 02:01:21,092] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:01:21,100] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:01:21,124] {logging_mixin.py:115} INFO - [2023-01-06 02:01:21,124] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:01:21,155] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.992 seconds
[2023-01-06 02:01:51,253] {processor.py:153} INFO - Started process (PID=12291) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:01:51,254] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:01:51,255] {logging_mixin.py:115} INFO - [2023-01-06 02:01:51,255] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:01:52,180] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:01:52,182] {logging_mixin.py:115} INFO - [2023-01-06 02:01:52,182] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:01:52,183] {logging_mixin.py:115} INFO - [2023-01-06 02:01:52,182] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:01:52,190] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:01:52,214] {logging_mixin.py:115} INFO - [2023-01-06 02:01:52,214] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:01:52,245] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.997 seconds
[2023-01-06 02:02:22,301] {processor.py:153} INFO - Started process (PID=12315) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:02:22,302] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:02:22,303] {logging_mixin.py:115} INFO - [2023-01-06 02:02:22,303] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:02:23,229] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:02:23,231] {logging_mixin.py:115} INFO - [2023-01-06 02:02:23,231] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:02:23,231] {logging_mixin.py:115} INFO - [2023-01-06 02:02:23,231] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:02:23,238] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:02:23,261] {logging_mixin.py:115} INFO - [2023-01-06 02:02:23,261] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:02:23,295] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.999 seconds
[2023-01-06 02:02:53,334] {processor.py:153} INFO - Started process (PID=12334) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:02:53,335] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:02:53,336] {logging_mixin.py:115} INFO - [2023-01-06 02:02:53,336] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:02:54,250] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:02:54,251] {logging_mixin.py:115} INFO - [2023-01-06 02:02:54,251] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:02:54,251] {logging_mixin.py:115} INFO - [2023-01-06 02:02:54,251] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:02:54,258] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:02:54,281] {logging_mixin.py:115} INFO - [2023-01-06 02:02:54,281] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:02:54,310] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.981 seconds
[2023-01-06 02:03:24,365] {processor.py:153} INFO - Started process (PID=12359) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:03:24,368] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:03:24,369] {logging_mixin.py:115} INFO - [2023-01-06 02:03:24,369] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:03:25,308] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:03:25,310] {logging_mixin.py:115} INFO - [2023-01-06 02:03:25,310] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:03:25,310] {logging_mixin.py:115} INFO - [2023-01-06 02:03:25,310] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:03:25,317] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:03:25,340] {logging_mixin.py:115} INFO - [2023-01-06 02:03:25,340] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:03:25,372] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.013 seconds
[2023-01-06 02:03:55,442] {processor.py:153} INFO - Started process (PID=12384) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:03:55,444] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:03:55,444] {logging_mixin.py:115} INFO - [2023-01-06 02:03:55,444] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:03:56,370] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:03:56,371] {logging_mixin.py:115} INFO - [2023-01-06 02:03:56,371] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:03:56,372] {logging_mixin.py:115} INFO - [2023-01-06 02:03:56,372] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:03:56,379] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:03:56,404] {logging_mixin.py:115} INFO - [2023-01-06 02:03:56,404] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:03:56,437] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.000 seconds
[2023-01-06 02:04:26,522] {processor.py:153} INFO - Started process (PID=12410) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:04:26,523] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:04:26,523] {logging_mixin.py:115} INFO - [2023-01-06 02:04:26,523] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:04:27,513] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:04:27,514] {logging_mixin.py:115} INFO - [2023-01-06 02:04:27,514] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:04:27,515] {logging_mixin.py:115} INFO - [2023-01-06 02:04:27,514] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:04:27,522] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:04:27,546] {logging_mixin.py:115} INFO - [2023-01-06 02:04:27,546] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:04:27,577] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.060 seconds
[2023-01-06 02:04:57,650] {processor.py:153} INFO - Started process (PID=12429) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:04:57,651] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:04:57,652] {logging_mixin.py:115} INFO - [2023-01-06 02:04:57,652] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:04:58,595] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:04:58,596] {logging_mixin.py:115} INFO - [2023-01-06 02:04:58,596] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:04:58,597] {logging_mixin.py:115} INFO - [2023-01-06 02:04:58,596] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:04:58,604] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:04:58,628] {logging_mixin.py:115} INFO - [2023-01-06 02:04:58,628] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:04:58,662] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.017 seconds
[2023-01-06 02:05:28,734] {processor.py:153} INFO - Started process (PID=12452) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:05:28,735] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:05:28,736] {logging_mixin.py:115} INFO - [2023-01-06 02:05:28,736] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:05:29,681] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:05:29,683] {logging_mixin.py:115} INFO - [2023-01-06 02:05:29,683] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:05:29,684] {logging_mixin.py:115} INFO - [2023-01-06 02:05:29,683] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:05:29,691] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:05:29,718] {logging_mixin.py:115} INFO - [2023-01-06 02:05:29,717] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:05:29,752] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.024 seconds
[2023-01-06 02:05:59,824] {processor.py:153} INFO - Started process (PID=12478) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:05:59,825] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:05:59,826] {logging_mixin.py:115} INFO - [2023-01-06 02:05:59,826] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:06:00,816] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:06:00,817] {logging_mixin.py:115} INFO - [2023-01-06 02:06:00,817] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:06:00,818] {logging_mixin.py:115} INFO - [2023-01-06 02:06:00,817] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:06:00,825] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:06:00,852] {logging_mixin.py:115} INFO - [2023-01-06 02:06:00,852] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:06:00,883] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.065 seconds
[2023-01-06 02:06:30,953] {processor.py:153} INFO - Started process (PID=12502) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:06:30,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:06:30,955] {logging_mixin.py:115} INFO - [2023-01-06 02:06:30,955] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:06:31,888] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:06:31,890] {logging_mixin.py:115} INFO - [2023-01-06 02:06:31,890] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:06:31,890] {logging_mixin.py:115} INFO - [2023-01-06 02:06:31,890] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:06:31,897] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:06:31,927] {logging_mixin.py:115} INFO - [2023-01-06 02:06:31,927] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:06:31,964] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.016 seconds
[2023-01-06 02:07:01,997] {processor.py:153} INFO - Started process (PID=12520) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:07:01,998] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:07:01,999] {logging_mixin.py:115} INFO - [2023-01-06 02:07:01,999] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:07:02,894] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:07:02,895] {logging_mixin.py:115} INFO - [2023-01-06 02:07:02,895] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:07:02,896] {logging_mixin.py:115} INFO - [2023-01-06 02:07:02,895] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:07:02,903] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:07:02,925] {logging_mixin.py:115} INFO - [2023-01-06 02:07:02,925] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:07:02,954] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.962 seconds
[2023-01-06 02:07:33,049] {processor.py:153} INFO - Started process (PID=12546) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:07:33,051] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:07:33,051] {logging_mixin.py:115} INFO - [2023-01-06 02:07:33,051] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:07:34,008] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:07:34,010] {logging_mixin.py:115} INFO - [2023-01-06 02:07:34,010] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:07:34,011] {logging_mixin.py:115} INFO - [2023-01-06 02:07:34,010] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:07:34,018] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:07:34,042] {logging_mixin.py:115} INFO - [2023-01-06 02:07:34,042] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:07:34,074] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.030 seconds
[2023-01-06 02:08:04,146] {processor.py:153} INFO - Started process (PID=12571) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:08:04,147] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:08:04,148] {logging_mixin.py:115} INFO - [2023-01-06 02:08:04,147] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:08:05,135] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:08:05,136] {logging_mixin.py:115} INFO - [2023-01-06 02:08:05,136] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:08:05,137] {logging_mixin.py:115} INFO - [2023-01-06 02:08:05,137] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:08:05,146] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:08:05,169] {logging_mixin.py:115} INFO - [2023-01-06 02:08:05,168] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:08:05,199] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.059 seconds
[2023-01-06 02:08:35,289] {processor.py:153} INFO - Started process (PID=12591) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:08:35,290] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:08:35,291] {logging_mixin.py:115} INFO - [2023-01-06 02:08:35,291] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:08:36,260] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:08:36,262] {logging_mixin.py:115} INFO - [2023-01-06 02:08:36,262] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:08:36,262] {logging_mixin.py:115} INFO - [2023-01-06 02:08:36,262] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:08:36,269] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:08:36,292] {logging_mixin.py:115} INFO - [2023-01-06 02:08:36,292] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:08:36,323] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.041 seconds
[2023-01-06 02:09:06,395] {processor.py:153} INFO - Started process (PID=12613) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:09:06,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:09:06,397] {logging_mixin.py:115} INFO - [2023-01-06 02:09:06,397] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:09:07,356] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:09:07,358] {logging_mixin.py:115} INFO - [2023-01-06 02:09:07,358] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:09:07,358] {logging_mixin.py:115} INFO - [2023-01-06 02:09:07,358] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:09:07,365] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:09:07,389] {logging_mixin.py:115} INFO - [2023-01-06 02:09:07,389] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:09:07,418] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.028 seconds
[2023-01-06 02:09:37,490] {processor.py:153} INFO - Started process (PID=12637) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:09:37,492] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:09:37,492] {logging_mixin.py:115} INFO - [2023-01-06 02:09:37,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:09:38,417] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:09:38,418] {logging_mixin.py:115} INFO - [2023-01-06 02:09:38,418] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:09:38,419] {logging_mixin.py:115} INFO - [2023-01-06 02:09:38,418] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:09:38,426] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:09:38,449] {logging_mixin.py:115} INFO - [2023-01-06 02:09:38,449] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:09:38,478] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.993 seconds
[2023-01-06 02:10:08,554] {processor.py:153} INFO - Started process (PID=12662) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:10:08,554] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:10:08,555] {logging_mixin.py:115} INFO - [2023-01-06 02:10:08,555] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:10:09,518] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:10:09,520] {logging_mixin.py:115} INFO - [2023-01-06 02:10:09,520] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:10:09,520] {logging_mixin.py:115} INFO - [2023-01-06 02:10:09,520] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:10:09,527] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:10:09,549] {logging_mixin.py:115} INFO - [2023-01-06 02:10:09,549] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:10:09,578] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.029 seconds
[2023-01-06 02:10:39,667] {processor.py:153} INFO - Started process (PID=12680) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:10:39,669] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:10:39,669] {logging_mixin.py:115} INFO - [2023-01-06 02:10:39,669] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:10:40,606] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:10:40,608] {logging_mixin.py:115} INFO - [2023-01-06 02:10:40,608] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:10:40,608] {logging_mixin.py:115} INFO - [2023-01-06 02:10:40,608] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:10:40,615] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:10:40,639] {logging_mixin.py:115} INFO - [2023-01-06 02:10:40,639] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:10:40,671] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.009 seconds
[2023-01-06 02:11:10,746] {processor.py:153} INFO - Started process (PID=12707) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:11:10,748] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:11:10,748] {logging_mixin.py:115} INFO - [2023-01-06 02:11:10,748] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:11:11,698] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:11:11,699] {logging_mixin.py:115} INFO - [2023-01-06 02:11:11,699] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:11:11,700] {logging_mixin.py:115} INFO - [2023-01-06 02:11:11,700] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:11:11,707] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:11:11,731] {logging_mixin.py:115} INFO - [2023-01-06 02:11:11,730] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:11:11,766] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.025 seconds
[2023-01-06 02:11:41,839] {processor.py:153} INFO - Started process (PID=12732) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:11:41,840] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:11:41,840] {logging_mixin.py:115} INFO - [2023-01-06 02:11:41,840] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:11:42,779] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:11:42,781] {logging_mixin.py:115} INFO - [2023-01-06 02:11:42,781] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:11:42,781] {logging_mixin.py:115} INFO - [2023-01-06 02:11:42,781] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:11:42,788] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:11:42,815] {logging_mixin.py:115} INFO - [2023-01-06 02:11:42,815] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:11:42,845] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.010 seconds
[2023-01-06 02:12:12,910] {processor.py:153} INFO - Started process (PID=12757) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:12:12,910] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:12:12,911] {logging_mixin.py:115} INFO - [2023-01-06 02:12:12,911] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:12:13,914] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:12:13,916] {logging_mixin.py:115} INFO - [2023-01-06 02:12:13,916] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:12:13,916] {logging_mixin.py:115} INFO - [2023-01-06 02:12:13,916] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:12:13,923] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:12:13,947] {logging_mixin.py:115} INFO - [2023-01-06 02:12:13,947] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:12:13,977] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.073 seconds
[2023-01-06 02:12:44,992] {processor.py:153} INFO - Started process (PID=12775) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:12:44,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:12:44,994] {logging_mixin.py:115} INFO - [2023-01-06 02:12:44,994] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:12:45,971] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:12:45,973] {logging_mixin.py:115} INFO - [2023-01-06 02:12:45,973] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:12:45,973] {logging_mixin.py:115} INFO - [2023-01-06 02:12:45,973] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:12:45,980] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:12:46,006] {logging_mixin.py:115} INFO - [2023-01-06 02:12:46,005] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:12:46,036] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.048 seconds
[2023-01-06 02:13:16,114] {processor.py:153} INFO - Started process (PID=12800) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:13:16,115] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:13:16,115] {logging_mixin.py:115} INFO - [2023-01-06 02:13:16,115] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:13:17,051] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:13:17,052] {logging_mixin.py:115} INFO - [2023-01-06 02:13:17,052] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:13:17,053] {logging_mixin.py:115} INFO - [2023-01-06 02:13:17,052] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:13:17,060] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:13:17,083] {logging_mixin.py:115} INFO - [2023-01-06 02:13:17,082] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:13:17,112] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.003 seconds
[2023-01-06 02:13:47,182] {processor.py:153} INFO - Started process (PID=12825) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:13:47,183] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:13:47,184] {logging_mixin.py:115} INFO - [2023-01-06 02:13:47,184] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:13:48,123] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:13:48,124] {logging_mixin.py:115} INFO - [2023-01-06 02:13:48,124] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:13:48,125] {logging_mixin.py:115} INFO - [2023-01-06 02:13:48,124] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:13:48,131] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:13:48,155] {logging_mixin.py:115} INFO - [2023-01-06 02:13:48,154] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:13:48,184] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.007 seconds
[2023-01-06 02:14:18,253] {processor.py:153} INFO - Started process (PID=12849) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:14:18,254] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:14:18,255] {logging_mixin.py:115} INFO - [2023-01-06 02:14:18,254] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:14:19,201] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:14:19,203] {logging_mixin.py:115} INFO - [2023-01-06 02:14:19,203] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:14:19,203] {logging_mixin.py:115} INFO - [2023-01-06 02:14:19,203] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:14:19,210] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:14:19,233] {logging_mixin.py:115} INFO - [2023-01-06 02:14:19,233] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:14:19,263] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.015 seconds
[2023-01-06 02:14:49,308] {processor.py:153} INFO - Started process (PID=12867) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:14:49,313] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:14:49,314] {logging_mixin.py:115} INFO - [2023-01-06 02:14:49,314] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:14:50,248] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:14:50,249] {logging_mixin.py:115} INFO - [2023-01-06 02:14:50,249] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:14:50,250] {logging_mixin.py:115} INFO - [2023-01-06 02:14:50,249] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:14:50,257] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:14:50,279] {logging_mixin.py:115} INFO - [2023-01-06 02:14:50,279] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:14:50,308] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.005 seconds
[2023-01-06 02:15:20,398] {processor.py:153} INFO - Started process (PID=12893) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:15:20,398] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:15:20,399] {logging_mixin.py:115} INFO - [2023-01-06 02:15:20,399] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:15:21,363] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:15:21,364] {logging_mixin.py:115} INFO - [2023-01-06 02:15:21,364] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:15:21,364] {logging_mixin.py:115} INFO - [2023-01-06 02:15:21,364] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:15:21,371] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:15:21,397] {logging_mixin.py:115} INFO - [2023-01-06 02:15:21,396] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:15:21,427] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.034 seconds
[2023-01-06 02:15:51,497] {processor.py:153} INFO - Started process (PID=12918) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:15:51,499] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:15:51,500] {logging_mixin.py:115} INFO - [2023-01-06 02:15:51,499] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:15:52,417] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:15:52,419] {logging_mixin.py:115} INFO - [2023-01-06 02:15:52,418] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:15:52,419] {logging_mixin.py:115} INFO - [2023-01-06 02:15:52,419] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:15:52,426] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:15:52,450] {logging_mixin.py:115} INFO - [2023-01-06 02:15:52,448] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:15:52,478] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.985 seconds
[2023-01-06 02:16:22,577] {processor.py:153} INFO - Started process (PID=12944) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:16:22,578] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:16:22,579] {logging_mixin.py:115} INFO - [2023-01-06 02:16:22,579] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:16:23,561] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:16:23,562] {logging_mixin.py:115} INFO - [2023-01-06 02:16:23,562] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:16:23,563] {logging_mixin.py:115} INFO - [2023-01-06 02:16:23,563] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:16:23,570] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:16:23,596] {logging_mixin.py:115} INFO - [2023-01-06 02:16:23,594] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:16:23,626] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.055 seconds
[2023-01-06 02:16:53,697] {processor.py:153} INFO - Started process (PID=12962) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:16:53,698] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:16:53,699] {logging_mixin.py:115} INFO - [2023-01-06 02:16:53,698] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:16:54,620] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:16:54,621] {logging_mixin.py:115} INFO - [2023-01-06 02:16:54,621] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:16:54,622] {logging_mixin.py:115} INFO - [2023-01-06 02:16:54,622] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:16:54,634] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:16:54,670] {logging_mixin.py:115} INFO - [2023-01-06 02:16:54,667] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:16:54,707] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.015 seconds
[2023-01-06 02:17:24,783] {processor.py:153} INFO - Started process (PID=12988) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:17:24,783] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:17:24,784] {logging_mixin.py:115} INFO - [2023-01-06 02:17:24,784] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:17:25,731] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:17:25,733] {logging_mixin.py:115} INFO - [2023-01-06 02:17:25,733] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:17:25,734] {logging_mixin.py:115} INFO - [2023-01-06 02:17:25,733] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:17:25,744] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:17:25,780] {logging_mixin.py:115} INFO - [2023-01-06 02:17:25,778] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:17:25,826] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.049 seconds
[2023-01-06 02:17:55,906] {processor.py:153} INFO - Started process (PID=13015) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:17:55,907] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:17:55,907] {logging_mixin.py:115} INFO - [2023-01-06 02:17:55,907] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:17:56,899] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:17:56,900] {logging_mixin.py:115} INFO - [2023-01-06 02:17:56,900] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:17:56,901] {logging_mixin.py:115} INFO - [2023-01-06 02:17:56,901] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:17:56,908] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:17:56,932] {logging_mixin.py:115} INFO - [2023-01-06 02:17:56,931] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:17:56,960] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.059 seconds
[2023-01-06 02:18:27,036] {processor.py:153} INFO - Started process (PID=13040) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:18:27,037] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:18:27,038] {logging_mixin.py:115} INFO - [2023-01-06 02:18:27,038] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:18:28,014] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:18:28,016] {logging_mixin.py:115} INFO - [2023-01-06 02:18:28,016] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:18:28,016] {logging_mixin.py:115} INFO - [2023-01-06 02:18:28,016] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:18:28,023] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:18:28,053] {logging_mixin.py:115} INFO - [2023-01-06 02:18:28,051] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:18:28,075] {logging_mixin.py:115} INFO - [2023-01-06 02:18:28,075] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 02:18:28,085] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.054 seconds
[2023-01-06 02:18:58,160] {processor.py:153} INFO - Started process (PID=13058) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:18:58,161] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:18:58,162] {logging_mixin.py:115} INFO - [2023-01-06 02:18:58,162] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:18:59,086] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:18:59,088] {logging_mixin.py:115} INFO - [2023-01-06 02:18:59,087] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:18:59,088] {logging_mixin.py:115} INFO - [2023-01-06 02:18:59,088] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:18:59,095] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:18:59,120] {logging_mixin.py:115} INFO - [2023-01-06 02:18:59,118] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:18:59,140] {logging_mixin.py:115} INFO - [2023-01-06 02:18:59,140] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 02:18:59,150] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.995 seconds
[2023-01-06 02:19:29,223] {processor.py:153} INFO - Started process (PID=13082) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:19:29,226] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:19:29,226] {logging_mixin.py:115} INFO - [2023-01-06 02:19:29,226] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:19:30,138] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:19:30,139] {logging_mixin.py:115} INFO - [2023-01-06 02:19:30,139] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:19:30,140] {logging_mixin.py:115} INFO - [2023-01-06 02:19:30,139] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:19:30,147] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 02:19:30,172] {logging_mixin.py:115} INFO - [2023-01-06 02:19:30,170] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:19:30,193] {logging_mixin.py:115} INFO - [2023-01-06 02:19:30,193] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 02:19:30,203] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.985 seconds
[2023-01-06 21:30:25,399] {processor.py:153} INFO - Started process (PID=33) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:30:25,402] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:30:25,402] {logging_mixin.py:115} INFO - [2023-01-06 21:30:25,402] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:30:28,969] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:30:28,971] {logging_mixin.py:115} INFO - [2023-01-06 21:30:28,971] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:30:28,972] {logging_mixin.py:115} INFO - [2023-01-06 21:30:28,971] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:30:28,995] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:30:29,031] {logging_mixin.py:115} INFO - [2023-01-06 21:30:29,031] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:30:29,065] {logging_mixin.py:115} INFO - [2023-01-06 21:30:29,065] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:30:29,256] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 3.862 seconds
[2023-01-06 21:30:59,328] {processor.py:153} INFO - Started process (PID=62) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:30:59,329] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:30:59,330] {logging_mixin.py:115} INFO - [2023-01-06 21:30:59,330] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:31:00,277] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:31:00,278] {logging_mixin.py:115} INFO - [2023-01-06 21:31:00,278] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:31:00,278] {logging_mixin.py:115} INFO - [2023-01-06 21:31:00,278] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:31:00,285] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:31:00,306] {logging_mixin.py:115} INFO - [2023-01-06 21:31:00,306] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:31:00,325] {logging_mixin.py:115} INFO - [2023-01-06 21:31:00,325] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:31:00,334] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.010 seconds
[2023-01-06 21:31:30,403] {processor.py:153} INFO - Started process (PID=85) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:31:30,403] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:31:30,404] {logging_mixin.py:115} INFO - [2023-01-06 21:31:30,404] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:31:31,569] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:31:31,571] {logging_mixin.py:115} INFO - [2023-01-06 21:31:31,571] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:31:31,571] {logging_mixin.py:115} INFO - [2023-01-06 21:31:31,571] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:31:31,578] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:31:31,599] {logging_mixin.py:115} INFO - [2023-01-06 21:31:31,598] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:31:31,619] {logging_mixin.py:115} INFO - [2023-01-06 21:31:31,618] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:31:31,627] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.230 seconds
[2023-01-06 21:32:01,659] {processor.py:153} INFO - Started process (PID=103) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:32:01,665] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:32:01,666] {logging_mixin.py:115} INFO - [2023-01-06 21:32:01,666] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:32:02,622] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:32:02,623] {logging_mixin.py:115} INFO - [2023-01-06 21:32:02,623] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:32:02,624] {logging_mixin.py:115} INFO - [2023-01-06 21:32:02,623] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:32:02,630] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:32:02,651] {logging_mixin.py:115} INFO - [2023-01-06 21:32:02,651] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:32:02,671] {logging_mixin.py:115} INFO - [2023-01-06 21:32:02,671] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:32:02,680] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.025 seconds
[2023-01-06 21:32:32,756] {processor.py:153} INFO - Started process (PID=129) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:32:32,759] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:32:32,760] {logging_mixin.py:115} INFO - [2023-01-06 21:32:32,759] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:32:33,686] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:32:33,689] {logging_mixin.py:115} INFO - [2023-01-06 21:32:33,689] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:32:33,691] {logging_mixin.py:115} INFO - [2023-01-06 21:32:33,690] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:32:33,702] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:32:33,733] {logging_mixin.py:115} INFO - [2023-01-06 21:32:33,733] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:32:33,764] {logging_mixin.py:115} INFO - [2023-01-06 21:32:33,763] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:32:33,775] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.024 seconds
[2023-01-06 21:33:03,871] {processor.py:153} INFO - Started process (PID=154) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:33:03,872] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:33:03,872] {logging_mixin.py:115} INFO - [2023-01-06 21:33:03,872] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:33:04,758] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:33:04,759] {logging_mixin.py:115} INFO - [2023-01-06 21:33:04,759] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:33:04,760] {logging_mixin.py:115} INFO - [2023-01-06 21:33:04,759] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:33:04,766] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:33:04,794] {logging_mixin.py:115} INFO - [2023-01-06 21:33:04,793] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:33:04,822] {logging_mixin.py:115} INFO - [2023-01-06 21:33:04,822] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:33:04,831] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.964 seconds
[2023-01-06 21:33:34,911] {processor.py:153} INFO - Started process (PID=179) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:33:34,913] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:33:34,913] {logging_mixin.py:115} INFO - [2023-01-06 21:33:34,913] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:33:35,861] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:33:35,862] {logging_mixin.py:115} INFO - [2023-01-06 21:33:35,862] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:33:35,862] {logging_mixin.py:115} INFO - [2023-01-06 21:33:35,862] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:33:35,869] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:33:35,890] {logging_mixin.py:115} INFO - [2023-01-06 21:33:35,890] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:33:35,910] {logging_mixin.py:115} INFO - [2023-01-06 21:33:35,910] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:33:35,919] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.012 seconds
[2023-01-06 21:34:05,988] {processor.py:153} INFO - Started process (PID=197) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:34:05,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:34:05,990] {logging_mixin.py:115} INFO - [2023-01-06 21:34:05,990] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:34:06,915] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:34:06,917] {logging_mixin.py:115} INFO - [2023-01-06 21:34:06,916] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:34:06,917] {logging_mixin.py:115} INFO - [2023-01-06 21:34:06,917] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:34:06,928] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:34:06,958] {logging_mixin.py:115} INFO - [2023-01-06 21:34:06,958] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:34:06,988] {logging_mixin.py:115} INFO - [2023-01-06 21:34:06,988] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:34:07,000] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.017 seconds
[2023-01-06 21:34:37,097] {processor.py:153} INFO - Started process (PID=222) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:34:37,098] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:34:37,099] {logging_mixin.py:115} INFO - [2023-01-06 21:34:37,098] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:34:37,966] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:34:37,968] {logging_mixin.py:115} INFO - [2023-01-06 21:34:37,968] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:34:37,968] {logging_mixin.py:115} INFO - [2023-01-06 21:34:37,968] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:34:37,975] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:34:37,997] {logging_mixin.py:115} INFO - [2023-01-06 21:34:37,997] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:34:38,017] {logging_mixin.py:115} INFO - [2023-01-06 21:34:38,017] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:34:38,026] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.933 seconds
[2023-01-06 21:35:08,087] {processor.py:153} INFO - Started process (PID=247) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:35:08,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:35:08,089] {logging_mixin.py:115} INFO - [2023-01-06 21:35:08,089] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:35:08,984] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:35:08,985] {logging_mixin.py:115} INFO - [2023-01-06 21:35:08,985] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:35:08,986] {logging_mixin.py:115} INFO - [2023-01-06 21:35:08,985] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:35:08,992] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:35:09,013] {logging_mixin.py:115} INFO - [2023-01-06 21:35:09,013] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:35:09,033] {logging_mixin.py:115} INFO - [2023-01-06 21:35:09,033] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:35:09,042] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.959 seconds
[2023-01-06 21:35:39,117] {processor.py:153} INFO - Started process (PID=264) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:35:39,118] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:35:39,119] {logging_mixin.py:115} INFO - [2023-01-06 21:35:39,119] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:35:40,560] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:35:40,561] {logging_mixin.py:115} INFO - [2023-01-06 21:35:40,561] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:35:40,562] {logging_mixin.py:115} INFO - [2023-01-06 21:35:40,562] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:35:40,575] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:35:40,604] {logging_mixin.py:115} INFO - [2023-01-06 21:35:40,603] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:35:40,634] {logging_mixin.py:115} INFO - [2023-01-06 21:35:40,633] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:35:40,646] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.534 seconds
[2023-01-06 21:36:10,717] {processor.py:153} INFO - Started process (PID=288) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:36:10,718] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:36:10,719] {logging_mixin.py:115} INFO - [2023-01-06 21:36:10,718] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:36:11,650] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:36:11,651] {logging_mixin.py:115} INFO - [2023-01-06 21:36:11,651] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:36:11,652] {logging_mixin.py:115} INFO - [2023-01-06 21:36:11,651] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:36:11,658] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:36:11,680] {logging_mixin.py:115} INFO - [2023-01-06 21:36:11,680] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:36:11,700] {logging_mixin.py:115} INFO - [2023-01-06 21:36:11,700] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:36:11,709] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.997 seconds
[2023-01-06 21:36:41,789] {processor.py:153} INFO - Started process (PID=315) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:36:41,789] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:36:41,790] {logging_mixin.py:115} INFO - [2023-01-06 21:36:41,790] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:36:42,668] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:36:42,670] {logging_mixin.py:115} INFO - [2023-01-06 21:36:42,670] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:36:42,670] {logging_mixin.py:115} INFO - [2023-01-06 21:36:42,670] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:36:42,677] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:36:42,698] {logging_mixin.py:115} INFO - [2023-01-06 21:36:42,698] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:36:42,718] {logging_mixin.py:115} INFO - [2023-01-06 21:36:42,718] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:36:42,728] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.944 seconds
[2023-01-06 21:37:12,791] {processor.py:153} INFO - Started process (PID=342) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:37:12,792] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:37:12,792] {logging_mixin.py:115} INFO - [2023-01-06 21:37:12,792] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:37:13,793] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:37:13,795] {logging_mixin.py:115} INFO - [2023-01-06 21:37:13,795] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:37:13,796] {logging_mixin.py:115} INFO - [2023-01-06 21:37:13,795] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:37:13,806] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:37:13,830] {logging_mixin.py:115} INFO - [2023-01-06 21:37:13,830] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:37:13,851] {logging_mixin.py:115} INFO - [2023-01-06 21:37:13,851] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:37:13,860] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.074 seconds
[2023-01-06 21:37:43,953] {processor.py:153} INFO - Started process (PID=358) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:37:43,955] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:37:43,956] {logging_mixin.py:115} INFO - [2023-01-06 21:37:43,955] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:37:44,971] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:37:44,973] {logging_mixin.py:115} INFO - [2023-01-06 21:37:44,972] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:37:44,973] {logging_mixin.py:115} INFO - [2023-01-06 21:37:44,973] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:37:44,984] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:37:45,015] {logging_mixin.py:115} INFO - [2023-01-06 21:37:45,015] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:37:45,046] {logging_mixin.py:115} INFO - [2023-01-06 21:37:45,046] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:37:45,067] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.119 seconds
[2023-01-06 21:38:15,209] {processor.py:153} INFO - Started process (PID=383) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:38:15,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:38:15,211] {logging_mixin.py:115} INFO - [2023-01-06 21:38:15,211] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:38:16,090] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:38:16,091] {logging_mixin.py:115} INFO - [2023-01-06 21:38:16,091] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:38:16,092] {logging_mixin.py:115} INFO - [2023-01-06 21:38:16,091] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:38:16,098] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:38:16,119] {logging_mixin.py:115} INFO - [2023-01-06 21:38:16,119] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:38:16,139] {logging_mixin.py:115} INFO - [2023-01-06 21:38:16,139] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:38:16,149] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.944 seconds
[2023-01-06 21:38:46,218] {processor.py:153} INFO - Started process (PID=409) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:38:46,219] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:38:46,220] {logging_mixin.py:115} INFO - [2023-01-06 21:38:46,219] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:38:47,424] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:38:47,425] {logging_mixin.py:115} INFO - [2023-01-06 21:38:47,425] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:38:47,426] {logging_mixin.py:115} INFO - [2023-01-06 21:38:47,426] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:38:47,436] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:38:47,464] {logging_mixin.py:115} INFO - [2023-01-06 21:38:47,463] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:38:47,485] {logging_mixin.py:115} INFO - [2023-01-06 21:38:47,485] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:38:47,495] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.283 seconds
[2023-01-06 21:39:17,562] {processor.py:153} INFO - Started process (PID=435) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:39:17,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:39:17,563] {logging_mixin.py:115} INFO - [2023-01-06 21:39:17,563] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:39:18,485] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:39:18,486] {logging_mixin.py:115} INFO - [2023-01-06 21:39:18,486] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:39:18,487] {logging_mixin.py:115} INFO - [2023-01-06 21:39:18,486] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:39:18,493] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:39:18,515] {logging_mixin.py:115} INFO - [2023-01-06 21:39:18,514] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:39:18,535] {logging_mixin.py:115} INFO - [2023-01-06 21:39:18,535] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:39:18,544] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.987 seconds
[2023-01-06 21:39:48,631] {processor.py:153} INFO - Started process (PID=452) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:39:48,632] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:39:48,633] {logging_mixin.py:115} INFO - [2023-01-06 21:39:48,633] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:39:49,776] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:39:49,778] {logging_mixin.py:115} INFO - [2023-01-06 21:39:49,778] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:39:49,778] {logging_mixin.py:115} INFO - [2023-01-06 21:39:49,778] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:39:49,790] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:39:49,815] {logging_mixin.py:115} INFO - [2023-01-06 21:39:49,814] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:39:49,835] {logging_mixin.py:115} INFO - [2023-01-06 21:39:49,835] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:39:49,844] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.218 seconds
[2023-01-06 21:40:19,882] {processor.py:153} INFO - Started process (PID=478) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:40:19,883] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:40:19,884] {logging_mixin.py:115} INFO - [2023-01-06 21:40:19,884] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:40:20,864] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:40:20,865] {logging_mixin.py:115} INFO - [2023-01-06 21:40:20,865] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:40:20,865] {logging_mixin.py:115} INFO - [2023-01-06 21:40:20,865] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:40:20,872] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:40:20,895] {logging_mixin.py:115} INFO - [2023-01-06 21:40:20,895] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:40:20,920] {logging_mixin.py:115} INFO - [2023-01-06 21:40:20,920] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:40:20,929] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.052 seconds
[2023-01-06 21:40:50,998] {processor.py:153} INFO - Started process (PID=503) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:40:50,999] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:40:51,000] {logging_mixin.py:115} INFO - [2023-01-06 21:40:50,999] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:40:51,941] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:40:51,942] {logging_mixin.py:115} INFO - [2023-01-06 21:40:51,942] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:40:51,943] {logging_mixin.py:115} INFO - [2023-01-06 21:40:51,942] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:40:51,950] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:40:51,971] {logging_mixin.py:115} INFO - [2023-01-06 21:40:51,971] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:40:51,991] {logging_mixin.py:115} INFO - [2023-01-06 21:40:51,991] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:40:52,000] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.006 seconds
[2023-01-06 21:41:22,074] {processor.py:153} INFO - Started process (PID=529) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:41:22,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:41:22,076] {logging_mixin.py:115} INFO - [2023-01-06 21:41:22,076] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:41:22,962] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:41:22,964] {logging_mixin.py:115} INFO - [2023-01-06 21:41:22,964] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:41:22,964] {logging_mixin.py:115} INFO - [2023-01-06 21:41:22,964] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:41:22,971] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:41:22,992] {logging_mixin.py:115} INFO - [2023-01-06 21:41:22,992] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:41:23,012] {logging_mixin.py:115} INFO - [2023-01-06 21:41:23,012] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:41:23,022] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.952 seconds
[2023-01-06 21:41:53,094] {processor.py:153} INFO - Started process (PID=549) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:41:53,102] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:41:53,103] {logging_mixin.py:115} INFO - [2023-01-06 21:41:53,102] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:41:54,296] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:41:54,297] {logging_mixin.py:115} INFO - [2023-01-06 21:41:54,297] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:41:54,298] {logging_mixin.py:115} INFO - [2023-01-06 21:41:54,298] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:41:54,306] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:41:54,329] {logging_mixin.py:115} INFO - [2023-01-06 21:41:54,328] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:41:54,349] {logging_mixin.py:115} INFO - [2023-01-06 21:41:54,349] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:41:54,359] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.270 seconds
[2023-01-06 21:42:24,394] {processor.py:153} INFO - Started process (PID=574) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:42:24,394] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:42:24,395] {logging_mixin.py:115} INFO - [2023-01-06 21:42:24,395] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:42:25,303] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:42:25,304] {logging_mixin.py:115} INFO - [2023-01-06 21:42:25,304] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:42:25,305] {logging_mixin.py:115} INFO - [2023-01-06 21:42:25,304] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:42:25,311] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:42:25,333] {logging_mixin.py:115} INFO - [2023-01-06 21:42:25,332] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:42:25,353] {logging_mixin.py:115} INFO - [2023-01-06 21:42:25,353] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:42:25,362] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.973 seconds
[2023-01-06 21:42:55,428] {processor.py:153} INFO - Started process (PID=600) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:42:55,430] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:42:55,430] {logging_mixin.py:115} INFO - [2023-01-06 21:42:55,430] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:42:56,303] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:42:56,304] {logging_mixin.py:115} INFO - [2023-01-06 21:42:56,304] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:42:56,305] {logging_mixin.py:115} INFO - [2023-01-06 21:42:56,305] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:42:56,312] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:42:56,333] {logging_mixin.py:115} INFO - [2023-01-06 21:42:56,333] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:42:56,353] {logging_mixin.py:115} INFO - [2023-01-06 21:42:56,353] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:42:56,362] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.938 seconds
[2023-01-06 21:43:26,435] {processor.py:153} INFO - Started process (PID=627) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:43:26,435] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:43:26,436] {logging_mixin.py:115} INFO - [2023-01-06 21:43:26,436] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:43:27,458] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:43:27,459] {logging_mixin.py:115} INFO - [2023-01-06 21:43:27,459] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:43:27,459] {logging_mixin.py:115} INFO - [2023-01-06 21:43:27,459] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:43:27,466] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:43:27,487] {logging_mixin.py:115} INFO - [2023-01-06 21:43:27,487] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:43:27,507] {logging_mixin.py:115} INFO - [2023-01-06 21:43:27,507] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:43:27,516] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.089 seconds
[2023-01-06 21:43:57,582] {processor.py:153} INFO - Started process (PID=645) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:43:57,583] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:43:57,584] {logging_mixin.py:115} INFO - [2023-01-06 21:43:57,584] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:43:58,726] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:43:58,727] {logging_mixin.py:115} INFO - [2023-01-06 21:43:58,727] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:43:58,728] {logging_mixin.py:115} INFO - [2023-01-06 21:43:58,727] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:43:58,735] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:43:58,758] {logging_mixin.py:115} INFO - [2023-01-06 21:43:58,757] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:43:58,783] {logging_mixin.py:115} INFO - [2023-01-06 21:43:58,783] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:43:58,792] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.215 seconds
[2023-01-06 21:44:28,851] {processor.py:153} INFO - Started process (PID=671) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:44:28,851] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:44:28,852] {logging_mixin.py:115} INFO - [2023-01-06 21:44:28,852] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:44:29,742] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:44:29,743] {logging_mixin.py:115} INFO - [2023-01-06 21:44:29,743] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:44:29,744] {logging_mixin.py:115} INFO - [2023-01-06 21:44:29,743] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:44:29,750] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:44:29,773] {logging_mixin.py:115} INFO - [2023-01-06 21:44:29,772] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:44:29,793] {logging_mixin.py:115} INFO - [2023-01-06 21:44:29,792] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:44:29,802] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.955 seconds
[2023-01-06 21:44:59,870] {processor.py:153} INFO - Started process (PID=696) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:44:59,872] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:44:59,872] {logging_mixin.py:115} INFO - [2023-01-06 21:44:59,872] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:45:00,796] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:45:00,797] {logging_mixin.py:115} INFO - [2023-01-06 21:45:00,797] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:45:00,797] {logging_mixin.py:115} INFO - [2023-01-06 21:45:00,797] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:45:00,804] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:45:00,825] {logging_mixin.py:115} INFO - [2023-01-06 21:45:00,825] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:45:00,845] {logging_mixin.py:115} INFO - [2023-01-06 21:45:00,845] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:45:00,854] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.988 seconds
[2023-01-06 21:45:30,951] {processor.py:153} INFO - Started process (PID=722) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:45:30,953] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:45:30,953] {logging_mixin.py:115} INFO - [2023-01-06 21:45:30,953] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:45:31,879] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:45:31,880] {logging_mixin.py:115} INFO - [2023-01-06 21:45:31,880] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:45:31,880] {logging_mixin.py:115} INFO - [2023-01-06 21:45:31,880] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:45:31,887] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:45:31,908] {logging_mixin.py:115} INFO - [2023-01-06 21:45:31,907] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:45:31,928] {logging_mixin.py:115} INFO - [2023-01-06 21:45:31,927] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:45:31,936] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.989 seconds
[2023-01-06 21:46:02,005] {processor.py:153} INFO - Started process (PID=740) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:46:02,006] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:46:02,007] {logging_mixin.py:115} INFO - [2023-01-06 21:46:02,007] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:46:03,138] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:46:03,139] {logging_mixin.py:115} INFO - [2023-01-06 21:46:03,139] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:46:03,139] {logging_mixin.py:115} INFO - [2023-01-06 21:46:03,139] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:46:03,146] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:46:03,171] {logging_mixin.py:115} INFO - [2023-01-06 21:46:03,170] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:46:03,191] {logging_mixin.py:115} INFO - [2023-01-06 21:46:03,191] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:46:03,200] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.201 seconds
[2023-01-06 21:46:33,274] {processor.py:153} INFO - Started process (PID=766) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:46:33,275] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:46:33,275] {logging_mixin.py:115} INFO - [2023-01-06 21:46:33,275] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:46:34,141] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:46:34,143] {logging_mixin.py:115} INFO - [2023-01-06 21:46:34,142] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:46:34,143] {logging_mixin.py:115} INFO - [2023-01-06 21:46:34,143] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:46:34,150] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:46:34,171] {logging_mixin.py:115} INFO - [2023-01-06 21:46:34,171] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:46:34,191] {logging_mixin.py:115} INFO - [2023-01-06 21:46:34,191] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:46:34,200] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.931 seconds
[2023-01-06 21:47:04,268] {processor.py:153} INFO - Started process (PID=792) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:47:04,269] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:47:04,269] {logging_mixin.py:115} INFO - [2023-01-06 21:47:04,269] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:47:05,149] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:47:05,151] {logging_mixin.py:115} INFO - [2023-01-06 21:47:05,151] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:47:05,151] {logging_mixin.py:115} INFO - [2023-01-06 21:47:05,151] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:47:05,158] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:47:05,179] {logging_mixin.py:115} INFO - [2023-01-06 21:47:05,179] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:47:05,199] {logging_mixin.py:115} INFO - [2023-01-06 21:47:05,199] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:47:05,208] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.944 seconds
[2023-01-06 21:47:35,279] {processor.py:153} INFO - Started process (PID=818) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:47:35,280] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:47:35,281] {logging_mixin.py:115} INFO - [2023-01-06 21:47:35,281] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:47:36,302] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:47:36,303] {logging_mixin.py:115} INFO - [2023-01-06 21:47:36,303] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:47:36,304] {logging_mixin.py:115} INFO - [2023-01-06 21:47:36,304] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:47:36,311] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:47:36,332] {logging_mixin.py:115} INFO - [2023-01-06 21:47:36,332] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:47:36,352] {logging_mixin.py:115} INFO - [2023-01-06 21:47:36,352] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:47:36,362] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.087 seconds
[2023-01-06 21:48:06,431] {processor.py:153} INFO - Started process (PID=844) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:48:06,432] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:48:06,433] {logging_mixin.py:115} INFO - [2023-01-06 21:48:06,433] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:48:07,518] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:48:07,520] {logging_mixin.py:115} INFO - [2023-01-06 21:48:07,519] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:48:07,520] {logging_mixin.py:115} INFO - [2023-01-06 21:48:07,520] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:48:07,531] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:48:07,555] {logging_mixin.py:115} INFO - [2023-01-06 21:48:07,555] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:48:07,576] {logging_mixin.py:115} INFO - [2023-01-06 21:48:07,576] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:48:07,585] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.160 seconds
[2023-01-06 21:48:37,652] {processor.py:153} INFO - Started process (PID=862) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:48:37,653] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:48:37,653] {logging_mixin.py:115} INFO - [2023-01-06 21:48:37,653] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:48:38,543] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:48:38,544] {logging_mixin.py:115} INFO - [2023-01-06 21:48:38,544] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:48:38,544] {logging_mixin.py:115} INFO - [2023-01-06 21:48:38,544] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:48:38,551] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:48:38,572] {logging_mixin.py:115} INFO - [2023-01-06 21:48:38,572] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:48:38,593] {logging_mixin.py:115} INFO - [2023-01-06 21:48:38,593] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:48:38,602] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.955 seconds
[2023-01-06 21:49:08,672] {processor.py:153} INFO - Started process (PID=886) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:49:08,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:49:08,673] {logging_mixin.py:115} INFO - [2023-01-06 21:49:08,673] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:49:09,532] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:49:09,534] {logging_mixin.py:115} INFO - [2023-01-06 21:49:09,534] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:49:09,534] {logging_mixin.py:115} INFO - [2023-01-06 21:49:09,534] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:49:09,541] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:49:09,562] {logging_mixin.py:115} INFO - [2023-01-06 21:49:09,562] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:49:09,582] {logging_mixin.py:115} INFO - [2023-01-06 21:49:09,582] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:49:09,592] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.924 seconds
[2023-01-06 21:49:39,660] {processor.py:153} INFO - Started process (PID=911) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:49:39,662] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:49:39,663] {logging_mixin.py:115} INFO - [2023-01-06 21:49:39,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:49:40,573] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:49:40,574] {logging_mixin.py:115} INFO - [2023-01-06 21:49:40,574] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:49:40,575] {logging_mixin.py:115} INFO - [2023-01-06 21:49:40,574] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:49:40,581] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:49:40,602] {logging_mixin.py:115} INFO - [2023-01-06 21:49:40,602] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:49:40,622] {logging_mixin.py:115} INFO - [2023-01-06 21:49:40,622] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:49:40,632] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.976 seconds
[2023-01-06 21:50:10,707] {processor.py:153} INFO - Started process (PID=936) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:50:10,709] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:50:10,709] {logging_mixin.py:115} INFO - [2023-01-06 21:50:10,709] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:50:11,766] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:50:11,767] {logging_mixin.py:115} INFO - [2023-01-06 21:50:11,767] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:50:11,767] {logging_mixin.py:115} INFO - [2023-01-06 21:50:11,767] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:50:11,774] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:50:11,804] {logging_mixin.py:115} INFO - [2023-01-06 21:50:11,803] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:50:11,828] {logging_mixin.py:115} INFO - [2023-01-06 21:50:11,828] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:50:11,838] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.137 seconds
[2023-01-06 21:50:41,908] {processor.py:153} INFO - Started process (PID=954) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:50:41,909] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:50:41,909] {logging_mixin.py:115} INFO - [2023-01-06 21:50:41,909] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:50:42,803] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:50:42,804] {logging_mixin.py:115} INFO - [2023-01-06 21:50:42,804] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:50:42,805] {logging_mixin.py:115} INFO - [2023-01-06 21:50:42,805] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:50:42,812] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:50:42,846] {logging_mixin.py:115} INFO - [2023-01-06 21:50:42,846] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:50:42,875] {logging_mixin.py:115} INFO - [2023-01-06 21:50:42,875] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:50:42,888] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.984 seconds
[2023-01-06 21:51:12,973] {processor.py:153} INFO - Started process (PID=978) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:51:12,975] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:51:12,976] {logging_mixin.py:115} INFO - [2023-01-06 21:51:12,976] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:51:13,909] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:51:13,910] {logging_mixin.py:115} INFO - [2023-01-06 21:51:13,910] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:51:13,910] {logging_mixin.py:115} INFO - [2023-01-06 21:51:13,910] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:51:13,917] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:51:13,938] {logging_mixin.py:115} INFO - [2023-01-06 21:51:13,938] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:51:13,958] {logging_mixin.py:115} INFO - [2023-01-06 21:51:13,958] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:51:13,968] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.999 seconds
[2023-01-06 21:51:44,052] {processor.py:153} INFO - Started process (PID=1003) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:51:44,054] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:51:44,055] {logging_mixin.py:115} INFO - [2023-01-06 21:51:44,055] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:51:45,022] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:51:45,024] {logging_mixin.py:115} INFO - [2023-01-06 21:51:45,023] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:51:45,024] {logging_mixin.py:115} INFO - [2023-01-06 21:51:45,024] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:51:45,035] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:51:45,059] {logging_mixin.py:115} INFO - [2023-01-06 21:51:45,059] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:51:45,080] {logging_mixin.py:115} INFO - [2023-01-06 21:51:45,079] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:51:45,089] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.041 seconds
[2023-01-06 21:52:15,144] {processor.py:153} INFO - Started process (PID=1029) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:52:15,145] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:52:15,146] {logging_mixin.py:115} INFO - [2023-01-06 21:52:15,146] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:52:16,077] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:52:16,078] {logging_mixin.py:115} INFO - [2023-01-06 21:52:16,078] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:52:16,078] {logging_mixin.py:115} INFO - [2023-01-06 21:52:16,078] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:52:16,085] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:52:16,106] {logging_mixin.py:115} INFO - [2023-01-06 21:52:16,106] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:52:16,126] {logging_mixin.py:115} INFO - [2023-01-06 21:52:16,126] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:52:16,135] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-06 21:52:46,222] {processor.py:153} INFO - Started process (PID=1046) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:52:46,224] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:52:46,224] {logging_mixin.py:115} INFO - [2023-01-06 21:52:46,224] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:52:47,416] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:52:47,417] {logging_mixin.py:115} INFO - [2023-01-06 21:52:47,417] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:52:47,418] {logging_mixin.py:115} INFO - [2023-01-06 21:52:47,417] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:52:47,424] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:52:47,445] {logging_mixin.py:115} INFO - [2023-01-06 21:52:47,445] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:52:47,465] {logging_mixin.py:115} INFO - [2023-01-06 21:52:47,465] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:52:47,475] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.258 seconds
[2023-01-06 21:53:17,541] {processor.py:153} INFO - Started process (PID=1074) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:53:17,542] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:53:17,543] {logging_mixin.py:115} INFO - [2023-01-06 21:53:17,543] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:53:18,675] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:53:18,676] {logging_mixin.py:115} INFO - [2023-01-06 21:53:18,676] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:53:18,676] {logging_mixin.py:115} INFO - [2023-01-06 21:53:18,676] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:53:18,683] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:53:18,705] {logging_mixin.py:115} INFO - [2023-01-06 21:53:18,704] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:53:18,725] {logging_mixin.py:115} INFO - [2023-01-06 21:53:18,725] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:53:18,734] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.198 seconds
[2023-01-06 21:53:48,804] {processor.py:153} INFO - Started process (PID=1100) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:53:48,805] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:53:48,805] {logging_mixin.py:115} INFO - [2023-01-06 21:53:48,805] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:53:49,669] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:53:49,671] {logging_mixin.py:115} INFO - [2023-01-06 21:53:49,671] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:53:49,671] {logging_mixin.py:115} INFO - [2023-01-06 21:53:49,671] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:53:49,678] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:53:49,700] {logging_mixin.py:115} INFO - [2023-01-06 21:53:49,700] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:53:49,720] {logging_mixin.py:115} INFO - [2023-01-06 21:53:49,720] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:53:49,730] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.930 seconds
[2023-01-06 21:54:19,798] {processor.py:153} INFO - Started process (PID=1125) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:54:19,799] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:54:19,800] {logging_mixin.py:115} INFO - [2023-01-06 21:54:19,800] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:54:20,678] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:54:20,680] {logging_mixin.py:115} INFO - [2023-01-06 21:54:20,680] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:54:20,680] {logging_mixin.py:115} INFO - [2023-01-06 21:54:20,680] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:54:20,687] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:54:20,720] {logging_mixin.py:115} INFO - [2023-01-06 21:54:20,720] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:54:20,745] {logging_mixin.py:115} INFO - [2023-01-06 21:54:20,744] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:54:20,755] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.962 seconds
[2023-01-06 21:54:50,827] {processor.py:153} INFO - Started process (PID=1143) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:54:50,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:54:50,829] {logging_mixin.py:115} INFO - [2023-01-06 21:54:50,829] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:54:52,131] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:54:52,133] {logging_mixin.py:115} INFO - [2023-01-06 21:54:52,133] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:54:52,133] {logging_mixin.py:115} INFO - [2023-01-06 21:54:52,133] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:54:52,140] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:54:52,162] {logging_mixin.py:115} INFO - [2023-01-06 21:54:52,162] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:54:52,182] {logging_mixin.py:115} INFO - [2023-01-06 21:54:52,182] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:54:52,192] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.371 seconds
[2023-01-06 21:55:22,262] {processor.py:153} INFO - Started process (PID=1170) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:55:22,264] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:55:22,264] {logging_mixin.py:115} INFO - [2023-01-06 21:55:22,264] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:55:23,134] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:55:23,135] {logging_mixin.py:115} INFO - [2023-01-06 21:55:23,135] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:55:23,136] {logging_mixin.py:115} INFO - [2023-01-06 21:55:23,136] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:55:23,143] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:55:23,166] {logging_mixin.py:115} INFO - [2023-01-06 21:55:23,165] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:55:23,186] {logging_mixin.py:115} INFO - [2023-01-06 21:55:23,185] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:55:23,195] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.937 seconds
[2023-01-06 21:55:53,299] {processor.py:153} INFO - Started process (PID=1195) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:55:53,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:55:53,301] {logging_mixin.py:115} INFO - [2023-01-06 21:55:53,301] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:55:54,151] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:55:54,153] {logging_mixin.py:115} INFO - [2023-01-06 21:55:54,152] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:55:54,153] {logging_mixin.py:115} INFO - [2023-01-06 21:55:54,153] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:55:54,160] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:55:54,182] {logging_mixin.py:115} INFO - [2023-01-06 21:55:54,181] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:55:54,202] {logging_mixin.py:115} INFO - [2023-01-06 21:55:54,202] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:55:54,211] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.917 seconds
[2023-01-06 21:56:24,305] {processor.py:153} INFO - Started process (PID=1221) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:56:24,307] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:56:24,308] {logging_mixin.py:115} INFO - [2023-01-06 21:56:24,307] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:56:25,192] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:56:25,193] {logging_mixin.py:115} INFO - [2023-01-06 21:56:25,193] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:56:25,194] {logging_mixin.py:115} INFO - [2023-01-06 21:56:25,193] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:56:25,200] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:56:25,223] {logging_mixin.py:115} INFO - [2023-01-06 21:56:25,223] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:56:25,244] {logging_mixin.py:115} INFO - [2023-01-06 21:56:25,244] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:56:25,253] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.952 seconds
[2023-01-06 21:56:55,352] {processor.py:153} INFO - Started process (PID=1238) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:56:55,353] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:56:55,353] {logging_mixin.py:115} INFO - [2023-01-06 21:56:55,353] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:56:56,276] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:56:56,277] {logging_mixin.py:115} INFO - [2023-01-06 21:56:56,277] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:56:56,278] {logging_mixin.py:115} INFO - [2023-01-06 21:56:56,277] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:56:56,285] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:56:56,307] {logging_mixin.py:115} INFO - [2023-01-06 21:56:56,307] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:56:56,327] {logging_mixin.py:115} INFO - [2023-01-06 21:56:56,327] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:56:56,337] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.989 seconds
[2023-01-06 21:57:26,423] {processor.py:153} INFO - Started process (PID=1264) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:57:26,424] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:57:26,424] {logging_mixin.py:115} INFO - [2023-01-06 21:57:26,424] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:57:27,305] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:57:27,306] {logging_mixin.py:115} INFO - [2023-01-06 21:57:27,306] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:57:27,307] {logging_mixin.py:115} INFO - [2023-01-06 21:57:27,307] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:57:27,314] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:57:27,335] {logging_mixin.py:115} INFO - [2023-01-06 21:57:27,335] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:57:27,355] {logging_mixin.py:115} INFO - [2023-01-06 21:57:27,355] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:57:27,364] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.946 seconds
[2023-01-06 21:57:57,438] {processor.py:153} INFO - Started process (PID=1289) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:57:57,438] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:57:57,439] {logging_mixin.py:115} INFO - [2023-01-06 21:57:57,439] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:57:58,368] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:57:58,370] {logging_mixin.py:115} INFO - [2023-01-06 21:57:58,369] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:57:58,370] {logging_mixin.py:115} INFO - [2023-01-06 21:57:58,370] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:57:58,377] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:57:58,402] {logging_mixin.py:115} INFO - [2023-01-06 21:57:58,402] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:57:58,422] {logging_mixin.py:115} INFO - [2023-01-06 21:57:58,422] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:57:58,431] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.999 seconds
[2023-01-06 21:58:28,515] {processor.py:153} INFO - Started process (PID=1314) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:58:28,516] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:58:28,516] {logging_mixin.py:115} INFO - [2023-01-06 21:58:28,516] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:58:29,352] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:58:29,353] {logging_mixin.py:115} INFO - [2023-01-06 21:58:29,353] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:58:29,353] {logging_mixin.py:115} INFO - [2023-01-06 21:58:29,353] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:58:29,360] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:58:29,381] {logging_mixin.py:115} INFO - [2023-01-06 21:58:29,381] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:58:29,402] {logging_mixin.py:115} INFO - [2023-01-06 21:58:29,402] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:58:29,411] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.900 seconds
[2023-01-06 21:58:59,478] {processor.py:153} INFO - Started process (PID=1338) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:58:59,479] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:58:59,480] {logging_mixin.py:115} INFO - [2023-01-06 21:58:59,480] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:59:00,618] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:59:00,619] {logging_mixin.py:115} INFO - [2023-01-06 21:59:00,619] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:59:00,619] {logging_mixin.py:115} INFO - [2023-01-06 21:59:00,619] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:59:00,626] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:59:00,647] {logging_mixin.py:115} INFO - [2023-01-06 21:59:00,647] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:59:00,667] {logging_mixin.py:115} INFO - [2023-01-06 21:59:00,667] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:59:00,676] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.204 seconds
[2023-01-06 21:59:30,746] {processor.py:153} INFO - Started process (PID=1356) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:59:30,748] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:59:30,748] {logging_mixin.py:115} INFO - [2023-01-06 21:59:30,748] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:59:31,742] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:59:31,744] {logging_mixin.py:115} INFO - [2023-01-06 21:59:31,744] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:59:31,744] {logging_mixin.py:115} INFO - [2023-01-06 21:59:31,744] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:59:31,751] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 21:59:31,773] {logging_mixin.py:115} INFO - [2023-01-06 21:59:31,773] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:59:31,794] {logging_mixin.py:115} INFO - [2023-01-06 21:59:31,794] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 21:59:31,804] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.063 seconds
[2023-01-06 22:00:01,866] {processor.py:153} INFO - Started process (PID=1382) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:00:01,867] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:00:01,867] {logging_mixin.py:115} INFO - [2023-01-06 22:00:01,867] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:00:02,722] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:00:02,723] {logging_mixin.py:115} INFO - [2023-01-06 22:00:02,723] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:00:02,723] {logging_mixin.py:115} INFO - [2023-01-06 22:00:02,723] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:00:02,730] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:00:02,751] {logging_mixin.py:115} INFO - [2023-01-06 22:00:02,751] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:00:02,772] {logging_mixin.py:115} INFO - [2023-01-06 22:00:02,772] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:00:02,781] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.920 seconds
[2023-01-06 22:00:32,855] {processor.py:153} INFO - Started process (PID=1409) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:00:32,856] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:00:32,856] {logging_mixin.py:115} INFO - [2023-01-06 22:00:32,856] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:00:33,712] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:00:33,713] {logging_mixin.py:115} INFO - [2023-01-06 22:00:33,713] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:00:33,713] {logging_mixin.py:115} INFO - [2023-01-06 22:00:33,713] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:00:33,720] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:00:33,742] {logging_mixin.py:115} INFO - [2023-01-06 22:00:33,741] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:00:33,762] {logging_mixin.py:115} INFO - [2023-01-06 22:00:33,762] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:00:33,771] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.921 seconds
[2023-01-06 22:01:03,839] {processor.py:153} INFO - Started process (PID=1432) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:01:03,841] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:01:03,842] {logging_mixin.py:115} INFO - [2023-01-06 22:01:03,842] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:01:04,833] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:01:04,835] {logging_mixin.py:115} INFO - [2023-01-06 22:01:04,834] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:01:04,835] {logging_mixin.py:115} INFO - [2023-01-06 22:01:04,835] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:01:04,842] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:01:04,865] {logging_mixin.py:115} INFO - [2023-01-06 22:01:04,864] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:01:04,885] {logging_mixin.py:115} INFO - [2023-01-06 22:01:04,885] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:01:04,895] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.060 seconds
[2023-01-06 22:01:34,961] {processor.py:153} INFO - Started process (PID=1450) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:01:34,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:01:34,962] {logging_mixin.py:115} INFO - [2023-01-06 22:01:34,962] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:01:35,832] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:01:35,833] {logging_mixin.py:115} INFO - [2023-01-06 22:01:35,833] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:01:35,834] {logging_mixin.py:115} INFO - [2023-01-06 22:01:35,834] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:01:35,841] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:01:35,872] {logging_mixin.py:115} INFO - [2023-01-06 22:01:35,871] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:01:35,892] {logging_mixin.py:115} INFO - [2023-01-06 22:01:35,892] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:01:35,901] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.944 seconds
[2023-01-06 22:02:05,966] {processor.py:153} INFO - Started process (PID=1476) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:02:05,967] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:02:05,968] {logging_mixin.py:115} INFO - [2023-01-06 22:02:05,968] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:02:06,818] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:02:06,819] {logging_mixin.py:115} INFO - [2023-01-06 22:02:06,819] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:02:06,820] {logging_mixin.py:115} INFO - [2023-01-06 22:02:06,819] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:02:06,828] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:02:06,850] {logging_mixin.py:115} INFO - [2023-01-06 22:02:06,850] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:02:06,870] {logging_mixin.py:115} INFO - [2023-01-06 22:02:06,870] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:02:06,880] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.918 seconds
[2023-01-06 22:02:36,954] {processor.py:153} INFO - Started process (PID=1501) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:02:36,955] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:02:36,956] {logging_mixin.py:115} INFO - [2023-01-06 22:02:36,956] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:02:37,837] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:02:37,838] {logging_mixin.py:115} INFO - [2023-01-06 22:02:37,838] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:02:37,838] {logging_mixin.py:115} INFO - [2023-01-06 22:02:37,838] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:02:37,845] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:02:37,867] {logging_mixin.py:115} INFO - [2023-01-06 22:02:37,866] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:02:37,887] {logging_mixin.py:115} INFO - [2023-01-06 22:02:37,887] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:02:37,898] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.948 seconds
[2023-01-06 22:03:07,970] {processor.py:153} INFO - Started process (PID=1527) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:03:07,971] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:03:07,972] {logging_mixin.py:115} INFO - [2023-01-06 22:03:07,972] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:03:08,819] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:03:08,821] {logging_mixin.py:115} INFO - [2023-01-06 22:03:08,820] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:03:08,821] {logging_mixin.py:115} INFO - [2023-01-06 22:03:08,821] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:03:08,828] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:03:08,850] {logging_mixin.py:115} INFO - [2023-01-06 22:03:08,849] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:03:08,870] {logging_mixin.py:115} INFO - [2023-01-06 22:03:08,870] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:03:08,879] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.913 seconds
[2023-01-06 22:03:38,946] {processor.py:153} INFO - Started process (PID=1545) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:03:38,947] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:03:38,947] {logging_mixin.py:115} INFO - [2023-01-06 22:03:38,947] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:03:39,824] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:03:39,825] {logging_mixin.py:115} INFO - [2023-01-06 22:03:39,825] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:03:39,826] {logging_mixin.py:115} INFO - [2023-01-06 22:03:39,826] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:03:39,832] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:03:39,854] {logging_mixin.py:115} INFO - [2023-01-06 22:03:39,854] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:03:39,875] {logging_mixin.py:115} INFO - [2023-01-06 22:03:39,875] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:03:39,886] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.945 seconds
[2023-01-06 22:04:09,964] {processor.py:153} INFO - Started process (PID=1569) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:04:09,966] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:04:09,966] {logging_mixin.py:115} INFO - [2023-01-06 22:04:09,966] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:04:10,916] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:04:10,917] {logging_mixin.py:115} INFO - [2023-01-06 22:04:10,917] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:04:10,918] {logging_mixin.py:115} INFO - [2023-01-06 22:04:10,917] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:04:10,924] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:04:10,946] {logging_mixin.py:115} INFO - [2023-01-06 22:04:10,945] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:04:10,966] {logging_mixin.py:115} INFO - [2023-01-06 22:04:10,966] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:04:10,975] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.015 seconds
[2023-01-06 22:04:41,041] {processor.py:153} INFO - Started process (PID=1595) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:04:41,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:04:41,042] {logging_mixin.py:115} INFO - [2023-01-06 22:04:41,042] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:04:41,905] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:04:41,906] {logging_mixin.py:115} INFO - [2023-01-06 22:04:41,906] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:04:41,907] {logging_mixin.py:115} INFO - [2023-01-06 22:04:41,907] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:04:41,913] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:04:41,934] {logging_mixin.py:115} INFO - [2023-01-06 22:04:41,934] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:04:41,954] {logging_mixin.py:115} INFO - [2023-01-06 22:04:41,954] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:04:41,963] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.926 seconds
[2023-01-06 22:05:12,037] {processor.py:153} INFO - Started process (PID=1620) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:05:12,039] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:05:12,039] {logging_mixin.py:115} INFO - [2023-01-06 22:05:12,039] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:05:12,917] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:05:12,919] {logging_mixin.py:115} INFO - [2023-01-06 22:05:12,919] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:05:12,919] {logging_mixin.py:115} INFO - [2023-01-06 22:05:12,919] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:05:12,926] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:05:12,947] {logging_mixin.py:115} INFO - [2023-01-06 22:05:12,946] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:05:12,967] {logging_mixin.py:115} INFO - [2023-01-06 22:05:12,967] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:05:12,976] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.943 seconds
[2023-01-06 22:05:43,928] {processor.py:153} INFO - Started process (PID=1645) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:05:43,929] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:05:43,930] {logging_mixin.py:115} INFO - [2023-01-06 22:05:43,930] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:05:44,823] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:05:44,825] {logging_mixin.py:115} INFO - [2023-01-06 22:05:44,825] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:05:44,825] {logging_mixin.py:115} INFO - [2023-01-06 22:05:44,825] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:05:44,832] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:05:44,853] {logging_mixin.py:115} INFO - [2023-01-06 22:05:44,853] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:05:44,873] {logging_mixin.py:115} INFO - [2023-01-06 22:05:44,873] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:05:44,882] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.960 seconds
[2023-01-06 22:06:14,996] {processor.py:153} INFO - Started process (PID=1663) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:06:14,998] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:06:14,999] {logging_mixin.py:115} INFO - [2023-01-06 22:06:14,998] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:06:15,871] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:06:15,872] {logging_mixin.py:115} INFO - [2023-01-06 22:06:15,872] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:06:15,873] {logging_mixin.py:115} INFO - [2023-01-06 22:06:15,872] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:06:15,879] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:06:15,903] {logging_mixin.py:115} INFO - [2023-01-06 22:06:15,903] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:06:15,923] {logging_mixin.py:115} INFO - [2023-01-06 22:06:15,923] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:06:15,932] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.940 seconds
[2023-01-06 22:06:45,997] {processor.py:153} INFO - Started process (PID=1689) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:06:45,998] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:06:45,999] {logging_mixin.py:115} INFO - [2023-01-06 22:06:45,999] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:06:46,840] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:06:46,841] {logging_mixin.py:115} INFO - [2023-01-06 22:06:46,841] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:06:46,842] {logging_mixin.py:115} INFO - [2023-01-06 22:06:46,842] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:06:46,848] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:06:46,869] {logging_mixin.py:115} INFO - [2023-01-06 22:06:46,869] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:06:46,889] {logging_mixin.py:115} INFO - [2023-01-06 22:06:46,889] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:06:46,898] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.906 seconds
[2023-01-06 22:07:16,963] {processor.py:153} INFO - Started process (PID=1714) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:07:16,964] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:07:16,964] {logging_mixin.py:115} INFO - [2023-01-06 22:07:16,964] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:07:17,832] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:07:17,834] {logging_mixin.py:115} INFO - [2023-01-06 22:07:17,834] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:07:17,835] {logging_mixin.py:115} INFO - [2023-01-06 22:07:17,834] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:07:17,842] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:07:17,866] {logging_mixin.py:115} INFO - [2023-01-06 22:07:17,866] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:07:17,889] {logging_mixin.py:115} INFO - [2023-01-06 22:07:17,889] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:07:17,898] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.940 seconds
[2023-01-06 22:07:47,969] {processor.py:153} INFO - Started process (PID=1739) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:07:47,969] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:07:47,970] {logging_mixin.py:115} INFO - [2023-01-06 22:07:47,970] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:07:48,832] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:07:48,833] {logging_mixin.py:115} INFO - [2023-01-06 22:07:48,833] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:07:48,834] {logging_mixin.py:115} INFO - [2023-01-06 22:07:48,834] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:07:48,841] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:07:48,862] {logging_mixin.py:115} INFO - [2023-01-06 22:07:48,862] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:07:48,882] {logging_mixin.py:115} INFO - [2023-01-06 22:07:48,882] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:07:48,891] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.926 seconds
[2023-01-06 22:08:18,955] {processor.py:153} INFO - Started process (PID=1758) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:08:18,956] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:08:18,957] {logging_mixin.py:115} INFO - [2023-01-06 22:08:18,957] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:08:19,825] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:08:19,826] {logging_mixin.py:115} INFO - [2023-01-06 22:08:19,826] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:08:19,827] {logging_mixin.py:115} INFO - [2023-01-06 22:08:19,827] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:08:19,834] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:08:19,859] {logging_mixin.py:115} INFO - [2023-01-06 22:08:19,858] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:08:19,884] {logging_mixin.py:115} INFO - [2023-01-06 22:08:19,884] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:08:19,893] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.943 seconds
[2023-01-06 22:08:49,967] {processor.py:153} INFO - Started process (PID=1783) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:08:49,969] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:08:49,969] {logging_mixin.py:115} INFO - [2023-01-06 22:08:49,969] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:08:50,813] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:08:50,814] {logging_mixin.py:115} INFO - [2023-01-06 22:08:50,814] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:08:50,815] {logging_mixin.py:115} INFO - [2023-01-06 22:08:50,815] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:08:50,822] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:08:50,843] {logging_mixin.py:115} INFO - [2023-01-06 22:08:50,842] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:08:50,863] {logging_mixin.py:115} INFO - [2023-01-06 22:08:50,863] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:08:50,872] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.909 seconds
[2023-01-06 22:09:20,940] {processor.py:153} INFO - Started process (PID=1809) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:09:20,942] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:09:20,942] {logging_mixin.py:115} INFO - [2023-01-06 22:09:20,942] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:09:21,799] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:09:21,800] {logging_mixin.py:115} INFO - [2023-01-06 22:09:21,800] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:09:21,801] {logging_mixin.py:115} INFO - [2023-01-06 22:09:21,800] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:09:21,808] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:09:21,830] {logging_mixin.py:115} INFO - [2023-01-06 22:09:21,830] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:09:21,850] {logging_mixin.py:115} INFO - [2023-01-06 22:09:21,850] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:09:21,860] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.924 seconds
[2023-01-06 22:09:51,934] {processor.py:153} INFO - Started process (PID=1834) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:09:51,935] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:09:51,935] {logging_mixin.py:115} INFO - [2023-01-06 22:09:51,935] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:09:52,785] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:09:52,786] {logging_mixin.py:115} INFO - [2023-01-06 22:09:52,786] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:09:52,786] {logging_mixin.py:115} INFO - [2023-01-06 22:09:52,786] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:09:52,793] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:09:52,814] {logging_mixin.py:115} INFO - [2023-01-06 22:09:52,814] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:09:52,834] {logging_mixin.py:115} INFO - [2023-01-06 22:09:52,834] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:09:52,843] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.914 seconds
[2023-01-06 22:10:22,914] {processor.py:153} INFO - Started process (PID=1853) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:10:22,915] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:10:22,916] {logging_mixin.py:115} INFO - [2023-01-06 22:10:22,915] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:10:23,805] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:10:23,807] {logging_mixin.py:115} INFO - [2023-01-06 22:10:23,807] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:10:23,807] {logging_mixin.py:115} INFO - [2023-01-06 22:10:23,807] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:10:23,814] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:10:23,848] {logging_mixin.py:115} INFO - [2023-01-06 22:10:23,847] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:10:23,883] {logging_mixin.py:115} INFO - [2023-01-06 22:10:23,883] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:10:23,896] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.987 seconds
[2023-01-06 22:10:54,000] {processor.py:153} INFO - Started process (PID=1878) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:10:54,001] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:10:54,002] {logging_mixin.py:115} INFO - [2023-01-06 22:10:54,002] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:10:54,901] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:10:54,902] {logging_mixin.py:115} INFO - [2023-01-06 22:10:54,902] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:10:54,903] {logging_mixin.py:115} INFO - [2023-01-06 22:10:54,903] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:10:54,910] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:10:54,931] {logging_mixin.py:115} INFO - [2023-01-06 22:10:54,931] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:10:54,951] {logging_mixin.py:115} INFO - [2023-01-06 22:10:54,951] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:10:54,960] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.965 seconds
[2023-01-06 22:11:25,028] {processor.py:153} INFO - Started process (PID=1903) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:11:25,029] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:11:25,030] {logging_mixin.py:115} INFO - [2023-01-06 22:11:25,030] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:11:25,933] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:11:25,934] {logging_mixin.py:115} INFO - [2023-01-06 22:11:25,934] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:11:25,935] {logging_mixin.py:115} INFO - [2023-01-06 22:11:25,934] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:11:25,941] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:11:25,964] {logging_mixin.py:115} INFO - [2023-01-06 22:11:25,963] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:11:25,984] {logging_mixin.py:115} INFO - [2023-01-06 22:11:25,984] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:11:25,994] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.971 seconds
[2023-01-06 22:11:56,867] {processor.py:153} INFO - Started process (PID=1928) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:11:56,867] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:11:56,868] {logging_mixin.py:115} INFO - [2023-01-06 22:11:56,868] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:11:57,743] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:11:57,744] {logging_mixin.py:115} INFO - [2023-01-06 22:11:57,744] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:11:57,745] {logging_mixin.py:115} INFO - [2023-01-06 22:11:57,745] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:11:57,752] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:11:57,773] {logging_mixin.py:115} INFO - [2023-01-06 22:11:57,772] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:11:57,795] {logging_mixin.py:115} INFO - [2023-01-06 22:11:57,795] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:11:57,805] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.943 seconds
[2023-01-06 22:12:27,923] {processor.py:153} INFO - Started process (PID=1952) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:12:27,925] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:12:27,925] {logging_mixin.py:115} INFO - [2023-01-06 22:12:27,925] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:12:28,829] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:12:28,831] {logging_mixin.py:115} INFO - [2023-01-06 22:12:28,830] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:12:28,831] {logging_mixin.py:115} INFO - [2023-01-06 22:12:28,831] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:12:28,838] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:12:28,859] {logging_mixin.py:115} INFO - [2023-01-06 22:12:28,859] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:12:28,880] {logging_mixin.py:115} INFO - [2023-01-06 22:12:28,880] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:12:28,889] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.970 seconds
[2023-01-06 22:12:58,957] {processor.py:153} INFO - Started process (PID=1970) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:12:58,957] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:12:58,958] {logging_mixin.py:115} INFO - [2023-01-06 22:12:58,958] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:12:59,803] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:12:59,805] {logging_mixin.py:115} INFO - [2023-01-06 22:12:59,805] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:12:59,805] {logging_mixin.py:115} INFO - [2023-01-06 22:12:59,805] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:12:59,812] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:12:59,833] {logging_mixin.py:115} INFO - [2023-01-06 22:12:59,833] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:12:59,853] {logging_mixin.py:115} INFO - [2023-01-06 22:12:59,853] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:12:59,862] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.910 seconds
[2023-01-06 22:13:29,929] {processor.py:153} INFO - Started process (PID=1998) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:13:29,931] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:13:29,931] {logging_mixin.py:115} INFO - [2023-01-06 22:13:29,931] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:13:30,800] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:13:30,801] {logging_mixin.py:115} INFO - [2023-01-06 22:13:30,801] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:13:30,802] {logging_mixin.py:115} INFO - [2023-01-06 22:13:30,802] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:13:30,808] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:13:30,830] {logging_mixin.py:115} INFO - [2023-01-06 22:13:30,829] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:13:30,850] {logging_mixin.py:115} INFO - [2023-01-06 22:13:30,850] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:13:30,859] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.934 seconds
[2023-01-06 22:14:00,929] {processor.py:153} INFO - Started process (PID=2023) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:14:00,930] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:14:00,930] {logging_mixin.py:115} INFO - [2023-01-06 22:14:00,930] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:14:01,782] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:14:01,784] {logging_mixin.py:115} INFO - [2023-01-06 22:14:01,784] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:14:01,784] {logging_mixin.py:115} INFO - [2023-01-06 22:14:01,784] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:14:01,791] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:14:01,813] {logging_mixin.py:115} INFO - [2023-01-06 22:14:01,813] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:14:01,833] {logging_mixin.py:115} INFO - [2023-01-06 22:14:01,833] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:14:01,842] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.918 seconds
[2023-01-06 22:14:31,909] {processor.py:153} INFO - Started process (PID=2047) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:14:31,910] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:14:31,911] {logging_mixin.py:115} INFO - [2023-01-06 22:14:31,911] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:14:32,783] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:14:32,784] {logging_mixin.py:115} INFO - [2023-01-06 22:14:32,784] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:14:32,785] {logging_mixin.py:115} INFO - [2023-01-06 22:14:32,785] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:14:32,792] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:14:32,813] {logging_mixin.py:115} INFO - [2023-01-06 22:14:32,812] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:14:32,832] {logging_mixin.py:115} INFO - [2023-01-06 22:14:32,832] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:14:32,842] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.938 seconds
[2023-01-06 22:15:02,914] {processor.py:153} INFO - Started process (PID=2065) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:15:02,916] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:15:02,916] {logging_mixin.py:115} INFO - [2023-01-06 22:15:02,916] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:15:03,783] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:15:03,784] {logging_mixin.py:115} INFO - [2023-01-06 22:15:03,784] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:15:03,785] {logging_mixin.py:115} INFO - [2023-01-06 22:15:03,784] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:15:03,791] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:15:03,813] {logging_mixin.py:115} INFO - [2023-01-06 22:15:03,813] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:15:03,833] {logging_mixin.py:115} INFO - [2023-01-06 22:15:03,833] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:15:03,842] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.932 seconds
[2023-01-06 22:15:33,915] {processor.py:153} INFO - Started process (PID=2091) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:15:33,916] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:15:33,916] {logging_mixin.py:115} INFO - [2023-01-06 22:15:33,916] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:15:34,795] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:15:34,796] {logging_mixin.py:115} INFO - [2023-01-06 22:15:34,796] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:15:34,796] {logging_mixin.py:115} INFO - [2023-01-06 22:15:34,796] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:15:34,803] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:15:34,832] {logging_mixin.py:115} INFO - [2023-01-06 22:15:34,831] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:15:34,861] {logging_mixin.py:115} INFO - [2023-01-06 22:15:34,861] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:15:34,873] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.962 seconds
[2023-01-06 22:16:04,953] {processor.py:153} INFO - Started process (PID=2116) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:16:04,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:16:04,955] {logging_mixin.py:115} INFO - [2023-01-06 22:16:04,954] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:16:05,815] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:16:05,816] {logging_mixin.py:115} INFO - [2023-01-06 22:16:05,816] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:16:05,817] {logging_mixin.py:115} INFO - [2023-01-06 22:16:05,816] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:16:05,823] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:16:05,845] {logging_mixin.py:115} INFO - [2023-01-06 22:16:05,845] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:16:05,865] {logging_mixin.py:115} INFO - [2023-01-06 22:16:05,865] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:16:05,875] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.926 seconds
[2023-01-06 22:16:35,965] {processor.py:153} INFO - Started process (PID=2141) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:16:35,966] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:16:35,966] {logging_mixin.py:115} INFO - [2023-01-06 22:16:35,966] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:16:36,818] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:16:36,819] {logging_mixin.py:115} INFO - [2023-01-06 22:16:36,819] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:16:36,819] {logging_mixin.py:115} INFO - [2023-01-06 22:16:36,819] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:16:36,826] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:16:36,847] {logging_mixin.py:115} INFO - [2023-01-06 22:16:36,847] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:16:36,868] {logging_mixin.py:115} INFO - [2023-01-06 22:16:36,868] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:16:36,877] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.916 seconds
[2023-01-06 22:17:06,964] {processor.py:153} INFO - Started process (PID=2159) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:17:06,966] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:17:06,967] {logging_mixin.py:115} INFO - [2023-01-06 22:17:06,967] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:17:07,915] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:17:07,916] {logging_mixin.py:115} INFO - [2023-01-06 22:17:07,916] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:17:07,917] {logging_mixin.py:115} INFO - [2023-01-06 22:17:07,917] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:17:07,929] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:17:07,961] {logging_mixin.py:115} INFO - [2023-01-06 22:17:07,961] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:17:07,991] {logging_mixin.py:115} INFO - [2023-01-06 22:17:07,991] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:17:08,004] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.045 seconds
[2023-01-06 22:17:38,068] {processor.py:153} INFO - Started process (PID=2184) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:17:38,069] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:17:38,069] {logging_mixin.py:115} INFO - [2023-01-06 22:17:38,069] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:17:38,938] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:17:38,939] {logging_mixin.py:115} INFO - [2023-01-06 22:17:38,939] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:17:38,940] {logging_mixin.py:115} INFO - [2023-01-06 22:17:38,940] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:17:38,947] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:17:38,968] {logging_mixin.py:115} INFO - [2023-01-06 22:17:38,967] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:17:38,987] {logging_mixin.py:115} INFO - [2023-01-06 22:17:38,987] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:17:38,996] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.933 seconds
[2023-01-06 22:18:09,061] {processor.py:153} INFO - Started process (PID=2207) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:18:09,063] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:18:09,063] {logging_mixin.py:115} INFO - [2023-01-06 22:18:09,063] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:18:09,912] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:18:09,913] {logging_mixin.py:115} INFO - [2023-01-06 22:18:09,913] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:18:09,913] {logging_mixin.py:115} INFO - [2023-01-06 22:18:09,913] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:18:09,920] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:18:09,941] {logging_mixin.py:115} INFO - [2023-01-06 22:18:09,941] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:18:09,961] {logging_mixin.py:115} INFO - [2023-01-06 22:18:09,961] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:18:09,970] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.913 seconds
[2023-01-06 22:18:40,039] {processor.py:153} INFO - Started process (PID=2231) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:18:40,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:18:40,040] {logging_mixin.py:115} INFO - [2023-01-06 22:18:40,040] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:18:40,887] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:18:40,888] {logging_mixin.py:115} INFO - [2023-01-06 22:18:40,888] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:18:40,889] {logging_mixin.py:115} INFO - [2023-01-06 22:18:40,889] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:18:40,895] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:18:40,916] {logging_mixin.py:115} INFO - [2023-01-06 22:18:40,916] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:18:40,936] {logging_mixin.py:115} INFO - [2023-01-06 22:18:40,936] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:18:40,945] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.910 seconds
[2023-01-06 22:19:11,016] {processor.py:153} INFO - Started process (PID=2249) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:19:11,018] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:19:11,018] {logging_mixin.py:115} INFO - [2023-01-06 22:19:11,018] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:19:11,881] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:19:11,882] {logging_mixin.py:115} INFO - [2023-01-06 22:19:11,882] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:19:11,883] {logging_mixin.py:115} INFO - [2023-01-06 22:19:11,883] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:19:11,890] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:19:11,911] {logging_mixin.py:115} INFO - [2023-01-06 22:19:11,910] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:19:11,931] {logging_mixin.py:115} INFO - [2023-01-06 22:19:11,930] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:19:11,940] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.928 seconds
[2023-01-06 22:19:42,004] {processor.py:153} INFO - Started process (PID=2273) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:19:42,005] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:19:42,005] {logging_mixin.py:115} INFO - [2023-01-06 22:19:42,005] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:19:42,846] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:19:42,847] {logging_mixin.py:115} INFO - [2023-01-06 22:19:42,847] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:19:42,847] {logging_mixin.py:115} INFO - [2023-01-06 22:19:42,847] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:19:42,854] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:19:42,875] {logging_mixin.py:115} INFO - [2023-01-06 22:19:42,875] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:19:42,895] {logging_mixin.py:115} INFO - [2023-01-06 22:19:42,895] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:19:42,904] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.905 seconds
[2023-01-06 22:20:12,972] {processor.py:153} INFO - Started process (PID=2299) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:20:12,973] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:20:12,974] {logging_mixin.py:115} INFO - [2023-01-06 22:20:12,974] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:20:13,830] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:20:13,831] {logging_mixin.py:115} INFO - [2023-01-06 22:20:13,831] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:20:13,832] {logging_mixin.py:115} INFO - [2023-01-06 22:20:13,831] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:20:13,838] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:20:13,866] {logging_mixin.py:115} INFO - [2023-01-06 22:20:13,866] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:20:13,890] {logging_mixin.py:115} INFO - [2023-01-06 22:20:13,890] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:20:13,900] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.932 seconds
[2023-01-06 22:20:43,968] {processor.py:153} INFO - Started process (PID=2322) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:20:43,969] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:20:43,969] {logging_mixin.py:115} INFO - [2023-01-06 22:20:43,969] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:20:44,843] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:20:44,844] {logging_mixin.py:115} INFO - [2023-01-06 22:20:44,844] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:20:44,845] {logging_mixin.py:115} INFO - [2023-01-06 22:20:44,844] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:20:44,851] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:20:44,872] {logging_mixin.py:115} INFO - [2023-01-06 22:20:44,872] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:20:44,892] {logging_mixin.py:115} INFO - [2023-01-06 22:20:44,892] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:20:44,901] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.938 seconds
[2023-01-06 22:21:14,970] {processor.py:153} INFO - Started process (PID=2341) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:21:14,973] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:21:14,974] {logging_mixin.py:115} INFO - [2023-01-06 22:21:14,974] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:21:15,884] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:21:15,885] {logging_mixin.py:115} INFO - [2023-01-06 22:21:15,885] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:21:15,886] {logging_mixin.py:115} INFO - [2023-01-06 22:21:15,886] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:21:15,893] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:21:15,914] {logging_mixin.py:115} INFO - [2023-01-06 22:21:15,913] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:21:15,933] {logging_mixin.py:115} INFO - [2023-01-06 22:21:15,933] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:21:15,942] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.977 seconds
[2023-01-06 22:21:46,038] {processor.py:153} INFO - Started process (PID=2365) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:21:46,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:21:46,041] {logging_mixin.py:115} INFO - [2023-01-06 22:21:46,040] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:21:46,923] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:21:46,924] {logging_mixin.py:115} INFO - [2023-01-06 22:21:46,924] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:21:46,924] {logging_mixin.py:115} INFO - [2023-01-06 22:21:46,924] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:21:46,931] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:21:46,953] {logging_mixin.py:115} INFO - [2023-01-06 22:21:46,953] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:21:46,973] {logging_mixin.py:115} INFO - [2023-01-06 22:21:46,973] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:21:46,982] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.949 seconds
[2023-01-06 22:22:17,077] {processor.py:153} INFO - Started process (PID=2390) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:22:17,078] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:22:17,078] {logging_mixin.py:115} INFO - [2023-01-06 22:22:17,078] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:22:17,947] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:22:17,949] {logging_mixin.py:115} INFO - [2023-01-06 22:22:17,949] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:22:17,949] {logging_mixin.py:115} INFO - [2023-01-06 22:22:17,949] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:22:17,956] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:22:17,977] {logging_mixin.py:115} INFO - [2023-01-06 22:22:17,977] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:22:17,996] {logging_mixin.py:115} INFO - [2023-01-06 22:22:17,996] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:22:18,006] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.933 seconds
[2023-01-06 22:22:48,047] {processor.py:153} INFO - Started process (PID=2417) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:22:48,048] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:22:48,049] {logging_mixin.py:115} INFO - [2023-01-06 22:22:48,049] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:22:48,901] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:22:48,902] {logging_mixin.py:115} INFO - [2023-01-06 22:22:48,902] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:22:48,903] {logging_mixin.py:115} INFO - [2023-01-06 22:22:48,903] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:22:48,910] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:22:48,931] {logging_mixin.py:115} INFO - [2023-01-06 22:22:48,931] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:22:48,951] {logging_mixin.py:115} INFO - [2023-01-06 22:22:48,950] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:22:48,960] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.917 seconds
[2023-01-06 22:23:19,164] {processor.py:153} INFO - Started process (PID=2442) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:23:19,165] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:23:19,166] {logging_mixin.py:115} INFO - [2023-01-06 22:23:19,165] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:23:20,040] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:23:20,041] {logging_mixin.py:115} INFO - [2023-01-06 22:23:20,041] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:23:20,042] {logging_mixin.py:115} INFO - [2023-01-06 22:23:20,041] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:23:20,048] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:23:20,070] {logging_mixin.py:115} INFO - [2023-01-06 22:23:20,070] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:23:20,090] {logging_mixin.py:115} INFO - [2023-01-06 22:23:20,090] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:23:20,099] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.940 seconds
[2023-01-06 22:23:50,169] {processor.py:153} INFO - Started process (PID=2459) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:23:50,171] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:23:50,171] {logging_mixin.py:115} INFO - [2023-01-06 22:23:50,171] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:23:51,070] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:23:51,071] {logging_mixin.py:115} INFO - [2023-01-06 22:23:51,071] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:23:51,072] {logging_mixin.py:115} INFO - [2023-01-06 22:23:51,071] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:23:51,078] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:23:51,100] {logging_mixin.py:115} INFO - [2023-01-06 22:23:51,100] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:23:51,120] {logging_mixin.py:115} INFO - [2023-01-06 22:23:51,120] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:23:51,129] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.964 seconds
[2023-01-06 22:24:21,200] {processor.py:153} INFO - Started process (PID=2484) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:24:21,202] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:24:21,202] {logging_mixin.py:115} INFO - [2023-01-06 22:24:21,202] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:24:22,053] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:24:22,055] {logging_mixin.py:115} INFO - [2023-01-06 22:24:22,054] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:24:22,055] {logging_mixin.py:115} INFO - [2023-01-06 22:24:22,055] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:24:22,062] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:24:22,083] {logging_mixin.py:115} INFO - [2023-01-06 22:24:22,082] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:24:22,103] {logging_mixin.py:115} INFO - [2023-01-06 22:24:22,102] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:24:22,112] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.916 seconds
[2023-01-06 22:24:52,179] {processor.py:153} INFO - Started process (PID=2510) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:24:52,180] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:24:52,181] {logging_mixin.py:115} INFO - [2023-01-06 22:24:52,180] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:24:53,045] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:24:53,047] {logging_mixin.py:115} INFO - [2023-01-06 22:24:53,047] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:24:53,048] {logging_mixin.py:115} INFO - [2023-01-06 22:24:53,047] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:24:53,059] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:24:53,081] {logging_mixin.py:115} INFO - [2023-01-06 22:24:53,080] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:24:53,106] {logging_mixin.py:115} INFO - [2023-01-06 22:24:53,106] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:24:53,128] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.954 seconds
[2023-01-06 22:25:23,209] {processor.py:153} INFO - Started process (PID=2536) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:25:23,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:25:23,210] {logging_mixin.py:115} INFO - [2023-01-06 22:25:23,210] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:25:24,104] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:25:24,106] {logging_mixin.py:115} INFO - [2023-01-06 22:25:24,106] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:25:24,106] {logging_mixin.py:115} INFO - [2023-01-06 22:25:24,106] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:25:24,113] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:25:24,134] {logging_mixin.py:115} INFO - [2023-01-06 22:25:24,134] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:25:24,154] {logging_mixin.py:115} INFO - [2023-01-06 22:25:24,154] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:25:24,163] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.959 seconds
[2023-01-06 22:25:54,251] {processor.py:153} INFO - Started process (PID=2553) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:25:54,252] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:25:54,253] {logging_mixin.py:115} INFO - [2023-01-06 22:25:54,252] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:25:55,183] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:25:55,184] {logging_mixin.py:115} INFO - [2023-01-06 22:25:55,184] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:25:55,185] {logging_mixin.py:115} INFO - [2023-01-06 22:25:55,185] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:25:55,192] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:25:55,214] {logging_mixin.py:115} INFO - [2023-01-06 22:25:55,214] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:25:55,234] {logging_mixin.py:115} INFO - [2023-01-06 22:25:55,234] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:25:55,244] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.997 seconds
[2023-01-06 22:26:25,326] {processor.py:153} INFO - Started process (PID=2578) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:26:25,326] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:26:25,327] {logging_mixin.py:115} INFO - [2023-01-06 22:26:25,327] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:26:26,179] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:26:26,180] {logging_mixin.py:115} INFO - [2023-01-06 22:26:26,180] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:26:26,181] {logging_mixin.py:115} INFO - [2023-01-06 22:26:26,180] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:26:26,187] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:26:26,210] {logging_mixin.py:115} INFO - [2023-01-06 22:26:26,210] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:26:26,230] {logging_mixin.py:115} INFO - [2023-01-06 22:26:26,230] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:26:26,240] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.918 seconds
[2023-01-06 22:26:56,310] {processor.py:153} INFO - Started process (PID=2602) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:26:56,311] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:26:56,311] {logging_mixin.py:115} INFO - [2023-01-06 22:26:56,311] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:26:57,161] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:26:57,162] {logging_mixin.py:115} INFO - [2023-01-06 22:26:57,162] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:26:57,163] {logging_mixin.py:115} INFO - [2023-01-06 22:26:57,163] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:26:57,169] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:26:57,191] {logging_mixin.py:115} INFO - [2023-01-06 22:26:57,191] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:26:57,212] {logging_mixin.py:115} INFO - [2023-01-06 22:26:57,212] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:26:57,221] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.916 seconds
[2023-01-06 22:27:27,287] {processor.py:153} INFO - Started process (PID=2627) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:27:27,290] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:27:27,291] {logging_mixin.py:115} INFO - [2023-01-06 22:27:27,291] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:27:28,162] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:27:28,163] {logging_mixin.py:115} INFO - [2023-01-06 22:27:28,163] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:27:28,164] {logging_mixin.py:115} INFO - [2023-01-06 22:27:28,164] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:27:28,171] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:27:28,192] {logging_mixin.py:115} INFO - [2023-01-06 22:27:28,192] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:27:28,212] {logging_mixin.py:115} INFO - [2023-01-06 22:27:28,212] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:27:28,221] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.938 seconds
[2023-01-06 22:27:58,288] {processor.py:153} INFO - Started process (PID=2646) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:27:58,289] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:27:58,289] {logging_mixin.py:115} INFO - [2023-01-06 22:27:58,289] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:27:59,498] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:27:59,499] {logging_mixin.py:115} INFO - [2023-01-06 22:27:59,499] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:27:59,500] {logging_mixin.py:115} INFO - [2023-01-06 22:27:59,499] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:27:59,509] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:27:59,535] {logging_mixin.py:115} INFO - [2023-01-06 22:27:59,535] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:27:59,563] {logging_mixin.py:115} INFO - [2023-01-06 22:27:59,563] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:27:59,577] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.294 seconds
[2023-01-06 22:28:29,647] {processor.py:153} INFO - Started process (PID=2672) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:28:29,648] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:28:29,649] {logging_mixin.py:115} INFO - [2023-01-06 22:28:29,649] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:28:30,500] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:28:30,501] {logging_mixin.py:115} INFO - [2023-01-06 22:28:30,501] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:28:30,502] {logging_mixin.py:115} INFO - [2023-01-06 22:28:30,501] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:28:30,508] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:28:30,529] {logging_mixin.py:115} INFO - [2023-01-06 22:28:30,529] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:28:30,549] {logging_mixin.py:115} INFO - [2023-01-06 22:28:30,549] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:28:30,558] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.916 seconds
[2023-01-06 22:29:01,277] {processor.py:153} INFO - Started process (PID=2698) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:29:01,279] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:29:01,280] {logging_mixin.py:115} INFO - [2023-01-06 22:29:01,280] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:29:02,131] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:29:02,132] {logging_mixin.py:115} INFO - [2023-01-06 22:29:02,132] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:29:02,133] {logging_mixin.py:115} INFO - [2023-01-06 22:29:02,133] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:29:02,139] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:29:02,160] {logging_mixin.py:115} INFO - [2023-01-06 22:29:02,160] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:29:02,180] {logging_mixin.py:115} INFO - [2023-01-06 22:29:02,180] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:29:02,189] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.917 seconds
[2023-01-06 22:29:32,269] {processor.py:153} INFO - Started process (PID=2722) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:29:32,270] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:29:32,270] {logging_mixin.py:115} INFO - [2023-01-06 22:29:32,270] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:29:33,177] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:29:33,179] {logging_mixin.py:115} INFO - [2023-01-06 22:29:33,179] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:29:33,179] {logging_mixin.py:115} INFO - [2023-01-06 22:29:33,179] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:29:33,186] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:29:33,208] {logging_mixin.py:115} INFO - [2023-01-06 22:29:33,207] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:29:33,228] {logging_mixin.py:115} INFO - [2023-01-06 22:29:33,228] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:29:33,237] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.972 seconds
[2023-01-06 22:30:03,451] {processor.py:153} INFO - Started process (PID=2747) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:30:03,453] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:30:03,453] {logging_mixin.py:115} INFO - [2023-01-06 22:30:03,453] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:30:04,307] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:30:04,308] {logging_mixin.py:115} INFO - [2023-01-06 22:30:04,308] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:30:04,309] {logging_mixin.py:115} INFO - [2023-01-06 22:30:04,308] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:30:04,315] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:30:04,337] {logging_mixin.py:115} INFO - [2023-01-06 22:30:04,336] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:30:04,357] {logging_mixin.py:115} INFO - [2023-01-06 22:30:04,357] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:30:04,367] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.921 seconds
[2023-01-06 22:30:34,434] {processor.py:153} INFO - Started process (PID=2765) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:30:34,436] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:30:34,436] {logging_mixin.py:115} INFO - [2023-01-06 22:30:34,436] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:30:35,291] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:30:35,292] {logging_mixin.py:115} INFO - [2023-01-06 22:30:35,292] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:30:35,293] {logging_mixin.py:115} INFO - [2023-01-06 22:30:35,293] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:30:35,304] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:30:35,328] {logging_mixin.py:115} INFO - [2023-01-06 22:30:35,327] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:30:35,348] {logging_mixin.py:115} INFO - [2023-01-06 22:30:35,348] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:30:35,357] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.927 seconds
[2023-01-06 22:31:05,425] {processor.py:153} INFO - Started process (PID=2790) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:31:05,427] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:31:05,427] {logging_mixin.py:115} INFO - [2023-01-06 22:31:05,427] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:31:06,308] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:31:06,309] {logging_mixin.py:115} INFO - [2023-01-06 22:31:06,309] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:31:06,309] {logging_mixin.py:115} INFO - [2023-01-06 22:31:06,309] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:31:06,316] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:31:06,338] {logging_mixin.py:115} INFO - [2023-01-06 22:31:06,338] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:31:06,366] {logging_mixin.py:115} INFO - [2023-01-06 22:31:06,366] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:31:06,375] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.954 seconds
[2023-01-06 22:31:36,443] {processor.py:153} INFO - Started process (PID=2815) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:31:36,444] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:31:36,445] {logging_mixin.py:115} INFO - [2023-01-06 22:31:36,445] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:31:37,308] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:31:37,310] {logging_mixin.py:115} INFO - [2023-01-06 22:31:37,310] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:31:37,310] {logging_mixin.py:115} INFO - [2023-01-06 22:31:37,310] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:31:37,317] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:31:37,338] {logging_mixin.py:115} INFO - [2023-01-06 22:31:37,338] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:31:37,359] {logging_mixin.py:115} INFO - [2023-01-06 22:31:37,358] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:31:37,368] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.929 seconds
[2023-01-06 22:32:07,437] {processor.py:153} INFO - Started process (PID=2840) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:32:07,439] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:32:07,439] {logging_mixin.py:115} INFO - [2023-01-06 22:32:07,439] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:32:08,312] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:32:08,313] {logging_mixin.py:115} INFO - [2023-01-06 22:32:08,313] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:32:08,314] {logging_mixin.py:115} INFO - [2023-01-06 22:32:08,314] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:32:08,320] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:32:08,342] {logging_mixin.py:115} INFO - [2023-01-06 22:32:08,341] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:32:08,362] {logging_mixin.py:115} INFO - [2023-01-06 22:32:08,362] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:32:08,371] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.938 seconds
[2023-01-06 22:32:38,442] {processor.py:153} INFO - Started process (PID=2856) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:32:38,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:32:38,443] {logging_mixin.py:115} INFO - [2023-01-06 22:32:38,443] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:32:39,307] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:32:39,309] {logging_mixin.py:115} INFO - [2023-01-06 22:32:39,308] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:32:39,309] {logging_mixin.py:115} INFO - [2023-01-06 22:32:39,309] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:32:39,316] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:32:39,338] {logging_mixin.py:115} INFO - [2023-01-06 22:32:39,337] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:32:39,358] {logging_mixin.py:115} INFO - [2023-01-06 22:32:39,357] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:32:39,368] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.931 seconds
[2023-01-06 22:33:09,446] {processor.py:153} INFO - Started process (PID=2881) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:33:09,447] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:33:09,448] {logging_mixin.py:115} INFO - [2023-01-06 22:33:09,447] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:33:10,288] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:33:10,290] {logging_mixin.py:115} INFO - [2023-01-06 22:33:10,290] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:33:10,290] {logging_mixin.py:115} INFO - [2023-01-06 22:33:10,290] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:33:10,297] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:33:10,318] {logging_mixin.py:115} INFO - [2023-01-06 22:33:10,318] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:33:10,338] {logging_mixin.py:115} INFO - [2023-01-06 22:33:10,338] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:33:10,348] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.907 seconds
[2023-01-06 22:33:40,919] {processor.py:153} INFO - Started process (PID=2906) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:33:40,920] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:33:40,921] {logging_mixin.py:115} INFO - [2023-01-06 22:33:40,920] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:33:41,774] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:33:41,776] {logging_mixin.py:115} INFO - [2023-01-06 22:33:41,775] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:33:41,776] {logging_mixin.py:115} INFO - [2023-01-06 22:33:41,776] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:33:41,783] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:33:41,804] {logging_mixin.py:115} INFO - [2023-01-06 22:33:41,804] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:33:41,824] {logging_mixin.py:115} INFO - [2023-01-06 22:33:41,824] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:33:41,834] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.920 seconds
[2023-01-06 22:34:11,929] {processor.py:153} INFO - Started process (PID=2931) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:34:11,929] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:34:11,930] {logging_mixin.py:115} INFO - [2023-01-06 22:34:11,930] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:34:12,775] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:34:12,776] {logging_mixin.py:115} INFO - [2023-01-06 22:34:12,776] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:34:12,777] {logging_mixin.py:115} INFO - [2023-01-06 22:34:12,776] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:34:12,783] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:34:12,804] {logging_mixin.py:115} INFO - [2023-01-06 22:34:12,804] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:34:12,824] {logging_mixin.py:115} INFO - [2023-01-06 22:34:12,824] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:34:12,833] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.909 seconds
[2023-01-06 22:34:42,888] {processor.py:153} INFO - Started process (PID=2949) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:34:42,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:34:42,891] {logging_mixin.py:115} INFO - [2023-01-06 22:34:42,890] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:34:43,765] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:34:43,766] {logging_mixin.py:115} INFO - [2023-01-06 22:34:43,766] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:34:43,767] {logging_mixin.py:115} INFO - [2023-01-06 22:34:43,767] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:34:43,773] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:34:43,806] {logging_mixin.py:115} INFO - [2023-01-06 22:34:43,806] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:34:43,827] {logging_mixin.py:115} INFO - [2023-01-06 22:34:43,827] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:34:43,836] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.952 seconds
[2023-01-06 22:35:14,091] {processor.py:153} INFO - Started process (PID=2975) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:35:14,092] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:35:14,093] {logging_mixin.py:115} INFO - [2023-01-06 22:35:14,093] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:35:14,935] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:35:14,937] {logging_mixin.py:115} INFO - [2023-01-06 22:35:14,937] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:35:14,937] {logging_mixin.py:115} INFO - [2023-01-06 22:35:14,937] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:35:14,944] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:35:14,965] {logging_mixin.py:115} INFO - [2023-01-06 22:35:14,964] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:35:14,984] {logging_mixin.py:115} INFO - [2023-01-06 22:35:14,984] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:35:14,993] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.907 seconds
[2023-01-06 22:35:45,062] {processor.py:153} INFO - Started process (PID=2999) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:35:45,063] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:35:45,063] {logging_mixin.py:115} INFO - [2023-01-06 22:35:45,063] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:35:45,917] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:35:45,918] {logging_mixin.py:115} INFO - [2023-01-06 22:35:45,918] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:35:45,918] {logging_mixin.py:115} INFO - [2023-01-06 22:35:45,918] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:35:45,925] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:35:45,946] {logging_mixin.py:115} INFO - [2023-01-06 22:35:45,946] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:35:45,965] {logging_mixin.py:115} INFO - [2023-01-06 22:35:45,965] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:35:45,974] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.918 seconds
[2023-01-06 22:36:16,041] {processor.py:153} INFO - Started process (PID=3024) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:36:16,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:36:16,043] {logging_mixin.py:115} INFO - [2023-01-06 22:36:16,043] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:36:16,898] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:36:16,899] {logging_mixin.py:115} INFO - [2023-01-06 22:36:16,899] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:36:16,900] {logging_mixin.py:115} INFO - [2023-01-06 22:36:16,899] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:36:16,906] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:36:16,928] {logging_mixin.py:115} INFO - [2023-01-06 22:36:16,928] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:36:16,948] {logging_mixin.py:115} INFO - [2023-01-06 22:36:16,948] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:36:16,957] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.922 seconds
[2023-01-06 22:36:47,025] {processor.py:153} INFO - Started process (PID=3042) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:36:47,026] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:36:47,027] {logging_mixin.py:115} INFO - [2023-01-06 22:36:47,026] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:36:47,984] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:36:47,985] {logging_mixin.py:115} INFO - [2023-01-06 22:36:47,985] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:36:47,986] {logging_mixin.py:115} INFO - [2023-01-06 22:36:47,985] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:36:47,992] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:36:48,020] {logging_mixin.py:115} INFO - [2023-01-06 22:36:48,020] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:36:48,041] {logging_mixin.py:115} INFO - [2023-01-06 22:36:48,041] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:36:48,051] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.031 seconds
[2023-01-06 22:37:18,113] {processor.py:153} INFO - Started process (PID=3068) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:37:18,114] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:37:18,115] {logging_mixin.py:115} INFO - [2023-01-06 22:37:18,115] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:37:18,974] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:37:18,975] {logging_mixin.py:115} INFO - [2023-01-06 22:37:18,975] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:37:18,976] {logging_mixin.py:115} INFO - [2023-01-06 22:37:18,975] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:37:18,983] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:37:19,005] {logging_mixin.py:115} INFO - [2023-01-06 22:37:19,004] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:37:19,024] {logging_mixin.py:115} INFO - [2023-01-06 22:37:19,024] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:37:19,034] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.926 seconds
[2023-01-06 22:37:49,102] {processor.py:153} INFO - Started process (PID=3093) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:37:49,103] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:37:49,104] {logging_mixin.py:115} INFO - [2023-01-06 22:37:49,103] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:37:49,986] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:37:49,987] {logging_mixin.py:115} INFO - [2023-01-06 22:37:49,987] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:37:49,988] {logging_mixin.py:115} INFO - [2023-01-06 22:37:49,987] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:37:49,994] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:37:50,016] {logging_mixin.py:115} INFO - [2023-01-06 22:37:50,015] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:37:50,036] {logging_mixin.py:115} INFO - [2023-01-06 22:37:50,036] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:37:50,045] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.948 seconds
[2023-01-06 22:38:20,111] {processor.py:153} INFO - Started process (PID=3118) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:38:20,113] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:38:20,113] {logging_mixin.py:115} INFO - [2023-01-06 22:38:20,113] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:38:20,971] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:38:20,972] {logging_mixin.py:115} INFO - [2023-01-06 22:38:20,972] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:38:20,973] {logging_mixin.py:115} INFO - [2023-01-06 22:38:20,972] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:38:20,979] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:38:21,002] {logging_mixin.py:115} INFO - [2023-01-06 22:38:21,001] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:38:21,022] {logging_mixin.py:115} INFO - [2023-01-06 22:38:21,022] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:38:21,031] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.924 seconds
[2023-01-06 22:38:51,102] {processor.py:153} INFO - Started process (PID=3144) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:38:51,104] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:38:51,104] {logging_mixin.py:115} INFO - [2023-01-06 22:38:51,104] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:38:51,997] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:38:51,998] {logging_mixin.py:115} INFO - [2023-01-06 22:38:51,998] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:38:51,999] {logging_mixin.py:115} INFO - [2023-01-06 22:38:51,998] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:38:52,005] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:38:52,027] {logging_mixin.py:115} INFO - [2023-01-06 22:38:52,027] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:38:52,050] {logging_mixin.py:115} INFO - [2023-01-06 22:38:52,050] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:38:52,059] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.962 seconds
[2023-01-06 22:39:22,127] {processor.py:153} INFO - Started process (PID=3162) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:39:22,129] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:39:22,129] {logging_mixin.py:115} INFO - [2023-01-06 22:39:22,129] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:39:23,066] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:39:23,068] {logging_mixin.py:115} INFO - [2023-01-06 22:39:23,068] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:39:23,068] {logging_mixin.py:115} INFO - [2023-01-06 22:39:23,068] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:39:23,075] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:39:23,098] {logging_mixin.py:115} INFO - [2023-01-06 22:39:23,098] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:39:23,120] {logging_mixin.py:115} INFO - [2023-01-06 22:39:23,120] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:39:23,130] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.008 seconds
[2023-01-06 22:39:53,205] {processor.py:153} INFO - Started process (PID=3186) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:39:53,205] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:39:53,206] {logging_mixin.py:115} INFO - [2023-01-06 22:39:53,206] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:39:54,064] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:39:54,065] {logging_mixin.py:115} INFO - [2023-01-06 22:39:54,065] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:39:54,066] {logging_mixin.py:115} INFO - [2023-01-06 22:39:54,065] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:39:54,072] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:39:54,096] {logging_mixin.py:115} INFO - [2023-01-06 22:39:54,096] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:39:54,119] {logging_mixin.py:115} INFO - [2023-01-06 22:39:54,119] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:39:54,129] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.930 seconds
[2023-01-06 22:40:24,234] {processor.py:153} INFO - Started process (PID=3211) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:40:24,236] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:40:24,236] {logging_mixin.py:115} INFO - [2023-01-06 22:40:24,236] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:40:25,097] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:40:25,098] {logging_mixin.py:115} INFO - [2023-01-06 22:40:25,098] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:40:25,099] {logging_mixin.py:115} INFO - [2023-01-06 22:40:25,098] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:40:25,105] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:40:25,127] {logging_mixin.py:115} INFO - [2023-01-06 22:40:25,126] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:40:25,147] {logging_mixin.py:115} INFO - [2023-01-06 22:40:25,147] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:40:25,156] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.927 seconds
[2023-01-06 22:40:55,308] {processor.py:153} INFO - Started process (PID=3236) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:40:55,310] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:40:55,310] {logging_mixin.py:115} INFO - [2023-01-06 22:40:55,310] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:40:56,194] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:40:56,196] {logging_mixin.py:115} INFO - [2023-01-06 22:40:56,196] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:40:56,196] {logging_mixin.py:115} INFO - [2023-01-06 22:40:56,196] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:40:56,203] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:40:56,235] {logging_mixin.py:115} INFO - [2023-01-06 22:40:56,235] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:40:56,257] {logging_mixin.py:115} INFO - [2023-01-06 22:40:56,257] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:40:56,266] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.963 seconds
[2023-01-06 22:41:26,339] {processor.py:153} INFO - Started process (PID=3254) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:41:26,342] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:41:26,343] {logging_mixin.py:115} INFO - [2023-01-06 22:41:26,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:41:27,231] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:41:27,233] {logging_mixin.py:115} INFO - [2023-01-06 22:41:27,233] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:41:27,233] {logging_mixin.py:115} INFO - [2023-01-06 22:41:27,233] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:41:27,240] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:41:27,262] {logging_mixin.py:115} INFO - [2023-01-06 22:41:27,262] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:41:27,283] {logging_mixin.py:115} INFO - [2023-01-06 22:41:27,282] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:41:27,292] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.958 seconds
[2023-01-06 22:41:57,364] {processor.py:153} INFO - Started process (PID=3280) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:41:57,366] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:41:57,366] {logging_mixin.py:115} INFO - [2023-01-06 22:41:57,366] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:41:58,212] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:41:58,213] {logging_mixin.py:115} INFO - [2023-01-06 22:41:58,213] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:41:58,214] {logging_mixin.py:115} INFO - [2023-01-06 22:41:58,213] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:41:58,220] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:41:58,247] {logging_mixin.py:115} INFO - [2023-01-06 22:41:58,247] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:41:58,270] {logging_mixin.py:115} INFO - [2023-01-06 22:41:58,270] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:41:58,279] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.920 seconds
[2023-01-06 22:42:28,346] {processor.py:153} INFO - Started process (PID=3305) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:42:28,346] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:42:28,347] {logging_mixin.py:115} INFO - [2023-01-06 22:42:28,347] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:42:29,238] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:42:29,239] {logging_mixin.py:115} INFO - [2023-01-06 22:42:29,239] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:42:29,240] {logging_mixin.py:115} INFO - [2023-01-06 22:42:29,239] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:42:29,246] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:42:29,274] {logging_mixin.py:115} INFO - [2023-01-06 22:42:29,274] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:42:29,301] {logging_mixin.py:115} INFO - [2023-01-06 22:42:29,300] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:42:29,310] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.969 seconds
[2023-01-06 22:42:59,385] {processor.py:153} INFO - Started process (PID=3331) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:42:59,386] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:42:59,387] {logging_mixin.py:115} INFO - [2023-01-06 22:42:59,387] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:43:00,241] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:43:00,242] {logging_mixin.py:115} INFO - [2023-01-06 22:43:00,242] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:43:00,243] {logging_mixin.py:115} INFO - [2023-01-06 22:43:00,242] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:43:00,249] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:43:00,270] {logging_mixin.py:115} INFO - [2023-01-06 22:43:00,270] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:43:00,290] {logging_mixin.py:115} INFO - [2023-01-06 22:43:00,289] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:43:00,299] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.918 seconds
[2023-01-06 22:43:30,367] {processor.py:153} INFO - Started process (PID=3349) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:43:30,368] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:43:30,369] {logging_mixin.py:115} INFO - [2023-01-06 22:43:30,369] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:43:31,253] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:43:31,254] {logging_mixin.py:115} INFO - [2023-01-06 22:43:31,254] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:43:31,254] {logging_mixin.py:115} INFO - [2023-01-06 22:43:31,254] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:43:31,261] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:43:31,283] {logging_mixin.py:115} INFO - [2023-01-06 22:43:31,282] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:43:31,303] {logging_mixin.py:115} INFO - [2023-01-06 22:43:31,303] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:43:31,312] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.949 seconds
[2023-01-06 22:44:01,385] {processor.py:153} INFO - Started process (PID=3374) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:44:01,386] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:44:01,387] {logging_mixin.py:115} INFO - [2023-01-06 22:44:01,387] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:44:02,258] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:44:02,259] {logging_mixin.py:115} INFO - [2023-01-06 22:44:02,259] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:44:02,260] {logging_mixin.py:115} INFO - [2023-01-06 22:44:02,260] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:44:02,267] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:44:02,289] {logging_mixin.py:115} INFO - [2023-01-06 22:44:02,289] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:44:02,309] {logging_mixin.py:115} INFO - [2023-01-06 22:44:02,309] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:44:02,318] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.938 seconds
[2023-01-06 22:44:32,762] {processor.py:153} INFO - Started process (PID=3400) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:44:32,763] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:44:32,763] {logging_mixin.py:115} INFO - [2023-01-06 22:44:32,763] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:44:33,609] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:44:33,610] {logging_mixin.py:115} INFO - [2023-01-06 22:44:33,610] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:44:33,610] {logging_mixin.py:115} INFO - [2023-01-06 22:44:33,610] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:44:33,617] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:44:33,639] {logging_mixin.py:115} INFO - [2023-01-06 22:44:33,639] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:44:33,659] {logging_mixin.py:115} INFO - [2023-01-06 22:44:33,659] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:44:33,668] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.910 seconds
[2023-01-06 22:45:03,835] {processor.py:153} INFO - Started process (PID=3424) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:45:03,836] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:45:03,837] {logging_mixin.py:115} INFO - [2023-01-06 22:45:03,837] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:45:04,684] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:45:04,685] {logging_mixin.py:115} INFO - [2023-01-06 22:45:04,685] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:45:04,685] {logging_mixin.py:115} INFO - [2023-01-06 22:45:04,685] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:45:04,692] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:45:04,713] {logging_mixin.py:115} INFO - [2023-01-06 22:45:04,713] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:45:04,738] {logging_mixin.py:115} INFO - [2023-01-06 22:45:04,738] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:45:04,749] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.918 seconds
[2023-01-06 22:45:34,818] {processor.py:153} INFO - Started process (PID=3443) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:45:34,819] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:45:34,820] {logging_mixin.py:115} INFO - [2023-01-06 22:45:34,819] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:45:35,800] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:45:35,802] {logging_mixin.py:115} INFO - [2023-01-06 22:45:35,801] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:45:35,802] {logging_mixin.py:115} INFO - [2023-01-06 22:45:35,802] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:45:35,809] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:45:35,831] {logging_mixin.py:115} INFO - [2023-01-06 22:45:35,831] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:45:35,851] {logging_mixin.py:115} INFO - [2023-01-06 22:45:35,851] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:45:35,860] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.047 seconds
[2023-01-06 22:46:05,928] {processor.py:153} INFO - Started process (PID=3468) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:46:05,929] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:46:05,930] {logging_mixin.py:115} INFO - [2023-01-06 22:46:05,930] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:46:06,788] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:46:06,789] {logging_mixin.py:115} INFO - [2023-01-06 22:46:06,789] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:46:06,790] {logging_mixin.py:115} INFO - [2023-01-06 22:46:06,790] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:46:06,797] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:46:06,819] {logging_mixin.py:115} INFO - [2023-01-06 22:46:06,818] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:46:06,839] {logging_mixin.py:115} INFO - [2023-01-06 22:46:06,838] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:46:06,848] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.924 seconds
[2023-01-06 22:46:36,910] {processor.py:153} INFO - Started process (PID=3493) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:46:36,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:46:36,912] {logging_mixin.py:115} INFO - [2023-01-06 22:46:36,911] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:46:37,799] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:46:37,801] {logging_mixin.py:115} INFO - [2023-01-06 22:46:37,800] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:46:37,801] {logging_mixin.py:115} INFO - [2023-01-06 22:46:37,801] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:46:37,808] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:46:37,829] {logging_mixin.py:115} INFO - [2023-01-06 22:46:37,828] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:46:37,849] {logging_mixin.py:115} INFO - [2023-01-06 22:46:37,849] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:46:37,857] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.952 seconds
[2023-01-06 22:47:07,942] {processor.py:153} INFO - Started process (PID=3518) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:47:07,943] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:47:07,944] {logging_mixin.py:115} INFO - [2023-01-06 22:47:07,944] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:47:08,831] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:47:08,832] {logging_mixin.py:115} INFO - [2023-01-06 22:47:08,832] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:47:08,832] {logging_mixin.py:115} INFO - [2023-01-06 22:47:08,832] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:47:08,839] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:47:08,861] {logging_mixin.py:115} INFO - [2023-01-06 22:47:08,860] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:47:08,881] {logging_mixin.py:115} INFO - [2023-01-06 22:47:08,881] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:47:08,892] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.956 seconds
[2023-01-06 22:47:38,966] {processor.py:153} INFO - Started process (PID=3544) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:47:38,967] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:47:38,968] {logging_mixin.py:115} INFO - [2023-01-06 22:47:38,968] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:47:39,822] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:47:39,823] {logging_mixin.py:115} INFO - [2023-01-06 22:47:39,823] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:47:39,824] {logging_mixin.py:115} INFO - [2023-01-06 22:47:39,823] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:47:39,830] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:47:39,855] {logging_mixin.py:115} INFO - [2023-01-06 22:47:39,855] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:47:39,876] {logging_mixin.py:115} INFO - [2023-01-06 22:47:39,876] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:47:39,886] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.924 seconds
[2023-01-06 22:48:09,955] {processor.py:153} INFO - Started process (PID=3562) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:48:09,957] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:48:09,957] {logging_mixin.py:115} INFO - [2023-01-06 22:48:09,957] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:48:10,846] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:48:10,847] {logging_mixin.py:115} INFO - [2023-01-06 22:48:10,847] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:48:10,847] {logging_mixin.py:115} INFO - [2023-01-06 22:48:10,847] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:48:10,854] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:48:10,876] {logging_mixin.py:115} INFO - [2023-01-06 22:48:10,876] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:48:10,898] {logging_mixin.py:115} INFO - [2023-01-06 22:48:10,898] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:48:10,907] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.956 seconds
[2023-01-06 22:48:40,974] {processor.py:153} INFO - Started process (PID=3587) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:48:40,976] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:48:40,976] {logging_mixin.py:115} INFO - [2023-01-06 22:48:40,976] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:48:41,864] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:48:41,866] {logging_mixin.py:115} INFO - [2023-01-06 22:48:41,866] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:48:41,866] {logging_mixin.py:115} INFO - [2023-01-06 22:48:41,866] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:48:41,878] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:48:41,901] {logging_mixin.py:115} INFO - [2023-01-06 22:48:41,901] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:48:41,922] {logging_mixin.py:115} INFO - [2023-01-06 22:48:41,922] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:48:41,931] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.962 seconds
[2023-01-06 22:49:12,008] {processor.py:153} INFO - Started process (PID=3612) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:49:12,009] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:49:12,009] {logging_mixin.py:115} INFO - [2023-01-06 22:49:12,009] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:49:12,859] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:49:12,860] {logging_mixin.py:115} INFO - [2023-01-06 22:49:12,860] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:49:12,861] {logging_mixin.py:115} INFO - [2023-01-06 22:49:12,860] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:49:12,867] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:49:12,889] {logging_mixin.py:115} INFO - [2023-01-06 22:49:12,888] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:49:12,909] {logging_mixin.py:115} INFO - [2023-01-06 22:49:12,909] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:49:12,918] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.914 seconds
[2023-01-06 22:49:42,992] {processor.py:153} INFO - Started process (PID=3637) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:49:42,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:49:42,994] {logging_mixin.py:115} INFO - [2023-01-06 22:49:42,994] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:49:43,900] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:49:43,902] {logging_mixin.py:115} INFO - [2023-01-06 22:49:43,901] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:49:43,902] {logging_mixin.py:115} INFO - [2023-01-06 22:49:43,902] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:49:43,909] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:49:43,930] {logging_mixin.py:115} INFO - [2023-01-06 22:49:43,930] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:49:43,950] {logging_mixin.py:115} INFO - [2023-01-06 22:49:43,949] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:49:43,959] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.973 seconds
[2023-01-06 22:50:14,055] {processor.py:153} INFO - Started process (PID=3655) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:50:14,057] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:50:14,058] {logging_mixin.py:115} INFO - [2023-01-06 22:50:14,057] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:50:15,220] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:50:15,221] {logging_mixin.py:115} INFO - [2023-01-06 22:50:15,221] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:50:15,222] {logging_mixin.py:115} INFO - [2023-01-06 22:50:15,221] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:50:15,228] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:50:15,250] {logging_mixin.py:115} INFO - [2023-01-06 22:50:15,250] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:50:15,271] {logging_mixin.py:115} INFO - [2023-01-06 22:50:15,271] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:50:15,281] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.232 seconds
[2023-01-06 22:50:45,314] {processor.py:153} INFO - Started process (PID=3680) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:50:45,314] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:50:45,315] {logging_mixin.py:115} INFO - [2023-01-06 22:50:45,315] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:50:46,168] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:50:46,169] {logging_mixin.py:115} INFO - [2023-01-06 22:50:46,169] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:50:46,170] {logging_mixin.py:115} INFO - [2023-01-06 22:50:46,169] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:50:46,176] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:50:46,198] {logging_mixin.py:115} INFO - [2023-01-06 22:50:46,197] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:50:46,218] {logging_mixin.py:115} INFO - [2023-01-06 22:50:46,218] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:50:46,226] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.917 seconds
[2023-01-06 22:51:16,361] {processor.py:153} INFO - Started process (PID=3706) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:51:16,362] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:51:16,362] {logging_mixin.py:115} INFO - [2023-01-06 22:51:16,362] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:51:17,219] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:51:17,221] {logging_mixin.py:115} INFO - [2023-01-06 22:51:17,220] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:51:17,221] {logging_mixin.py:115} INFO - [2023-01-06 22:51:17,221] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:51:17,228] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:51:17,249] {logging_mixin.py:115} INFO - [2023-01-06 22:51:17,248] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:51:17,269] {logging_mixin.py:115} INFO - [2023-01-06 22:51:17,269] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:51:17,278] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.922 seconds
[2023-01-06 22:51:47,348] {processor.py:153} INFO - Started process (PID=3730) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:51:47,350] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:51:47,350] {logging_mixin.py:115} INFO - [2023-01-06 22:51:47,350] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:51:48,201] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:51:48,202] {logging_mixin.py:115} INFO - [2023-01-06 22:51:48,202] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:51:48,203] {logging_mixin.py:115} INFO - [2023-01-06 22:51:48,203] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:51:48,210] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:51:48,231] {logging_mixin.py:115} INFO - [2023-01-06 22:51:48,231] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:51:48,251] {logging_mixin.py:115} INFO - [2023-01-06 22:51:48,251] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:51:48,260] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.917 seconds
[2023-01-06 22:52:18,326] {processor.py:153} INFO - Started process (PID=3747) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:52:18,327] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:52:18,328] {logging_mixin.py:115} INFO - [2023-01-06 22:52:18,327] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:52:19,180] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:52:19,181] {logging_mixin.py:115} INFO - [2023-01-06 22:52:19,181] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:52:19,182] {logging_mixin.py:115} INFO - [2023-01-06 22:52:19,181] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:52:19,188] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:52:19,210] {logging_mixin.py:115} INFO - [2023-01-06 22:52:19,209] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:52:19,229] {logging_mixin.py:115} INFO - [2023-01-06 22:52:19,229] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:52:19,239] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.917 seconds
[2023-01-06 22:52:49,307] {processor.py:153} INFO - Started process (PID=3772) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:52:49,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:52:49,309] {logging_mixin.py:115} INFO - [2023-01-06 22:52:49,309] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:52:50,171] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:52:50,172] {logging_mixin.py:115} INFO - [2023-01-06 22:52:50,172] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:52:50,172] {logging_mixin.py:115} INFO - [2023-01-06 22:52:50,172] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:52:50,179] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:52:50,200] {logging_mixin.py:115} INFO - [2023-01-06 22:52:50,199] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:52:50,219] {logging_mixin.py:115} INFO - [2023-01-06 22:52:50,219] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:52:50,228] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.926 seconds
[2023-01-06 22:53:20,294] {processor.py:153} INFO - Started process (PID=3799) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:53:20,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:53:20,295] {logging_mixin.py:115} INFO - [2023-01-06 22:53:20,295] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:53:21,207] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:53:21,208] {logging_mixin.py:115} INFO - [2023-01-06 22:53:21,208] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:53:21,209] {logging_mixin.py:115} INFO - [2023-01-06 22:53:21,208] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:53:21,215] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:53:21,237] {logging_mixin.py:115} INFO - [2023-01-06 22:53:21,237] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:53:21,257] {logging_mixin.py:115} INFO - [2023-01-06 22:53:21,257] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:53:21,266] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.977 seconds
[2023-01-06 22:53:51,341] {processor.py:153} INFO - Started process (PID=3824) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:53:51,345] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:53:51,345] {logging_mixin.py:115} INFO - [2023-01-06 22:53:51,345] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:53:52,229] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:53:52,230] {logging_mixin.py:115} INFO - [2023-01-06 22:53:52,230] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:53:52,230] {logging_mixin.py:115} INFO - [2023-01-06 22:53:52,230] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:53:52,237] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:53:52,258] {logging_mixin.py:115} INFO - [2023-01-06 22:53:52,258] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:53:52,278] {logging_mixin.py:115} INFO - [2023-01-06 22:53:52,278] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:53:52,290] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.954 seconds
[2023-01-06 22:54:22,357] {processor.py:153} INFO - Started process (PID=3842) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:54:22,358] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:54:22,359] {logging_mixin.py:115} INFO - [2023-01-06 22:54:22,359] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:54:23,239] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:54:23,241] {logging_mixin.py:115} INFO - [2023-01-06 22:54:23,241] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:54:23,241] {logging_mixin.py:115} INFO - [2023-01-06 22:54:23,241] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:54:23,248] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:54:23,270] {logging_mixin.py:115} INFO - [2023-01-06 22:54:23,270] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:54:23,291] {logging_mixin.py:115} INFO - [2023-01-06 22:54:23,291] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:54:23,301] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.948 seconds
[2023-01-06 22:54:53,383] {processor.py:153} INFO - Started process (PID=3867) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:54:53,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:54:53,385] {logging_mixin.py:115} INFO - [2023-01-06 22:54:53,385] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:54:54,234] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:54:54,235] {logging_mixin.py:115} INFO - [2023-01-06 22:54:54,235] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:54:54,236] {logging_mixin.py:115} INFO - [2023-01-06 22:54:54,235] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:54:54,242] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:54:54,263] {logging_mixin.py:115} INFO - [2023-01-06 22:54:54,263] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:54:54,283] {logging_mixin.py:115} INFO - [2023-01-06 22:54:54,283] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:54:54,292] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.915 seconds
[2023-01-06 22:55:24,381] {processor.py:153} INFO - Started process (PID=3892) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:55:24,382] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:55:24,383] {logging_mixin.py:115} INFO - [2023-01-06 22:55:24,382] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:55:25,260] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:55:25,261] {logging_mixin.py:115} INFO - [2023-01-06 22:55:25,261] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:55:25,262] {logging_mixin.py:115} INFO - [2023-01-06 22:55:25,261] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:55:25,268] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:55:25,289] {logging_mixin.py:115} INFO - [2023-01-06 22:55:25,289] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:55:25,309] {logging_mixin.py:115} INFO - [2023-01-06 22:55:25,309] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:55:25,318] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.941 seconds
[2023-01-06 22:55:55,423] {processor.py:153} INFO - Started process (PID=3917) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:55:55,424] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:55:55,425] {logging_mixin.py:115} INFO - [2023-01-06 22:55:55,425] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:55:56,288] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:55:56,289] {logging_mixin.py:115} INFO - [2023-01-06 22:55:56,289] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:55:56,289] {logging_mixin.py:115} INFO - [2023-01-06 22:55:56,289] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:55:56,296] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:55:56,317] {logging_mixin.py:115} INFO - [2023-01-06 22:55:56,317] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:55:56,337] {logging_mixin.py:115} INFO - [2023-01-06 22:55:56,337] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:55:56,346] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.927 seconds
[2023-01-06 22:56:26,436] {processor.py:153} INFO - Started process (PID=3941) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:56:26,437] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:56:26,437] {logging_mixin.py:115} INFO - [2023-01-06 22:56:26,437] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:56:27,298] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:56:27,299] {logging_mixin.py:115} INFO - [2023-01-06 22:56:27,299] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:56:27,299] {logging_mixin.py:115} INFO - [2023-01-06 22:56:27,299] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:56:27,306] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:56:27,335] {logging_mixin.py:115} INFO - [2023-01-06 22:56:27,335] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:56:27,363] {logging_mixin.py:115} INFO - [2023-01-06 22:56:27,363] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:56:27,372] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.940 seconds
[2023-01-06 22:56:57,490] {processor.py:153} INFO - Started process (PID=3959) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:56:57,491] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:56:57,492] {logging_mixin.py:115} INFO - [2023-01-06 22:56:57,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:56:58,355] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:56:58,356] {logging_mixin.py:115} INFO - [2023-01-06 22:56:58,356] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:56:58,356] {logging_mixin.py:115} INFO - [2023-01-06 22:56:58,356] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:56:58,363] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:56:58,384] {logging_mixin.py:115} INFO - [2023-01-06 22:56:58,384] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:56:58,403] {logging_mixin.py:115} INFO - [2023-01-06 22:56:58,403] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:56:58,412] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.926 seconds
[2023-01-06 22:57:28,505] {processor.py:153} INFO - Started process (PID=3983) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:57:28,506] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:57:28,507] {logging_mixin.py:115} INFO - [2023-01-06 22:57:28,507] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:57:29,346] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:57:29,347] {logging_mixin.py:115} INFO - [2023-01-06 22:57:29,347] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:57:29,348] {logging_mixin.py:115} INFO - [2023-01-06 22:57:29,347] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:57:29,354] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:57:29,375] {logging_mixin.py:115} INFO - [2023-01-06 22:57:29,375] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:57:29,395] {logging_mixin.py:115} INFO - [2023-01-06 22:57:29,395] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:57:29,404] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.903 seconds
[2023-01-06 22:57:59,499] {processor.py:153} INFO - Started process (PID=4010) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:57:59,500] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:57:59,501] {logging_mixin.py:115} INFO - [2023-01-06 22:57:59,500] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:58:00,348] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:58:00,349] {logging_mixin.py:115} INFO - [2023-01-06 22:58:00,349] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:58:00,350] {logging_mixin.py:115} INFO - [2023-01-06 22:58:00,350] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:58:00,357] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:58:00,378] {logging_mixin.py:115} INFO - [2023-01-06 22:58:00,377] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:58:00,398] {logging_mixin.py:115} INFO - [2023-01-06 22:58:00,398] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:58:00,407] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.912 seconds
[2023-01-06 22:58:30,497] {processor.py:153} INFO - Started process (PID=4036) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:58:30,498] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:58:30,499] {logging_mixin.py:115} INFO - [2023-01-06 22:58:30,499] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:58:31,354] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:58:31,356] {logging_mixin.py:115} INFO - [2023-01-06 22:58:31,356] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:58:31,357] {logging_mixin.py:115} INFO - [2023-01-06 22:58:31,356] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:58:31,364] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:58:31,387] {logging_mixin.py:115} INFO - [2023-01-06 22:58:31,387] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:58:31,409] {logging_mixin.py:115} INFO - [2023-01-06 22:58:31,409] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:58:31,421] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.928 seconds
[2023-01-06 22:59:01,489] {processor.py:153} INFO - Started process (PID=4053) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:59:01,490] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:59:01,490] {logging_mixin.py:115} INFO - [2023-01-06 22:59:01,490] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:59:02,346] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:59:02,347] {logging_mixin.py:115} INFO - [2023-01-06 22:59:02,347] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:59:02,347] {logging_mixin.py:115} INFO - [2023-01-06 22:59:02,347] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:59:02,354] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:59:02,375] {logging_mixin.py:115} INFO - [2023-01-06 22:59:02,375] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:59:02,395] {logging_mixin.py:115} INFO - [2023-01-06 22:59:02,395] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:59:02,404] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.920 seconds
[2023-01-06 22:59:32,601] {processor.py:153} INFO - Started process (PID=4077) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:59:32,601] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:59:32,602] {logging_mixin.py:115} INFO - [2023-01-06 22:59:32,602] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:59:33,445] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:59:33,446] {logging_mixin.py:115} INFO - [2023-01-06 22:59:33,446] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:59:33,447] {logging_mixin.py:115} INFO - [2023-01-06 22:59:33,447] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:59:33,453] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 22:59:33,475] {logging_mixin.py:115} INFO - [2023-01-06 22:59:33,474] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:59:33,494] {logging_mixin.py:115} INFO - [2023-01-06 22:59:33,494] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 22:59:33,503] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.907 seconds
[2023-01-06 23:00:03,573] {processor.py:153} INFO - Started process (PID=4102) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:00:03,573] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:00:03,574] {logging_mixin.py:115} INFO - [2023-01-06 23:00:03,574] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:00:04,446] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:00:04,447] {logging_mixin.py:115} INFO - [2023-01-06 23:00:04,447] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:00:04,447] {logging_mixin.py:115} INFO - [2023-01-06 23:00:04,447] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:00:04,454] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:00:04,475] {logging_mixin.py:115} INFO - [2023-01-06 23:00:04,475] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:00:04,496] {logging_mixin.py:115} INFO - [2023-01-06 23:00:04,496] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:00:04,505] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.937 seconds
[2023-01-06 23:00:34,589] {processor.py:153} INFO - Started process (PID=4126) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:00:34,590] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:00:34,591] {logging_mixin.py:115} INFO - [2023-01-06 23:00:34,591] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:00:35,482] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:00:35,483] {logging_mixin.py:115} INFO - [2023-01-06 23:00:35,483] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:00:35,484] {logging_mixin.py:115} INFO - [2023-01-06 23:00:35,484] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:00:35,490] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:00:35,512] {logging_mixin.py:115} INFO - [2023-01-06 23:00:35,512] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:00:35,532] {logging_mixin.py:115} INFO - [2023-01-06 23:00:35,532] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:00:35,541] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.957 seconds
[2023-01-06 23:01:05,611] {processor.py:153} INFO - Started process (PID=4145) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:01:05,615] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:01:05,615] {logging_mixin.py:115} INFO - [2023-01-06 23:01:05,615] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:01:06,491] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:01:06,493] {logging_mixin.py:115} INFO - [2023-01-06 23:01:06,493] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:01:06,493] {logging_mixin.py:115} INFO - [2023-01-06 23:01:06,493] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:01:06,500] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:01:06,521] {logging_mixin.py:115} INFO - [2023-01-06 23:01:06,521] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:01:06,541] {logging_mixin.py:115} INFO - [2023-01-06 23:01:06,541] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:01:06,551] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.945 seconds
[2023-01-06 23:01:36,626] {processor.py:153} INFO - Started process (PID=4172) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:01:36,627] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:01:36,628] {logging_mixin.py:115} INFO - [2023-01-06 23:01:36,628] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:01:37,490] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:01:37,491] {logging_mixin.py:115} INFO - [2023-01-06 23:01:37,491] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:01:37,492] {logging_mixin.py:115} INFO - [2023-01-06 23:01:37,492] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:01:37,499] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:01:37,523] {logging_mixin.py:115} INFO - [2023-01-06 23:01:37,523] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:01:37,549] {logging_mixin.py:115} INFO - [2023-01-06 23:01:37,549] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:01:37,559] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.938 seconds
[2023-01-06 23:02:07,635] {processor.py:153} INFO - Started process (PID=4196) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:02:07,636] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:02:07,636] {logging_mixin.py:115} INFO - [2023-01-06 23:02:07,636] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:02:08,478] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:02:08,480] {logging_mixin.py:115} INFO - [2023-01-06 23:02:08,479] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:02:08,480] {logging_mixin.py:115} INFO - [2023-01-06 23:02:08,480] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:02:08,487] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:02:08,508] {logging_mixin.py:115} INFO - [2023-01-06 23:02:08,508] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:02:08,528] {logging_mixin.py:115} INFO - [2023-01-06 23:02:08,528] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:02:08,538] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.908 seconds
[2023-01-06 23:02:38,632] {processor.py:153} INFO - Started process (PID=4222) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:02:38,633] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:02:38,633] {logging_mixin.py:115} INFO - [2023-01-06 23:02:38,633] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:02:39,477] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:02:39,479] {logging_mixin.py:115} INFO - [2023-01-06 23:02:39,478] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:02:39,479] {logging_mixin.py:115} INFO - [2023-01-06 23:02:39,479] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:02:39,486] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:02:39,507] {logging_mixin.py:115} INFO - [2023-01-06 23:02:39,507] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:02:39,527] {logging_mixin.py:115} INFO - [2023-01-06 23:02:39,527] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:02:39,536] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.909 seconds
[2023-01-06 23:03:09,904] {processor.py:153} INFO - Started process (PID=4241) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:03:09,905] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:03:09,905] {logging_mixin.py:115} INFO - [2023-01-06 23:03:09,905] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:03:10,764] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:03:10,765] {logging_mixin.py:115} INFO - [2023-01-06 23:03:10,765] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:03:10,765] {logging_mixin.py:115} INFO - [2023-01-06 23:03:10,765] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:03:10,772] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:03:10,794] {logging_mixin.py:115} INFO - [2023-01-06 23:03:10,794] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:03:10,814] {logging_mixin.py:115} INFO - [2023-01-06 23:03:10,814] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:03:10,826] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.927 seconds
[2023-01-06 23:03:40,923] {processor.py:153} INFO - Started process (PID=4264) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:03:40,924] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:03:40,924] {logging_mixin.py:115} INFO - [2023-01-06 23:03:40,924] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:03:41,777] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:03:41,778] {logging_mixin.py:115} INFO - [2023-01-06 23:03:41,778] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:03:41,778] {logging_mixin.py:115} INFO - [2023-01-06 23:03:41,778] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:03:41,785] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:03:41,806] {logging_mixin.py:115} INFO - [2023-01-06 23:03:41,806] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:03:41,826] {logging_mixin.py:115} INFO - [2023-01-06 23:03:41,826] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:03:41,835] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.916 seconds
[2023-01-06 23:04:11,904] {processor.py:153} INFO - Started process (PID=4289) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:04:11,905] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:04:11,906] {logging_mixin.py:115} INFO - [2023-01-06 23:04:11,906] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:04:12,772] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:04:12,773] {logging_mixin.py:115} INFO - [2023-01-06 23:04:12,773] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:04:12,774] {logging_mixin.py:115} INFO - [2023-01-06 23:04:12,774] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:04:12,781] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:04:12,809] {logging_mixin.py:115} INFO - [2023-01-06 23:04:12,808] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:04:12,839] {logging_mixin.py:115} INFO - [2023-01-06 23:04:12,839] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:04:12,849] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.950 seconds
[2023-01-06 23:04:43,075] {processor.py:153} INFO - Started process (PID=4314) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:04:43,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:04:43,076] {logging_mixin.py:115} INFO - [2023-01-06 23:04:43,076] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:04:43,945] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:04:43,946] {logging_mixin.py:115} INFO - [2023-01-06 23:04:43,946] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:04:43,946] {logging_mixin.py:115} INFO - [2023-01-06 23:04:43,946] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:04:43,953] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:04:43,974] {logging_mixin.py:115} INFO - [2023-01-06 23:04:43,974] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:04:43,994] {logging_mixin.py:115} INFO - [2023-01-06 23:04:43,994] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:04:44,003] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.933 seconds
[2023-01-06 23:05:14,073] {processor.py:153} INFO - Started process (PID=4332) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:05:14,074] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:05:14,074] {logging_mixin.py:115} INFO - [2023-01-06 23:05:14,074] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:05:14,961] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:05:14,963] {logging_mixin.py:115} INFO - [2023-01-06 23:05:14,963] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:05:14,963] {logging_mixin.py:115} INFO - [2023-01-06 23:05:14,963] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:05:14,970] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:05:14,991] {logging_mixin.py:115} INFO - [2023-01-06 23:05:14,991] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:05:15,012] {logging_mixin.py:115} INFO - [2023-01-06 23:05:15,011] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:05:15,021] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.952 seconds
[2023-01-06 23:05:45,087] {processor.py:153} INFO - Started process (PID=4356) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:05:45,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:05:45,089] {logging_mixin.py:115} INFO - [2023-01-06 23:05:45,089] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:05:45,939] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:05:45,940] {logging_mixin.py:115} INFO - [2023-01-06 23:05:45,940] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:05:45,940] {logging_mixin.py:115} INFO - [2023-01-06 23:05:45,940] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:05:45,947] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:05:45,968] {logging_mixin.py:115} INFO - [2023-01-06 23:05:45,967] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:05:45,988] {logging_mixin.py:115} INFO - [2023-01-06 23:05:45,988] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:05:45,997] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.914 seconds
[2023-01-06 23:06:16,063] {processor.py:153} INFO - Started process (PID=4382) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:06:16,065] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:06:16,065] {logging_mixin.py:115} INFO - [2023-01-06 23:06:16,065] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:06:16,906] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:06:16,907] {logging_mixin.py:115} INFO - [2023-01-06 23:06:16,907] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:06:16,907] {logging_mixin.py:115} INFO - [2023-01-06 23:06:16,907] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:06:16,914] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:06:16,935] {logging_mixin.py:115} INFO - [2023-01-06 23:06:16,935] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:06:16,955] {logging_mixin.py:115} INFO - [2023-01-06 23:06:16,955] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:06:16,964] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.906 seconds
[2023-01-06 23:06:47,034] {processor.py:153} INFO - Started process (PID=4407) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:06:47,036] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:06:47,036] {logging_mixin.py:115} INFO - [2023-01-06 23:06:47,036] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:06:47,880] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:06:47,881] {logging_mixin.py:115} INFO - [2023-01-06 23:06:47,881] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:06:47,881] {logging_mixin.py:115} INFO - [2023-01-06 23:06:47,881] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:06:47,888] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:06:47,910] {logging_mixin.py:115} INFO - [2023-01-06 23:06:47,910] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:06:47,930] {logging_mixin.py:115} INFO - [2023-01-06 23:06:47,930] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:06:47,939] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.910 seconds
[2023-01-06 23:07:18,014] {processor.py:153} INFO - Started process (PID=4433) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:07:18,015] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:07:18,015] {logging_mixin.py:115} INFO - [2023-01-06 23:07:18,015] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:07:18,893] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:07:18,895] {logging_mixin.py:115} INFO - [2023-01-06 23:07:18,894] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:07:18,895] {logging_mixin.py:115} INFO - [2023-01-06 23:07:18,895] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:07:18,902] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:07:18,923] {logging_mixin.py:115} INFO - [2023-01-06 23:07:18,923] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:07:18,948] {logging_mixin.py:115} INFO - [2023-01-06 23:07:18,948] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:07:18,957] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.949 seconds
[2023-01-06 23:07:49,041] {processor.py:153} INFO - Started process (PID=4451) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:07:49,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:07:49,042] {logging_mixin.py:115} INFO - [2023-01-06 23:07:49,042] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:07:49,901] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:07:49,902] {logging_mixin.py:115} INFO - [2023-01-06 23:07:49,902] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:07:49,903] {logging_mixin.py:115} INFO - [2023-01-06 23:07:49,903] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:07:49,912] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:07:49,936] {logging_mixin.py:115} INFO - [2023-01-06 23:07:49,936] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:07:49,956] {logging_mixin.py:115} INFO - [2023-01-06 23:07:49,956] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:07:49,966] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.931 seconds
[2023-01-06 23:08:20,062] {processor.py:153} INFO - Started process (PID=4477) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:08:20,063] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:08:20,063] {logging_mixin.py:115} INFO - [2023-01-06 23:08:20,063] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:08:20,924] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:08:20,926] {logging_mixin.py:115} INFO - [2023-01-06 23:08:20,925] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:08:20,926] {logging_mixin.py:115} INFO - [2023-01-06 23:08:20,926] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:08:20,933] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:08:20,955] {logging_mixin.py:115} INFO - [2023-01-06 23:08:20,954] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:08:20,976] {logging_mixin.py:115} INFO - [2023-01-06 23:08:20,975] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:08:20,984] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.928 seconds
[2023-01-06 23:08:51,080] {processor.py:153} INFO - Started process (PID=4502) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:08:51,083] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:08:51,084] {logging_mixin.py:115} INFO - [2023-01-06 23:08:51,084] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:08:51,953] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:08:51,954] {logging_mixin.py:115} INFO - [2023-01-06 23:08:51,954] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:08:51,954] {logging_mixin.py:115} INFO - [2023-01-06 23:08:51,954] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:08:51,961] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:08:51,982] {logging_mixin.py:115} INFO - [2023-01-06 23:08:51,982] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:08:52,002] {logging_mixin.py:115} INFO - [2023-01-06 23:08:52,002] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:08:52,011] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.937 seconds
[2023-01-06 23:09:22,106] {processor.py:153} INFO - Started process (PID=4528) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:09:22,108] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:09:22,108] {logging_mixin.py:115} INFO - [2023-01-06 23:09:22,108] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:09:22,988] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:09:22,989] {logging_mixin.py:115} INFO - [2023-01-06 23:09:22,989] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:09:22,990] {logging_mixin.py:115} INFO - [2023-01-06 23:09:22,989] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:09:22,996] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:09:23,018] {logging_mixin.py:115} INFO - [2023-01-06 23:09:23,018] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:09:23,040] {logging_mixin.py:115} INFO - [2023-01-06 23:09:23,040] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:09:23,049] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.948 seconds
[2023-01-06 23:09:53,124] {processor.py:153} INFO - Started process (PID=4546) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:09:53,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:09:53,126] {logging_mixin.py:115} INFO - [2023-01-06 23:09:53,126] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:09:53,976] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:09:53,977] {logging_mixin.py:115} INFO - [2023-01-06 23:09:53,977] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:09:53,978] {logging_mixin.py:115} INFO - [2023-01-06 23:09:53,977] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:09:53,984] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:09:54,006] {logging_mixin.py:115} INFO - [2023-01-06 23:09:54,006] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:09:54,026] {logging_mixin.py:115} INFO - [2023-01-06 23:09:54,026] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:09:54,035] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.916 seconds
[2023-01-06 23:10:24,279] {processor.py:153} INFO - Started process (PID=4572) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:10:24,280] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:10:24,281] {logging_mixin.py:115} INFO - [2023-01-06 23:10:24,281] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:10:25,126] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:10:25,127] {logging_mixin.py:115} INFO - [2023-01-06 23:10:25,127] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:10:25,128] {logging_mixin.py:115} INFO - [2023-01-06 23:10:25,127] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:10:25,134] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:10:25,155] {logging_mixin.py:115} INFO - [2023-01-06 23:10:25,155] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:10:25,175] {logging_mixin.py:115} INFO - [2023-01-06 23:10:25,175] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:10:25,184] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.910 seconds
[2023-01-06 23:10:55,250] {processor.py:153} INFO - Started process (PID=4599) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:10:55,252] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:10:55,252] {logging_mixin.py:115} INFO - [2023-01-06 23:10:55,252] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:10:56,111] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:10:56,112] {logging_mixin.py:115} INFO - [2023-01-06 23:10:56,112] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:10:56,113] {logging_mixin.py:115} INFO - [2023-01-06 23:10:56,112] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:10:56,120] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:10:56,142] {logging_mixin.py:115} INFO - [2023-01-06 23:10:56,142] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:10:56,162] {logging_mixin.py:115} INFO - [2023-01-06 23:10:56,162] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:10:56,170] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.925 seconds
[2023-01-06 23:11:26,241] {processor.py:153} INFO - Started process (PID=4625) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:11:26,241] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:11:26,242] {logging_mixin.py:115} INFO - [2023-01-06 23:11:26,242] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:11:27,101] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:11:27,102] {logging_mixin.py:115} INFO - [2023-01-06 23:11:27,102] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:11:27,102] {logging_mixin.py:115} INFO - [2023-01-06 23:11:27,102] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:11:27,109] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:11:27,130] {logging_mixin.py:115} INFO - [2023-01-06 23:11:27,130] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:11:27,150] {logging_mixin.py:115} INFO - [2023-01-06 23:11:27,150] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:11:27,159] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.923 seconds
[2023-01-06 23:11:57,224] {processor.py:153} INFO - Started process (PID=4643) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:11:57,225] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:11:57,226] {logging_mixin.py:115} INFO - [2023-01-06 23:11:57,226] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:11:58,084] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:11:58,085] {logging_mixin.py:115} INFO - [2023-01-06 23:11:58,085] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:11:58,086] {logging_mixin.py:115} INFO - [2023-01-06 23:11:58,085] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:11:58,092] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:11:58,114] {logging_mixin.py:115} INFO - [2023-01-06 23:11:58,113] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:11:58,134] {logging_mixin.py:115} INFO - [2023-01-06 23:11:58,134] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:11:58,143] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.924 seconds
[2023-01-06 23:12:28,212] {processor.py:153} INFO - Started process (PID=4669) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:12:28,213] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:12:28,213] {logging_mixin.py:115} INFO - [2023-01-06 23:12:28,213] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:12:29,108] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:12:29,110] {logging_mixin.py:115} INFO - [2023-01-06 23:12:29,109] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:12:29,110] {logging_mixin.py:115} INFO - [2023-01-06 23:12:29,110] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:12:29,117] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:12:29,138] {logging_mixin.py:115} INFO - [2023-01-06 23:12:29,137] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:12:29,158] {logging_mixin.py:115} INFO - [2023-01-06 23:12:29,158] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:12:29,167] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.960 seconds
[2023-01-06 23:12:59,249] {processor.py:153} INFO - Started process (PID=4693) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:12:59,250] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:12:59,251] {logging_mixin.py:115} INFO - [2023-01-06 23:12:59,251] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:13:00,096] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:13:00,098] {logging_mixin.py:115} INFO - [2023-01-06 23:13:00,098] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:13:00,098] {logging_mixin.py:115} INFO - [2023-01-06 23:13:00,098] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:13:00,105] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:13:00,126] {logging_mixin.py:115} INFO - [2023-01-06 23:13:00,125] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:13:00,145] {logging_mixin.py:115} INFO - [2023-01-06 23:13:00,145] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:13:00,154] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.910 seconds
[2023-01-06 23:13:30,246] {processor.py:153} INFO - Started process (PID=4717) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:13:30,247] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:13:30,247] {logging_mixin.py:115} INFO - [2023-01-06 23:13:30,247] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:13:31,109] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:13:31,111] {logging_mixin.py:115} INFO - [2023-01-06 23:13:31,111] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:13:31,111] {logging_mixin.py:115} INFO - [2023-01-06 23:13:31,111] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:13:31,118] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:13:31,142] {logging_mixin.py:115} INFO - [2023-01-06 23:13:31,142] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:13:31,162] {logging_mixin.py:115} INFO - [2023-01-06 23:13:31,162] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:13:31,171] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.929 seconds
[2023-01-06 23:14:01,269] {processor.py:153} INFO - Started process (PID=4737) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:14:01,270] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:14:01,271] {logging_mixin.py:115} INFO - [2023-01-06 23:14:01,271] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:14:02,267] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:14:02,268] {logging_mixin.py:115} INFO - [2023-01-06 23:14:02,268] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:14:02,269] {logging_mixin.py:115} INFO - [2023-01-06 23:14:02,269] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:14:02,280] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:14:02,310] {logging_mixin.py:115} INFO - [2023-01-06 23:14:02,310] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:14:02,339] {logging_mixin.py:115} INFO - [2023-01-06 23:14:02,339] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:14:02,351] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.087 seconds
[2023-01-06 23:14:32,419] {processor.py:153} INFO - Started process (PID=4762) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:14:32,420] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:14:32,421] {logging_mixin.py:115} INFO - [2023-01-06 23:14:32,421] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:14:33,259] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:14:33,260] {logging_mixin.py:115} INFO - [2023-01-06 23:14:33,260] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:14:33,261] {logging_mixin.py:115} INFO - [2023-01-06 23:14:33,260] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:14:33,267] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:14:33,289] {logging_mixin.py:115} INFO - [2023-01-06 23:14:33,289] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:14:33,309] {logging_mixin.py:115} INFO - [2023-01-06 23:14:33,309] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-06 23:14:33,318] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.904 seconds
[2023-01-06 23:15:03,388] {processor.py:153} INFO - Started process (PID=4788) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:15:03,389] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:15:03,389] {logging_mixin.py:115} INFO - [2023-01-06 23:15:03,389] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:15:04,253] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:15:04,254] {logging_mixin.py:115} INFO - [2023-01-06 23:15:04,254] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:15:04,255] {logging_mixin.py:115} INFO - [2023-01-06 23:15:04,255] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:15:04,261] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:15:04,282] {logging_mixin.py:115} INFO - [2023-01-06 23:15:04,282] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:15:04,313] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.929 seconds
[2023-01-06 23:15:34,380] {processor.py:153} INFO - Started process (PID=4813) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:15:34,381] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:15:34,382] {logging_mixin.py:115} INFO - [2023-01-06 23:15:34,382] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:15:35,242] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:15:35,244] {logging_mixin.py:115} INFO - [2023-01-06 23:15:35,244] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:15:35,244] {logging_mixin.py:115} INFO - [2023-01-06 23:15:35,244] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:15:35,251] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:15:35,283] {logging_mixin.py:115} INFO - [2023-01-06 23:15:35,283] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:15:35,312] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.936 seconds
[2023-01-06 23:16:05,380] {processor.py:153} INFO - Started process (PID=4831) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:16:05,381] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:16:05,382] {logging_mixin.py:115} INFO - [2023-01-06 23:16:05,382] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:16:06,267] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:16:06,268] {logging_mixin.py:115} INFO - [2023-01-06 23:16:06,268] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:16:06,269] {logging_mixin.py:115} INFO - [2023-01-06 23:16:06,269] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:16:06,276] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:16:06,304] {logging_mixin.py:115} INFO - [2023-01-06 23:16:06,303] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:16:06,339] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.963 seconds
[2023-01-06 23:16:36,407] {processor.py:153} INFO - Started process (PID=4855) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:16:36,409] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:16:36,409] {logging_mixin.py:115} INFO - [2023-01-06 23:16:36,409] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:16:37,291] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:16:37,292] {logging_mixin.py:115} INFO - [2023-01-06 23:16:37,292] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:16:37,292] {logging_mixin.py:115} INFO - [2023-01-06 23:16:37,292] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:16:37,299] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:16:37,320] {logging_mixin.py:115} INFO - [2023-01-06 23:16:37,320] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:16:37,347] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.945 seconds
[2023-01-06 23:17:07,417] {processor.py:153} INFO - Started process (PID=4881) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:17:07,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:17:07,419] {logging_mixin.py:115} INFO - [2023-01-06 23:17:07,419] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:17:08,290] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:17:08,291] {logging_mixin.py:115} INFO - [2023-01-06 23:17:08,291] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:17:08,292] {logging_mixin.py:115} INFO - [2023-01-06 23:17:08,292] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:17:08,299] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:17:08,320] {logging_mixin.py:115} INFO - [2023-01-06 23:17:08,320] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:17:08,347] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.935 seconds
[2023-01-06 23:17:38,427] {processor.py:153} INFO - Started process (PID=4906) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:17:38,429] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:17:38,429] {logging_mixin.py:115} INFO - [2023-01-06 23:17:38,429] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:17:39,289] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:17:39,290] {logging_mixin.py:115} INFO - [2023-01-06 23:17:39,290] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:17:39,291] {logging_mixin.py:115} INFO - [2023-01-06 23:17:39,290] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:17:39,298] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:17:39,319] {logging_mixin.py:115} INFO - [2023-01-06 23:17:39,319] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:17:39,346] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.925 seconds
[2023-01-06 23:18:09,422] {processor.py:153} INFO - Started process (PID=4924) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:18:09,426] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:18:09,427] {logging_mixin.py:115} INFO - [2023-01-06 23:18:09,426] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:18:10,332] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:18:10,333] {logging_mixin.py:115} INFO - [2023-01-06 23:18:10,333] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:18:10,334] {logging_mixin.py:115} INFO - [2023-01-06 23:18:10,334] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:18:10,341] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:18:10,367] {logging_mixin.py:115} INFO - [2023-01-06 23:18:10,367] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:18:10,402] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.985 seconds
[2023-01-06 23:18:40,484] {processor.py:153} INFO - Started process (PID=4948) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:18:40,485] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:18:40,486] {logging_mixin.py:115} INFO - [2023-01-06 23:18:40,486] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:18:41,352] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:18:41,353] {logging_mixin.py:115} INFO - [2023-01-06 23:18:41,353] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:18:41,354] {logging_mixin.py:115} INFO - [2023-01-06 23:18:41,354] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:18:41,361] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:18:41,383] {logging_mixin.py:115} INFO - [2023-01-06 23:18:41,383] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:18:41,409] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.930 seconds
[2023-01-06 23:19:11,493] {processor.py:153} INFO - Started process (PID=4973) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:19:11,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:19:11,494] {logging_mixin.py:115} INFO - [2023-01-06 23:19:11,494] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:19:12,340] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:19:12,341] {logging_mixin.py:115} INFO - [2023-01-06 23:19:12,341] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:19:12,342] {logging_mixin.py:115} INFO - [2023-01-06 23:19:12,341] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:19:12,351] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:19:12,375] {logging_mixin.py:115} INFO - [2023-01-06 23:19:12,375] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:19:12,401] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.913 seconds
[2023-01-06 23:19:42,467] {processor.py:153} INFO - Started process (PID=5000) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:19:42,469] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:19:42,469] {logging_mixin.py:115} INFO - [2023-01-06 23:19:42,469] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:19:43,326] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:19:43,328] {logging_mixin.py:115} INFO - [2023-01-06 23:19:43,327] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:19:43,328] {logging_mixin.py:115} INFO - [2023-01-06 23:19:43,328] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:19:43,335] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:19:43,356] {logging_mixin.py:115} INFO - [2023-01-06 23:19:43,355] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:19:43,382] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.920 seconds
[2023-01-06 23:20:13,449] {processor.py:153} INFO - Started process (PID=5019) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:20:13,449] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:20:13,450] {logging_mixin.py:115} INFO - [2023-01-06 23:20:13,450] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:20:14,554] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:20:14,556] {logging_mixin.py:115} INFO - [2023-01-06 23:20:14,556] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:20:14,557] {logging_mixin.py:115} INFO - [2023-01-06 23:20:14,556] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:20:14,569] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:20:14,600] {logging_mixin.py:115} INFO - [2023-01-06 23:20:14,599] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:20:14,638] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.194 seconds
[2023-01-06 23:20:44,713] {processor.py:153} INFO - Started process (PID=5045) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:20:44,714] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:20:44,715] {logging_mixin.py:115} INFO - [2023-01-06 23:20:44,715] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:20:45,596] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:20:45,597] {logging_mixin.py:115} INFO - [2023-01-06 23:20:45,597] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:20:45,598] {logging_mixin.py:115} INFO - [2023-01-06 23:20:45,597] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:20:45,604] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:20:45,624] {logging_mixin.py:115} INFO - [2023-01-06 23:20:45,624] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:20:45,650] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.942 seconds
[2023-01-06 23:21:15,720] {processor.py:153} INFO - Started process (PID=5072) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:21:15,721] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:21:15,721] {logging_mixin.py:115} INFO - [2023-01-06 23:21:15,721] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:21:16,588] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:21:16,589] {logging_mixin.py:115} INFO - [2023-01-06 23:21:16,589] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:21:16,590] {logging_mixin.py:115} INFO - [2023-01-06 23:21:16,589] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:21:16,596] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:21:16,618] {logging_mixin.py:115} INFO - [2023-01-06 23:21:16,617] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:21:16,644] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.928 seconds
[2023-01-06 23:21:46,714] {processor.py:153} INFO - Started process (PID=5099) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:21:46,715] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:21:46,715] {logging_mixin.py:115} INFO - [2023-01-06 23:21:46,715] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:21:47,576] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:21:47,577] {logging_mixin.py:115} INFO - [2023-01-06 23:21:47,577] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:21:47,578] {logging_mixin.py:115} INFO - [2023-01-06 23:21:47,577] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:21:47,585] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:21:47,614] {logging_mixin.py:115} INFO - [2023-01-06 23:21:47,613] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:21:47,644] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.935 seconds
[2023-01-06 23:22:17,716] {processor.py:153} INFO - Started process (PID=5118) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:22:17,717] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:22:17,718] {logging_mixin.py:115} INFO - [2023-01-06 23:22:17,718] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:22:18,658] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:22:18,659] {logging_mixin.py:115} INFO - [2023-01-06 23:22:18,659] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:22:18,660] {logging_mixin.py:115} INFO - [2023-01-06 23:22:18,660] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:22:18,672] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:22:18,701] {logging_mixin.py:115} INFO - [2023-01-06 23:22:18,700] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:22:18,727] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.016 seconds
[2023-01-06 23:22:48,801] {processor.py:153} INFO - Started process (PID=5145) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:22:48,802] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:22:48,803] {logging_mixin.py:115} INFO - [2023-01-06 23:22:48,803] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:22:49,735] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:22:49,736] {logging_mixin.py:115} INFO - [2023-01-06 23:22:49,736] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:22:49,737] {logging_mixin.py:115} INFO - [2023-01-06 23:22:49,736] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:22:49,743] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:22:49,764] {logging_mixin.py:115} INFO - [2023-01-06 23:22:49,764] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:22:49,791] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.995 seconds
[2023-01-06 23:23:19,870] {processor.py:153} INFO - Started process (PID=5170) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:23:19,870] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:23:19,871] {logging_mixin.py:115} INFO - [2023-01-06 23:23:19,871] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:23:20,766] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:23:20,767] {logging_mixin.py:115} INFO - [2023-01-06 23:23:20,767] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:23:20,768] {logging_mixin.py:115} INFO - [2023-01-06 23:23:20,768] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:23:20,775] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:23:20,798] {logging_mixin.py:115} INFO - [2023-01-06 23:23:20,798] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:23:20,831] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.966 seconds
[2023-01-06 23:23:50,905] {processor.py:153} INFO - Started process (PID=5195) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:23:50,906] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:23:50,907] {logging_mixin.py:115} INFO - [2023-01-06 23:23:50,907] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:23:51,776] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:23:51,777] {logging_mixin.py:115} INFO - [2023-01-06 23:23:51,777] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:23:51,778] {logging_mixin.py:115} INFO - [2023-01-06 23:23:51,777] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:23:51,784] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:23:51,805] {logging_mixin.py:115} INFO - [2023-01-06 23:23:51,805] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:23:51,830] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.930 seconds
[2023-01-06 23:24:21,907] {processor.py:153} INFO - Started process (PID=5214) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:24:21,909] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:24:21,909] {logging_mixin.py:115} INFO - [2023-01-06 23:24:21,909] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:24:22,792] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:24:22,793] {logging_mixin.py:115} INFO - [2023-01-06 23:24:22,793] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:24:22,793] {logging_mixin.py:115} INFO - [2023-01-06 23:24:22,793] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:24:22,800] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:24:22,827] {logging_mixin.py:115} INFO - [2023-01-06 23:24:22,827] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:24:22,860] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.958 seconds
[2023-01-06 23:24:52,934] {processor.py:153} INFO - Started process (PID=5238) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:24:52,935] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:24:52,936] {logging_mixin.py:115} INFO - [2023-01-06 23:24:52,936] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:24:53,818] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:24:53,820] {logging_mixin.py:115} INFO - [2023-01-06 23:24:53,819] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:24:53,820] {logging_mixin.py:115} INFO - [2023-01-06 23:24:53,820] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:24:53,827] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:24:53,850] {logging_mixin.py:115} INFO - [2023-01-06 23:24:53,849] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:24:53,876] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.946 seconds
[2023-01-06 23:25:23,947] {processor.py:153} INFO - Started process (PID=5263) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:25:23,947] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:25:23,948] {logging_mixin.py:115} INFO - [2023-01-06 23:25:23,948] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:25:24,796] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:25:24,798] {logging_mixin.py:115} INFO - [2023-01-06 23:25:24,798] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:25:24,798] {logging_mixin.py:115} INFO - [2023-01-06 23:25:24,798] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:25:24,805] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:25:24,826] {logging_mixin.py:115} INFO - [2023-01-06 23:25:24,826] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:25:24,853] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.911 seconds
[2023-01-06 23:25:55,533] {processor.py:153} INFO - Started process (PID=5289) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:25:55,537] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:25:55,537] {logging_mixin.py:115} INFO - [2023-01-06 23:25:55,537] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:25:56,409] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:25:56,410] {logging_mixin.py:115} INFO - [2023-01-06 23:25:56,410] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:25:56,411] {logging_mixin.py:115} INFO - [2023-01-06 23:25:56,411] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:25:56,417] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:25:56,439] {logging_mixin.py:115} INFO - [2023-01-06 23:25:56,439] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:25:56,465] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.937 seconds
[2023-01-06 23:26:26,597] {processor.py:153} INFO - Started process (PID=5307) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:26:26,598] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:26:26,599] {logging_mixin.py:115} INFO - [2023-01-06 23:26:26,599] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:26:27,598] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:26:27,600] {logging_mixin.py:115} INFO - [2023-01-06 23:26:27,600] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:26:27,601] {logging_mixin.py:115} INFO - [2023-01-06 23:26:27,600] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:26:27,612] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:26:27,644] {logging_mixin.py:115} INFO - [2023-01-06 23:26:27,644] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:26:27,681] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.089 seconds
[2023-01-06 23:26:57,755] {processor.py:153} INFO - Started process (PID=5331) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:26:57,756] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:26:57,756] {logging_mixin.py:115} INFO - [2023-01-06 23:26:57,756] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:26:58,625] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:26:58,627] {logging_mixin.py:115} INFO - [2023-01-06 23:26:58,627] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:26:58,627] {logging_mixin.py:115} INFO - [2023-01-06 23:26:58,627] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:26:58,634] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:26:58,656] {logging_mixin.py:115} INFO - [2023-01-06 23:26:58,655] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:26:58,684] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.935 seconds
[2023-01-06 23:27:28,754] {processor.py:153} INFO - Started process (PID=5356) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:27:28,757] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:27:28,758] {logging_mixin.py:115} INFO - [2023-01-06 23:27:28,757] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:27:29,639] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:27:29,640] {logging_mixin.py:115} INFO - [2023-01-06 23:27:29,640] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:27:29,641] {logging_mixin.py:115} INFO - [2023-01-06 23:27:29,640] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:27:29,647] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:27:29,668] {logging_mixin.py:115} INFO - [2023-01-06 23:27:29,668] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:27:29,696] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.946 seconds
[2023-01-06 23:27:59,766] {processor.py:153} INFO - Started process (PID=5382) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:27:59,767] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:27:59,767] {logging_mixin.py:115} INFO - [2023-01-06 23:27:59,767] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:28:00,718] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:28:00,720] {logging_mixin.py:115} INFO - [2023-01-06 23:28:00,719] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:28:00,720] {logging_mixin.py:115} INFO - [2023-01-06 23:28:00,720] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:28:00,727] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:28:00,754] {logging_mixin.py:115} INFO - [2023-01-06 23:28:00,754] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:28:00,785] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.024 seconds
[2023-01-06 23:28:30,849] {processor.py:153} INFO - Started process (PID=5401) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:28:30,850] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:28:30,851] {logging_mixin.py:115} INFO - [2023-01-06 23:28:30,851] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:28:31,723] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:28:31,724] {logging_mixin.py:115} INFO - [2023-01-06 23:28:31,724] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:28:31,724] {logging_mixin.py:115} INFO - [2023-01-06 23:28:31,724] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:28:31,731] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:28:31,752] {logging_mixin.py:115} INFO - [2023-01-06 23:28:31,751] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:28:31,779] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.934 seconds
[2023-01-06 23:29:01,848] {processor.py:153} INFO - Started process (PID=5426) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:29:01,850] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:29:01,850] {logging_mixin.py:115} INFO - [2023-01-06 23:29:01,850] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:29:02,725] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:29:02,727] {logging_mixin.py:115} INFO - [2023-01-06 23:29:02,726] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:29:02,727] {logging_mixin.py:115} INFO - [2023-01-06 23:29:02,727] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:29:02,734] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:29:02,755] {logging_mixin.py:115} INFO - [2023-01-06 23:29:02,754] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:29:02,781] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.937 seconds
[2023-01-06 23:29:32,844] {processor.py:153} INFO - Started process (PID=5452) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:29:32,845] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:29:32,846] {logging_mixin.py:115} INFO - [2023-01-06 23:29:32,846] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:29:33,736] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:29:33,738] {logging_mixin.py:115} INFO - [2023-01-06 23:29:33,738] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:29:33,739] {logging_mixin.py:115} INFO - [2023-01-06 23:29:33,738] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:29:33,750] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:29:33,772] {logging_mixin.py:115} INFO - [2023-01-06 23:29:33,772] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:29:33,799] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.959 seconds
[2023-01-06 23:30:03,876] {processor.py:153} INFO - Started process (PID=5479) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:30:03,876] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:30:03,877] {logging_mixin.py:115} INFO - [2023-01-06 23:30:03,877] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:30:04,749] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:30:04,751] {logging_mixin.py:115} INFO - [2023-01-06 23:30:04,750] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:30:04,751] {logging_mixin.py:115} INFO - [2023-01-06 23:30:04,751] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:30:04,758] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:30:04,779] {logging_mixin.py:115} INFO - [2023-01-06 23:30:04,779] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:30:04,806] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.935 seconds
[2023-01-06 23:30:34,889] {processor.py:153} INFO - Started process (PID=5498) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:30:34,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:30:34,891] {logging_mixin.py:115} INFO - [2023-01-06 23:30:34,891] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:30:35,758] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:30:35,759] {logging_mixin.py:115} INFO - [2023-01-06 23:30:35,759] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:30:35,760] {logging_mixin.py:115} INFO - [2023-01-06 23:30:35,759] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:30:35,768] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:30:35,792] {logging_mixin.py:115} INFO - [2023-01-06 23:30:35,791] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:30:35,820] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.936 seconds
[2023-01-06 23:31:05,902] {processor.py:153} INFO - Started process (PID=5526) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:31:05,903] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:31:05,903] {logging_mixin.py:115} INFO - [2023-01-06 23:31:05,903] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:31:06,838] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:31:06,840] {logging_mixin.py:115} INFO - [2023-01-06 23:31:06,840] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:31:06,840] {logging_mixin.py:115} INFO - [2023-01-06 23:31:06,840] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:31:06,847] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:31:06,868] {logging_mixin.py:115} INFO - [2023-01-06 23:31:06,868] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:31:06,894] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.997 seconds
[2023-01-06 23:31:36,969] {processor.py:153} INFO - Started process (PID=5551) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:31:36,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:31:36,971] {logging_mixin.py:115} INFO - [2023-01-06 23:31:36,971] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:31:37,844] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:31:37,845] {logging_mixin.py:115} INFO - [2023-01-06 23:31:37,845] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:31:37,846] {logging_mixin.py:115} INFO - [2023-01-06 23:31:37,845] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:31:37,852] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:31:37,873] {logging_mixin.py:115} INFO - [2023-01-06 23:31:37,873] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:31:37,899] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.935 seconds
[2023-01-06 23:32:07,967] {processor.py:153} INFO - Started process (PID=5575) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:32:07,969] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:32:07,969] {logging_mixin.py:115} INFO - [2023-01-06 23:32:07,969] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:32:08,831] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:32:08,833] {logging_mixin.py:115} INFO - [2023-01-06 23:32:08,833] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:32:08,833] {logging_mixin.py:115} INFO - [2023-01-06 23:32:08,833] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:32:08,840] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:32:08,861] {logging_mixin.py:115} INFO - [2023-01-06 23:32:08,861] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:32:08,887] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.925 seconds
[2023-01-06 23:32:38,952] {processor.py:153} INFO - Started process (PID=5594) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:32:38,952] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:32:38,953] {logging_mixin.py:115} INFO - [2023-01-06 23:32:38,953] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:32:39,813] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:32:39,814] {logging_mixin.py:115} INFO - [2023-01-06 23:32:39,814] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:32:39,814] {logging_mixin.py:115} INFO - [2023-01-06 23:32:39,814] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:32:39,821] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:32:39,843] {logging_mixin.py:115} INFO - [2023-01-06 23:32:39,842] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:32:39,869] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.921 seconds
[2023-01-06 23:33:09,939] {processor.py:153} INFO - Started process (PID=5620) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:33:09,940] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:33:09,941] {logging_mixin.py:115} INFO - [2023-01-06 23:33:09,941] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:33:10,789] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:33:10,790] {logging_mixin.py:115} INFO - [2023-01-06 23:33:10,790] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:33:10,791] {logging_mixin.py:115} INFO - [2023-01-06 23:33:10,790] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:33:10,797] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:33:10,818] {logging_mixin.py:115} INFO - [2023-01-06 23:33:10,818] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:33:10,845] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.910 seconds
[2023-01-06 23:33:40,911] {processor.py:153} INFO - Started process (PID=5646) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:33:40,912] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:33:40,913] {logging_mixin.py:115} INFO - [2023-01-06 23:33:40,913] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:33:41,756] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:33:41,758] {logging_mixin.py:115} INFO - [2023-01-06 23:33:41,758] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:33:41,758] {logging_mixin.py:115} INFO - [2023-01-06 23:33:41,758] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:33:41,765] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:33:41,786] {logging_mixin.py:115} INFO - [2023-01-06 23:33:41,786] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:33:41,812] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.905 seconds
[2023-01-06 23:34:11,883] {processor.py:153} INFO - Started process (PID=5663) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:34:11,884] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:34:11,885] {logging_mixin.py:115} INFO - [2023-01-06 23:34:11,885] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:34:12,781] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:34:12,782] {logging_mixin.py:115} INFO - [2023-01-06 23:34:12,782] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:34:12,782] {logging_mixin.py:115} INFO - [2023-01-06 23:34:12,782] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:34:12,789] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:34:12,810] {logging_mixin.py:115} INFO - [2023-01-06 23:34:12,810] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:34:12,836] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.958 seconds
[2023-01-06 23:34:42,910] {processor.py:153} INFO - Started process (PID=5688) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:34:42,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:34:42,911] {logging_mixin.py:115} INFO - [2023-01-06 23:34:42,911] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:34:43,801] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:34:43,802] {logging_mixin.py:115} INFO - [2023-01-06 23:34:43,802] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:34:43,803] {logging_mixin.py:115} INFO - [2023-01-06 23:34:43,802] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:34:43,809] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:34:43,830] {logging_mixin.py:115} INFO - [2023-01-06 23:34:43,830] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:34:43,857] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.951 seconds
[2023-01-06 23:35:13,929] {processor.py:153} INFO - Started process (PID=5713) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:35:13,931] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:35:13,931] {logging_mixin.py:115} INFO - [2023-01-06 23:35:13,931] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:35:14,788] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:35:14,789] {logging_mixin.py:115} INFO - [2023-01-06 23:35:14,789] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:35:14,790] {logging_mixin.py:115} INFO - [2023-01-06 23:35:14,790] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:35:14,797] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:35:14,819] {logging_mixin.py:115} INFO - [2023-01-06 23:35:14,819] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:35:14,846] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.921 seconds
[2023-01-06 23:35:44,928] {processor.py:153} INFO - Started process (PID=5738) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:35:44,929] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:35:44,929] {logging_mixin.py:115} INFO - [2023-01-06 23:35:44,929] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:35:45,778] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:35:45,779] {logging_mixin.py:115} INFO - [2023-01-06 23:35:45,779] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:35:45,779] {logging_mixin.py:115} INFO - [2023-01-06 23:35:45,779] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:35:45,786] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:35:45,807] {logging_mixin.py:115} INFO - [2023-01-06 23:35:45,807] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:35:45,834] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.910 seconds
[2023-01-06 23:36:15,912] {processor.py:153} INFO - Started process (PID=5762) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:36:15,913] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:36:15,915] {logging_mixin.py:115} INFO - [2023-01-06 23:36:15,915] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:36:16,798] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:36:16,799] {logging_mixin.py:115} INFO - [2023-01-06 23:36:16,799] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:36:16,800] {logging_mixin.py:115} INFO - [2023-01-06 23:36:16,799] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:36:16,807] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:36:16,830] {logging_mixin.py:115} INFO - [2023-01-06 23:36:16,830] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:36:16,856] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.950 seconds
[2023-01-06 23:36:46,943] {processor.py:153} INFO - Started process (PID=5780) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:36:46,943] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:36:46,945] {logging_mixin.py:115} INFO - [2023-01-06 23:36:46,945] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:36:47,794] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:36:47,796] {logging_mixin.py:115} INFO - [2023-01-06 23:36:47,796] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:36:47,796] {logging_mixin.py:115} INFO - [2023-01-06 23:36:47,796] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:36:47,803] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:36:47,831] {logging_mixin.py:115} INFO - [2023-01-06 23:36:47,831] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:36:47,863] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.924 seconds
[2023-01-06 23:37:17,957] {processor.py:153} INFO - Started process (PID=5805) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:37:17,958] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:37:17,959] {logging_mixin.py:115} INFO - [2023-01-06 23:37:17,959] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:37:18,827] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:37:18,828] {logging_mixin.py:115} INFO - [2023-01-06 23:37:18,828] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:37:18,828] {logging_mixin.py:115} INFO - [2023-01-06 23:37:18,828] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:37:18,835] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:37:18,857] {logging_mixin.py:115} INFO - [2023-01-06 23:37:18,857] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:37:18,883] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.930 seconds
[2023-01-06 23:37:48,976] {processor.py:153} INFO - Started process (PID=5830) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:37:48,976] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:37:48,978] {logging_mixin.py:115} INFO - [2023-01-06 23:37:48,978] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:37:49,818] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:37:49,819] {logging_mixin.py:115} INFO - [2023-01-06 23:37:49,819] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:37:49,819] {logging_mixin.py:115} INFO - [2023-01-06 23:37:49,819] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:37:49,826] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:37:49,847] {logging_mixin.py:115} INFO - [2023-01-06 23:37:49,847] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:37:49,873] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.903 seconds
[2023-01-06 23:38:19,973] {processor.py:153} INFO - Started process (PID=5855) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:38:19,974] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:38:19,975] {logging_mixin.py:115} INFO - [2023-01-06 23:38:19,975] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:38:20,843] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:38:20,844] {logging_mixin.py:115} INFO - [2023-01-06 23:38:20,844] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:38:20,845] {logging_mixin.py:115} INFO - [2023-01-06 23:38:20,845] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:38:20,851] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:38:20,873] {logging_mixin.py:115} INFO - [2023-01-06 23:38:20,873] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:38:20,899] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.930 seconds
[2023-01-06 23:38:50,988] {processor.py:153} INFO - Started process (PID=5874) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:38:50,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:38:50,991] {logging_mixin.py:115} INFO - [2023-01-06 23:38:50,991] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:38:51,973] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:38:51,975] {logging_mixin.py:115} INFO - [2023-01-06 23:38:51,975] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:38:51,976] {logging_mixin.py:115} INFO - [2023-01-06 23:38:51,975] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:38:51,987] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:38:52,016] {logging_mixin.py:115} INFO - [2023-01-06 23:38:52,016] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:38:52,053] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.069 seconds
[2023-01-06 23:39:22,122] {processor.py:153} INFO - Started process (PID=5898) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:39:22,124] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:39:22,125] {logging_mixin.py:115} INFO - [2023-01-06 23:39:22,125] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:39:22,973] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:39:22,974] {logging_mixin.py:115} INFO - [2023-01-06 23:39:22,974] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:39:22,975] {logging_mixin.py:115} INFO - [2023-01-06 23:39:22,974] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:39:22,981] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:39:23,003] {logging_mixin.py:115} INFO - [2023-01-06 23:39:23,002] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:39:23,029] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.911 seconds
[2023-01-06 23:39:53,058] {processor.py:153} INFO - Started process (PID=5924) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:39:53,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:39:53,060] {logging_mixin.py:115} INFO - [2023-01-06 23:39:53,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:39:53,924] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:39:53,925] {logging_mixin.py:115} INFO - [2023-01-06 23:39:53,925] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:39:53,926] {logging_mixin.py:115} INFO - [2023-01-06 23:39:53,925] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:39:53,933] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:39:53,954] {logging_mixin.py:115} INFO - [2023-01-06 23:39:53,954] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:39:53,980] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.927 seconds
[2023-01-06 23:40:24,102] {processor.py:153} INFO - Started process (PID=5949) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:40:24,103] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:40:24,104] {logging_mixin.py:115} INFO - [2023-01-06 23:40:24,104] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:40:24,982] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:40:24,983] {logging_mixin.py:115} INFO - [2023-01-06 23:40:24,983] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:40:24,983] {logging_mixin.py:115} INFO - [2023-01-06 23:40:24,983] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:40:24,990] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:40:25,012] {logging_mixin.py:115} INFO - [2023-01-06 23:40:25,012] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:40:25,039] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.942 seconds
[2023-01-06 23:40:55,125] {processor.py:153} INFO - Started process (PID=5967) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:40:55,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:40:55,126] {logging_mixin.py:115} INFO - [2023-01-06 23:40:55,126] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:40:56,035] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:40:56,036] {logging_mixin.py:115} INFO - [2023-01-06 23:40:56,036] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:40:56,036] {logging_mixin.py:115} INFO - [2023-01-06 23:40:56,036] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:40:56,043] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:40:56,064] {logging_mixin.py:115} INFO - [2023-01-06 23:40:56,064] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:40:56,090] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.970 seconds
[2023-01-06 23:41:26,158] {processor.py:153} INFO - Started process (PID=5991) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:41:26,160] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:41:26,160] {logging_mixin.py:115} INFO - [2023-01-06 23:41:26,160] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:41:27,041] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:41:27,042] {logging_mixin.py:115} INFO - [2023-01-06 23:41:27,042] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:41:27,043] {logging_mixin.py:115} INFO - [2023-01-06 23:41:27,042] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:41:27,049] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:41:27,070] {logging_mixin.py:115} INFO - [2023-01-06 23:41:27,070] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:41:27,096] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.942 seconds
[2023-01-06 23:41:57,171] {processor.py:153} INFO - Started process (PID=6016) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:41:57,172] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:41:57,173] {logging_mixin.py:115} INFO - [2023-01-06 23:41:57,173] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:41:58,041] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:41:58,042] {logging_mixin.py:115} INFO - [2023-01-06 23:41:58,042] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:41:58,042] {logging_mixin.py:115} INFO - [2023-01-06 23:41:58,042] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:41:58,049] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:41:58,070] {logging_mixin.py:115} INFO - [2023-01-06 23:41:58,070] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:41:58,098] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.932 seconds
[2023-01-06 23:42:28,161] {processor.py:153} INFO - Started process (PID=6040) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:42:28,162] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:42:28,162] {logging_mixin.py:115} INFO - [2023-01-06 23:42:28,162] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:42:29,009] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:42:29,010] {logging_mixin.py:115} INFO - [2023-01-06 23:42:29,010] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:42:29,010] {logging_mixin.py:115} INFO - [2023-01-06 23:42:29,010] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:42:29,017] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:42:29,038] {logging_mixin.py:115} INFO - [2023-01-06 23:42:29,038] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:42:29,064] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.908 seconds
[2023-01-06 23:42:59,131] {processor.py:153} INFO - Started process (PID=6058) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:42:59,135] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:42:59,136] {logging_mixin.py:115} INFO - [2023-01-06 23:42:59,136] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:43:00,034] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:43:00,035] {logging_mixin.py:115} INFO - [2023-01-06 23:43:00,035] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:43:00,036] {logging_mixin.py:115} INFO - [2023-01-06 23:43:00,035] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:43:00,042] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:43:00,065] {logging_mixin.py:115} INFO - [2023-01-06 23:43:00,065] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:43:00,093] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.966 seconds
[2023-01-06 23:43:30,171] {processor.py:153} INFO - Started process (PID=6083) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:43:30,171] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:43:30,172] {logging_mixin.py:115} INFO - [2023-01-06 23:43:30,172] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:43:31,039] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:43:31,040] {logging_mixin.py:115} INFO - [2023-01-06 23:43:31,040] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:43:31,040] {logging_mixin.py:115} INFO - [2023-01-06 23:43:31,040] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:43:31,047] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:43:31,070] {logging_mixin.py:115} INFO - [2023-01-06 23:43:31,069] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:43:31,097] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.931 seconds
[2023-01-06 23:44:01,194] {processor.py:153} INFO - Started process (PID=6108) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:44:01,195] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:44:01,196] {logging_mixin.py:115} INFO - [2023-01-06 23:44:01,195] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:44:02,040] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:44:02,041] {logging_mixin.py:115} INFO - [2023-01-06 23:44:02,041] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:44:02,042] {logging_mixin.py:115} INFO - [2023-01-06 23:44:02,041] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:44:02,048] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:44:02,070] {logging_mixin.py:115} INFO - [2023-01-06 23:44:02,070] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:44:02,097] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.908 seconds
[2023-01-06 23:44:32,471] {processor.py:153} INFO - Started process (PID=6133) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:44:32,472] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:44:32,472] {logging_mixin.py:115} INFO - [2023-01-06 23:44:32,472] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:44:33,333] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:44:33,334] {logging_mixin.py:115} INFO - [2023-01-06 23:44:33,334] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:44:33,335] {logging_mixin.py:115} INFO - [2023-01-06 23:44:33,334] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:44:33,341] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:44:33,363] {logging_mixin.py:115} INFO - [2023-01-06 23:44:33,362] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:44:33,389] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.923 seconds
[2023-01-06 23:45:03,484] {processor.py:153} INFO - Started process (PID=6151) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:45:03,484] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:45:03,485] {logging_mixin.py:115} INFO - [2023-01-06 23:45:03,485] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:45:04,431] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:45:04,432] {logging_mixin.py:115} INFO - [2023-01-06 23:45:04,432] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:45:04,433] {logging_mixin.py:115} INFO - [2023-01-06 23:45:04,432] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:45:04,439] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:45:04,467] {logging_mixin.py:115} INFO - [2023-01-06 23:45:04,467] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:45:04,495] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.015 seconds
[2023-01-06 23:45:34,559] {processor.py:153} INFO - Started process (PID=6176) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:45:34,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:45:34,561] {logging_mixin.py:115} INFO - [2023-01-06 23:45:34,561] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:45:35,420] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:45:35,421] {logging_mixin.py:115} INFO - [2023-01-06 23:45:35,421] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:45:35,422] {logging_mixin.py:115} INFO - [2023-01-06 23:45:35,421] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:45:35,429] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:45:35,450] {logging_mixin.py:115} INFO - [2023-01-06 23:45:35,449] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:45:35,477] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.922 seconds
[2023-01-06 23:46:05,544] {processor.py:153} INFO - Started process (PID=6200) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:46:05,544] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:46:05,545] {logging_mixin.py:115} INFO - [2023-01-06 23:46:05,545] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:46:06,418] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:46:06,420] {logging_mixin.py:115} INFO - [2023-01-06 23:46:06,420] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:46:06,420] {logging_mixin.py:115} INFO - [2023-01-06 23:46:06,420] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:46:06,427] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:46:06,448] {logging_mixin.py:115} INFO - [2023-01-06 23:46:06,448] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:46:06,474] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.935 seconds
[2023-01-06 23:46:36,538] {processor.py:153} INFO - Started process (PID=6225) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:46:36,538] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:46:36,539] {logging_mixin.py:115} INFO - [2023-01-06 23:46:36,539] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:46:37,422] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:46:37,423] {logging_mixin.py:115} INFO - [2023-01-06 23:46:37,423] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:46:37,423] {logging_mixin.py:115} INFO - [2023-01-06 23:46:37,423] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:46:37,430] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:46:37,452] {logging_mixin.py:115} INFO - [2023-01-06 23:46:37,451] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:46:37,478] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.945 seconds
[2023-01-06 23:47:07,552] {processor.py:153} INFO - Started process (PID=6242) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:47:07,553] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:47:07,553] {logging_mixin.py:115} INFO - [2023-01-06 23:47:07,553] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:47:08,448] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:47:08,449] {logging_mixin.py:115} INFO - [2023-01-06 23:47:08,449] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:47:08,450] {logging_mixin.py:115} INFO - [2023-01-06 23:47:08,449] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:47:08,456] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:47:08,478] {logging_mixin.py:115} INFO - [2023-01-06 23:47:08,477] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:47:08,505] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.957 seconds
[2023-01-06 23:47:38,576] {processor.py:153} INFO - Started process (PID=6267) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:47:38,577] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:47:38,577] {logging_mixin.py:115} INFO - [2023-01-06 23:47:38,577] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:47:39,443] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:47:39,445] {logging_mixin.py:115} INFO - [2023-01-06 23:47:39,444] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:47:39,445] {logging_mixin.py:115} INFO - [2023-01-06 23:47:39,445] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:47:39,452] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:47:39,473] {logging_mixin.py:115} INFO - [2023-01-06 23:47:39,473] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:47:39,499] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.928 seconds
[2023-01-06 23:48:09,571] {processor.py:153} INFO - Started process (PID=6291) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:48:09,574] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:48:09,574] {logging_mixin.py:115} INFO - [2023-01-06 23:48:09,574] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:48:10,457] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:48:10,458] {logging_mixin.py:115} INFO - [2023-01-06 23:48:10,458] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:48:10,459] {logging_mixin.py:115} INFO - [2023-01-06 23:48:10,458] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:48:10,465] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:48:10,492] {logging_mixin.py:115} INFO - [2023-01-06 23:48:10,492] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:48:10,524] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.958 seconds
[2023-01-06 23:48:40,603] {processor.py:153} INFO - Started process (PID=6317) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:48:40,604] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:48:40,605] {logging_mixin.py:115} INFO - [2023-01-06 23:48:40,605] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:48:41,460] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:48:41,461] {logging_mixin.py:115} INFO - [2023-01-06 23:48:41,461] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:48:41,462] {logging_mixin.py:115} INFO - [2023-01-06 23:48:41,461] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:48:41,468] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:48:41,489] {logging_mixin.py:115} INFO - [2023-01-06 23:48:41,489] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:48:41,515] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.916 seconds
[2023-01-06 23:49:11,608] {processor.py:153} INFO - Started process (PID=6342) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:49:11,609] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:49:11,610] {logging_mixin.py:115} INFO - [2023-01-06 23:49:11,610] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:49:12,506] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:49:12,508] {logging_mixin.py:115} INFO - [2023-01-06 23:49:12,508] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:49:12,508] {logging_mixin.py:115} INFO - [2023-01-06 23:49:12,508] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:49:12,516] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:49:12,538] {logging_mixin.py:115} INFO - [2023-01-06 23:49:12,537] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:49:12,564] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.961 seconds
[2023-01-06 23:49:42,658] {processor.py:153} INFO - Started process (PID=6360) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:49:42,659] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:49:42,660] {logging_mixin.py:115} INFO - [2023-01-06 23:49:42,659] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:49:43,582] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:49:43,584] {logging_mixin.py:115} INFO - [2023-01-06 23:49:43,584] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:49:43,584] {logging_mixin.py:115} INFO - [2023-01-06 23:49:43,584] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:49:43,596] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:49:43,625] {logging_mixin.py:115} INFO - [2023-01-06 23:49:43,625] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:49:43,653] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.000 seconds
[2023-01-06 23:50:13,730] {processor.py:153} INFO - Started process (PID=6384) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:50:13,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:50:13,731] {logging_mixin.py:115} INFO - [2023-01-06 23:50:13,731] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:50:14,579] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:50:14,580] {logging_mixin.py:115} INFO - [2023-01-06 23:50:14,580] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:50:14,581] {logging_mixin.py:115} INFO - [2023-01-06 23:50:14,580] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:50:14,587] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:50:14,608] {logging_mixin.py:115} INFO - [2023-01-06 23:50:14,608] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:50:14,634] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.910 seconds
[2023-01-06 23:50:44,699] {processor.py:153} INFO - Started process (PID=6408) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:50:44,700] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:50:44,700] {logging_mixin.py:115} INFO - [2023-01-06 23:50:44,700] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:50:45,543] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:50:45,545] {logging_mixin.py:115} INFO - [2023-01-06 23:50:45,545] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:50:45,545] {logging_mixin.py:115} INFO - [2023-01-06 23:50:45,545] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:50:45,552] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:50:45,574] {logging_mixin.py:115} INFO - [2023-01-06 23:50:45,574] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:50:45,600] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.906 seconds
[2023-01-06 23:51:15,664] {processor.py:153} INFO - Started process (PID=6435) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:51:15,665] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:51:15,665] {logging_mixin.py:115} INFO - [2023-01-06 23:51:15,665] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:51:16,540] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:51:16,541] {logging_mixin.py:115} INFO - [2023-01-06 23:51:16,541] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:51:16,542] {logging_mixin.py:115} INFO - [2023-01-06 23:51:16,542] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:51:16,553] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:51:16,583] {logging_mixin.py:115} INFO - [2023-01-06 23:51:16,582] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:51:16,610] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.951 seconds
[2023-01-06 23:51:46,677] {processor.py:153} INFO - Started process (PID=6453) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:51:46,678] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:51:46,678] {logging_mixin.py:115} INFO - [2023-01-06 23:51:46,678] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:51:47,547] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:51:47,548] {logging_mixin.py:115} INFO - [2023-01-06 23:51:47,548] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:51:47,549] {logging_mixin.py:115} INFO - [2023-01-06 23:51:47,548] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:51:47,556] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:51:47,578] {logging_mixin.py:115} INFO - [2023-01-06 23:51:47,577] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:51:47,604] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.932 seconds
[2023-01-06 23:52:17,671] {processor.py:153} INFO - Started process (PID=6479) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:52:17,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:52:17,673] {logging_mixin.py:115} INFO - [2023-01-06 23:52:17,673] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:52:18,520] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:52:18,521] {logging_mixin.py:115} INFO - [2023-01-06 23:52:18,521] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:52:18,522] {logging_mixin.py:115} INFO - [2023-01-06 23:52:18,522] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:52:18,528] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:52:18,550] {logging_mixin.py:115} INFO - [2023-01-06 23:52:18,550] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:52:18,577] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.910 seconds
[2023-01-06 23:52:48,646] {processor.py:153} INFO - Started process (PID=6505) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:52:48,647] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:52:48,648] {logging_mixin.py:115} INFO - [2023-01-06 23:52:48,648] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:52:49,524] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:52:49,525] {logging_mixin.py:115} INFO - [2023-01-06 23:52:49,525] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:52:49,526] {logging_mixin.py:115} INFO - [2023-01-06 23:52:49,525] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:52:49,532] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:52:49,554] {logging_mixin.py:115} INFO - [2023-01-06 23:52:49,554] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:52:49,581] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.941 seconds
[2023-01-06 23:53:19,649] {processor.py:153} INFO - Started process (PID=6530) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:53:19,649] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:53:19,650] {logging_mixin.py:115} INFO - [2023-01-06 23:53:19,650] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:53:20,549] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:53:20,550] {logging_mixin.py:115} INFO - [2023-01-06 23:53:20,550] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:53:20,550] {logging_mixin.py:115} INFO - [2023-01-06 23:53:20,550] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:53:20,557] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:53:20,579] {logging_mixin.py:115} INFO - [2023-01-06 23:53:20,579] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:53:20,606] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.962 seconds
[2023-01-06 23:53:50,674] {processor.py:153} INFO - Started process (PID=6548) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:53:50,676] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:53:50,676] {logging_mixin.py:115} INFO - [2023-01-06 23:53:50,676] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:53:51,647] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:53:51,648] {logging_mixin.py:115} INFO - [2023-01-06 23:53:51,648] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:53:51,649] {logging_mixin.py:115} INFO - [2023-01-06 23:53:51,648] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:53:51,655] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:53:51,684] {logging_mixin.py:115} INFO - [2023-01-06 23:53:51,683] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:53:51,710] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.040 seconds
[2023-01-06 23:54:21,784] {processor.py:153} INFO - Started process (PID=6575) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:54:21,784] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:54:21,785] {logging_mixin.py:115} INFO - [2023-01-06 23:54:21,785] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:54:22,684] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:54:22,686] {logging_mixin.py:115} INFO - [2023-01-06 23:54:22,685] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:54:22,686] {logging_mixin.py:115} INFO - [2023-01-06 23:54:22,686] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:54:22,697] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:54:22,732] {logging_mixin.py:115} INFO - [2023-01-06 23:54:22,732] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:54:22,767] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.989 seconds
[2023-01-06 23:54:52,844] {processor.py:153} INFO - Started process (PID=6600) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:54:52,845] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:54:52,845] {logging_mixin.py:115} INFO - [2023-01-06 23:54:52,845] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:54:53,695] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:54:53,696] {logging_mixin.py:115} INFO - [2023-01-06 23:54:53,696] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:54:53,696] {logging_mixin.py:115} INFO - [2023-01-06 23:54:53,696] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:54:53,703] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:54:53,725] {logging_mixin.py:115} INFO - [2023-01-06 23:54:53,724] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:54:53,751] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.912 seconds
[2023-01-06 23:55:23,814] {processor.py:153} INFO - Started process (PID=6626) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:55:23,814] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:55:23,815] {logging_mixin.py:115} INFO - [2023-01-06 23:55:23,815] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:55:24,647] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:55:24,649] {logging_mixin.py:115} INFO - [2023-01-06 23:55:24,649] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:55:24,649] {logging_mixin.py:115} INFO - [2023-01-06 23:55:24,649] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:55:24,656] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:55:24,677] {logging_mixin.py:115} INFO - [2023-01-06 23:55:24,677] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:55:24,703] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.894 seconds
[2023-01-06 23:55:54,774] {processor.py:153} INFO - Started process (PID=6644) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:55:54,775] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:55:54,776] {logging_mixin.py:115} INFO - [2023-01-06 23:55:54,776] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:55:55,887] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:55:55,889] {logging_mixin.py:115} INFO - [2023-01-06 23:55:55,888] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:55:55,889] {logging_mixin.py:115} INFO - [2023-01-06 23:55:55,889] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:55:55,896] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:55:55,918] {logging_mixin.py:115} INFO - [2023-01-06 23:55:55,918] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:55:55,946] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.179 seconds
[2023-01-06 23:56:26,016] {processor.py:153} INFO - Started process (PID=6669) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:56:26,016] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:56:26,017] {logging_mixin.py:115} INFO - [2023-01-06 23:56:26,017] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:56:26,866] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:56:26,867] {logging_mixin.py:115} INFO - [2023-01-06 23:56:26,867] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:56:26,868] {logging_mixin.py:115} INFO - [2023-01-06 23:56:26,868] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:56:26,875] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:56:26,897] {logging_mixin.py:115} INFO - [2023-01-06 23:56:26,896] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:56:26,923] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.912 seconds
[2023-01-06 23:56:56,989] {processor.py:153} INFO - Started process (PID=6694) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:56:56,990] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:56:56,990] {logging_mixin.py:115} INFO - [2023-01-06 23:56:56,990] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:56:57,844] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:56:57,846] {logging_mixin.py:115} INFO - [2023-01-06 23:56:57,846] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:56:57,847] {logging_mixin.py:115} INFO - [2023-01-06 23:56:57,846] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:56:57,854] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:56:57,875] {logging_mixin.py:115} INFO - [2023-01-06 23:56:57,875] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:56:57,901] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.917 seconds
[2023-01-06 23:57:27,969] {processor.py:153} INFO - Started process (PID=6719) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:57:27,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:57:27,970] {logging_mixin.py:115} INFO - [2023-01-06 23:57:27,970] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:57:28,874] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:57:28,876] {logging_mixin.py:115} INFO - [2023-01-06 23:57:28,876] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:57:28,877] {logging_mixin.py:115} INFO - [2023-01-06 23:57:28,876] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:57:28,887] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:57:28,911] {logging_mixin.py:115} INFO - [2023-01-06 23:57:28,910] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:57:28,938] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.973 seconds
[2023-01-06 23:57:59,010] {processor.py:153} INFO - Started process (PID=6737) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:57:59,012] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:57:59,012] {logging_mixin.py:115} INFO - [2023-01-06 23:57:59,012] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:57:59,916] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:57:59,917] {logging_mixin.py:115} INFO - [2023-01-06 23:57:59,917] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:57:59,918] {logging_mixin.py:115} INFO - [2023-01-06 23:57:59,917] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:57:59,924] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:57:59,946] {logging_mixin.py:115} INFO - [2023-01-06 23:57:59,946] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:57:59,973] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.967 seconds
[2023-01-06 23:58:30,052] {processor.py:153} INFO - Started process (PID=6762) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:58:30,053] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:58:30,054] {logging_mixin.py:115} INFO - [2023-01-06 23:58:30,054] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:58:30,909] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:58:30,910] {logging_mixin.py:115} INFO - [2023-01-06 23:58:30,910] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:58:30,910] {logging_mixin.py:115} INFO - [2023-01-06 23:58:30,910] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:58:30,917] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:58:30,938] {logging_mixin.py:115} INFO - [2023-01-06 23:58:30,938] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:58:30,964] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.916 seconds
[2023-01-06 23:59:01,055] {processor.py:153} INFO - Started process (PID=6787) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:59:01,056] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:59:01,057] {logging_mixin.py:115} INFO - [2023-01-06 23:59:01,057] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:59:01,925] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:59:01,926] {logging_mixin.py:115} INFO - [2023-01-06 23:59:01,926] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:59:01,927] {logging_mixin.py:115} INFO - [2023-01-06 23:59:01,927] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:59:01,934] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:59:01,955] {logging_mixin.py:115} INFO - [2023-01-06 23:59:01,954] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:59:01,981] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.930 seconds
[2023-01-06 23:59:32,071] {processor.py:153} INFO - Started process (PID=6812) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:59:32,071] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:59:32,072] {logging_mixin.py:115} INFO - [2023-01-06 23:59:32,072] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:59:32,905] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:59:32,906] {logging_mixin.py:115} INFO - [2023-01-06 23:59:32,906] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:59:32,906] {logging_mixin.py:115} INFO - [2023-01-06 23:59:32,906] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:59:32,913] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-06 23:59:32,934] {logging_mixin.py:115} INFO - [2023-01-06 23:59:32,934] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:59:32,961] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.894 seconds

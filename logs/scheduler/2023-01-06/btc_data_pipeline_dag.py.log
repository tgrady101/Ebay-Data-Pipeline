[2023-01-06 00:00:12,010] {processor.py:153} INFO - Started process (PID=6821) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:00:12,011] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:00:12,011] {logging_mixin.py:115} INFO - [2023-01-06 00:00:12,011] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:00:12,833] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:00:12,834] {logging_mixin.py:115} INFO - [2023-01-06 00:00:12,834] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:00:12,835] {logging_mixin.py:115} INFO - [2023-01-06 00:00:12,834] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:00:12,842] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:00:12,865] {logging_mixin.py:115} INFO - [2023-01-06 00:00:12,864] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:00:12,888] {logging_mixin.py:115} INFO - [2023-01-06 00:00:12,888] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:00:12,898] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.893 seconds
[2023-01-06 00:00:43,104] {processor.py:153} INFO - Started process (PID=6839) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:00:43,104] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:00:43,105] {logging_mixin.py:115} INFO - [2023-01-06 00:00:43,105] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:00:43,929] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:00:43,930] {logging_mixin.py:115} INFO - [2023-01-06 00:00:43,930] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:00:43,931] {logging_mixin.py:115} INFO - [2023-01-06 00:00:43,931] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:00:43,940] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:00:43,964] {logging_mixin.py:115} INFO - [2023-01-06 00:00:43,963] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:00:43,985] {logging_mixin.py:115} INFO - [2023-01-06 00:00:43,985] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:00:43,997] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.898 seconds
[2023-01-06 00:01:14,230] {processor.py:153} INFO - Started process (PID=6864) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:01:14,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:01:14,232] {logging_mixin.py:115} INFO - [2023-01-06 00:01:14,232] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:01:15,078] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:01:15,079] {logging_mixin.py:115} INFO - [2023-01-06 00:01:15,079] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:01:15,080] {logging_mixin.py:115} INFO - [2023-01-06 00:01:15,080] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:01:15,087] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:01:15,109] {logging_mixin.py:115} INFO - [2023-01-06 00:01:15,109] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:01:15,132] {logging_mixin.py:115} INFO - [2023-01-06 00:01:15,132] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:01:15,141] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.916 seconds
[2023-01-06 00:01:45,358] {processor.py:153} INFO - Started process (PID=6888) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:01:45,358] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:01:45,359] {logging_mixin.py:115} INFO - [2023-01-06 00:01:45,359] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:01:46,170] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:01:46,171] {logging_mixin.py:115} INFO - [2023-01-06 00:01:46,171] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:01:46,172] {logging_mixin.py:115} INFO - [2023-01-06 00:01:46,171] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:01:46,179] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:01:46,202] {logging_mixin.py:115} INFO - [2023-01-06 00:01:46,201] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:01:46,224] {logging_mixin.py:115} INFO - [2023-01-06 00:01:46,224] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:01:46,234] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.881 seconds
[2023-01-06 00:02:16,426] {processor.py:153} INFO - Started process (PID=6914) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:02:16,427] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:02:16,428] {logging_mixin.py:115} INFO - [2023-01-06 00:02:16,428] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:02:17,241] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:02:17,243] {logging_mixin.py:115} INFO - [2023-01-06 00:02:17,243] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:02:17,243] {logging_mixin.py:115} INFO - [2023-01-06 00:02:17,243] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:02:17,250] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:02:17,272] {logging_mixin.py:115} INFO - [2023-01-06 00:02:17,272] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:02:17,294] {logging_mixin.py:115} INFO - [2023-01-06 00:02:17,294] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:02:17,303] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.882 seconds
[2023-01-06 00:02:47,495] {processor.py:153} INFO - Started process (PID=6932) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:02:47,496] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:02:47,497] {logging_mixin.py:115} INFO - [2023-01-06 00:02:47,497] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:02:48,311] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:02:48,312] {logging_mixin.py:115} INFO - [2023-01-06 00:02:48,312] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:02:48,313] {logging_mixin.py:115} INFO - [2023-01-06 00:02:48,313] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:02:48,320] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:02:48,342] {logging_mixin.py:115} INFO - [2023-01-06 00:02:48,342] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:02:48,364] {logging_mixin.py:115} INFO - [2023-01-06 00:02:48,364] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:02:48,374] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.883 seconds
[2023-01-06 00:03:18,567] {processor.py:153} INFO - Started process (PID=6956) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:03:18,569] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:03:18,569] {logging_mixin.py:115} INFO - [2023-01-06 00:03:18,569] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:03:19,369] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:03:19,371] {logging_mixin.py:115} INFO - [2023-01-06 00:03:19,371] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:03:19,371] {logging_mixin.py:115} INFO - [2023-01-06 00:03:19,371] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:03:19,382] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:03:19,426] {logging_mixin.py:115} INFO - [2023-01-06 00:03:19,426] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:03:19,449] {logging_mixin.py:115} INFO - [2023-01-06 00:03:19,449] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:03:19,459] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.897 seconds
[2023-01-06 00:03:49,670] {processor.py:153} INFO - Started process (PID=6981) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:03:49,671] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:03:49,672] {logging_mixin.py:115} INFO - [2023-01-06 00:03:49,672] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:03:50,659] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:03:50,661] {logging_mixin.py:115} INFO - [2023-01-06 00:03:50,660] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:03:50,661] {logging_mixin.py:115} INFO - [2023-01-06 00:03:50,661] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:03:50,669] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:03:50,690] {logging_mixin.py:115} INFO - [2023-01-06 00:03:50,690] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:03:50,712] {logging_mixin.py:115} INFO - [2023-01-06 00:03:50,711] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:03:50,721] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.057 seconds
[2023-01-06 00:04:20,810] {processor.py:153} INFO - Started process (PID=7006) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:04:20,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:04:20,812] {logging_mixin.py:115} INFO - [2023-01-06 00:04:20,812] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:04:21,638] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:04:21,644] {logging_mixin.py:115} INFO - [2023-01-06 00:04:21,644] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:04:21,645] {logging_mixin.py:115} INFO - [2023-01-06 00:04:21,644] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:04:21,652] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:04:21,690] {logging_mixin.py:115} INFO - [2023-01-06 00:04:21,690] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:04:21,715] {logging_mixin.py:115} INFO - [2023-01-06 00:04:21,715] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:04:21,725] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.919 seconds
[2023-01-06 00:04:51,838] {processor.py:153} INFO - Started process (PID=7024) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:04:51,840] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:04:51,840] {logging_mixin.py:115} INFO - [2023-01-06 00:04:51,840] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:04:52,711] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:04:52,713] {logging_mixin.py:115} INFO - [2023-01-06 00:04:52,713] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:04:52,714] {logging_mixin.py:115} INFO - [2023-01-06 00:04:52,713] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:04:52,721] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:04:52,743] {logging_mixin.py:115} INFO - [2023-01-06 00:04:52,743] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:04:52,765] {logging_mixin.py:115} INFO - [2023-01-06 00:04:52,764] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:04:52,774] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.941 seconds
[2023-01-06 00:05:22,885] {processor.py:153} INFO - Started process (PID=7048) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:05:22,887] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:05:22,887] {logging_mixin.py:115} INFO - [2023-01-06 00:05:22,887] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:05:23,722] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:05:23,724] {logging_mixin.py:115} INFO - [2023-01-06 00:05:23,724] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:05:23,724] {logging_mixin.py:115} INFO - [2023-01-06 00:05:23,724] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:05:23,731] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:05:23,757] {logging_mixin.py:115} INFO - [2023-01-06 00:05:23,757] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:05:23,780] {logging_mixin.py:115} INFO - [2023-01-06 00:05:23,780] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:05:23,791] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.910 seconds
[2023-01-06 00:05:53,898] {processor.py:153} INFO - Started process (PID=7072) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:05:53,899] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:05:53,900] {logging_mixin.py:115} INFO - [2023-01-06 00:05:53,900] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:05:54,772] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:05:54,774] {logging_mixin.py:115} INFO - [2023-01-06 00:05:54,774] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:05:54,774] {logging_mixin.py:115} INFO - [2023-01-06 00:05:54,774] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:05:54,781] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:05:54,813] {logging_mixin.py:115} INFO - [2023-01-06 00:05:54,813] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:05:54,835] {logging_mixin.py:115} INFO - [2023-01-06 00:05:54,835] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:05:54,845] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.955 seconds
[2023-01-06 00:06:24,964] {processor.py:153} INFO - Started process (PID=7097) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:06:24,964] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:06:24,966] {logging_mixin.py:115} INFO - [2023-01-06 00:06:24,966] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:06:25,810] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:06:25,812] {logging_mixin.py:115} INFO - [2023-01-06 00:06:25,812] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:06:25,812] {logging_mixin.py:115} INFO - [2023-01-06 00:06:25,812] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:06:25,819] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:06:25,842] {logging_mixin.py:115} INFO - [2023-01-06 00:06:25,842] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:06:25,865] {logging_mixin.py:115} INFO - [2023-01-06 00:06:25,865] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:06:25,875] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.915 seconds
[2023-01-06 00:06:55,983] {processor.py:153} INFO - Started process (PID=7115) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:06:55,984] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:06:55,986] {logging_mixin.py:115} INFO - [2023-01-06 00:06:55,985] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:06:56,840] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:06:56,842] {logging_mixin.py:115} INFO - [2023-01-06 00:06:56,841] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:06:56,842] {logging_mixin.py:115} INFO - [2023-01-06 00:06:56,842] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:06:56,849] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:06:56,872] {logging_mixin.py:115} INFO - [2023-01-06 00:06:56,871] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:06:56,893] {logging_mixin.py:115} INFO - [2023-01-06 00:06:56,893] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:06:56,903] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.926 seconds
[2023-01-06 00:07:27,011] {processor.py:153} INFO - Started process (PID=7140) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:07:27,012] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:07:27,014] {logging_mixin.py:115} INFO - [2023-01-06 00:07:27,014] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:07:27,866] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:07:27,868] {logging_mixin.py:115} INFO - [2023-01-06 00:07:27,868] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:07:27,868] {logging_mixin.py:115} INFO - [2023-01-06 00:07:27,868] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:07:27,875] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:07:27,898] {logging_mixin.py:115} INFO - [2023-01-06 00:07:27,898] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:07:27,920] {logging_mixin.py:115} INFO - [2023-01-06 00:07:27,920] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:07:27,930] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.923 seconds
[2023-01-06 00:07:58,081] {processor.py:153} INFO - Started process (PID=7165) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:07:58,081] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:07:58,083] {logging_mixin.py:115} INFO - [2023-01-06 00:07:58,083] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:07:58,929] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:07:58,930] {logging_mixin.py:115} INFO - [2023-01-06 00:07:58,930] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:07:58,931] {logging_mixin.py:115} INFO - [2023-01-06 00:07:58,931] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:07:58,938] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:07:58,961] {logging_mixin.py:115} INFO - [2023-01-06 00:07:58,960] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:07:58,982] {logging_mixin.py:115} INFO - [2023-01-06 00:07:58,982] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:07:58,992] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.916 seconds
[2023-01-06 00:08:29,408] {processor.py:153} INFO - Started process (PID=7184) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:08:29,409] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:08:29,410] {logging_mixin.py:115} INFO - [2023-01-06 00:08:29,410] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:08:30,294] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:08:30,295] {logging_mixin.py:115} INFO - [2023-01-06 00:08:30,295] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:08:30,296] {logging_mixin.py:115} INFO - [2023-01-06 00:08:30,296] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:08:30,303] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:08:30,326] {logging_mixin.py:115} INFO - [2023-01-06 00:08:30,326] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:08:30,355] {logging_mixin.py:115} INFO - [2023-01-06 00:08:30,355] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:08:30,364] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.962 seconds
[2023-01-06 00:09:00,465] {processor.py:153} INFO - Started process (PID=7209) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:09:00,466] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:09:00,467] {logging_mixin.py:115} INFO - [2023-01-06 00:09:00,467] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:09:01,285] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:09:01,287] {logging_mixin.py:115} INFO - [2023-01-06 00:09:01,287] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:09:01,287] {logging_mixin.py:115} INFO - [2023-01-06 00:09:01,287] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:09:01,294] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:09:01,318] {logging_mixin.py:115} INFO - [2023-01-06 00:09:01,318] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:09:01,340] {logging_mixin.py:115} INFO - [2023-01-06 00:09:01,340] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:09:01,350] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.890 seconds
[2023-01-06 00:09:31,448] {processor.py:153} INFO - Started process (PID=7234) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:09:31,450] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:09:31,451] {logging_mixin.py:115} INFO - [2023-01-06 00:09:31,451] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:09:32,290] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:09:32,291] {logging_mixin.py:115} INFO - [2023-01-06 00:09:32,291] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:09:32,292] {logging_mixin.py:115} INFO - [2023-01-06 00:09:32,291] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:09:32,301] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:09:32,324] {logging_mixin.py:115} INFO - [2023-01-06 00:09:32,323] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:09:32,345] {logging_mixin.py:115} INFO - [2023-01-06 00:09:32,345] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:09:32,356] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.912 seconds
[2023-01-06 00:10:02,455] {processor.py:153} INFO - Started process (PID=7260) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:10:02,455] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:10:02,457] {logging_mixin.py:115} INFO - [2023-01-06 00:10:02,457] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:10:03,282] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:10:03,284] {logging_mixin.py:115} INFO - [2023-01-06 00:10:03,283] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:10:03,284] {logging_mixin.py:115} INFO - [2023-01-06 00:10:03,284] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:10:03,291] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:10:03,313] {logging_mixin.py:115} INFO - [2023-01-06 00:10:03,313] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:10:03,337] {logging_mixin.py:115} INFO - [2023-01-06 00:10:03,337] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:10:03,347] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.898 seconds
[2023-01-06 00:10:33,607] {processor.py:153} INFO - Started process (PID=7277) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:10:33,610] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:10:33,610] {logging_mixin.py:115} INFO - [2023-01-06 00:10:33,610] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:10:34,472] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:10:34,473] {logging_mixin.py:115} INFO - [2023-01-06 00:10:34,473] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:10:34,474] {logging_mixin.py:115} INFO - [2023-01-06 00:10:34,473] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:10:34,481] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:10:34,504] {logging_mixin.py:115} INFO - [2023-01-06 00:10:34,503] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:10:34,527] {logging_mixin.py:115} INFO - [2023-01-06 00:10:34,527] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:10:34,538] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.935 seconds
[2023-01-06 00:11:04,669] {processor.py:153} INFO - Started process (PID=7301) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:11:04,670] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:11:04,670] {logging_mixin.py:115} INFO - [2023-01-06 00:11:04,670] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:11:05,635] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:11:05,637] {logging_mixin.py:115} INFO - [2023-01-06 00:11:05,637] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:11:05,637] {logging_mixin.py:115} INFO - [2023-01-06 00:11:05,637] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:11:05,644] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:11:05,668] {logging_mixin.py:115} INFO - [2023-01-06 00:11:05,668] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:11:05,690] {logging_mixin.py:115} INFO - [2023-01-06 00:11:05,690] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:11:05,700] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.035 seconds
[2023-01-06 00:11:35,753] {processor.py:153} INFO - Started process (PID=7325) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:11:35,753] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:11:35,754] {logging_mixin.py:115} INFO - [2023-01-06 00:11:35,754] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:11:36,581] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:11:36,583] {logging_mixin.py:115} INFO - [2023-01-06 00:11:36,583] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:11:36,583] {logging_mixin.py:115} INFO - [2023-01-06 00:11:36,583] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:11:36,590] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:11:36,615] {logging_mixin.py:115} INFO - [2023-01-06 00:11:36,615] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:11:36,639] {logging_mixin.py:115} INFO - [2023-01-06 00:11:36,638] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:11:36,649] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.901 seconds
[2023-01-06 00:12:06,823] {processor.py:153} INFO - Started process (PID=7351) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:12:06,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:12:06,825] {logging_mixin.py:115} INFO - [2023-01-06 00:12:06,825] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:12:07,754] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:12:07,755] {logging_mixin.py:115} INFO - [2023-01-06 00:12:07,755] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:12:07,756] {logging_mixin.py:115} INFO - [2023-01-06 00:12:07,755] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:12:07,762] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:12:07,786] {logging_mixin.py:115} INFO - [2023-01-06 00:12:07,785] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:12:07,808] {logging_mixin.py:115} INFO - [2023-01-06 00:12:07,808] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:12:07,818] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.001 seconds
[2023-01-06 00:12:37,908] {processor.py:153} INFO - Started process (PID=7370) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:12:37,909] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:12:37,910] {logging_mixin.py:115} INFO - [2023-01-06 00:12:37,910] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:12:38,826] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:12:38,829] {logging_mixin.py:115} INFO - [2023-01-06 00:12:38,828] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:12:38,829] {logging_mixin.py:115} INFO - [2023-01-06 00:12:38,829] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:12:38,841] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:12:38,874] {logging_mixin.py:115} INFO - [2023-01-06 00:12:38,873] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:12:38,908] {logging_mixin.py:115} INFO - [2023-01-06 00:12:38,907] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:12:38,921] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.017 seconds
[2023-01-06 00:13:08,989] {processor.py:153} INFO - Started process (PID=7395) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:13:08,992] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:13:08,993] {logging_mixin.py:115} INFO - [2023-01-06 00:13:08,993] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:13:09,830] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:13:09,832] {logging_mixin.py:115} INFO - [2023-01-06 00:13:09,831] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:13:09,832] {logging_mixin.py:115} INFO - [2023-01-06 00:13:09,832] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:13:09,839] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:13:09,862] {logging_mixin.py:115} INFO - [2023-01-06 00:13:09,862] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:13:09,885] {logging_mixin.py:115} INFO - [2023-01-06 00:13:09,884] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:13:09,895] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.911 seconds
[2023-01-06 00:13:40,063] {processor.py:153} INFO - Started process (PID=7421) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:13:40,065] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:13:40,065] {logging_mixin.py:115} INFO - [2023-01-06 00:13:40,065] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:13:40,916] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:13:40,917] {logging_mixin.py:115} INFO - [2023-01-06 00:13:40,917] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:13:40,918] {logging_mixin.py:115} INFO - [2023-01-06 00:13:40,917] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:13:40,925] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:13:40,949] {logging_mixin.py:115} INFO - [2023-01-06 00:13:40,949] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:13:40,972] {logging_mixin.py:115} INFO - [2023-01-06 00:13:40,972] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:13:40,982] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.924 seconds
[2023-01-06 00:14:11,267] {processor.py:153} INFO - Started process (PID=7445) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:14:11,268] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:14:11,269] {logging_mixin.py:115} INFO - [2023-01-06 00:14:11,269] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:14:12,162] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:14:12,163] {logging_mixin.py:115} INFO - [2023-01-06 00:14:12,163] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:14:12,164] {logging_mixin.py:115} INFO - [2023-01-06 00:14:12,164] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:14:12,176] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:14:12,200] {logging_mixin.py:115} INFO - [2023-01-06 00:14:12,200] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:14:12,223] {logging_mixin.py:115} INFO - [2023-01-06 00:14:12,223] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:14:12,234] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.971 seconds
[2023-01-06 00:14:42,349] {processor.py:153} INFO - Started process (PID=7462) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:14:42,351] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:14:42,352] {logging_mixin.py:115} INFO - [2023-01-06 00:14:42,352] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:14:43,183] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:14:43,184] {logging_mixin.py:115} INFO - [2023-01-06 00:14:43,184] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:14:43,184] {logging_mixin.py:115} INFO - [2023-01-06 00:14:43,184] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:14:43,191] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:14:43,215] {logging_mixin.py:115} INFO - [2023-01-06 00:14:43,215] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:14:43,240] {logging_mixin.py:115} INFO - [2023-01-06 00:14:43,240] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:14:43,251] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.906 seconds
[2023-01-06 00:15:13,437] {processor.py:153} INFO - Started process (PID=7488) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:15:13,439] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:15:13,440] {logging_mixin.py:115} INFO - [2023-01-06 00:15:13,440] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:15:14,264] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:15:14,265] {logging_mixin.py:115} INFO - [2023-01-06 00:15:14,265] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:15:14,265] {logging_mixin.py:115} INFO - [2023-01-06 00:15:14,265] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:15:14,272] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:15:14,294] {logging_mixin.py:115} INFO - [2023-01-06 00:15:14,294] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:15:14,316] {logging_mixin.py:115} INFO - [2023-01-06 00:15:14,315] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:15:14,325] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.894 seconds
[2023-01-06 00:15:44,576] {processor.py:153} INFO - Started process (PID=7513) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:15:44,577] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:15:44,577] {logging_mixin.py:115} INFO - [2023-01-06 00:15:44,577] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:15:45,410] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:15:45,411] {logging_mixin.py:115} INFO - [2023-01-06 00:15:45,411] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:15:45,412] {logging_mixin.py:115} INFO - [2023-01-06 00:15:45,411] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:15:45,419] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:15:45,441] {logging_mixin.py:115} INFO - [2023-01-06 00:15:45,440] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:15:45,463] {logging_mixin.py:115} INFO - [2023-01-06 00:15:45,463] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:15:45,473] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.902 seconds
[2023-01-06 00:16:15,656] {processor.py:153} INFO - Started process (PID=7538) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:16:15,661] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:16:15,662] {logging_mixin.py:115} INFO - [2023-01-06 00:16:15,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:16:16,531] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:16:16,532] {logging_mixin.py:115} INFO - [2023-01-06 00:16:16,532] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:16:16,533] {logging_mixin.py:115} INFO - [2023-01-06 00:16:16,533] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:16:16,540] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:16:16,563] {logging_mixin.py:115} INFO - [2023-01-06 00:16:16,563] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:16:16,585] {logging_mixin.py:115} INFO - [2023-01-06 00:16:16,585] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:16:16,595] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.943 seconds
[2023-01-06 00:16:46,729] {processor.py:153} INFO - Started process (PID=7555) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:16:46,730] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:16:46,730] {logging_mixin.py:115} INFO - [2023-01-06 00:16:46,730] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:16:47,582] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:16:47,583] {logging_mixin.py:115} INFO - [2023-01-06 00:16:47,583] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:16:47,584] {logging_mixin.py:115} INFO - [2023-01-06 00:16:47,583] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:16:47,591] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:16:47,613] {logging_mixin.py:115} INFO - [2023-01-06 00:16:47,613] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:16:47,635] {logging_mixin.py:115} INFO - [2023-01-06 00:16:47,635] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:16:47,645] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.921 seconds
[2023-01-06 00:17:17,760] {processor.py:153} INFO - Started process (PID=7579) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:17:17,762] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:17:17,763] {logging_mixin.py:115} INFO - [2023-01-06 00:17:17,763] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:17:18,627] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:17:18,628] {logging_mixin.py:115} INFO - [2023-01-06 00:17:18,628] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:17:18,629] {logging_mixin.py:115} INFO - [2023-01-06 00:17:18,629] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:17:18,636] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:17:18,660] {logging_mixin.py:115} INFO - [2023-01-06 00:17:18,660] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:17:18,683] {logging_mixin.py:115} INFO - [2023-01-06 00:17:18,683] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:17:18,694] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.940 seconds
[2023-01-06 00:17:48,833] {processor.py:153} INFO - Started process (PID=7605) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:17:48,834] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:17:48,834] {logging_mixin.py:115} INFO - [2023-01-06 00:17:48,834] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:17:49,703] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:17:49,704] {logging_mixin.py:115} INFO - [2023-01-06 00:17:49,704] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:17:49,705] {logging_mixin.py:115} INFO - [2023-01-06 00:17:49,704] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:17:49,712] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:17:49,736] {logging_mixin.py:115} INFO - [2023-01-06 00:17:49,736] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:17:49,761] {logging_mixin.py:115} INFO - [2023-01-06 00:17:49,760] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:17:49,771] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.943 seconds
[2023-01-06 00:18:19,884] {processor.py:153} INFO - Started process (PID=7630) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:18:19,886] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:18:19,887] {logging_mixin.py:115} INFO - [2023-01-06 00:18:19,887] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:18:20,920] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:18:20,921] {logging_mixin.py:115} INFO - [2023-01-06 00:18:20,921] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:18:20,922] {logging_mixin.py:115} INFO - [2023-01-06 00:18:20,922] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:18:20,929] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:18:20,952] {logging_mixin.py:115} INFO - [2023-01-06 00:18:20,952] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:18:20,975] {logging_mixin.py:115} INFO - [2023-01-06 00:18:20,975] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:18:20,986] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.107 seconds
[2023-01-06 00:18:51,970] {processor.py:153} INFO - Started process (PID=7648) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:18:51,971] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:18:51,972] {logging_mixin.py:115} INFO - [2023-01-06 00:18:51,971] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:18:52,790] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:18:52,791] {logging_mixin.py:115} INFO - [2023-01-06 00:18:52,791] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:18:52,792] {logging_mixin.py:115} INFO - [2023-01-06 00:18:52,791] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:18:52,799] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:18:52,822] {logging_mixin.py:115} INFO - [2023-01-06 00:18:52,822] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:18:52,845] {logging_mixin.py:115} INFO - [2023-01-06 00:18:52,845] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:18:52,855] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.890 seconds
[2023-01-06 00:19:23,044] {processor.py:153} INFO - Started process (PID=7673) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:19:23,046] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:19:23,046] {logging_mixin.py:115} INFO - [2023-01-06 00:19:23,046] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:19:23,870] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:19:23,872] {logging_mixin.py:115} INFO - [2023-01-06 00:19:23,872] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:19:23,872] {logging_mixin.py:115} INFO - [2023-01-06 00:19:23,872] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:19:23,879] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:19:23,902] {logging_mixin.py:115} INFO - [2023-01-06 00:19:23,902] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:19:23,924] {logging_mixin.py:115} INFO - [2023-01-06 00:19:23,923] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:19:23,933] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.895 seconds
[2023-01-06 00:19:54,268] {processor.py:153} INFO - Started process (PID=7698) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:19:54,268] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:19:54,269] {logging_mixin.py:115} INFO - [2023-01-06 00:19:54,269] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:19:55,118] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:19:55,119] {logging_mixin.py:115} INFO - [2023-01-06 00:19:55,119] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:19:55,120] {logging_mixin.py:115} INFO - [2023-01-06 00:19:55,120] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:19:55,127] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:19:55,151] {logging_mixin.py:115} INFO - [2023-01-06 00:19:55,151] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:19:55,173] {logging_mixin.py:115} INFO - [2023-01-06 00:19:55,173] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:19:55,183] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.920 seconds
[2023-01-06 00:20:25,369] {processor.py:153} INFO - Started process (PID=7723) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:20:25,370] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:20:25,371] {logging_mixin.py:115} INFO - [2023-01-06 00:20:25,371] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:20:26,219] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:20:26,221] {logging_mixin.py:115} INFO - [2023-01-06 00:20:26,221] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:20:26,221] {logging_mixin.py:115} INFO - [2023-01-06 00:20:26,221] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:20:26,228] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:20:26,252] {logging_mixin.py:115} INFO - [2023-01-06 00:20:26,252] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:20:26,277] {logging_mixin.py:115} INFO - [2023-01-06 00:20:26,276] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:20:26,287] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.922 seconds
[2023-01-06 00:20:56,438] {processor.py:153} INFO - Started process (PID=7741) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:20:56,438] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:20:56,439] {logging_mixin.py:115} INFO - [2023-01-06 00:20:56,439] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:20:57,276] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:20:57,277] {logging_mixin.py:115} INFO - [2023-01-06 00:20:57,277] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:20:57,278] {logging_mixin.py:115} INFO - [2023-01-06 00:20:57,278] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:20:57,285] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:20:57,308] {logging_mixin.py:115} INFO - [2023-01-06 00:20:57,307] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:20:57,330] {logging_mixin.py:115} INFO - [2023-01-06 00:20:57,329] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:20:57,340] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.907 seconds
[2023-01-06 00:21:27,598] {processor.py:153} INFO - Started process (PID=7765) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:21:27,601] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:21:27,601] {logging_mixin.py:115} INFO - [2023-01-06 00:21:27,601] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:21:28,448] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:21:28,450] {logging_mixin.py:115} INFO - [2023-01-06 00:21:28,450] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:21:28,450] {logging_mixin.py:115} INFO - [2023-01-06 00:21:28,450] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:21:28,457] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:21:28,482] {logging_mixin.py:115} INFO - [2023-01-06 00:21:28,482] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:21:28,505] {logging_mixin.py:115} INFO - [2023-01-06 00:21:28,505] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:21:28,516] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.924 seconds
[2023-01-06 00:21:58,715] {processor.py:153} INFO - Started process (PID=7790) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:21:58,715] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:21:58,716] {logging_mixin.py:115} INFO - [2023-01-06 00:21:58,716] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:21:59,567] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:21:59,568] {logging_mixin.py:115} INFO - [2023-01-06 00:21:59,568] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:21:59,569] {logging_mixin.py:115} INFO - [2023-01-06 00:21:59,569] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:21:59,576] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:21:59,600] {logging_mixin.py:115} INFO - [2023-01-06 00:21:59,600] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:21:59,623] {logging_mixin.py:115} INFO - [2023-01-06 00:21:59,623] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:21:59,633] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.923 seconds
[2023-01-06 00:22:29,780] {processor.py:153} INFO - Started process (PID=7816) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:22:29,781] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:22:29,784] {logging_mixin.py:115} INFO - [2023-01-06 00:22:29,783] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:22:30,596] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:22:30,598] {logging_mixin.py:115} INFO - [2023-01-06 00:22:30,598] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:22:30,598] {logging_mixin.py:115} INFO - [2023-01-06 00:22:30,598] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:22:30,605] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:22:30,628] {logging_mixin.py:115} INFO - [2023-01-06 00:22:30,627] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:22:30,649] {logging_mixin.py:115} INFO - [2023-01-06 00:22:30,649] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:22:30,658] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.884 seconds
[2023-01-06 00:23:00,861] {processor.py:153} INFO - Started process (PID=7833) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:23:00,862] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:23:00,863] {logging_mixin.py:115} INFO - [2023-01-06 00:23:00,863] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:23:01,690] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:23:01,692] {logging_mixin.py:115} INFO - [2023-01-06 00:23:01,692] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:23:01,692] {logging_mixin.py:115} INFO - [2023-01-06 00:23:01,692] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:23:01,699] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:23:01,729] {logging_mixin.py:115} INFO - [2023-01-06 00:23:01,729] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:23:01,758] {logging_mixin.py:115} INFO - [2023-01-06 00:23:01,758] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:23:01,769] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.913 seconds
[2023-01-06 00:23:31,932] {processor.py:153} INFO - Started process (PID=7859) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:23:31,933] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:23:31,934] {logging_mixin.py:115} INFO - [2023-01-06 00:23:31,934] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:23:32,787] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:23:32,788] {logging_mixin.py:115} INFO - [2023-01-06 00:23:32,788] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:23:32,789] {logging_mixin.py:115} INFO - [2023-01-06 00:23:32,788] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:23:32,796] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:23:32,822] {logging_mixin.py:115} INFO - [2023-01-06 00:23:32,822] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:23:32,845] {logging_mixin.py:115} INFO - [2023-01-06 00:23:32,845] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:23:32,855] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.928 seconds
[2023-01-06 00:24:03,043] {processor.py:153} INFO - Started process (PID=7884) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:24:03,044] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:24:03,045] {logging_mixin.py:115} INFO - [2023-01-06 00:24:03,045] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:24:03,866] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:24:03,867] {logging_mixin.py:115} INFO - [2023-01-06 00:24:03,867] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:24:03,868] {logging_mixin.py:115} INFO - [2023-01-06 00:24:03,867] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:24:03,876] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:24:03,904] {logging_mixin.py:115} INFO - [2023-01-06 00:24:03,904] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:24:03,929] {logging_mixin.py:115} INFO - [2023-01-06 00:24:03,929] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:24:03,940] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.902 seconds
[2023-01-06 00:24:34,202] {processor.py:153} INFO - Started process (PID=7910) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:24:34,203] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:24:34,204] {logging_mixin.py:115} INFO - [2023-01-06 00:24:34,204] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:24:35,171] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:24:35,173] {logging_mixin.py:115} INFO - [2023-01-06 00:24:35,173] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:24:35,173] {logging_mixin.py:115} INFO - [2023-01-06 00:24:35,173] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:24:35,180] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:24:35,211] {logging_mixin.py:115} INFO - [2023-01-06 00:24:35,210] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:24:35,242] {logging_mixin.py:115} INFO - [2023-01-06 00:24:35,241] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:24:35,255] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.059 seconds
[2023-01-06 00:25:05,328] {processor.py:153} INFO - Started process (PID=7928) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:25:05,330] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:25:05,330] {logging_mixin.py:115} INFO - [2023-01-06 00:25:05,330] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:25:06,163] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:25:06,164] {logging_mixin.py:115} INFO - [2023-01-06 00:25:06,164] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:25:06,165] {logging_mixin.py:115} INFO - [2023-01-06 00:25:06,164] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:25:06,172] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:25:06,196] {logging_mixin.py:115} INFO - [2023-01-06 00:25:06,196] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:25:06,219] {logging_mixin.py:115} INFO - [2023-01-06 00:25:06,219] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:25:06,229] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.909 seconds
[2023-01-06 00:25:36,409] {processor.py:153} INFO - Started process (PID=7953) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:25:36,410] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:25:36,411] {logging_mixin.py:115} INFO - [2023-01-06 00:25:36,411] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:25:37,244] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:25:37,245] {logging_mixin.py:115} INFO - [2023-01-06 00:25:37,245] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:25:37,245] {logging_mixin.py:115} INFO - [2023-01-06 00:25:37,245] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:25:37,252] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:25:37,275] {logging_mixin.py:115} INFO - [2023-01-06 00:25:37,275] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:25:37,296] {logging_mixin.py:115} INFO - [2023-01-06 00:25:37,296] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:25:37,305] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.901 seconds
[2023-01-06 00:26:07,524] {processor.py:153} INFO - Started process (PID=7978) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:26:07,526] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:26:07,526] {logging_mixin.py:115} INFO - [2023-01-06 00:26:07,526] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:26:08,341] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:26:08,342] {logging_mixin.py:115} INFO - [2023-01-06 00:26:08,342] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:26:08,343] {logging_mixin.py:115} INFO - [2023-01-06 00:26:08,342] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:26:08,349] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:26:08,373] {logging_mixin.py:115} INFO - [2023-01-06 00:26:08,372] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:26:08,395] {logging_mixin.py:115} INFO - [2023-01-06 00:26:08,395] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:26:08,405] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.886 seconds
[2023-01-06 00:26:38,603] {processor.py:153} INFO - Started process (PID=8001) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:26:38,604] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:26:38,604] {logging_mixin.py:115} INFO - [2023-01-06 00:26:38,604] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:26:39,420] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:26:39,422] {logging_mixin.py:115} INFO - [2023-01-06 00:26:39,422] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:26:39,422] {logging_mixin.py:115} INFO - [2023-01-06 00:26:39,422] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:26:39,430] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:26:39,453] {logging_mixin.py:115} INFO - [2023-01-06 00:26:39,453] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:26:39,476] {logging_mixin.py:115} INFO - [2023-01-06 00:26:39,476] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:26:39,486] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.887 seconds
[2023-01-06 00:27:09,672] {processor.py:153} INFO - Started process (PID=8018) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:27:09,673] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:27:09,674] {logging_mixin.py:115} INFO - [2023-01-06 00:27:09,674] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:27:10,509] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:27:10,510] {logging_mixin.py:115} INFO - [2023-01-06 00:27:10,510] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:27:10,511] {logging_mixin.py:115} INFO - [2023-01-06 00:27:10,510] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:27:10,518] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:27:10,541] {logging_mixin.py:115} INFO - [2023-01-06 00:27:10,541] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:27:10,565] {logging_mixin.py:115} INFO - [2023-01-06 00:27:10,565] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:27:10,575] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.909 seconds
[2023-01-06 00:27:40,747] {processor.py:153} INFO - Started process (PID=8043) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:27:40,748] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:27:40,748] {logging_mixin.py:115} INFO - [2023-01-06 00:27:40,748] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:27:41,582] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:27:41,584] {logging_mixin.py:115} INFO - [2023-01-06 00:27:41,583] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:27:41,584] {logging_mixin.py:115} INFO - [2023-01-06 00:27:41,584] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:27:41,591] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:27:41,613] {logging_mixin.py:115} INFO - [2023-01-06 00:27:41,613] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:27:41,636] {logging_mixin.py:115} INFO - [2023-01-06 00:27:41,636] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:27:41,649] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.906 seconds
[2023-01-06 00:28:11,752] {processor.py:153} INFO - Started process (PID=8068) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:28:11,754] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:28:11,754] {logging_mixin.py:115} INFO - [2023-01-06 00:28:11,754] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:28:12,666] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:28:12,668] {logging_mixin.py:115} INFO - [2023-01-06 00:28:12,667] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:28:12,668] {logging_mixin.py:115} INFO - [2023-01-06 00:28:12,668] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:28:12,679] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:28:12,705] {logging_mixin.py:115} INFO - [2023-01-06 00:28:12,704] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:28:12,728] {logging_mixin.py:115} INFO - [2023-01-06 00:28:12,728] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:28:12,739] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.992 seconds
[2023-01-06 00:28:13,765] {processor.py:153} INFO - Started process (PID=8070) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:28:13,766] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:28:13,766] {logging_mixin.py:115} INFO - [2023-01-06 00:28:13,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:28:14,609] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:28:14,610] {logging_mixin.py:115} INFO - [2023-01-06 00:28:14,610] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:28:14,611] {logging_mixin.py:115} INFO - [2023-01-06 00:28:14,611] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:28:14,618] {logging_mixin.py:115} INFO - [2023-01-06 00:28:14,618] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 88, in <module>
    download_stock_data_from_datalake_task >> create_cluster_dataproc_task >> submit_spark_job_task >> delete_cluster_dataproc_task
NameError: name 'download_stock_data_from_datalake_task' is not defined
[2023-01-06 00:28:14,619] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:28:14,637] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.877 seconds
[2023-01-06 00:28:37,719] {processor.py:153} INFO - Started process (PID=8089) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:28:37,721] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:28:37,721] {logging_mixin.py:115} INFO - [2023-01-06 00:28:37,721] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:28:38,605] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:28:38,607] {logging_mixin.py:115} INFO - [2023-01-06 00:28:38,607] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:28:38,608] {logging_mixin.py:115} INFO - [2023-01-06 00:28:38,607] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:28:38,616] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:28:38,675] {logging_mixin.py:115} INFO - [2023-01-06 00:28:38,675] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:28:38,694] {logging_mixin.py:115} INFO - [2023-01-06 00:28:38,694] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:28:38,708] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.993 seconds
[2023-01-06 00:29:08,849] {processor.py:153} INFO - Started process (PID=8118) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:29:08,850] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:29:08,850] {logging_mixin.py:115} INFO - [2023-01-06 00:29:08,850] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:29:09,791] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:29:09,793] {logging_mixin.py:115} INFO - [2023-01-06 00:29:09,793] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:29:09,794] {logging_mixin.py:115} INFO - [2023-01-06 00:29:09,793] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:29:09,801] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:29:09,825] {logging_mixin.py:115} INFO - [2023-01-06 00:29:09,825] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:29:09,849] {logging_mixin.py:115} INFO - [2023-01-06 00:29:09,849] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:29:09,859] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.015 seconds
[2023-01-06 00:29:39,940] {processor.py:153} INFO - Started process (PID=8136) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:29:39,942] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:29:39,943] {logging_mixin.py:115} INFO - [2023-01-06 00:29:39,943] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:29:40,799] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:29:40,801] {logging_mixin.py:115} INFO - [2023-01-06 00:29:40,800] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:29:40,801] {logging_mixin.py:115} INFO - [2023-01-06 00:29:40,801] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:29:40,808] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:29:40,831] {logging_mixin.py:115} INFO - [2023-01-06 00:29:40,831] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:29:40,853] {logging_mixin.py:115} INFO - [2023-01-06 00:29:40,853] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:29:40,864] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.929 seconds
[2023-01-06 00:30:11,018] {processor.py:153} INFO - Started process (PID=8161) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:30:11,019] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:30:11,019] {logging_mixin.py:115} INFO - [2023-01-06 00:30:11,019] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:30:11,860] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:30:11,862] {logging_mixin.py:115} INFO - [2023-01-06 00:30:11,862] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:30:11,862] {logging_mixin.py:115} INFO - [2023-01-06 00:30:11,862] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:30:11,869] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:30:11,892] {logging_mixin.py:115} INFO - [2023-01-06 00:30:11,892] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:30:11,915] {logging_mixin.py:115} INFO - [2023-01-06 00:30:11,915] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:30:11,925] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.912 seconds
[2023-01-06 00:30:42,048] {processor.py:153} INFO - Started process (PID=8186) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:30:42,050] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:30:42,051] {logging_mixin.py:115} INFO - [2023-01-06 00:30:42,050] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:30:42,920] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:30:42,921] {logging_mixin.py:115} INFO - [2023-01-06 00:30:42,921] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:30:42,922] {logging_mixin.py:115} INFO - [2023-01-06 00:30:42,921] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:30:42,928] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:30:42,951] {logging_mixin.py:115} INFO - [2023-01-06 00:30:42,950] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:30:42,973] {logging_mixin.py:115} INFO - [2023-01-06 00:30:42,973] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:30:42,983] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.940 seconds
[2023-01-06 00:31:13,274] {processor.py:153} INFO - Started process (PID=8211) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:31:13,275] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:31:13,275] {logging_mixin.py:115} INFO - [2023-01-06 00:31:13,275] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:31:14,183] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:31:14,185] {logging_mixin.py:115} INFO - [2023-01-06 00:31:14,184] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:31:14,185] {logging_mixin.py:115} INFO - [2023-01-06 00:31:14,185] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:31:14,194] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:31:14,221] {logging_mixin.py:115} INFO - [2023-01-06 00:31:14,221] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:31:14,243] {logging_mixin.py:115} INFO - [2023-01-06 00:31:14,243] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:31:14,256] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.987 seconds
[2023-01-06 00:31:44,354] {processor.py:153} INFO - Started process (PID=8229) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:31:44,354] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:31:44,355] {logging_mixin.py:115} INFO - [2023-01-06 00:31:44,355] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:31:45,232] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:31:45,233] {logging_mixin.py:115} INFO - [2023-01-06 00:31:45,233] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:31:45,234] {logging_mixin.py:115} INFO - [2023-01-06 00:31:45,234] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:31:45,241] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:31:45,263] {logging_mixin.py:115} INFO - [2023-01-06 00:31:45,263] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:31:45,286] {logging_mixin.py:115} INFO - [2023-01-06 00:31:45,285] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:31:45,295] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.947 seconds
[2023-01-06 00:32:15,570] {processor.py:153} INFO - Started process (PID=8256) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:32:15,572] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:32:15,573] {logging_mixin.py:115} INFO - [2023-01-06 00:32:15,573] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:32:16,431] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:32:16,433] {logging_mixin.py:115} INFO - [2023-01-06 00:32:16,432] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:32:16,433] {logging_mixin.py:115} INFO - [2023-01-06 00:32:16,433] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:32:16,440] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:32:16,465] {logging_mixin.py:115} INFO - [2023-01-06 00:32:16,465] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:32:16,487] {logging_mixin.py:115} INFO - [2023-01-06 00:32:16,487] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:32:16,497] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.931 seconds
[2023-01-06 00:32:46,742] {processor.py:153} INFO - Started process (PID=8281) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:32:46,743] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:32:46,744] {logging_mixin.py:115} INFO - [2023-01-06 00:32:46,744] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:32:47,618] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:32:47,620] {logging_mixin.py:115} INFO - [2023-01-06 00:32:47,619] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:32:47,620] {logging_mixin.py:115} INFO - [2023-01-06 00:32:47,620] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:32:47,627] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:32:47,649] {logging_mixin.py:115} INFO - [2023-01-06 00:32:47,649] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:32:47,671] {logging_mixin.py:115} INFO - [2023-01-06 00:32:47,671] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:32:47,681] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.944 seconds
[2023-01-06 00:33:17,824] {processor.py:153} INFO - Started process (PID=8305) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:33:17,825] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:33:17,826] {logging_mixin.py:115} INFO - [2023-01-06 00:33:17,826] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:33:18,666] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:33:18,668] {logging_mixin.py:115} INFO - [2023-01-06 00:33:18,668] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:33:18,668] {logging_mixin.py:115} INFO - [2023-01-06 00:33:18,668] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:33:18,675] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:33:18,698] {logging_mixin.py:115} INFO - [2023-01-06 00:33:18,698] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:33:18,721] {logging_mixin.py:115} INFO - [2023-01-06 00:33:18,721] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:33:18,731] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.912 seconds
[2023-01-06 00:33:48,889] {processor.py:153} INFO - Started process (PID=8323) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:33:48,889] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:33:48,890] {logging_mixin.py:115} INFO - [2023-01-06 00:33:48,890] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:33:49,738] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:33:49,740] {logging_mixin.py:115} INFO - [2023-01-06 00:33:49,740] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:33:49,741] {logging_mixin.py:115} INFO - [2023-01-06 00:33:49,740] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:33:49,752] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:33:49,782] {logging_mixin.py:115} INFO - [2023-01-06 00:33:49,782] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:33:49,809] {logging_mixin.py:115} INFO - [2023-01-06 00:33:49,809] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:33:49,824] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.940 seconds
[2023-01-06 00:34:20,014] {processor.py:153} INFO - Started process (PID=8347) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:34:20,016] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:34:20,016] {logging_mixin.py:115} INFO - [2023-01-06 00:34:20,016] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:34:20,840] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:34:20,842] {logging_mixin.py:115} INFO - [2023-01-06 00:34:20,841] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:34:20,842] {logging_mixin.py:115} INFO - [2023-01-06 00:34:20,842] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:34:20,849] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:34:20,872] {logging_mixin.py:115} INFO - [2023-01-06 00:34:20,871] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:34:20,894] {logging_mixin.py:115} INFO - [2023-01-06 00:34:20,894] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:34:20,904] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.895 seconds
[2023-01-06 00:34:51,342] {processor.py:153} INFO - Started process (PID=8372) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:34:51,342] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:34:51,343] {logging_mixin.py:115} INFO - [2023-01-06 00:34:51,343] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:34:52,166] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:34:52,168] {logging_mixin.py:115} INFO - [2023-01-06 00:34:52,168] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:34:52,168] {logging_mixin.py:115} INFO - [2023-01-06 00:34:52,168] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:34:52,175] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:34:52,199] {logging_mixin.py:115} INFO - [2023-01-06 00:34:52,199] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:34:52,221] {logging_mixin.py:115} INFO - [2023-01-06 00:34:52,221] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:34:52,230] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.894 seconds
[2023-01-06 00:35:22,424] {processor.py:153} INFO - Started process (PID=8397) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:35:22,426] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:35:22,427] {logging_mixin.py:115} INFO - [2023-01-06 00:35:22,427] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:35:23,340] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:35:23,342] {logging_mixin.py:115} INFO - [2023-01-06 00:35:23,342] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:35:23,343] {logging_mixin.py:115} INFO - [2023-01-06 00:35:23,343] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:35:23,352] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:35:23,375] {logging_mixin.py:115} INFO - [2023-01-06 00:35:23,374] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:35:23,397] {logging_mixin.py:115} INFO - [2023-01-06 00:35:23,396] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:35:23,407] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.987 seconds
[2023-01-06 00:35:53,505] {processor.py:153} INFO - Started process (PID=8415) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:35:53,506] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:35:53,507] {logging_mixin.py:115} INFO - [2023-01-06 00:35:53,506] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:35:54,339] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:35:54,341] {logging_mixin.py:115} INFO - [2023-01-06 00:35:54,341] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:35:54,341] {logging_mixin.py:115} INFO - [2023-01-06 00:35:54,341] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:35:54,348] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:35:54,370] {logging_mixin.py:115} INFO - [2023-01-06 00:35:54,370] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:35:54,392] {logging_mixin.py:115} INFO - [2023-01-06 00:35:54,392] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:35:54,403] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.902 seconds
[2023-01-06 00:36:24,668] {processor.py:153} INFO - Started process (PID=8440) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:36:24,670] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:36:24,670] {logging_mixin.py:115} INFO - [2023-01-06 00:36:24,670] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:36:25,483] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:36:25,484] {logging_mixin.py:115} INFO - [2023-01-06 00:36:25,484] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:36:25,484] {logging_mixin.py:115} INFO - [2023-01-06 00:36:25,484] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:36:25,491] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:36:25,514] {logging_mixin.py:115} INFO - [2023-01-06 00:36:25,514] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:36:25,537] {logging_mixin.py:115} INFO - [2023-01-06 00:36:25,537] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:36:25,548] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.884 seconds
[2023-01-06 00:36:55,743] {processor.py:153} INFO - Started process (PID=8465) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:36:55,746] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:36:55,746] {logging_mixin.py:115} INFO - [2023-01-06 00:36:55,746] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:36:56,570] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:36:56,571] {logging_mixin.py:115} INFO - [2023-01-06 00:36:56,571] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:36:56,572] {logging_mixin.py:115} INFO - [2023-01-06 00:36:56,571] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:36:56,579] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:36:56,602] {logging_mixin.py:115} INFO - [2023-01-06 00:36:56,601] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:36:56,624] {logging_mixin.py:115} INFO - [2023-01-06 00:36:56,624] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:36:56,634] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.896 seconds
[2023-01-06 00:37:26,810] {processor.py:153} INFO - Started process (PID=8491) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:37:26,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:37:26,812] {logging_mixin.py:115} INFO - [2023-01-06 00:37:26,812] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:37:27,636] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:37:27,638] {logging_mixin.py:115} INFO - [2023-01-06 00:37:27,638] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:37:27,638] {logging_mixin.py:115} INFO - [2023-01-06 00:37:27,638] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:37:27,645] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:37:27,669] {logging_mixin.py:115} INFO - [2023-01-06 00:37:27,668] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:37:27,692] {logging_mixin.py:115} INFO - [2023-01-06 00:37:27,692] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:37:27,702] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.896 seconds
[2023-01-06 00:37:57,875] {processor.py:153} INFO - Started process (PID=8509) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:37:57,878] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:37:57,879] {logging_mixin.py:115} INFO - [2023-01-06 00:37:57,879] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:37:58,707] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:37:58,708] {logging_mixin.py:115} INFO - [2023-01-06 00:37:58,708] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:37:58,709] {logging_mixin.py:115} INFO - [2023-01-06 00:37:58,709] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:37:58,716] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:37:58,747] {logging_mixin.py:115} INFO - [2023-01-06 00:37:58,747] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:37:58,770] {logging_mixin.py:115} INFO - [2023-01-06 00:37:58,770] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:37:58,780] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.911 seconds
[2023-01-06 00:38:28,989] {processor.py:153} INFO - Started process (PID=8533) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:38:28,990] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:38:28,990] {logging_mixin.py:115} INFO - [2023-01-06 00:38:28,990] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:38:29,813] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:38:29,815] {logging_mixin.py:115} INFO - [2023-01-06 00:38:29,815] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:38:29,815] {logging_mixin.py:115} INFO - [2023-01-06 00:38:29,815] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:38:29,823] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:38:29,848] {logging_mixin.py:115} INFO - [2023-01-06 00:38:29,848] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:38:29,873] {logging_mixin.py:115} INFO - [2023-01-06 00:38:29,873] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:38:29,884] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.900 seconds
[2023-01-06 00:39:00,051] {processor.py:153} INFO - Started process (PID=8559) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:39:00,052] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:39:00,053] {logging_mixin.py:115} INFO - [2023-01-06 00:39:00,053] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:39:00,958] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:39:00,960] {logging_mixin.py:115} INFO - [2023-01-06 00:39:00,960] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:39:00,961] {logging_mixin.py:115} INFO - [2023-01-06 00:39:00,960] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:39:00,967] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:39:00,990] {logging_mixin.py:115} INFO - [2023-01-06 00:39:00,989] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:39:01,012] {logging_mixin.py:115} INFO - [2023-01-06 00:39:01,011] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:39:01,022] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.976 seconds
[2023-01-06 00:39:31,128] {processor.py:153} INFO - Started process (PID=8585) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:39:31,130] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:39:31,131] {logging_mixin.py:115} INFO - [2023-01-06 00:39:31,131] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:39:32,106] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:39:32,108] {logging_mixin.py:115} INFO - [2023-01-06 00:39:32,108] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:39:32,108] {logging_mixin.py:115} INFO - [2023-01-06 00:39:32,108] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:39:32,115] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:39:32,138] {logging_mixin.py:115} INFO - [2023-01-06 00:39:32,138] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:39:32,160] {logging_mixin.py:115} INFO - [2023-01-06 00:39:32,160] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:39:32,170] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.049 seconds
[2023-01-06 00:40:02,245] {processor.py:153} INFO - Started process (PID=8603) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:40:02,247] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:40:02,247] {logging_mixin.py:115} INFO - [2023-01-06 00:40:02,247] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:40:03,085] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:40:03,086] {logging_mixin.py:115} INFO - [2023-01-06 00:40:03,086] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:40:03,087] {logging_mixin.py:115} INFO - [2023-01-06 00:40:03,086] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:40:03,094] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:40:03,116] {logging_mixin.py:115} INFO - [2023-01-06 00:40:03,116] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:40:03,137] {logging_mixin.py:115} INFO - [2023-01-06 00:40:03,137] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:40:03,147] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.907 seconds
[2023-01-06 00:40:33,527] {processor.py:153} INFO - Started process (PID=8628) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:40:33,528] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:40:33,529] {logging_mixin.py:115} INFO - [2023-01-06 00:40:33,529] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:40:34,407] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:40:34,408] {logging_mixin.py:115} INFO - [2023-01-06 00:40:34,408] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:40:34,409] {logging_mixin.py:115} INFO - [2023-01-06 00:40:34,408] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:40:34,417] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:40:34,441] {logging_mixin.py:115} INFO - [2023-01-06 00:40:34,440] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:40:34,465] {logging_mixin.py:115} INFO - [2023-01-06 00:40:34,464] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:40:34,475] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.954 seconds
[2023-01-06 00:41:04,586] {processor.py:153} INFO - Started process (PID=8652) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:41:04,588] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:41:04,589] {logging_mixin.py:115} INFO - [2023-01-06 00:41:04,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:41:05,592] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:41:05,593] {logging_mixin.py:115} INFO - [2023-01-06 00:41:05,593] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:41:05,594] {logging_mixin.py:115} INFO - [2023-01-06 00:41:05,593] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:41:05,601] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:41:05,626] {logging_mixin.py:115} INFO - [2023-01-06 00:41:05,625] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:41:05,648] {logging_mixin.py:115} INFO - [2023-01-06 00:41:05,647] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:41:05,657] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.076 seconds
[2023-01-06 00:41:35,734] {processor.py:153} INFO - Started process (PID=8678) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:41:35,735] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:41:35,735] {logging_mixin.py:115} INFO - [2023-01-06 00:41:35,735] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:41:36,608] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:41:36,609] {logging_mixin.py:115} INFO - [2023-01-06 00:41:36,609] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:41:36,610] {logging_mixin.py:115} INFO - [2023-01-06 00:41:36,609] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:41:36,617] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:41:36,640] {logging_mixin.py:115} INFO - [2023-01-06 00:41:36,640] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:41:36,663] {logging_mixin.py:115} INFO - [2023-01-06 00:41:36,663] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:41:36,673] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.944 seconds
[2023-01-06 00:42:06,753] {processor.py:153} INFO - Started process (PID=8696) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:42:06,756] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:42:06,757] {logging_mixin.py:115} INFO - [2023-01-06 00:42:06,756] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:42:07,578] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:42:07,579] {logging_mixin.py:115} INFO - [2023-01-06 00:42:07,579] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:42:07,580] {logging_mixin.py:115} INFO - [2023-01-06 00:42:07,579] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:42:07,586] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:42:07,608] {logging_mixin.py:115} INFO - [2023-01-06 00:42:07,608] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:42:07,630] {logging_mixin.py:115} INFO - [2023-01-06 00:42:07,630] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:42:07,640] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.891 seconds
[2023-01-06 00:42:37,881] {processor.py:153} INFO - Started process (PID=8724) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:42:37,883] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:42:37,883] {logging_mixin.py:115} INFO - [2023-01-06 00:42:37,883] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:42:38,721] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:42:38,723] {logging_mixin.py:115} INFO - [2023-01-06 00:42:38,723] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:42:38,723] {logging_mixin.py:115} INFO - [2023-01-06 00:42:38,723] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:42:38,732] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:42:38,756] {logging_mixin.py:115} INFO - [2023-01-06 00:42:38,756] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:42:38,785] {logging_mixin.py:115} INFO - [2023-01-06 00:42:38,785] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:42:38,798] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.922 seconds
[2023-01-06 00:43:08,964] {processor.py:153} INFO - Started process (PID=8750) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:43:08,965] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:43:08,966] {logging_mixin.py:115} INFO - [2023-01-06 00:43:08,966] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:43:09,803] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:43:09,805] {logging_mixin.py:115} INFO - [2023-01-06 00:43:09,805] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:43:09,805] {logging_mixin.py:115} INFO - [2023-01-06 00:43:09,805] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:43:09,812] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:43:09,837] {logging_mixin.py:115} INFO - [2023-01-06 00:43:09,837] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:43:09,862] {logging_mixin.py:115} INFO - [2023-01-06 00:43:09,862] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:43:09,873] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.915 seconds
[2023-01-06 00:43:40,103] {processor.py:153} INFO - Started process (PID=8767) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:43:40,105] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:43:40,106] {logging_mixin.py:115} INFO - [2023-01-06 00:43:40,105] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:43:40,967] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:43:40,968] {logging_mixin.py:115} INFO - [2023-01-06 00:43:40,968] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:43:40,969] {logging_mixin.py:115} INFO - [2023-01-06 00:43:40,968] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:43:40,976] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:43:41,002] {logging_mixin.py:115} INFO - [2023-01-06 00:43:41,001] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:43:41,026] {logging_mixin.py:115} INFO - [2023-01-06 00:43:41,026] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:43:41,037] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.939 seconds
[2023-01-06 00:44:11,194] {processor.py:153} INFO - Started process (PID=8791) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:44:11,195] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:44:11,196] {logging_mixin.py:115} INFO - [2023-01-06 00:44:11,196] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:44:12,040] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:44:12,041] {logging_mixin.py:115} INFO - [2023-01-06 00:44:12,041] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:44:12,042] {logging_mixin.py:115} INFO - [2023-01-06 00:44:12,041] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:44:12,049] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:44:12,072] {logging_mixin.py:115} INFO - [2023-01-06 00:44:12,071] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:44:12,094] {logging_mixin.py:115} INFO - [2023-01-06 00:44:12,094] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:44:12,103] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.915 seconds
[2023-01-06 00:44:42,316] {processor.py:153} INFO - Started process (PID=8817) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:44:42,316] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:44:42,317] {logging_mixin.py:115} INFO - [2023-01-06 00:44:42,317] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:44:43,140] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:44:43,141] {logging_mixin.py:115} INFO - [2023-01-06 00:44:43,141] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:44:43,142] {logging_mixin.py:115} INFO - [2023-01-06 00:44:43,141] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:44:43,149] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:44:43,173] {logging_mixin.py:115} INFO - [2023-01-06 00:44:43,173] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:44:43,196] {logging_mixin.py:115} INFO - [2023-01-06 00:44:43,196] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:44:43,206] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.895 seconds
[2023-01-06 00:45:13,394] {processor.py:153} INFO - Started process (PID=8842) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:45:13,398] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:45:13,399] {logging_mixin.py:115} INFO - [2023-01-06 00:45:13,399] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:45:14,223] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:45:14,225] {logging_mixin.py:115} INFO - [2023-01-06 00:45:14,224] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:45:14,225] {logging_mixin.py:115} INFO - [2023-01-06 00:45:14,225] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:45:14,236] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:45:14,282] {logging_mixin.py:115} INFO - [2023-01-06 00:45:14,282] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:45:14,316] {logging_mixin.py:115} INFO - [2023-01-06 00:45:14,316] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:45:14,329] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.940 seconds
[2023-01-06 00:45:44,461] {processor.py:153} INFO - Started process (PID=8861) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:45:44,462] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:45:44,462] {logging_mixin.py:115} INFO - [2023-01-06 00:45:44,462] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:45:45,311] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:45:45,312] {logging_mixin.py:115} INFO - [2023-01-06 00:45:45,312] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:45:45,313] {logging_mixin.py:115} INFO - [2023-01-06 00:45:45,313] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:45:45,320] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:45:45,349] {logging_mixin.py:115} INFO - [2023-01-06 00:45:45,348] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:45:45,371] {logging_mixin.py:115} INFO - [2023-01-06 00:45:45,371] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:45:45,382] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.926 seconds
[2023-01-06 00:46:15,558] {processor.py:153} INFO - Started process (PID=8887) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:46:15,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:46:15,560] {logging_mixin.py:115} INFO - [2023-01-06 00:46:15,560] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:46:16,412] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:46:16,414] {logging_mixin.py:115} INFO - [2023-01-06 00:46:16,414] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:46:16,414] {logging_mixin.py:115} INFO - [2023-01-06 00:46:16,414] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:46:16,421] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:46:16,444] {logging_mixin.py:115} INFO - [2023-01-06 00:46:16,443] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:46:16,465] {logging_mixin.py:115} INFO - [2023-01-06 00:46:16,465] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:46:16,475] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.922 seconds
[2023-01-06 00:46:46,637] {processor.py:153} INFO - Started process (PID=8912) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:46:46,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:46:46,641] {logging_mixin.py:115} INFO - [2023-01-06 00:46:46,640] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:46:47,491] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:46:47,492] {logging_mixin.py:115} INFO - [2023-01-06 00:46:47,492] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:46:47,493] {logging_mixin.py:115} INFO - [2023-01-06 00:46:47,493] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:46:47,500] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:46:47,524] {logging_mixin.py:115} INFO - [2023-01-06 00:46:47,524] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:46:47,547] {logging_mixin.py:115} INFO - [2023-01-06 00:46:47,547] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:46:47,557] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.927 seconds
[2023-01-06 00:47:17,702] {processor.py:153} INFO - Started process (PID=8938) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:47:17,704] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:47:17,705] {logging_mixin.py:115} INFO - [2023-01-06 00:47:17,705] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:47:18,561] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:47:18,562] {logging_mixin.py:115} INFO - [2023-01-06 00:47:18,562] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:47:18,563] {logging_mixin.py:115} INFO - [2023-01-06 00:47:18,562] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:47:18,570] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:47:18,592] {logging_mixin.py:115} INFO - [2023-01-06 00:47:18,592] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:47:18,614] {logging_mixin.py:115} INFO - [2023-01-06 00:47:18,614] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:47:18,624] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.927 seconds
[2023-01-06 00:47:48,828] {processor.py:153} INFO - Started process (PID=8956) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:47:48,829] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:47:48,830] {logging_mixin.py:115} INFO - [2023-01-06 00:47:48,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:47:49,676] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:47:49,678] {logging_mixin.py:115} INFO - [2023-01-06 00:47:49,678] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:47:49,678] {logging_mixin.py:115} INFO - [2023-01-06 00:47:49,678] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:47:49,687] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:47:49,709] {logging_mixin.py:115} INFO - [2023-01-06 00:47:49,709] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:47:49,731] {logging_mixin.py:115} INFO - [2023-01-06 00:47:49,731] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:47:49,741] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.918 seconds
[2023-01-06 00:48:20,001] {processor.py:153} INFO - Started process (PID=8981) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:48:20,002] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:48:20,003] {logging_mixin.py:115} INFO - [2023-01-06 00:48:20,003] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:48:20,878] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:48:20,879] {logging_mixin.py:115} INFO - [2023-01-06 00:48:20,879] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:48:20,880] {logging_mixin.py:115} INFO - [2023-01-06 00:48:20,880] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:48:20,892] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:48:20,915] {logging_mixin.py:115} INFO - [2023-01-06 00:48:20,914] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:48:20,936] {logging_mixin.py:115} INFO - [2023-01-06 00:48:20,936] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:48:20,946] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.950 seconds
[2023-01-06 00:48:51,053] {processor.py:153} INFO - Started process (PID=9006) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:48:51,056] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:48:51,056] {logging_mixin.py:115} INFO - [2023-01-06 00:48:51,056] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:48:51,853] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:48:51,854] {logging_mixin.py:115} INFO - [2023-01-06 00:48:51,854] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:48:51,855] {logging_mixin.py:115} INFO - [2023-01-06 00:48:51,854] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:48:51,862] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:48:51,885] {logging_mixin.py:115} INFO - [2023-01-06 00:48:51,884] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:48:51,907] {logging_mixin.py:115} INFO - [2023-01-06 00:48:51,907] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:48:51,918] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.869 seconds
[2023-01-06 00:49:22,120] {processor.py:153} INFO - Started process (PID=9031) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:49:22,120] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:49:22,121] {logging_mixin.py:115} INFO - [2023-01-06 00:49:22,121] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:49:22,980] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:49:22,982] {logging_mixin.py:115} INFO - [2023-01-06 00:49:22,982] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:49:22,982] {logging_mixin.py:115} INFO - [2023-01-06 00:49:22,982] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:49:22,989] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:49:23,014] {logging_mixin.py:115} INFO - [2023-01-06 00:49:23,013] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:49:23,040] {logging_mixin.py:115} INFO - [2023-01-06 00:49:23,040] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:49:23,057] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.942 seconds
[2023-01-06 00:49:53,174] {processor.py:153} INFO - Started process (PID=9049) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:49:53,175] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:49:53,176] {logging_mixin.py:115} INFO - [2023-01-06 00:49:53,176] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:49:54,029] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:49:54,030] {logging_mixin.py:115} INFO - [2023-01-06 00:49:54,030] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:49:54,031] {logging_mixin.py:115} INFO - [2023-01-06 00:49:54,030] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:49:54,037] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:49:54,061] {logging_mixin.py:115} INFO - [2023-01-06 00:49:54,060] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:49:54,082] {logging_mixin.py:115} INFO - [2023-01-06 00:49:54,082] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:49:54,092] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.923 seconds
[2023-01-06 00:50:24,301] {processor.py:153} INFO - Started process (PID=9073) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:50:24,302] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:50:24,303] {logging_mixin.py:115} INFO - [2023-01-06 00:50:24,303] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:50:25,153] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:50:25,154] {logging_mixin.py:115} INFO - [2023-01-06 00:50:25,154] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:50:25,155] {logging_mixin.py:115} INFO - [2023-01-06 00:50:25,154] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:50:25,162] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:50:25,185] {logging_mixin.py:115} INFO - [2023-01-06 00:50:25,184] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:50:25,208] {logging_mixin.py:115} INFO - [2023-01-06 00:50:25,208] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:50:25,219] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.922 seconds
[2023-01-06 00:50:55,438] {processor.py:153} INFO - Started process (PID=9097) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:50:55,438] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:50:55,439] {logging_mixin.py:115} INFO - [2023-01-06 00:50:55,439] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:50:56,246] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:50:56,248] {logging_mixin.py:115} INFO - [2023-01-06 00:50:56,248] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:50:56,248] {logging_mixin.py:115} INFO - [2023-01-06 00:50:56,248] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:50:56,255] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:50:56,278] {logging_mixin.py:115} INFO - [2023-01-06 00:50:56,278] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:50:56,301] {logging_mixin.py:115} INFO - [2023-01-06 00:50:56,301] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:50:56,312] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.879 seconds
[2023-01-06 00:51:26,509] {processor.py:153} INFO - Started process (PID=9123) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:51:26,510] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:51:26,511] {logging_mixin.py:115} INFO - [2023-01-06 00:51:26,511] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:51:27,316] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:51:27,317] {logging_mixin.py:115} INFO - [2023-01-06 00:51:27,317] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:51:27,318] {logging_mixin.py:115} INFO - [2023-01-06 00:51:27,318] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:51:27,325] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:51:27,348] {logging_mixin.py:115} INFO - [2023-01-06 00:51:27,348] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:51:27,370] {logging_mixin.py:115} INFO - [2023-01-06 00:51:27,370] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:51:27,381] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.877 seconds
[2023-01-06 00:51:57,599] {processor.py:153} INFO - Started process (PID=9141) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:51:57,600] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:51:57,601] {logging_mixin.py:115} INFO - [2023-01-06 00:51:57,600] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:51:58,431] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:51:58,432] {logging_mixin.py:115} INFO - [2023-01-06 00:51:58,432] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:51:58,433] {logging_mixin.py:115} INFO - [2023-01-06 00:51:58,433] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:51:58,440] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:51:58,463] {logging_mixin.py:115} INFO - [2023-01-06 00:51:58,463] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:51:58,485] {logging_mixin.py:115} INFO - [2023-01-06 00:51:58,485] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:51:58,496] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.903 seconds
[2023-01-06 00:52:28,820] {processor.py:153} INFO - Started process (PID=9166) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:52:28,822] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:52:28,822] {logging_mixin.py:115} INFO - [2023-01-06 00:52:28,822] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:52:29,658] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:52:29,660] {logging_mixin.py:115} INFO - [2023-01-06 00:52:29,660] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:52:29,660] {logging_mixin.py:115} INFO - [2023-01-06 00:52:29,660] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:52:29,667] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:52:29,690] {logging_mixin.py:115} INFO - [2023-01-06 00:52:29,690] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:52:29,713] {logging_mixin.py:115} INFO - [2023-01-06 00:52:29,713] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:52:29,725] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.910 seconds
[2023-01-06 00:52:59,827] {processor.py:153} INFO - Started process (PID=9193) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:52:59,829] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:52:59,830] {logging_mixin.py:115} INFO - [2023-01-06 00:52:59,829] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:53:00,670] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:53:00,671] {logging_mixin.py:115} INFO - [2023-01-06 00:53:00,671] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:53:00,672] {logging_mixin.py:115} INFO - [2023-01-06 00:53:00,671] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:53:00,679] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:53:00,701] {logging_mixin.py:115} INFO - [2023-01-06 00:53:00,701] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:53:00,722] {logging_mixin.py:115} INFO - [2023-01-06 00:53:00,722] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:53:00,732] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.910 seconds
[2023-01-06 00:53:30,828] {processor.py:153} INFO - Started process (PID=9217) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:53:30,829] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:53:30,829] {logging_mixin.py:115} INFO - [2023-01-06 00:53:30,829] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:53:31,721] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:53:31,723] {logging_mixin.py:115} INFO - [2023-01-06 00:53:31,723] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:53:31,723] {logging_mixin.py:115} INFO - [2023-01-06 00:53:31,723] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:53:31,730] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:53:31,752] {logging_mixin.py:115} INFO - [2023-01-06 00:53:31,752] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:53:31,774] {logging_mixin.py:115} INFO - [2023-01-06 00:53:31,774] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:53:31,784] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.961 seconds
[2023-01-06 00:54:01,979] {processor.py:153} INFO - Started process (PID=9235) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:54:01,980] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:54:01,981] {logging_mixin.py:115} INFO - [2023-01-06 00:54:01,981] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:54:02,811] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:54:02,812] {logging_mixin.py:115} INFO - [2023-01-06 00:54:02,812] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:54:02,813] {logging_mixin.py:115} INFO - [2023-01-06 00:54:02,813] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:54:02,820] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:54:02,842] {logging_mixin.py:115} INFO - [2023-01-06 00:54:02,842] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:54:02,864] {logging_mixin.py:115} INFO - [2023-01-06 00:54:02,864] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:54:02,873] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.900 seconds
[2023-01-06 00:54:33,057] {processor.py:153} INFO - Started process (PID=9261) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:54:33,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:54:33,059] {logging_mixin.py:115} INFO - [2023-01-06 00:54:33,058] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:54:33,892] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:54:33,893] {logging_mixin.py:115} INFO - [2023-01-06 00:54:33,893] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:54:33,894] {logging_mixin.py:115} INFO - [2023-01-06 00:54:33,893] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:54:33,900] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:54:33,922] {logging_mixin.py:115} INFO - [2023-01-06 00:54:33,922] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:54:33,944] {logging_mixin.py:115} INFO - [2023-01-06 00:54:33,944] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:54:33,954] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.902 seconds
[2023-01-06 00:55:04,140] {processor.py:153} INFO - Started process (PID=9286) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:55:04,141] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:55:04,141] {logging_mixin.py:115} INFO - [2023-01-06 00:55:04,141] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:55:04,964] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:55:04,965] {logging_mixin.py:115} INFO - [2023-01-06 00:55:04,965] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:55:04,966] {logging_mixin.py:115} INFO - [2023-01-06 00:55:04,965] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:55:04,973] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:55:04,996] {logging_mixin.py:115} INFO - [2023-01-06 00:55:04,995] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:55:05,019] {logging_mixin.py:115} INFO - [2023-01-06 00:55:05,018] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:55:05,029] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.894 seconds
[2023-01-06 00:55:35,141] {processor.py:153} INFO - Started process (PID=9311) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:55:35,143] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:55:35,144] {logging_mixin.py:115} INFO - [2023-01-06 00:55:35,144] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:55:36,112] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:55:36,114] {logging_mixin.py:115} INFO - [2023-01-06 00:55:36,114] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:55:36,114] {logging_mixin.py:115} INFO - [2023-01-06 00:55:36,114] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:55:36,121] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:55:36,146] {logging_mixin.py:115} INFO - [2023-01-06 00:55:36,146] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:55:36,167] {logging_mixin.py:115} INFO - [2023-01-06 00:55:36,167] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:55:36,177] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.043 seconds
[2023-01-06 00:56:06,270] {processor.py:153} INFO - Started process (PID=9329) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:56:06,271] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:56:06,271] {logging_mixin.py:115} INFO - [2023-01-06 00:56:06,271] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:56:07,099] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:56:07,100] {logging_mixin.py:115} INFO - [2023-01-06 00:56:07,100] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:56:07,101] {logging_mixin.py:115} INFO - [2023-01-06 00:56:07,101] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:56:07,108] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:56:07,131] {logging_mixin.py:115} INFO - [2023-01-06 00:56:07,131] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:56:07,152] {logging_mixin.py:115} INFO - [2023-01-06 00:56:07,152] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:56:07,162] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.898 seconds
[2023-01-06 00:56:37,569] {processor.py:153} INFO - Started process (PID=9355) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:56:37,570] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:56:37,571] {logging_mixin.py:115} INFO - [2023-01-06 00:56:37,571] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:56:38,400] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:56:38,401] {logging_mixin.py:115} INFO - [2023-01-06 00:56:38,401] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:56:38,402] {logging_mixin.py:115} INFO - [2023-01-06 00:56:38,402] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:56:38,409] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:56:38,432] {logging_mixin.py:115} INFO - [2023-01-06 00:56:38,432] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:56:38,453] {logging_mixin.py:115} INFO - [2023-01-06 00:56:38,453] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:56:38,464] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.901 seconds
[2023-01-06 00:57:08,681] {processor.py:153} INFO - Started process (PID=9379) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:57:08,682] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:57:08,683] {logging_mixin.py:115} INFO - [2023-01-06 00:57:08,683] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:57:09,550] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:57:09,552] {logging_mixin.py:115} INFO - [2023-01-06 00:57:09,552] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:57:09,552] {logging_mixin.py:115} INFO - [2023-01-06 00:57:09,552] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:57:09,559] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:57:09,592] {logging_mixin.py:115} INFO - [2023-01-06 00:57:09,592] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:57:09,621] {logging_mixin.py:115} INFO - [2023-01-06 00:57:09,621] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:57:09,632] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.957 seconds
[2023-01-06 00:57:39,741] {processor.py:153} INFO - Started process (PID=9404) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:57:39,742] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:57:39,743] {logging_mixin.py:115} INFO - [2023-01-06 00:57:39,743] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:57:40,552] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:57:40,554] {logging_mixin.py:115} INFO - [2023-01-06 00:57:40,553] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:57:40,554] {logging_mixin.py:115} INFO - [2023-01-06 00:57:40,554] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:57:40,561] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:57:40,585] {logging_mixin.py:115} INFO - [2023-01-06 00:57:40,585] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:57:40,606] {logging_mixin.py:115} INFO - [2023-01-06 00:57:40,606] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:57:40,616] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.881 seconds
[2023-01-06 00:58:10,837] {processor.py:153} INFO - Started process (PID=9422) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:58:10,841] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:58:10,842] {logging_mixin.py:115} INFO - [2023-01-06 00:58:10,842] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:58:11,688] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:58:11,689] {logging_mixin.py:115} INFO - [2023-01-06 00:58:11,689] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:58:11,690] {logging_mixin.py:115} INFO - [2023-01-06 00:58:11,690] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:58:11,697] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:58:11,721] {logging_mixin.py:115} INFO - [2023-01-06 00:58:11,721] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:58:11,741] {logging_mixin.py:115} INFO - [2023-01-06 00:58:11,741] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:58:11,751] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.919 seconds
[2023-01-06 00:58:41,849] {processor.py:153} INFO - Started process (PID=9447) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:58:41,850] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:58:41,851] {logging_mixin.py:115} INFO - [2023-01-06 00:58:41,851] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:58:42,742] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:58:42,744] {logging_mixin.py:115} INFO - [2023-01-06 00:58:42,744] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:58:42,744] {logging_mixin.py:115} INFO - [2023-01-06 00:58:42,744] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:58:42,751] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:58:42,775] {logging_mixin.py:115} INFO - [2023-01-06 00:58:42,774] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:58:42,795] {logging_mixin.py:115} INFO - [2023-01-06 00:58:42,795] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:58:42,805] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.961 seconds
[2023-01-06 00:59:12,939] {processor.py:153} INFO - Started process (PID=9471) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:59:12,940] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:59:12,940] {logging_mixin.py:115} INFO - [2023-01-06 00:59:12,940] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:59:13,736] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:59:13,737] {logging_mixin.py:115} INFO - [2023-01-06 00:59:13,737] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:59:13,738] {logging_mixin.py:115} INFO - [2023-01-06 00:59:13,737] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:59:13,745] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:59:13,769] {logging_mixin.py:115} INFO - [2023-01-06 00:59:13,769] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:59:13,790] {logging_mixin.py:115} INFO - [2023-01-06 00:59:13,790] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:59:13,800] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.867 seconds
[2023-01-06 00:59:43,907] {processor.py:153} INFO - Started process (PID=9494) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:59:43,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 00:59:43,909] {logging_mixin.py:115} INFO - [2023-01-06 00:59:43,909] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:59:44,755] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 00:59:44,756] {logging_mixin.py:115} INFO - [2023-01-06 00:59:44,756] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 00:59:44,757] {logging_mixin.py:115} INFO - [2023-01-06 00:59:44,757] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 00:59:44,766] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 00:59:44,796] {logging_mixin.py:115} INFO - [2023-01-06 00:59:44,796] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 00:59:44,827] {logging_mixin.py:115} INFO - [2023-01-06 00:59:44,826] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 00:59:44,837] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.936 seconds
[2023-01-06 01:00:15,052] {processor.py:153} INFO - Started process (PID=9514) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:00:15,053] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:00:15,054] {logging_mixin.py:115} INFO - [2023-01-06 01:00:15,054] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:00:15,928] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:00:15,930] {logging_mixin.py:115} INFO - [2023-01-06 01:00:15,930] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:00:15,931] {logging_mixin.py:115} INFO - [2023-01-06 01:00:15,930] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:00:15,942] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:00:15,969] {logging_mixin.py:115} INFO - [2023-01-06 01:00:15,969] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:00:15,992] {logging_mixin.py:115} INFO - [2023-01-06 01:00:15,992] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:00:16,003] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.956 seconds
[2023-01-06 01:00:46,114] {processor.py:153} INFO - Started process (PID=9539) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:00:46,116] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:00:46,116] {logging_mixin.py:115} INFO - [2023-01-06 01:00:46,116] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:00:47,043] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:00:47,044] {logging_mixin.py:115} INFO - [2023-01-06 01:00:47,044] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:00:47,045] {logging_mixin.py:115} INFO - [2023-01-06 01:00:47,045] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:00:47,053] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:00:47,079] {logging_mixin.py:115} INFO - [2023-01-06 01:00:47,078] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:00:47,100] {logging_mixin.py:115} INFO - [2023-01-06 01:00:47,100] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:00:47,111] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.002 seconds
[2023-01-06 01:01:17,207] {processor.py:153} INFO - Started process (PID=9564) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:01:17,207] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:01:17,208] {logging_mixin.py:115} INFO - [2023-01-06 01:01:17,208] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:01:18,022] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:01:18,024] {logging_mixin.py:115} INFO - [2023-01-06 01:01:18,024] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:01:18,024] {logging_mixin.py:115} INFO - [2023-01-06 01:01:18,024] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:01:18,031] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:01:18,054] {logging_mixin.py:115} INFO - [2023-01-06 01:01:18,054] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:01:18,074] {logging_mixin.py:115} INFO - [2023-01-06 01:01:18,074] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:01:18,084] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.882 seconds
[2023-01-06 01:01:48,280] {processor.py:153} INFO - Started process (PID=9582) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:01:48,281] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:01:48,282] {logging_mixin.py:115} INFO - [2023-01-06 01:01:48,282] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:01:49,147] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:01:49,148] {logging_mixin.py:115} INFO - [2023-01-06 01:01:49,148] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:01:49,149] {logging_mixin.py:115} INFO - [2023-01-06 01:01:49,149] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:01:49,156] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:01:49,187] {logging_mixin.py:115} INFO - [2023-01-06 01:01:49,187] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:01:49,213] {logging_mixin.py:115} INFO - [2023-01-06 01:01:49,212] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:01:49,222] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.947 seconds
[2023-01-06 01:02:19,409] {processor.py:153} INFO - Started process (PID=9607) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:02:19,410] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:02:19,411] {logging_mixin.py:115} INFO - [2023-01-06 01:02:19,411] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:02:20,246] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:02:20,248] {logging_mixin.py:115} INFO - [2023-01-06 01:02:20,248] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:02:20,248] {logging_mixin.py:115} INFO - [2023-01-06 01:02:20,248] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:02:20,257] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:02:20,281] {logging_mixin.py:115} INFO - [2023-01-06 01:02:20,280] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:02:20,301] {logging_mixin.py:115} INFO - [2023-01-06 01:02:20,301] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:02:20,314] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.910 seconds
[2023-01-06 01:02:50,531] {processor.py:153} INFO - Started process (PID=9633) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:02:50,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:02:50,533] {logging_mixin.py:115} INFO - [2023-01-06 01:02:50,533] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:02:51,399] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:02:51,401] {logging_mixin.py:115} INFO - [2023-01-06 01:02:51,401] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:02:51,401] {logging_mixin.py:115} INFO - [2023-01-06 01:02:51,401] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:02:51,408] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:02:51,438] {logging_mixin.py:115} INFO - [2023-01-06 01:02:51,438] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:02:51,462] {logging_mixin.py:115} INFO - [2023-01-06 01:02:51,461] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:02:51,472] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.946 seconds
[2023-01-06 01:03:21,628] {processor.py:153} INFO - Started process (PID=9656) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:03:21,629] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:03:21,629] {logging_mixin.py:115} INFO - [2023-01-06 01:03:21,629] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:03:22,484] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:03:22,486] {logging_mixin.py:115} INFO - [2023-01-06 01:03:22,486] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:03:22,486] {logging_mixin.py:115} INFO - [2023-01-06 01:03:22,486] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:03:22,493] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:03:22,527] {logging_mixin.py:115} INFO - [2023-01-06 01:03:22,527] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:03:22,553] {logging_mixin.py:115} INFO - [2023-01-06 01:03:22,553] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:03:22,564] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.941 seconds
[2023-01-06 01:03:52,745] {processor.py:153} INFO - Started process (PID=9674) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:03:52,746] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:03:52,747] {logging_mixin.py:115} INFO - [2023-01-06 01:03:52,747] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:03:53,577] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:03:53,578] {logging_mixin.py:115} INFO - [2023-01-06 01:03:53,578] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:03:53,579] {logging_mixin.py:115} INFO - [2023-01-06 01:03:53,579] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:03:53,586] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:03:53,610] {logging_mixin.py:115} INFO - [2023-01-06 01:03:53,610] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:03:53,630] {logging_mixin.py:115} INFO - [2023-01-06 01:03:53,630] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:03:53,640] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.900 seconds
[2023-01-06 01:04:23,960] {processor.py:153} INFO - Started process (PID=9701) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:04:23,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:04:23,962] {logging_mixin.py:115} INFO - [2023-01-06 01:04:23,962] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:04:24,811] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:04:24,813] {logging_mixin.py:115} INFO - [2023-01-06 01:04:24,812] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:04:24,813] {logging_mixin.py:115} INFO - [2023-01-06 01:04:24,813] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:04:24,824] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:04:24,849] {logging_mixin.py:115} INFO - [2023-01-06 01:04:24,849] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:04:24,872] {logging_mixin.py:115} INFO - [2023-01-06 01:04:24,872] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:04:24,883] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.927 seconds
[2023-01-06 01:04:55,101] {processor.py:153} INFO - Started process (PID=9727) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:04:55,101] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:04:55,102] {logging_mixin.py:115} INFO - [2023-01-06 01:04:55,102] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:04:55,927] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:04:55,929] {logging_mixin.py:115} INFO - [2023-01-06 01:04:55,928] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:04:55,929] {logging_mixin.py:115} INFO - [2023-01-06 01:04:55,929] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:04:55,936] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:04:55,962] {logging_mixin.py:115} INFO - [2023-01-06 01:04:55,961] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:04:55,985] {logging_mixin.py:115} INFO - [2023-01-06 01:04:55,985] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:04:55,995] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.900 seconds
[2023-01-06 01:05:26,236] {processor.py:153} INFO - Started process (PID=9752) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:05:26,237] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:05:26,238] {logging_mixin.py:115} INFO - [2023-01-06 01:05:26,238] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:05:27,176] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:05:27,178] {logging_mixin.py:115} INFO - [2023-01-06 01:05:27,178] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:05:27,178] {logging_mixin.py:115} INFO - [2023-01-06 01:05:27,178] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:05:27,185] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:05:27,211] {logging_mixin.py:115} INFO - [2023-01-06 01:05:27,211] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:05:27,235] {logging_mixin.py:115} INFO - [2023-01-06 01:05:27,235] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:05:27,246] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.015 seconds
[2023-01-06 01:05:57,321] {processor.py:153} INFO - Started process (PID=9770) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:05:57,322] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:05:57,322] {logging_mixin.py:115} INFO - [2023-01-06 01:05:57,322] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:05:58,158] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:05:58,160] {logging_mixin.py:115} INFO - [2023-01-06 01:05:58,160] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:05:58,160] {logging_mixin.py:115} INFO - [2023-01-06 01:05:58,160] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:05:58,167] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:05:58,200] {logging_mixin.py:115} INFO - [2023-01-06 01:05:58,199] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:05:58,227] {logging_mixin.py:115} INFO - [2023-01-06 01:05:58,227] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:05:58,238] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.922 seconds
[2023-01-06 01:06:28,436] {processor.py:153} INFO - Started process (PID=9796) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:06:28,437] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:06:28,438] {logging_mixin.py:115} INFO - [2023-01-06 01:06:28,438] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:06:29,287] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:06:29,289] {logging_mixin.py:115} INFO - [2023-01-06 01:06:29,288] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:06:29,289] {logging_mixin.py:115} INFO - [2023-01-06 01:06:29,289] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:06:29,296] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:06:29,320] {logging_mixin.py:115} INFO - [2023-01-06 01:06:29,319] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:06:29,343] {logging_mixin.py:115} INFO - [2023-01-06 01:06:29,343] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:06:29,360] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.930 seconds
[2023-01-06 01:06:59,586] {processor.py:153} INFO - Started process (PID=9821) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:06:59,587] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:06:59,587] {logging_mixin.py:115} INFO - [2023-01-06 01:06:59,587] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:07:00,450] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:07:00,452] {logging_mixin.py:115} INFO - [2023-01-06 01:07:00,452] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:07:00,452] {logging_mixin.py:115} INFO - [2023-01-06 01:07:00,452] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:07:00,459] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:07:00,484] {logging_mixin.py:115} INFO - [2023-01-06 01:07:00,484] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:07:00,506] {logging_mixin.py:115} INFO - [2023-01-06 01:07:00,506] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:07:00,517] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.936 seconds
[2023-01-06 01:07:30,624] {processor.py:153} INFO - Started process (PID=9846) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:07:30,625] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:07:30,626] {logging_mixin.py:115} INFO - [2023-01-06 01:07:30,626] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:07:31,489] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:07:31,490] {logging_mixin.py:115} INFO - [2023-01-06 01:07:31,490] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:07:31,491] {logging_mixin.py:115} INFO - [2023-01-06 01:07:31,491] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:07:31,500] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:07:31,529] {logging_mixin.py:115} INFO - [2023-01-06 01:07:31,529] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:07:31,559] {logging_mixin.py:115} INFO - [2023-01-06 01:07:31,559] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:07:31,573] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.954 seconds
[2023-01-06 01:08:01,705] {processor.py:153} INFO - Started process (PID=9864) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:08:01,706] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:08:01,707] {logging_mixin.py:115} INFO - [2023-01-06 01:08:01,707] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:08:02,544] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:08:02,546] {logging_mixin.py:115} INFO - [2023-01-06 01:08:02,546] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:08:02,546] {logging_mixin.py:115} INFO - [2023-01-06 01:08:02,546] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:08:02,553] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:08:02,578] {logging_mixin.py:115} INFO - [2023-01-06 01:08:02,577] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:08:02,600] {logging_mixin.py:115} INFO - [2023-01-06 01:08:02,599] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:08:02,610] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.910 seconds
[2023-01-06 01:08:32,787] {processor.py:153} INFO - Started process (PID=9890) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:08:32,791] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:08:32,791] {logging_mixin.py:115} INFO - [2023-01-06 01:08:32,791] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:08:33,644] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:08:33,645] {logging_mixin.py:115} INFO - [2023-01-06 01:08:33,645] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:08:33,646] {logging_mixin.py:115} INFO - [2023-01-06 01:08:33,645] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:08:33,653] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:08:33,677] {logging_mixin.py:115} INFO - [2023-01-06 01:08:33,677] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:08:33,699] {logging_mixin.py:115} INFO - [2023-01-06 01:08:33,699] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:08:33,711] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.928 seconds
[2023-01-06 01:09:03,842] {processor.py:153} INFO - Started process (PID=9916) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:09:03,844] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:09:03,844] {logging_mixin.py:115} INFO - [2023-01-06 01:09:03,844] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:09:04,766] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:09:04,768] {logging_mixin.py:115} INFO - [2023-01-06 01:09:04,768] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:09:04,768] {logging_mixin.py:115} INFO - [2023-01-06 01:09:04,768] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:09:04,775] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:09:04,800] {logging_mixin.py:115} INFO - [2023-01-06 01:09:04,800] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:09:04,822] {logging_mixin.py:115} INFO - [2023-01-06 01:09:04,821] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:09:04,831] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.993 seconds
[2023-01-06 01:09:34,922] {processor.py:153} INFO - Started process (PID=9942) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:09:34,923] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:09:34,924] {logging_mixin.py:115} INFO - [2023-01-06 01:09:34,924] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:09:35,755] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:09:35,756] {logging_mixin.py:115} INFO - [2023-01-06 01:09:35,756] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:09:35,757] {logging_mixin.py:115} INFO - [2023-01-06 01:09:35,756] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:09:35,764] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:09:35,787] {logging_mixin.py:115} INFO - [2023-01-06 01:09:35,787] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:09:35,808] {logging_mixin.py:115} INFO - [2023-01-06 01:09:35,808] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:09:35,818] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.901 seconds
[2023-01-06 01:10:05,994] {processor.py:153} INFO - Started process (PID=9959) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:10:05,995] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:10:05,996] {logging_mixin.py:115} INFO - [2023-01-06 01:10:05,996] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:10:06,824] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:10:06,825] {logging_mixin.py:115} INFO - [2023-01-06 01:10:06,825] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:10:06,826] {logging_mixin.py:115} INFO - [2023-01-06 01:10:06,826] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:10:06,833] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:10:06,857] {logging_mixin.py:115} INFO - [2023-01-06 01:10:06,857] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:10:06,879] {logging_mixin.py:115} INFO - [2023-01-06 01:10:06,879] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:10:06,890] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.901 seconds
[2023-01-06 01:10:37,109] {processor.py:153} INFO - Started process (PID=9986) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:10:37,110] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:10:37,110] {logging_mixin.py:115} INFO - [2023-01-06 01:10:37,110] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:10:37,926] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:10:37,928] {logging_mixin.py:115} INFO - [2023-01-06 01:10:37,928] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:10:37,928] {logging_mixin.py:115} INFO - [2023-01-06 01:10:37,928] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:10:37,935] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:10:37,958] {logging_mixin.py:115} INFO - [2023-01-06 01:10:37,958] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:10:37,978] {logging_mixin.py:115} INFO - [2023-01-06 01:10:37,978] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:10:37,988] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.883 seconds
[2023-01-06 01:11:08,173] {processor.py:153} INFO - Started process (PID=10011) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:11:08,174] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:11:08,175] {logging_mixin.py:115} INFO - [2023-01-06 01:11:08,175] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:11:09,021] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:11:09,023] {logging_mixin.py:115} INFO - [2023-01-06 01:11:09,023] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:11:09,023] {logging_mixin.py:115} INFO - [2023-01-06 01:11:09,023] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:11:09,030] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:11:09,054] {logging_mixin.py:115} INFO - [2023-01-06 01:11:09,053] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:11:09,074] {logging_mixin.py:115} INFO - [2023-01-06 01:11:09,074] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:11:09,084] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.916 seconds
[2023-01-06 01:11:39,263] {processor.py:153} INFO - Started process (PID=10037) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:11:39,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:11:39,266] {logging_mixin.py:115} INFO - [2023-01-06 01:11:39,265] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:11:40,131] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:11:40,132] {logging_mixin.py:115} INFO - [2023-01-06 01:11:40,132] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:11:40,133] {logging_mixin.py:115} INFO - [2023-01-06 01:11:40,133] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:11:40,140] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:11:40,163] {logging_mixin.py:115} INFO - [2023-01-06 01:11:40,163] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:11:40,185] {logging_mixin.py:115} INFO - [2023-01-06 01:11:40,184] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:11:40,195] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.938 seconds
[2023-01-06 01:12:10,362] {processor.py:153} INFO - Started process (PID=10055) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:12:10,363] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:12:10,363] {logging_mixin.py:115} INFO - [2023-01-06 01:12:10,363] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:12:11,185] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:12:11,187] {logging_mixin.py:115} INFO - [2023-01-06 01:12:11,187] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:12:11,188] {logging_mixin.py:115} INFO - [2023-01-06 01:12:11,187] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:12:11,194] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:12:11,219] {logging_mixin.py:115} INFO - [2023-01-06 01:12:11,219] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:12:11,240] {logging_mixin.py:115} INFO - [2023-01-06 01:12:11,239] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:12:11,250] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.893 seconds
[2023-01-06 01:12:41,473] {processor.py:153} INFO - Started process (PID=10080) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:12:41,475] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:12:41,475] {logging_mixin.py:115} INFO - [2023-01-06 01:12:41,475] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:12:42,336] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:12:42,337] {logging_mixin.py:115} INFO - [2023-01-06 01:12:42,337] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:12:42,338] {logging_mixin.py:115} INFO - [2023-01-06 01:12:42,337] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:12:42,345] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:12:42,369] {logging_mixin.py:115} INFO - [2023-01-06 01:12:42,369] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:12:42,390] {logging_mixin.py:115} INFO - [2023-01-06 01:12:42,390] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:12:42,401] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.933 seconds
[2023-01-06 01:13:12,549] {processor.py:153} INFO - Started process (PID=10107) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:13:12,551] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:13:12,552] {logging_mixin.py:115} INFO - [2023-01-06 01:13:12,552] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:13:13,614] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:13:13,616] {logging_mixin.py:115} INFO - [2023-01-06 01:13:13,616] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:13:13,616] {logging_mixin.py:115} INFO - [2023-01-06 01:13:13,616] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:13:13,623] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:13:13,647] {logging_mixin.py:115} INFO - [2023-01-06 01:13:13,647] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:13:13,668] {logging_mixin.py:115} INFO - [2023-01-06 01:13:13,668] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:13:13,678] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.135 seconds
[2023-01-06 01:13:44,640] {processor.py:153} INFO - Started process (PID=10132) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:13:44,641] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:13:44,642] {logging_mixin.py:115} INFO - [2023-01-06 01:13:44,642] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:13:45,548] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:13:45,549] {logging_mixin.py:115} INFO - [2023-01-06 01:13:45,549] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:13:45,550] {logging_mixin.py:115} INFO - [2023-01-06 01:13:45,549] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:13:45,556] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:13:45,582] {logging_mixin.py:115} INFO - [2023-01-06 01:13:45,582] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:13:45,604] {logging_mixin.py:115} INFO - [2023-01-06 01:13:45,604] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:13:45,614] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.980 seconds
[2023-01-06 01:14:15,716] {processor.py:153} INFO - Started process (PID=10150) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:14:15,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:14:15,717] {logging_mixin.py:115} INFO - [2023-01-06 01:14:15,717] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:14:16,557] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:14:16,558] {logging_mixin.py:115} INFO - [2023-01-06 01:14:16,558] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:14:16,558] {logging_mixin.py:115} INFO - [2023-01-06 01:14:16,558] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:14:16,566] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:14:16,591] {logging_mixin.py:115} INFO - [2023-01-06 01:14:16,591] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:14:16,615] {logging_mixin.py:115} INFO - [2023-01-06 01:14:16,615] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:14:16,626] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.915 seconds
[2023-01-06 01:14:46,877] {processor.py:153} INFO - Started process (PID=10174) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:14:46,879] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:14:46,879] {logging_mixin.py:115} INFO - [2023-01-06 01:14:46,879] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:14:47,793] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:14:47,794] {logging_mixin.py:115} INFO - [2023-01-06 01:14:47,794] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:14:47,795] {logging_mixin.py:115} INFO - [2023-01-06 01:14:47,795] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:14:47,802] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:14:47,826] {logging_mixin.py:115} INFO - [2023-01-06 01:14:47,825] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:14:47,846] {logging_mixin.py:115} INFO - [2023-01-06 01:14:47,846] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:14:47,856] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.984 seconds
[2023-01-06 01:15:17,975] {processor.py:153} INFO - Started process (PID=10199) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:15:17,976] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:15:17,976] {logging_mixin.py:115} INFO - [2023-01-06 01:15:17,976] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:15:18,797] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:15:18,798] {logging_mixin.py:115} INFO - [2023-01-06 01:15:18,798] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:15:18,799] {logging_mixin.py:115} INFO - [2023-01-06 01:15:18,798] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:15:18,805] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:15:18,832] {logging_mixin.py:115} INFO - [2023-01-06 01:15:18,832] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:15:18,858] {logging_mixin.py:115} INFO - [2023-01-06 01:15:18,858] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:15:18,869] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.899 seconds
[2023-01-06 01:15:49,044] {processor.py:153} INFO - Started process (PID=10224) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:15:49,046] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:15:49,047] {logging_mixin.py:115} INFO - [2023-01-06 01:15:49,046] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:15:49,886] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:15:49,887] {logging_mixin.py:115} INFO - [2023-01-06 01:15:49,887] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:15:49,888] {logging_mixin.py:115} INFO - [2023-01-06 01:15:49,887] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:15:49,895] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:15:49,918] {logging_mixin.py:115} INFO - [2023-01-06 01:15:49,918] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:15:49,938] {logging_mixin.py:115} INFO - [2023-01-06 01:15:49,938] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:15:49,949] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.909 seconds
[2023-01-06 01:16:20,144] {processor.py:153} INFO - Started process (PID=10242) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:16:20,145] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:16:20,145] {logging_mixin.py:115} INFO - [2023-01-06 01:16:20,145] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:16:21,031] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:16:21,032] {logging_mixin.py:115} INFO - [2023-01-06 01:16:21,032] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:16:21,033] {logging_mixin.py:115} INFO - [2023-01-06 01:16:21,032] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:16:21,040] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:16:21,065] {logging_mixin.py:115} INFO - [2023-01-06 01:16:21,064] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:16:21,087] {logging_mixin.py:115} INFO - [2023-01-06 01:16:21,087] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:16:21,098] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.959 seconds
[2023-01-06 01:16:51,304] {processor.py:153} INFO - Started process (PID=10265) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:16:51,305] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:16:51,306] {logging_mixin.py:115} INFO - [2023-01-06 01:16:51,306] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:16:52,182] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:16:52,184] {logging_mixin.py:115} INFO - [2023-01-06 01:16:52,183] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:16:52,184] {logging_mixin.py:115} INFO - [2023-01-06 01:16:52,184] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:16:52,191] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:16:52,215] {logging_mixin.py:115} INFO - [2023-01-06 01:16:52,215] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:16:52,241] {logging_mixin.py:115} INFO - [2023-01-06 01:16:52,240] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:16:52,251] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.951 seconds
[2023-01-06 01:17:22,478] {processor.py:153} INFO - Started process (PID=10290) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:17:22,480] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:17:22,480] {logging_mixin.py:115} INFO - [2023-01-06 01:17:22,480] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:17:23,315] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:17:23,317] {logging_mixin.py:115} INFO - [2023-01-06 01:17:23,316] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:17:23,317] {logging_mixin.py:115} INFO - [2023-01-06 01:17:23,317] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:17:23,324] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:17:23,349] {logging_mixin.py:115} INFO - [2023-01-06 01:17:23,349] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:17:23,370] {logging_mixin.py:115} INFO - [2023-01-06 01:17:23,370] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:17:23,380] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.907 seconds
[2023-01-06 01:17:53,581] {processor.py:153} INFO - Started process (PID=10308) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:17:53,584] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:17:53,585] {logging_mixin.py:115} INFO - [2023-01-06 01:17:53,585] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:17:54,462] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:17:54,464] {logging_mixin.py:115} INFO - [2023-01-06 01:17:54,464] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:17:54,464] {logging_mixin.py:115} INFO - [2023-01-06 01:17:54,464] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:17:54,471] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:17:54,502] {logging_mixin.py:115} INFO - [2023-01-06 01:17:54,502] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:17:54,526] {logging_mixin.py:115} INFO - [2023-01-06 01:17:54,526] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:17:54,537] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.960 seconds
[2023-01-06 01:18:24,658] {processor.py:153} INFO - Started process (PID=10334) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:18:24,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:18:24,661] {logging_mixin.py:115} INFO - [2023-01-06 01:18:24,661] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:18:25,537] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:18:25,539] {logging_mixin.py:115} INFO - [2023-01-06 01:18:25,539] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:18:25,539] {logging_mixin.py:115} INFO - [2023-01-06 01:18:25,539] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:18:25,546] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:18:25,572] {logging_mixin.py:115} INFO - [2023-01-06 01:18:25,571] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:18:25,594] {logging_mixin.py:115} INFO - [2023-01-06 01:18:25,594] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:18:25,605] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.953 seconds
[2023-01-06 01:18:55,776] {processor.py:153} INFO - Started process (PID=10358) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:18:55,777] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:18:55,778] {logging_mixin.py:115} INFO - [2023-01-06 01:18:55,778] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:18:56,630] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:18:56,631] {logging_mixin.py:115} INFO - [2023-01-06 01:18:56,631] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:18:56,632] {logging_mixin.py:115} INFO - [2023-01-06 01:18:56,632] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:18:56,639] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:18:56,662] {logging_mixin.py:115} INFO - [2023-01-06 01:18:56,662] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:18:56,682] {logging_mixin.py:115} INFO - [2023-01-06 01:18:56,682] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:18:56,692] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.922 seconds
[2023-01-06 01:19:26,877] {processor.py:153} INFO - Started process (PID=10382) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:19:26,878] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:19:26,879] {logging_mixin.py:115} INFO - [2023-01-06 01:19:26,879] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:19:27,787] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:19:27,789] {logging_mixin.py:115} INFO - [2023-01-06 01:19:27,789] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:19:27,790] {logging_mixin.py:115} INFO - [2023-01-06 01:19:27,789] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:19:27,797] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:19:27,823] {logging_mixin.py:115} INFO - [2023-01-06 01:19:27,822] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:19:27,844] {logging_mixin.py:115} INFO - [2023-01-06 01:19:27,844] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:19:27,854] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.984 seconds
[2023-01-06 01:19:57,955] {processor.py:153} INFO - Started process (PID=10401) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:19:57,956] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:19:57,956] {logging_mixin.py:115} INFO - [2023-01-06 01:19:57,956] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:19:58,823] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:19:58,824] {logging_mixin.py:115} INFO - [2023-01-06 01:19:58,824] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:19:58,825] {logging_mixin.py:115} INFO - [2023-01-06 01:19:58,824] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:19:58,832] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:19:58,856] {logging_mixin.py:115} INFO - [2023-01-06 01:19:58,856] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:19:58,877] {logging_mixin.py:115} INFO - [2023-01-06 01:19:58,877] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:19:58,887] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.937 seconds
[2023-01-06 01:20:29,072] {processor.py:153} INFO - Started process (PID=10427) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:20:29,073] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:20:29,074] {logging_mixin.py:115} INFO - [2023-01-06 01:20:29,074] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:20:29,988] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:20:29,990] {logging_mixin.py:115} INFO - [2023-01-06 01:20:29,990] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:20:29,990] {logging_mixin.py:115} INFO - [2023-01-06 01:20:29,990] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:20:29,998] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:20:30,024] {logging_mixin.py:115} INFO - [2023-01-06 01:20:30,024] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:20:30,048] {logging_mixin.py:115} INFO - [2023-01-06 01:20:30,048] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:20:30,059] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.993 seconds
[2023-01-06 01:21:00,157] {processor.py:153} INFO - Started process (PID=10452) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:21:00,158] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:21:00,159] {logging_mixin.py:115} INFO - [2023-01-06 01:21:00,159] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:21:01,025] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:21:01,027] {logging_mixin.py:115} INFO - [2023-01-06 01:21:01,026] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:21:01,027] {logging_mixin.py:115} INFO - [2023-01-06 01:21:01,027] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:21:01,035] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:21:01,060] {logging_mixin.py:115} INFO - [2023-01-06 01:21:01,060] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:21:01,082] {logging_mixin.py:115} INFO - [2023-01-06 01:21:01,081] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:21:01,094] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.943 seconds
[2023-01-06 01:21:31,273] {processor.py:153} INFO - Started process (PID=10477) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:21:31,274] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:21:31,275] {logging_mixin.py:115} INFO - [2023-01-06 01:21:31,275] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:21:32,142] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:21:32,144] {logging_mixin.py:115} INFO - [2023-01-06 01:21:32,143] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:21:32,144] {logging_mixin.py:115} INFO - [2023-01-06 01:21:32,144] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:21:32,155] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:21:32,188] {logging_mixin.py:115} INFO - [2023-01-06 01:21:32,187] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:21:32,218] {logging_mixin.py:115} INFO - [2023-01-06 01:21:32,218] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:21:32,231] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.964 seconds
[2023-01-06 01:22:02,344] {processor.py:153} INFO - Started process (PID=10494) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:22:02,345] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:22:02,346] {logging_mixin.py:115} INFO - [2023-01-06 01:22:02,346] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:22:03,203] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:22:03,204] {logging_mixin.py:115} INFO - [2023-01-06 01:22:03,204] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:22:03,205] {logging_mixin.py:115} INFO - [2023-01-06 01:22:03,205] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:22:03,212] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:22:03,237] {logging_mixin.py:115} INFO - [2023-01-06 01:22:03,236] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:22:03,257] {logging_mixin.py:115} INFO - [2023-01-06 01:22:03,257] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:22:03,266] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.927 seconds
[2023-01-06 01:22:33,446] {processor.py:153} INFO - Started process (PID=10518) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:22:33,447] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:22:33,448] {logging_mixin.py:115} INFO - [2023-01-06 01:22:33,448] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:22:34,295] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:22:34,296] {logging_mixin.py:115} INFO - [2023-01-06 01:22:34,296] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:22:34,296] {logging_mixin.py:115} INFO - [2023-01-06 01:22:34,296] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:22:34,304] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:22:34,328] {logging_mixin.py:115} INFO - [2023-01-06 01:22:34,328] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:22:34,349] {logging_mixin.py:115} INFO - [2023-01-06 01:22:34,349] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:22:34,359] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.917 seconds
[2023-01-06 01:23:04,710] {processor.py:153} INFO - Started process (PID=10542) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:23:04,713] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:23:04,713] {logging_mixin.py:115} INFO - [2023-01-06 01:23:04,713] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:23:05,607] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:23:05,608] {logging_mixin.py:115} INFO - [2023-01-06 01:23:05,608] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:23:05,608] {logging_mixin.py:115} INFO - [2023-01-06 01:23:05,608] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:23:05,616] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:23:05,640] {logging_mixin.py:115} INFO - [2023-01-06 01:23:05,640] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:23:05,660] {logging_mixin.py:115} INFO - [2023-01-06 01:23:05,660] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:23:05,670] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.966 seconds
[2023-01-06 01:23:35,774] {processor.py:153} INFO - Started process (PID=10567) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:23:35,775] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:23:35,775] {logging_mixin.py:115} INFO - [2023-01-06 01:23:35,775] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:23:36,629] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:23:36,630] {logging_mixin.py:115} INFO - [2023-01-06 01:23:36,630] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:23:36,631] {logging_mixin.py:115} INFO - [2023-01-06 01:23:36,631] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:23:36,643] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:23:36,671] {logging_mixin.py:115} INFO - [2023-01-06 01:23:36,670] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:23:36,692] {logging_mixin.py:115} INFO - [2023-01-06 01:23:36,692] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:23:36,702] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.934 seconds
[2023-01-06 01:24:06,829] {processor.py:153} INFO - Started process (PID=10584) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:24:06,831] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:24:06,832] {logging_mixin.py:115} INFO - [2023-01-06 01:24:06,831] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:24:07,655] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:24:07,657] {logging_mixin.py:115} INFO - [2023-01-06 01:24:07,656] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:24:07,657] {logging_mixin.py:115} INFO - [2023-01-06 01:24:07,657] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:24:07,664] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:24:07,688] {logging_mixin.py:115} INFO - [2023-01-06 01:24:07,687] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:24:07,708] {logging_mixin.py:115} INFO - [2023-01-06 01:24:07,708] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:24:07,718] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.894 seconds
[2023-01-06 01:24:37,819] {processor.py:153} INFO - Started process (PID=10610) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:24:37,820] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:24:37,820] {logging_mixin.py:115} INFO - [2023-01-06 01:24:37,820] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:24:38,664] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:24:38,666] {logging_mixin.py:115} INFO - [2023-01-06 01:24:38,666] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:24:38,666] {logging_mixin.py:115} INFO - [2023-01-06 01:24:38,666] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:24:38,673] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:24:38,698] {logging_mixin.py:115} INFO - [2023-01-06 01:24:38,698] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:24:38,720] {logging_mixin.py:115} INFO - [2023-01-06 01:24:38,720] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:24:38,730] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.916 seconds
[2023-01-06 01:25:08,972] {processor.py:153} INFO - Started process (PID=10635) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:25:08,974] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:25:08,974] {logging_mixin.py:115} INFO - [2023-01-06 01:25:08,974] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:25:09,817] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:25:09,818] {logging_mixin.py:115} INFO - [2023-01-06 01:25:09,818] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:25:09,819] {logging_mixin.py:115} INFO - [2023-01-06 01:25:09,819] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:25:09,826] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:25:09,851] {logging_mixin.py:115} INFO - [2023-01-06 01:25:09,851] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:25:09,872] {logging_mixin.py:115} INFO - [2023-01-06 01:25:09,872] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:25:09,882] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.914 seconds
[2023-01-06 01:25:40,091] {processor.py:153} INFO - Started process (PID=10654) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:25:40,091] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:25:40,093] {logging_mixin.py:115} INFO - [2023-01-06 01:25:40,093] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:25:40,946] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:25:40,948] {logging_mixin.py:115} INFO - [2023-01-06 01:25:40,948] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:25:40,949] {logging_mixin.py:115} INFO - [2023-01-06 01:25:40,948] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:25:40,957] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:25:40,980] {logging_mixin.py:115} INFO - [2023-01-06 01:25:40,980] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:25:41,001] {logging_mixin.py:115} INFO - [2023-01-06 01:25:41,000] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:25:41,011] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.925 seconds
[2023-01-06 01:26:11,145] {processor.py:153} INFO - Started process (PID=10677) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:26:11,146] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:26:11,148] {logging_mixin.py:115} INFO - [2023-01-06 01:26:11,148] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:26:11,965] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:26:11,966] {logging_mixin.py:115} INFO - [2023-01-06 01:26:11,966] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:26:11,967] {logging_mixin.py:115} INFO - [2023-01-06 01:26:11,966] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:26:11,974] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:26:11,997] {logging_mixin.py:115} INFO - [2023-01-06 01:26:11,997] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:26:12,017] {logging_mixin.py:115} INFO - [2023-01-06 01:26:12,017] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:26:12,028] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.888 seconds
[2023-01-06 01:26:42,225] {processor.py:153} INFO - Started process (PID=10702) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:26:42,227] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:26:42,228] {logging_mixin.py:115} INFO - [2023-01-06 01:26:42,228] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:26:43,092] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:26:43,094] {logging_mixin.py:115} INFO - [2023-01-06 01:26:43,093] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:26:43,094] {logging_mixin.py:115} INFO - [2023-01-06 01:26:43,094] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:26:43,105] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:26:43,137] {logging_mixin.py:115} INFO - [2023-01-06 01:26:43,136] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:26:43,159] {logging_mixin.py:115} INFO - [2023-01-06 01:26:43,159] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:26:43,170] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.950 seconds
[2023-01-06 01:27:13,281] {processor.py:153} INFO - Started process (PID=10728) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:27:13,282] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:27:13,283] {logging_mixin.py:115} INFO - [2023-01-06 01:27:13,283] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:27:14,221] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:27:14,222] {logging_mixin.py:115} INFO - [2023-01-06 01:27:14,222] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:27:14,223] {logging_mixin.py:115} INFO - [2023-01-06 01:27:14,222] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:27:14,229] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:27:14,254] {logging_mixin.py:115} INFO - [2023-01-06 01:27:14,253] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:27:14,275] {logging_mixin.py:115} INFO - [2023-01-06 01:27:14,275] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:27:14,286] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.010 seconds
[2023-01-06 01:27:44,366] {processor.py:153} INFO - Started process (PID=10746) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:27:44,367] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:27:44,368] {logging_mixin.py:115} INFO - [2023-01-06 01:27:44,368] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:27:45,280] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:27:45,282] {logging_mixin.py:115} INFO - [2023-01-06 01:27:45,282] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:27:45,283] {logging_mixin.py:115} INFO - [2023-01-06 01:27:45,282] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:27:45,294] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:27:45,329] {logging_mixin.py:115} INFO - [2023-01-06 01:27:45,329] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:27:45,360] {logging_mixin.py:115} INFO - [2023-01-06 01:27:45,360] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:27:45,370] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.010 seconds
[2023-01-06 01:28:15,452] {processor.py:153} INFO - Started process (PID=10772) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:28:15,453] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:28:15,455] {logging_mixin.py:115} INFO - [2023-01-06 01:28:15,455] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:28:16,301] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:28:16,302] {logging_mixin.py:115} INFO - [2023-01-06 01:28:16,302] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:28:16,303] {logging_mixin.py:115} INFO - [2023-01-06 01:28:16,302] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:28:16,310] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:28:16,335] {logging_mixin.py:115} INFO - [2023-01-06 01:28:16,335] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:28:16,359] {logging_mixin.py:115} INFO - [2023-01-06 01:28:16,359] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:28:16,369] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.922 seconds
[2023-01-06 01:28:46,903] {processor.py:153} INFO - Started process (PID=10798) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:28:46,904] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:28:46,905] {logging_mixin.py:115} INFO - [2023-01-06 01:28:46,905] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:28:47,739] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:28:47,740] {logging_mixin.py:115} INFO - [2023-01-06 01:28:47,740] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:28:47,741] {logging_mixin.py:115} INFO - [2023-01-06 01:28:47,740] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:28:47,748] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:28:47,772] {logging_mixin.py:115} INFO - [2023-01-06 01:28:47,772] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:28:47,794] {logging_mixin.py:115} INFO - [2023-01-06 01:28:47,794] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:28:47,805] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.907 seconds
[2023-01-06 01:29:17,988] {processor.py:153} INFO - Started process (PID=10822) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:29:17,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:29:17,991] {logging_mixin.py:115} INFO - [2023-01-06 01:29:17,990] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:29:18,980] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:29:18,982] {logging_mixin.py:115} INFO - [2023-01-06 01:29:18,982] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:29:18,983] {logging_mixin.py:115} INFO - [2023-01-06 01:29:18,983] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:29:19,003] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:29:19,042] {logging_mixin.py:115} INFO - [2023-01-06 01:29:19,042] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:29:19,077] {logging_mixin.py:115} INFO - [2023-01-06 01:29:19,077] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:29:19,100] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.117 seconds
[2023-01-06 01:29:49,186] {processor.py:153} INFO - Started process (PID=10840) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:29:49,188] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:29:49,189] {logging_mixin.py:115} INFO - [2023-01-06 01:29:49,189] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:29:50,022] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:29:50,024] {logging_mixin.py:115} INFO - [2023-01-06 01:29:50,024] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:29:50,025] {logging_mixin.py:115} INFO - [2023-01-06 01:29:50,024] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:29:50,036] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:29:50,085] {logging_mixin.py:115} INFO - [2023-01-06 01:29:50,084] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:29:50,115] {logging_mixin.py:115} INFO - [2023-01-06 01:29:50,114] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:29:50,127] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.945 seconds
[2023-01-06 01:30:20,272] {processor.py:153} INFO - Started process (PID=10865) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:30:20,273] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:30:20,273] {logging_mixin.py:115} INFO - [2023-01-06 01:30:20,273] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:30:21,122] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:30:21,123] {logging_mixin.py:115} INFO - [2023-01-06 01:30:21,123] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:30:21,124] {logging_mixin.py:115} INFO - [2023-01-06 01:30:21,123] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:30:21,131] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:30:21,155] {logging_mixin.py:115} INFO - [2023-01-06 01:30:21,154] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:30:21,176] {logging_mixin.py:115} INFO - [2023-01-06 01:30:21,176] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:30:21,187] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.919 seconds
[2023-01-06 01:30:51,356] {processor.py:153} INFO - Started process (PID=10890) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:30:51,358] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:30:51,358] {logging_mixin.py:115} INFO - [2023-01-06 01:30:51,358] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:30:52,191] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:30:52,192] {logging_mixin.py:115} INFO - [2023-01-06 01:30:52,192] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:30:52,193] {logging_mixin.py:115} INFO - [2023-01-06 01:30:52,193] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:30:52,200] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:30:52,223] {logging_mixin.py:115} INFO - [2023-01-06 01:30:52,223] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:30:52,245] {logging_mixin.py:115} INFO - [2023-01-06 01:30:52,244] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:30:52,256] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.904 seconds
[2023-01-06 01:31:22,415] {processor.py:153} INFO - Started process (PID=10914) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:31:22,416] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:31:22,417] {logging_mixin.py:115} INFO - [2023-01-06 01:31:22,417] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:31:23,406] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:31:23,407] {logging_mixin.py:115} INFO - [2023-01-06 01:31:23,407] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:31:23,408] {logging_mixin.py:115} INFO - [2023-01-06 01:31:23,407] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:31:23,415] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:31:23,442] {logging_mixin.py:115} INFO - [2023-01-06 01:31:23,441] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:31:23,466] {logging_mixin.py:115} INFO - [2023-01-06 01:31:23,466] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:31:23,480] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.069 seconds
[2023-01-06 01:31:53,520] {processor.py:153} INFO - Started process (PID=10932) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:31:53,522] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:31:53,522] {logging_mixin.py:115} INFO - [2023-01-06 01:31:53,522] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:31:54,346] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:31:54,347] {logging_mixin.py:115} INFO - [2023-01-06 01:31:54,347] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:31:54,348] {logging_mixin.py:115} INFO - [2023-01-06 01:31:54,347] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:31:54,355] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:31:54,380] {logging_mixin.py:115} INFO - [2023-01-06 01:31:54,379] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:31:54,401] {logging_mixin.py:115} INFO - [2023-01-06 01:31:54,401] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:31:54,412] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.896 seconds
[2023-01-06 01:32:24,579] {processor.py:153} INFO - Started process (PID=10957) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:32:24,580] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:32:24,581] {logging_mixin.py:115} INFO - [2023-01-06 01:32:24,581] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:32:25,426] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:32:25,428] {logging_mixin.py:115} INFO - [2023-01-06 01:32:25,427] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:32:25,428] {logging_mixin.py:115} INFO - [2023-01-06 01:32:25,428] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:32:25,435] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:32:25,458] {logging_mixin.py:115} INFO - [2023-01-06 01:32:25,458] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:32:25,479] {logging_mixin.py:115} INFO - [2023-01-06 01:32:25,479] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:32:25,489] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.916 seconds
[2023-01-06 01:32:55,752] {processor.py:153} INFO - Started process (PID=10982) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:32:55,753] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:32:55,754] {logging_mixin.py:115} INFO - [2023-01-06 01:32:55,754] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:32:56,593] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:32:56,594] {logging_mixin.py:115} INFO - [2023-01-06 01:32:56,594] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:32:56,595] {logging_mixin.py:115} INFO - [2023-01-06 01:32:56,594] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:32:56,602] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:32:56,624] {logging_mixin.py:115} INFO - [2023-01-06 01:32:56,624] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:32:56,645] {logging_mixin.py:115} INFO - [2023-01-06 01:32:56,645] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:32:56,655] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.908 seconds
[2023-01-06 01:33:26,750] {processor.py:153} INFO - Started process (PID=11008) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:33:26,751] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:33:26,752] {logging_mixin.py:115} INFO - [2023-01-06 01:33:26,752] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:33:27,662] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:33:27,664] {logging_mixin.py:115} INFO - [2023-01-06 01:33:27,664] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:33:27,664] {logging_mixin.py:115} INFO - [2023-01-06 01:33:27,664] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:33:27,671] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:33:27,703] {logging_mixin.py:115} INFO - [2023-01-06 01:33:27,702] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:33:27,738] {logging_mixin.py:115} INFO - [2023-01-06 01:33:27,738] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:33:27,758] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.014 seconds
[2023-01-06 01:33:57,839] {processor.py:153} INFO - Started process (PID=11026) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:33:57,840] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:33:57,840] {logging_mixin.py:115} INFO - [2023-01-06 01:33:57,840] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:33:58,685] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:33:58,686] {logging_mixin.py:115} INFO - [2023-01-06 01:33:58,686] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:33:58,686] {logging_mixin.py:115} INFO - [2023-01-06 01:33:58,686] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:33:58,694] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:33:58,718] {logging_mixin.py:115} INFO - [2023-01-06 01:33:58,717] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:33:58,738] {logging_mixin.py:115} INFO - [2023-01-06 01:33:58,738] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:33:58,748] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.914 seconds
[2023-01-06 01:34:28,850] {processor.py:153} INFO - Started process (PID=11050) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:34:28,853] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:34:28,854] {logging_mixin.py:115} INFO - [2023-01-06 01:34:28,854] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:34:29,716] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:34:29,717] {logging_mixin.py:115} INFO - [2023-01-06 01:34:29,717] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:34:29,718] {logging_mixin.py:115} INFO - [2023-01-06 01:34:29,718] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:34:29,725] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:34:29,749] {logging_mixin.py:115} INFO - [2023-01-06 01:34:29,749] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:34:29,770] {logging_mixin.py:115} INFO - [2023-01-06 01:34:29,770] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:34:29,780] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.935 seconds
[2023-01-06 01:34:59,937] {processor.py:153} INFO - Started process (PID=11077) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:34:59,939] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:34:59,939] {logging_mixin.py:115} INFO - [2023-01-06 01:34:59,939] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:35:00,834] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:35:00,836] {logging_mixin.py:115} INFO - [2023-01-06 01:35:00,836] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:35:00,836] {logging_mixin.py:115} INFO - [2023-01-06 01:35:00,836] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:35:00,848] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:35:00,873] {logging_mixin.py:115} INFO - [2023-01-06 01:35:00,873] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:35:00,897] {logging_mixin.py:115} INFO - [2023-01-06 01:35:00,897] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:35:00,906] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.975 seconds
[2023-01-06 01:35:31,028] {processor.py:153} INFO - Started process (PID=11102) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:35:31,029] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:35:31,030] {logging_mixin.py:115} INFO - [2023-01-06 01:35:31,030] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:35:31,930] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:35:31,931] {logging_mixin.py:115} INFO - [2023-01-06 01:35:31,931] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:35:31,932] {logging_mixin.py:115} INFO - [2023-01-06 01:35:31,931] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:35:31,939] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:35:31,963] {logging_mixin.py:115} INFO - [2023-01-06 01:35:31,962] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:35:31,985] {logging_mixin.py:115} INFO - [2023-01-06 01:35:31,985] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:35:31,995] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.972 seconds
[2023-01-06 01:36:02,166] {processor.py:153} INFO - Started process (PID=11120) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:36:02,168] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:36:02,168] {logging_mixin.py:115} INFO - [2023-01-06 01:36:02,168] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:36:03,016] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:36:03,018] {logging_mixin.py:115} INFO - [2023-01-06 01:36:03,018] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:36:03,018] {logging_mixin.py:115} INFO - [2023-01-06 01:36:03,018] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:36:03,025] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:36:03,050] {logging_mixin.py:115} INFO - [2023-01-06 01:36:03,049] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:36:03,072] {logging_mixin.py:115} INFO - [2023-01-06 01:36:03,071] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:36:03,083] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.921 seconds
[2023-01-06 01:36:33,265] {processor.py:153} INFO - Started process (PID=11144) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:36:33,267] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:36:33,267] {logging_mixin.py:115} INFO - [2023-01-06 01:36:33,267] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:36:34,122] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:36:34,123] {logging_mixin.py:115} INFO - [2023-01-06 01:36:34,123] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:36:34,124] {logging_mixin.py:115} INFO - [2023-01-06 01:36:34,123] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:36:34,131] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:36:34,156] {logging_mixin.py:115} INFO - [2023-01-06 01:36:34,155] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:36:34,178] {logging_mixin.py:115} INFO - [2023-01-06 01:36:34,177] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:36:34,188] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.928 seconds
[2023-01-06 01:37:04,435] {processor.py:153} INFO - Started process (PID=11170) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:37:04,436] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:37:04,437] {logging_mixin.py:115} INFO - [2023-01-06 01:37:04,437] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:37:05,279] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:37:05,280] {logging_mixin.py:115} INFO - [2023-01-06 01:37:05,280] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:37:05,281] {logging_mixin.py:115} INFO - [2023-01-06 01:37:05,280] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:37:05,288] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:37:05,312] {logging_mixin.py:115} INFO - [2023-01-06 01:37:05,311] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:37:05,332] {logging_mixin.py:115} INFO - [2023-01-06 01:37:05,332] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:37:05,342] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.913 seconds
[2023-01-06 01:37:35,518] {processor.py:153} INFO - Started process (PID=11195) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:37:35,519] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:37:35,520] {logging_mixin.py:115} INFO - [2023-01-06 01:37:35,520] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:37:36,356] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:37:36,358] {logging_mixin.py:115} INFO - [2023-01-06 01:37:36,358] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:37:36,358] {logging_mixin.py:115} INFO - [2023-01-06 01:37:36,358] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:37:36,365] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:37:36,389] {logging_mixin.py:115} INFO - [2023-01-06 01:37:36,389] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:37:36,410] {logging_mixin.py:115} INFO - [2023-01-06 01:37:36,410] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:37:36,419] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.906 seconds
[2023-01-06 01:38:06,580] {processor.py:153} INFO - Started process (PID=11213) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:38:06,581] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:38:06,582] {logging_mixin.py:115} INFO - [2023-01-06 01:38:06,582] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:38:07,416] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:38:07,417] {logging_mixin.py:115} INFO - [2023-01-06 01:38:07,417] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:38:07,418] {logging_mixin.py:115} INFO - [2023-01-06 01:38:07,418] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:38:07,425] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:38:07,450] {logging_mixin.py:115} INFO - [2023-01-06 01:38:07,450] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:38:07,471] {logging_mixin.py:115} INFO - [2023-01-06 01:38:07,471] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:38:07,481] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.908 seconds
[2023-01-06 01:38:37,646] {processor.py:153} INFO - Started process (PID=11239) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:38:37,648] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:38:37,648] {logging_mixin.py:115} INFO - [2023-01-06 01:38:37,648] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:38:38,476] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:38:38,477] {logging_mixin.py:115} INFO - [2023-01-06 01:38:38,477] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:38:38,478] {logging_mixin.py:115} INFO - [2023-01-06 01:38:38,478] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:38:38,485] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:38:38,508] {logging_mixin.py:115} INFO - [2023-01-06 01:38:38,508] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:38:38,529] {logging_mixin.py:115} INFO - [2023-01-06 01:38:38,528] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:38:38,539] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.897 seconds
[2023-01-06 01:39:08,785] {processor.py:153} INFO - Started process (PID=11265) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:39:08,786] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:39:08,787] {logging_mixin.py:115} INFO - [2023-01-06 01:39:08,787] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:39:09,672] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:39:09,674] {logging_mixin.py:115} INFO - [2023-01-06 01:39:09,674] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:39:09,675] {logging_mixin.py:115} INFO - [2023-01-06 01:39:09,675] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:39:09,683] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:39:09,706] {logging_mixin.py:115} INFO - [2023-01-06 01:39:09,706] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:39:09,727] {logging_mixin.py:115} INFO - [2023-01-06 01:39:09,726] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:39:09,737] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.956 seconds
[2023-01-06 01:39:39,839] {processor.py:153} INFO - Started process (PID=11283) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:39:39,840] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:39:39,840] {logging_mixin.py:115} INFO - [2023-01-06 01:39:39,840] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:39:40,690] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:39:40,691] {logging_mixin.py:115} INFO - [2023-01-06 01:39:40,691] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:39:40,692] {logging_mixin.py:115} INFO - [2023-01-06 01:39:40,692] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:39:40,699] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:39:40,730] {logging_mixin.py:115} INFO - [2023-01-06 01:39:40,730] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:39:40,757] {logging_mixin.py:115} INFO - [2023-01-06 01:39:40,757] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:39:40,767] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.933 seconds
[2023-01-06 01:40:10,900] {processor.py:153} INFO - Started process (PID=11308) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:40:10,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:40:10,901] {logging_mixin.py:115} INFO - [2023-01-06 01:40:10,901] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:40:11,741] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:40:11,743] {logging_mixin.py:115} INFO - [2023-01-06 01:40:11,743] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:40:11,743] {logging_mixin.py:115} INFO - [2023-01-06 01:40:11,743] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:40:11,751] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:40:11,776] {logging_mixin.py:115} INFO - [2023-01-06 01:40:11,775] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:40:11,796] {logging_mixin.py:115} INFO - [2023-01-06 01:40:11,796] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:40:11,806] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.912 seconds
[2023-01-06 01:40:41,999] {processor.py:153} INFO - Started process (PID=11335) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:40:42,001] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:40:42,001] {logging_mixin.py:115} INFO - [2023-01-06 01:40:42,001] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:40:42,852] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:40:42,854] {logging_mixin.py:115} INFO - [2023-01-06 01:40:42,854] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:40:42,854] {logging_mixin.py:115} INFO - [2023-01-06 01:40:42,854] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:40:42,867] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:40:42,892] {logging_mixin.py:115} INFO - [2023-01-06 01:40:42,892] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:40:42,913] {logging_mixin.py:115} INFO - [2023-01-06 01:40:42,913] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:40:42,923] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.929 seconds
[2023-01-06 01:41:13,076] {processor.py:153} INFO - Started process (PID=11361) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:41:13,077] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:41:13,078] {logging_mixin.py:115} INFO - [2023-01-06 01:41:13,078] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:41:13,912] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:41:13,914] {logging_mixin.py:115} INFO - [2023-01-06 01:41:13,914] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:41:13,915] {logging_mixin.py:115} INFO - [2023-01-06 01:41:13,914] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:41:13,926] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:41:13,956] {logging_mixin.py:115} INFO - [2023-01-06 01:41:13,956] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:41:13,988] {logging_mixin.py:115} INFO - [2023-01-06 01:41:13,987] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:41:14,002] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.932 seconds
[2023-01-06 01:41:44,132] {processor.py:153} INFO - Started process (PID=11379) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:41:44,135] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:41:44,136] {logging_mixin.py:115} INFO - [2023-01-06 01:41:44,136] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:41:45,034] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:41:45,036] {logging_mixin.py:115} INFO - [2023-01-06 01:41:45,036] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:41:45,037] {logging_mixin.py:115} INFO - [2023-01-06 01:41:45,036] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:41:45,048] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:41:45,074] {logging_mixin.py:115} INFO - [2023-01-06 01:41:45,074] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:41:45,094] {logging_mixin.py:115} INFO - [2023-01-06 01:41:45,094] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:41:45,104] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.976 seconds
[2023-01-06 01:42:15,208] {processor.py:153} INFO - Started process (PID=11404) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:42:15,209] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:42:15,210] {logging_mixin.py:115} INFO - [2023-01-06 01:42:15,210] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:42:16,167] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:42:16,168] {logging_mixin.py:115} INFO - [2023-01-06 01:42:16,168] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:42:16,169] {logging_mixin.py:115} INFO - [2023-01-06 01:42:16,168] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:42:16,176] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:42:16,204] {logging_mixin.py:115} INFO - [2023-01-06 01:42:16,204] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:42:16,234] {logging_mixin.py:115} INFO - [2023-01-06 01:42:16,234] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:42:16,244] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.041 seconds
[2023-01-06 01:42:46,318] {processor.py:153} INFO - Started process (PID=11429) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:42:46,319] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:42:46,320] {logging_mixin.py:115} INFO - [2023-01-06 01:42:46,319] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:42:47,177] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:42:47,178] {logging_mixin.py:115} INFO - [2023-01-06 01:42:47,178] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:42:47,179] {logging_mixin.py:115} INFO - [2023-01-06 01:42:47,178] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:42:47,186] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:42:47,210] {logging_mixin.py:115} INFO - [2023-01-06 01:42:47,209] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:42:47,231] {logging_mixin.py:115} INFO - [2023-01-06 01:42:47,230] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:42:47,241] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.928 seconds
[2023-01-06 01:43:17,347] {processor.py:153} INFO - Started process (PID=11453) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:43:17,350] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:43:17,350] {logging_mixin.py:115} INFO - [2023-01-06 01:43:17,350] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:43:18,188] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:43:18,189] {logging_mixin.py:115} INFO - [2023-01-06 01:43:18,189] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:43:18,190] {logging_mixin.py:115} INFO - [2023-01-06 01:43:18,189] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:43:18,196] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:43:18,226] {logging_mixin.py:115} INFO - [2023-01-06 01:43:18,226] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:43:18,255] {logging_mixin.py:115} INFO - [2023-01-06 01:43:18,254] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:43:18,267] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.925 seconds
[2023-01-06 01:43:48,365] {processor.py:153} INFO - Started process (PID=11471) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:43:48,366] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:43:48,366] {logging_mixin.py:115} INFO - [2023-01-06 01:43:48,366] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:43:49,212] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:43:49,214] {logging_mixin.py:115} INFO - [2023-01-06 01:43:49,214] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:43:49,215] {logging_mixin.py:115} INFO - [2023-01-06 01:43:49,215] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:43:49,224] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:43:49,281] {logging_mixin.py:115} INFO - [2023-01-06 01:43:49,281] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:43:49,310] {logging_mixin.py:115} INFO - [2023-01-06 01:43:49,310] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:43:49,321] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.962 seconds
[2023-01-06 01:44:19,462] {processor.py:153} INFO - Started process (PID=11496) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:44:19,464] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:44:19,465] {logging_mixin.py:115} INFO - [2023-01-06 01:44:19,464] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:44:20,296] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:44:20,297] {logging_mixin.py:115} INFO - [2023-01-06 01:44:20,297] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:44:20,298] {logging_mixin.py:115} INFO - [2023-01-06 01:44:20,298] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:44:20,305] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:44:20,328] {logging_mixin.py:115} INFO - [2023-01-06 01:44:20,328] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:44:20,350] {logging_mixin.py:115} INFO - [2023-01-06 01:44:20,349] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:44:20,360] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.904 seconds
[2023-01-06 01:44:50,676] {processor.py:153} INFO - Started process (PID=11521) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:44:50,677] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:44:50,678] {logging_mixin.py:115} INFO - [2023-01-06 01:44:50,678] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:44:51,498] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:44:51,499] {logging_mixin.py:115} INFO - [2023-01-06 01:44:51,499] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:44:51,500] {logging_mixin.py:115} INFO - [2023-01-06 01:44:51,500] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:44:51,507] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:44:51,530] {logging_mixin.py:115} INFO - [2023-01-06 01:44:51,530] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:44:51,551] {logging_mixin.py:115} INFO - [2023-01-06 01:44:51,551] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:44:51,561] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.890 seconds
[2023-01-06 01:45:21,673] {processor.py:153} INFO - Started process (PID=11546) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:45:21,674] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:45:21,675] {logging_mixin.py:115} INFO - [2023-01-06 01:45:21,675] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:45:22,526] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:45:22,527] {logging_mixin.py:115} INFO - [2023-01-06 01:45:22,527] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:45:22,528] {logging_mixin.py:115} INFO - [2023-01-06 01:45:22,528] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:45:22,535] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:45:22,566] {logging_mixin.py:115} INFO - [2023-01-06 01:45:22,565] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:45:22,594] {logging_mixin.py:115} INFO - [2023-01-06 01:45:22,593] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:45:22,604] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.935 seconds
[2023-01-06 01:45:52,806] {processor.py:153} INFO - Started process (PID=11563) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:45:52,806] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:45:52,807] {logging_mixin.py:115} INFO - [2023-01-06 01:45:52,807] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:45:53,625] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:45:53,627] {logging_mixin.py:115} INFO - [2023-01-06 01:45:53,626] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:45:53,627] {logging_mixin.py:115} INFO - [2023-01-06 01:45:53,627] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:45:53,634] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:45:53,658] {logging_mixin.py:115} INFO - [2023-01-06 01:45:53,657] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:45:53,678] {logging_mixin.py:115} INFO - [2023-01-06 01:45:53,678] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:45:53,688] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.887 seconds
[2023-01-06 01:46:23,881] {processor.py:153} INFO - Started process (PID=11588) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:46:23,883] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:46:23,884] {logging_mixin.py:115} INFO - [2023-01-06 01:46:23,884] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:46:24,725] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:46:24,726] {logging_mixin.py:115} INFO - [2023-01-06 01:46:24,726] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:46:24,726] {logging_mixin.py:115} INFO - [2023-01-06 01:46:24,726] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:46:24,733] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:46:24,757] {logging_mixin.py:115} INFO - [2023-01-06 01:46:24,757] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:46:24,779] {logging_mixin.py:115} INFO - [2023-01-06 01:46:24,779] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:46:24,790] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.913 seconds
[2023-01-06 01:46:54,960] {processor.py:153} INFO - Started process (PID=11613) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:46:54,961] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:46:54,961] {logging_mixin.py:115} INFO - [2023-01-06 01:46:54,961] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:46:55,785] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:46:55,786] {logging_mixin.py:115} INFO - [2023-01-06 01:46:55,786] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:46:55,787] {logging_mixin.py:115} INFO - [2023-01-06 01:46:55,786] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:46:55,794] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:46:55,819] {logging_mixin.py:115} INFO - [2023-01-06 01:46:55,818] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:46:55,841] {logging_mixin.py:115} INFO - [2023-01-06 01:46:55,840] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:46:55,850] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.895 seconds
[2023-01-06 01:47:26,024] {processor.py:153} INFO - Started process (PID=11640) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:47:26,026] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:47:26,027] {logging_mixin.py:115} INFO - [2023-01-06 01:47:26,027] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:47:26,947] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:47:26,949] {logging_mixin.py:115} INFO - [2023-01-06 01:47:26,948] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:47:26,949] {logging_mixin.py:115} INFO - [2023-01-06 01:47:26,949] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:47:26,956] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:47:26,981] {logging_mixin.py:115} INFO - [2023-01-06 01:47:26,980] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:47:27,001] {logging_mixin.py:115} INFO - [2023-01-06 01:47:27,001] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:47:27,012] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.992 seconds
[2023-01-06 01:47:57,109] {processor.py:153} INFO - Started process (PID=11658) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:47:57,110] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:47:57,110] {logging_mixin.py:115} INFO - [2023-01-06 01:47:57,110] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:47:57,962] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:47:57,963] {logging_mixin.py:115} INFO - [2023-01-06 01:47:57,963] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:47:57,963] {logging_mixin.py:115} INFO - [2023-01-06 01:47:57,963] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:47:57,970] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:47:57,995] {logging_mixin.py:115} INFO - [2023-01-06 01:47:57,995] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:47:58,017] {logging_mixin.py:115} INFO - [2023-01-06 01:47:58,016] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:47:58,027] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.922 seconds
[2023-01-06 01:48:28,165] {processor.py:153} INFO - Started process (PID=11683) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:48:28,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:48:28,167] {logging_mixin.py:115} INFO - [2023-01-06 01:48:28,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:48:28,998] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:48:28,999] {logging_mixin.py:115} INFO - [2023-01-06 01:48:28,999] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:48:28,999] {logging_mixin.py:115} INFO - [2023-01-06 01:48:28,999] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:48:29,006] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:48:29,029] {logging_mixin.py:115} INFO - [2023-01-06 01:48:29,029] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:48:29,049] {logging_mixin.py:115} INFO - [2023-01-06 01:48:29,049] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:48:29,059] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.899 seconds
[2023-01-06 01:48:59,246] {processor.py:153} INFO - Started process (PID=11708) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:48:59,248] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:48:59,249] {logging_mixin.py:115} INFO - [2023-01-06 01:48:59,249] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:49:00,086] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:49:00,088] {logging_mixin.py:115} INFO - [2023-01-06 01:49:00,088] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:49:00,089] {logging_mixin.py:115} INFO - [2023-01-06 01:49:00,088] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:49:00,100] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:49:00,134] {logging_mixin.py:115} INFO - [2023-01-06 01:49:00,133] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:49:00,158] {logging_mixin.py:115} INFO - [2023-01-06 01:49:00,158] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:49:00,167] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.926 seconds
[2023-01-06 01:49:30,358] {processor.py:153} INFO - Started process (PID=11733) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:49:30,359] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:49:30,360] {logging_mixin.py:115} INFO - [2023-01-06 01:49:30,360] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:49:31,542] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:49:31,544] {logging_mixin.py:115} INFO - [2023-01-06 01:49:31,543] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:49:31,544] {logging_mixin.py:115} INFO - [2023-01-06 01:49:31,544] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:49:31,556] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:49:31,589] {logging_mixin.py:115} INFO - [2023-01-06 01:49:31,588] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:49:31,619] {logging_mixin.py:115} INFO - [2023-01-06 01:49:31,619] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:49:31,632] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.281 seconds
[2023-01-06 01:50:02,503] {processor.py:153} INFO - Started process (PID=11751) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:50:02,503] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:50:02,504] {logging_mixin.py:115} INFO - [2023-01-06 01:50:02,504] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:50:03,362] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:50:03,364] {logging_mixin.py:115} INFO - [2023-01-06 01:50:03,364] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:50:03,364] {logging_mixin.py:115} INFO - [2023-01-06 01:50:03,364] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:50:03,371] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:50:03,395] {logging_mixin.py:115} INFO - [2023-01-06 01:50:03,395] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:50:03,417] {logging_mixin.py:115} INFO - [2023-01-06 01:50:03,417] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:50:03,427] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.929 seconds
[2023-01-06 01:50:33,656] {processor.py:153} INFO - Started process (PID=11776) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:50:33,657] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:50:33,658] {logging_mixin.py:115} INFO - [2023-01-06 01:50:33,658] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:50:34,504] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:50:34,506] {logging_mixin.py:115} INFO - [2023-01-06 01:50:34,505] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:50:34,506] {logging_mixin.py:115} INFO - [2023-01-06 01:50:34,506] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:50:34,514] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:50:34,538] {logging_mixin.py:115} INFO - [2023-01-06 01:50:34,537] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:50:34,560] {logging_mixin.py:115} INFO - [2023-01-06 01:50:34,560] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:50:34,570] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.919 seconds
[2023-01-06 01:51:04,906] {processor.py:153} INFO - Started process (PID=11802) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:51:04,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:51:04,908] {logging_mixin.py:115} INFO - [2023-01-06 01:51:04,908] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:51:05,745] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:51:05,746] {logging_mixin.py:115} INFO - [2023-01-06 01:51:05,746] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:51:05,747] {logging_mixin.py:115} INFO - [2023-01-06 01:51:05,746] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:51:05,754] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:51:05,778] {logging_mixin.py:115} INFO - [2023-01-06 01:51:05,778] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:51:05,800] {logging_mixin.py:115} INFO - [2023-01-06 01:51:05,800] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:51:05,810] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.908 seconds
[2023-01-06 01:51:35,983] {processor.py:153} INFO - Started process (PID=11827) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:51:35,985] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:51:35,986] {logging_mixin.py:115} INFO - [2023-01-06 01:51:35,985] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:51:36,939] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:51:36,940] {logging_mixin.py:115} INFO - [2023-01-06 01:51:36,940] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:51:36,941] {logging_mixin.py:115} INFO - [2023-01-06 01:51:36,941] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:51:36,948] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:51:36,975] {logging_mixin.py:115} INFO - [2023-01-06 01:51:36,975] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:51:36,998] {logging_mixin.py:115} INFO - [2023-01-06 01:51:36,998] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:51:37,008] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.030 seconds
[2023-01-06 01:52:07,091] {processor.py:153} INFO - Started process (PID=11845) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:52:07,092] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:52:07,093] {logging_mixin.py:115} INFO - [2023-01-06 01:52:07,093] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:52:07,944] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:52:07,946] {logging_mixin.py:115} INFO - [2023-01-06 01:52:07,946] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:52:07,946] {logging_mixin.py:115} INFO - [2023-01-06 01:52:07,946] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:52:07,953] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:52:07,979] {logging_mixin.py:115} INFO - [2023-01-06 01:52:07,978] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:52:07,999] {logging_mixin.py:115} INFO - [2023-01-06 01:52:07,999] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:52:08,009] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.925 seconds
[2023-01-06 01:52:38,185] {processor.py:153} INFO - Started process (PID=11870) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:52:38,186] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:52:38,187] {logging_mixin.py:115} INFO - [2023-01-06 01:52:38,187] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:52:39,054] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:52:39,056] {logging_mixin.py:115} INFO - [2023-01-06 01:52:39,055] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:52:39,056] {logging_mixin.py:115} INFO - [2023-01-06 01:52:39,056] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:52:39,063] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:52:39,088] {logging_mixin.py:115} INFO - [2023-01-06 01:52:39,088] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:52:39,110] {logging_mixin.py:115} INFO - [2023-01-06 01:52:39,110] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:52:39,121] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.941 seconds
[2023-01-06 01:53:09,298] {processor.py:153} INFO - Started process (PID=11895) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:53:09,299] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:53:09,299] {logging_mixin.py:115} INFO - [2023-01-06 01:53:09,299] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:53:10,113] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:53:10,114] {logging_mixin.py:115} INFO - [2023-01-06 01:53:10,114] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:53:10,115] {logging_mixin.py:115} INFO - [2023-01-06 01:53:10,114] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:53:10,122] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:53:10,146] {logging_mixin.py:115} INFO - [2023-01-06 01:53:10,145] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:53:10,168] {logging_mixin.py:115} INFO - [2023-01-06 01:53:10,168] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:53:10,178] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.885 seconds
[2023-01-06 01:53:40,478] {processor.py:153} INFO - Started process (PID=11920) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:53:40,479] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:53:40,480] {logging_mixin.py:115} INFO - [2023-01-06 01:53:40,480] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:53:41,368] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:53:41,370] {logging_mixin.py:115} INFO - [2023-01-06 01:53:41,370] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:53:41,370] {logging_mixin.py:115} INFO - [2023-01-06 01:53:41,370] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:53:41,377] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:53:41,402] {logging_mixin.py:115} INFO - [2023-01-06 01:53:41,402] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:53:41,424] {logging_mixin.py:115} INFO - [2023-01-06 01:53:41,423] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:53:41,434] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.961 seconds
[2023-01-06 01:54:11,560] {processor.py:153} INFO - Started process (PID=11939) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:54:11,561] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:54:11,562] {logging_mixin.py:115} INFO - [2023-01-06 01:54:11,562] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:54:12,400] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:54:12,402] {logging_mixin.py:115} INFO - [2023-01-06 01:54:12,402] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:54:12,403] {logging_mixin.py:115} INFO - [2023-01-06 01:54:12,402] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:54:12,410] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:54:12,444] {logging_mixin.py:115} INFO - [2023-01-06 01:54:12,443] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:54:12,466] {logging_mixin.py:115} INFO - [2023-01-06 01:54:12,466] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:54:12,477] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.922 seconds
[2023-01-06 01:54:42,639] {processor.py:153} INFO - Started process (PID=11964) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:54:42,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:54:42,640] {logging_mixin.py:115} INFO - [2023-01-06 01:54:42,640] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:54:43,504] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:54:43,506] {logging_mixin.py:115} INFO - [2023-01-06 01:54:43,505] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:54:43,506] {logging_mixin.py:115} INFO - [2023-01-06 01:54:43,506] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:54:43,513] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:54:43,538] {logging_mixin.py:115} INFO - [2023-01-06 01:54:43,537] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:54:43,559] {logging_mixin.py:115} INFO - [2023-01-06 01:54:43,558] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:54:43,569] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.935 seconds
[2023-01-06 01:55:13,873] {processor.py:153} INFO - Started process (PID=11990) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:55:13,876] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:55:13,877] {logging_mixin.py:115} INFO - [2023-01-06 01:55:13,877] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:55:14,723] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:55:14,725] {logging_mixin.py:115} INFO - [2023-01-06 01:55:14,724] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:55:14,725] {logging_mixin.py:115} INFO - [2023-01-06 01:55:14,725] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:55:14,732] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:55:14,756] {logging_mixin.py:115} INFO - [2023-01-06 01:55:14,756] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:55:14,777] {logging_mixin.py:115} INFO - [2023-01-06 01:55:14,777] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:55:14,787] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.919 seconds
[2023-01-06 01:55:44,965] {processor.py:153} INFO - Started process (PID=12018) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:55:44,967] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:55:44,967] {logging_mixin.py:115} INFO - [2023-01-06 01:55:44,967] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:55:45,997] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:55:45,998] {logging_mixin.py:115} INFO - [2023-01-06 01:55:45,998] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:55:45,999] {logging_mixin.py:115} INFO - [2023-01-06 01:55:45,999] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:55:46,007] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:55:46,032] {logging_mixin.py:115} INFO - [2023-01-06 01:55:46,031] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:55:46,053] {logging_mixin.py:115} INFO - [2023-01-06 01:55:46,053] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:55:46,063] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.102 seconds
[2023-01-06 01:56:17,057] {processor.py:153} INFO - Started process (PID=12037) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:56:17,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:56:17,060] {logging_mixin.py:115} INFO - [2023-01-06 01:56:17,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:56:17,885] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:56:17,886] {logging_mixin.py:115} INFO - [2023-01-06 01:56:17,886] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:56:17,887] {logging_mixin.py:115} INFO - [2023-01-06 01:56:17,886] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:56:17,894] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:56:17,918] {logging_mixin.py:115} INFO - [2023-01-06 01:56:17,918] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:56:17,940] {logging_mixin.py:115} INFO - [2023-01-06 01:56:17,940] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:56:17,951] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.899 seconds
[2023-01-06 01:56:48,139] {processor.py:153} INFO - Started process (PID=12062) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:56:48,140] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:56:48,142] {logging_mixin.py:115} INFO - [2023-01-06 01:56:48,142] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:56:48,998] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:56:49,000] {logging_mixin.py:115} INFO - [2023-01-06 01:56:49,000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:56:49,001] {logging_mixin.py:115} INFO - [2023-01-06 01:56:49,000] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:56:49,009] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:56:49,035] {logging_mixin.py:115} INFO - [2023-01-06 01:56:49,035] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:56:49,059] {logging_mixin.py:115} INFO - [2023-01-06 01:56:49,059] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:56:49,070] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.937 seconds
[2023-01-06 01:57:19,259] {processor.py:153} INFO - Started process (PID=12088) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:57:19,260] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:57:19,262] {logging_mixin.py:115} INFO - [2023-01-06 01:57:19,262] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:57:20,112] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:57:20,114] {logging_mixin.py:115} INFO - [2023-01-06 01:57:20,114] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:57:20,114] {logging_mixin.py:115} INFO - [2023-01-06 01:57:20,114] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:57:20,122] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:57:20,148] {logging_mixin.py:115} INFO - [2023-01-06 01:57:20,148] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:57:20,171] {logging_mixin.py:115} INFO - [2023-01-06 01:57:20,171] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:57:20,182] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.929 seconds
[2023-01-06 01:57:50,378] {processor.py:153} INFO - Started process (PID=12112) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:57:50,382] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:57:50,384] {logging_mixin.py:115} INFO - [2023-01-06 01:57:50,384] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:57:51,242] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:57:51,243] {logging_mixin.py:115} INFO - [2023-01-06 01:57:51,243] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:57:51,244] {logging_mixin.py:115} INFO - [2023-01-06 01:57:51,244] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:57:51,251] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:57:51,276] {logging_mixin.py:115} INFO - [2023-01-06 01:57:51,276] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:57:51,298] {logging_mixin.py:115} INFO - [2023-01-06 01:57:51,298] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:57:51,308] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.935 seconds
[2023-01-06 01:58:21,471] {processor.py:153} INFO - Started process (PID=12130) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:58:21,474] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:58:21,476] {logging_mixin.py:115} INFO - [2023-01-06 01:58:21,476] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:58:22,314] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:58:22,316] {logging_mixin.py:115} INFO - [2023-01-06 01:58:22,315] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:58:22,316] {logging_mixin.py:115} INFO - [2023-01-06 01:58:22,316] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:58:22,323] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:58:22,347] {logging_mixin.py:115} INFO - [2023-01-06 01:58:22,347] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:58:22,368] {logging_mixin.py:115} INFO - [2023-01-06 01:58:22,368] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:58:22,378] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.912 seconds
[2023-01-06 01:58:52,556] {processor.py:153} INFO - Started process (PID=12157) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:58:52,557] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:58:52,560] {logging_mixin.py:115} INFO - [2023-01-06 01:58:52,560] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:58:53,390] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:58:53,392] {logging_mixin.py:115} INFO - [2023-01-06 01:58:53,392] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:58:53,392] {logging_mixin.py:115} INFO - [2023-01-06 01:58:53,392] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:58:53,399] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:58:53,423] {logging_mixin.py:115} INFO - [2023-01-06 01:58:53,422] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:58:53,448] {logging_mixin.py:115} INFO - [2023-01-06 01:58:53,448] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:58:53,458] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.906 seconds
[2023-01-06 01:59:23,706] {processor.py:153} INFO - Started process (PID=12182) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:59:23,707] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:59:23,709] {logging_mixin.py:115} INFO - [2023-01-06 01:59:23,709] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:59:24,527] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:59:24,529] {logging_mixin.py:115} INFO - [2023-01-06 01:59:24,529] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:59:24,529] {logging_mixin.py:115} INFO - [2023-01-06 01:59:24,529] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:59:24,536] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:59:24,561] {logging_mixin.py:115} INFO - [2023-01-06 01:59:24,560] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:59:24,583] {logging_mixin.py:115} INFO - [2023-01-06 01:59:24,583] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:59:24,593] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.892 seconds
[2023-01-06 01:59:54,770] {processor.py:153} INFO - Started process (PID=12207) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:59:54,770] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 01:59:54,773] {logging_mixin.py:115} INFO - [2023-01-06 01:59:54,772] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:59:55,617] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 01:59:55,618] {logging_mixin.py:115} INFO - [2023-01-06 01:59:55,618] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 01:59:55,619] {logging_mixin.py:115} INFO - [2023-01-06 01:59:55,619] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 01:59:55,630] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 01:59:55,658] {logging_mixin.py:115} INFO - [2023-01-06 01:59:55,658] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 01:59:55,692] {logging_mixin.py:115} INFO - [2023-01-06 01:59:55,692] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 01:59:55,714] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.948 seconds
[2023-01-06 02:00:25,834] {processor.py:153} INFO - Started process (PID=12225) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:00:25,835] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:00:25,836] {logging_mixin.py:115} INFO - [2023-01-06 02:00:25,836] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:00:26,728] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:00:26,730] {logging_mixin.py:115} INFO - [2023-01-06 02:00:26,730] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:00:26,730] {logging_mixin.py:115} INFO - [2023-01-06 02:00:26,730] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:00:26,737] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:00:26,760] {logging_mixin.py:115} INFO - [2023-01-06 02:00:26,760] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:00:26,781] {logging_mixin.py:115} INFO - [2023-01-06 02:00:26,781] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:00:26,791] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.962 seconds
[2023-01-06 02:00:57,154] {processor.py:153} INFO - Started process (PID=12250) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:00:57,155] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:00:57,156] {logging_mixin.py:115} INFO - [2023-01-06 02:00:57,156] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:00:58,022] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:00:58,024] {logging_mixin.py:115} INFO - [2023-01-06 02:00:58,024] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:00:58,024] {logging_mixin.py:115} INFO - [2023-01-06 02:00:58,024] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:00:58,031] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:00:58,055] {logging_mixin.py:115} INFO - [2023-01-06 02:00:58,055] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:00:58,076] {logging_mixin.py:115} INFO - [2023-01-06 02:00:58,076] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:00:58,087] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.937 seconds
[2023-01-06 02:01:28,193] {processor.py:153} INFO - Started process (PID=12275) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:01:28,200] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:01:28,201] {logging_mixin.py:115} INFO - [2023-01-06 02:01:28,200] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:01:29,150] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:01:29,152] {logging_mixin.py:115} INFO - [2023-01-06 02:01:29,152] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:01:29,153] {logging_mixin.py:115} INFO - [2023-01-06 02:01:29,153] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:01:29,164] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:01:29,260] {logging_mixin.py:115} INFO - [2023-01-06 02:01:29,260] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:01:29,307] {logging_mixin.py:115} INFO - [2023-01-06 02:01:29,307] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:01:29,324] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.137 seconds
[2023-01-06 02:02:00,281] {processor.py:153} INFO - Started process (PID=12300) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:02:00,282] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:02:00,283] {logging_mixin.py:115} INFO - [2023-01-06 02:02:00,283] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:02:01,155] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:02:01,157] {logging_mixin.py:115} INFO - [2023-01-06 02:02:01,157] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:02:01,157] {logging_mixin.py:115} INFO - [2023-01-06 02:02:01,157] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:02:01,164] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:02:01,188] {logging_mixin.py:115} INFO - [2023-01-06 02:02:01,187] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:02:01,208] {logging_mixin.py:115} INFO - [2023-01-06 02:02:01,208] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:02:01,218] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.941 seconds
[2023-01-06 02:02:31,341] {processor.py:153} INFO - Started process (PID=12317) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:02:31,342] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:02:31,343] {logging_mixin.py:115} INFO - [2023-01-06 02:02:31,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:02:32,192] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:02:32,193] {logging_mixin.py:115} INFO - [2023-01-06 02:02:32,193] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:02:32,194] {logging_mixin.py:115} INFO - [2023-01-06 02:02:32,194] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:02:32,201] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:02:32,223] {logging_mixin.py:115} INFO - [2023-01-06 02:02:32,223] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:02:32,243] {logging_mixin.py:115} INFO - [2023-01-06 02:02:32,243] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:02:32,253] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.917 seconds
[2023-01-06 02:03:02,376] {processor.py:153} INFO - Started process (PID=12343) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:03:02,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:03:02,378] {logging_mixin.py:115} INFO - [2023-01-06 02:03:02,377] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:03:03,229] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:03:03,231] {logging_mixin.py:115} INFO - [2023-01-06 02:03:03,231] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:03:03,231] {logging_mixin.py:115} INFO - [2023-01-06 02:03:03,231] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:03:03,238] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:03:03,261] {logging_mixin.py:115} INFO - [2023-01-06 02:03:03,260] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:03:03,281] {logging_mixin.py:115} INFO - [2023-01-06 02:03:03,281] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:03:03,290] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.921 seconds
[2023-01-06 02:03:33,391] {processor.py:153} INFO - Started process (PID=12368) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:03:33,392] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:03:33,393] {logging_mixin.py:115} INFO - [2023-01-06 02:03:33,392] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:03:34,210] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:03:34,211] {logging_mixin.py:115} INFO - [2023-01-06 02:03:34,211] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:03:34,211] {logging_mixin.py:115} INFO - [2023-01-06 02:03:34,211] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:03:34,218] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:03:34,241] {logging_mixin.py:115} INFO - [2023-01-06 02:03:34,241] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:03:34,262] {logging_mixin.py:115} INFO - [2023-01-06 02:03:34,262] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:03:34,272] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.886 seconds
[2023-01-06 02:04:04,471] {processor.py:153} INFO - Started process (PID=12393) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:04:04,473] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:04:04,474] {logging_mixin.py:115} INFO - [2023-01-06 02:04:04,474] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:04:05,294] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:04:05,295] {logging_mixin.py:115} INFO - [2023-01-06 02:04:05,295] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:04:05,296] {logging_mixin.py:115} INFO - [2023-01-06 02:04:05,295] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:04:05,302] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:04:05,325] {logging_mixin.py:115} INFO - [2023-01-06 02:04:05,325] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:04:05,348] {logging_mixin.py:115} INFO - [2023-01-06 02:04:05,348] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:04:05,362] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.895 seconds
[2023-01-06 02:04:35,547] {processor.py:153} INFO - Started process (PID=12412) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:04:35,548] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:04:35,548] {logging_mixin.py:115} INFO - [2023-01-06 02:04:35,548] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:04:36,422] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:04:36,424] {logging_mixin.py:115} INFO - [2023-01-06 02:04:36,423] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:04:36,424] {logging_mixin.py:115} INFO - [2023-01-06 02:04:36,424] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:04:36,433] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:04:36,457] {logging_mixin.py:115} INFO - [2023-01-06 02:04:36,456] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:04:36,478] {logging_mixin.py:115} INFO - [2023-01-06 02:04:36,478] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:04:36,491] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.950 seconds
[2023-01-06 02:05:06,676] {processor.py:153} INFO - Started process (PID=12438) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:05:06,677] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:05:06,678] {logging_mixin.py:115} INFO - [2023-01-06 02:05:06,678] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:05:07,528] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:05:07,530] {logging_mixin.py:115} INFO - [2023-01-06 02:05:07,530] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:05:07,530] {logging_mixin.py:115} INFO - [2023-01-06 02:05:07,530] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:05:07,537] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:05:07,561] {logging_mixin.py:115} INFO - [2023-01-06 02:05:07,561] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:05:07,582] {logging_mixin.py:115} INFO - [2023-01-06 02:05:07,582] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:05:07,592] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.921 seconds
[2023-01-06 02:05:37,758] {processor.py:153} INFO - Started process (PID=12461) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:05:37,760] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:05:37,761] {logging_mixin.py:115} INFO - [2023-01-06 02:05:37,760] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:05:38,602] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:05:38,603] {logging_mixin.py:115} INFO - [2023-01-06 02:05:38,603] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:05:38,604] {logging_mixin.py:115} INFO - [2023-01-06 02:05:38,604] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:05:38,611] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:05:38,634] {logging_mixin.py:115} INFO - [2023-01-06 02:05:38,634] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:05:38,656] {logging_mixin.py:115} INFO - [2023-01-06 02:05:38,656] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:05:38,666] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.913 seconds
[2023-01-06 02:06:08,849] {processor.py:153} INFO - Started process (PID=12487) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:06:08,850] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:06:08,851] {logging_mixin.py:115} INFO - [2023-01-06 02:06:08,851] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:06:09,755] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:06:09,757] {logging_mixin.py:115} INFO - [2023-01-06 02:06:09,757] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:06:09,758] {logging_mixin.py:115} INFO - [2023-01-06 02:06:09,757] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:06:09,766] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:06:09,790] {logging_mixin.py:115} INFO - [2023-01-06 02:06:09,789] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:06:09,811] {logging_mixin.py:115} INFO - [2023-01-06 02:06:09,811] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:06:09,821] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.977 seconds
[2023-01-06 02:06:39,982] {processor.py:153} INFO - Started process (PID=12504) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:06:39,983] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:06:39,984] {logging_mixin.py:115} INFO - [2023-01-06 02:06:39,984] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:06:40,828] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:06:40,831] {logging_mixin.py:115} INFO - [2023-01-06 02:06:40,830] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:06:40,832] {logging_mixin.py:115} INFO - [2023-01-06 02:06:40,831] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:06:40,842] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:06:40,873] {logging_mixin.py:115} INFO - [2023-01-06 02:06:40,872] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:06:40,901] {logging_mixin.py:115} INFO - [2023-01-06 02:06:40,901] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:06:40,914] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.939 seconds
[2023-01-06 02:07:11,003] {processor.py:153} INFO - Started process (PID=12530) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:07:11,004] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:07:11,005] {logging_mixin.py:115} INFO - [2023-01-06 02:07:11,005] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:07:11,910] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:07:11,911] {logging_mixin.py:115} INFO - [2023-01-06 02:07:11,911] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:07:11,912] {logging_mixin.py:115} INFO - [2023-01-06 02:07:11,912] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:07:11,919] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:07:11,941] {logging_mixin.py:115} INFO - [2023-01-06 02:07:11,941] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:07:11,962] {logging_mixin.py:115} INFO - [2023-01-06 02:07:11,962] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:07:11,972] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.975 seconds
[2023-01-06 02:07:42,102] {processor.py:153} INFO - Started process (PID=12555) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:07:42,103] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:07:42,103] {logging_mixin.py:115} INFO - [2023-01-06 02:07:42,103] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:07:42,925] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:07:42,927] {logging_mixin.py:115} INFO - [2023-01-06 02:07:42,927] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:07:42,928] {logging_mixin.py:115} INFO - [2023-01-06 02:07:42,927] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:07:42,935] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:07:42,957] {logging_mixin.py:115} INFO - [2023-01-06 02:07:42,957] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:07:42,978] {logging_mixin.py:115} INFO - [2023-01-06 02:07:42,978] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:07:42,988] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.892 seconds
[2023-01-06 02:08:13,169] {processor.py:153} INFO - Started process (PID=12580) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:08:13,171] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:08:13,172] {logging_mixin.py:115} INFO - [2023-01-06 02:08:13,171] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:08:14,006] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:08:14,008] {logging_mixin.py:115} INFO - [2023-01-06 02:08:14,008] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:08:14,008] {logging_mixin.py:115} INFO - [2023-01-06 02:08:14,008] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:08:14,015] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:08:14,038] {logging_mixin.py:115} INFO - [2023-01-06 02:08:14,038] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:08:14,059] {logging_mixin.py:115} INFO - [2023-01-06 02:08:14,059] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:08:14,069] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.905 seconds
[2023-01-06 02:08:44,314] {processor.py:153} INFO - Started process (PID=12598) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:08:44,316] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:08:44,316] {logging_mixin.py:115} INFO - [2023-01-06 02:08:44,316] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:08:45,139] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:08:45,140] {logging_mixin.py:115} INFO - [2023-01-06 02:08:45,140] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:08:45,141] {logging_mixin.py:115} INFO - [2023-01-06 02:08:45,140] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:08:45,147] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:08:45,170] {logging_mixin.py:115} INFO - [2023-01-06 02:08:45,169] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:08:45,191] {logging_mixin.py:115} INFO - [2023-01-06 02:08:45,191] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:08:45,202] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.893 seconds
[2023-01-06 02:09:15,421] {processor.py:153} INFO - Started process (PID=12622) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:09:15,422] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:09:15,422] {logging_mixin.py:115} INFO - [2023-01-06 02:09:15,422] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:09:16,259] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:09:16,260] {logging_mixin.py:115} INFO - [2023-01-06 02:09:16,260] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:09:16,261] {logging_mixin.py:115} INFO - [2023-01-06 02:09:16,260] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:09:16,269] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:09:16,292] {logging_mixin.py:115} INFO - [2023-01-06 02:09:16,292] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:09:16,313] {logging_mixin.py:115} INFO - [2023-01-06 02:09:16,313] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:09:16,324] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.909 seconds
[2023-01-06 02:09:46,516] {processor.py:153} INFO - Started process (PID=12646) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:09:46,517] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:09:46,517] {logging_mixin.py:115} INFO - [2023-01-06 02:09:46,517] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:09:47,358] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:09:47,359] {logging_mixin.py:115} INFO - [2023-01-06 02:09:47,359] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:09:47,360] {logging_mixin.py:115} INFO - [2023-01-06 02:09:47,360] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:09:47,367] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:09:47,390] {logging_mixin.py:115} INFO - [2023-01-06 02:09:47,390] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:09:47,411] {logging_mixin.py:115} INFO - [2023-01-06 02:09:47,411] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:09:47,422] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.911 seconds
[2023-01-06 02:10:17,581] {processor.py:153} INFO - Started process (PID=12671) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:10:17,582] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:10:17,583] {logging_mixin.py:115} INFO - [2023-01-06 02:10:17,583] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:10:18,743] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:10:18,745] {logging_mixin.py:115} INFO - [2023-01-06 02:10:18,744] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:10:18,745] {logging_mixin.py:115} INFO - [2023-01-06 02:10:18,745] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:10:18,757] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:10:18,789] {logging_mixin.py:115} INFO - [2023-01-06 02:10:18,789] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:10:18,819] {logging_mixin.py:115} INFO - [2023-01-06 02:10:18,819] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:10:18,832] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.257 seconds
[2023-01-06 02:10:49,703] {processor.py:153} INFO - Started process (PID=12690) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:10:49,704] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:10:49,705] {logging_mixin.py:115} INFO - [2023-01-06 02:10:49,704] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:10:50,508] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:10:50,510] {logging_mixin.py:115} INFO - [2023-01-06 02:10:50,509] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:10:50,510] {logging_mixin.py:115} INFO - [2023-01-06 02:10:50,510] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:10:50,517] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:10:50,540] {logging_mixin.py:115} INFO - [2023-01-06 02:10:50,540] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:10:50,562] {logging_mixin.py:115} INFO - [2023-01-06 02:10:50,562] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:10:50,572] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.875 seconds
[2023-01-06 02:11:20,772] {processor.py:153} INFO - Started process (PID=12716) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:11:20,773] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:11:20,774] {logging_mixin.py:115} INFO - [2023-01-06 02:11:20,773] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:11:21,603] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:11:21,605] {logging_mixin.py:115} INFO - [2023-01-06 02:11:21,605] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:11:21,605] {logging_mixin.py:115} INFO - [2023-01-06 02:11:21,605] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:11:21,612] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:11:21,635] {logging_mixin.py:115} INFO - [2023-01-06 02:11:21,635] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:11:21,657] {logging_mixin.py:115} INFO - [2023-01-06 02:11:21,657] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:11:21,667] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.900 seconds
[2023-01-06 02:11:51,876] {processor.py:153} INFO - Started process (PID=12741) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:11:51,877] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:11:51,878] {logging_mixin.py:115} INFO - [2023-01-06 02:11:51,878] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:11:52,746] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:11:52,748] {logging_mixin.py:115} INFO - [2023-01-06 02:11:52,748] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:11:52,749] {logging_mixin.py:115} INFO - [2023-01-06 02:11:52,748] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:11:52,756] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:11:52,785] {logging_mixin.py:115} INFO - [2023-01-06 02:11:52,784] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:11:52,809] {logging_mixin.py:115} INFO - [2023-01-06 02:11:52,809] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:11:52,824] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.954 seconds
[2023-01-06 02:12:22,944] {processor.py:153} INFO - Started process (PID=12766) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:12:22,945] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:12:22,945] {logging_mixin.py:115} INFO - [2023-01-06 02:12:22,945] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:12:23,851] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:12:23,853] {logging_mixin.py:115} INFO - [2023-01-06 02:12:23,853] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:12:23,853] {logging_mixin.py:115} INFO - [2023-01-06 02:12:23,853] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:12:23,861] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:12:23,888] {logging_mixin.py:115} INFO - [2023-01-06 02:12:23,888] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:12:23,911] {logging_mixin.py:115} INFO - [2023-01-06 02:12:23,911] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:12:23,921] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.982 seconds
[2023-01-06 02:12:54,021] {processor.py:153} INFO - Started process (PID=12784) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:12:54,023] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:12:54,024] {logging_mixin.py:115} INFO - [2023-01-06 02:12:54,024] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:12:54,849] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:12:54,850] {logging_mixin.py:115} INFO - [2023-01-06 02:12:54,850] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:12:54,851] {logging_mixin.py:115} INFO - [2023-01-06 02:12:54,851] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:12:54,858] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:12:54,888] {logging_mixin.py:115} INFO - [2023-01-06 02:12:54,888] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:12:54,909] {logging_mixin.py:115} INFO - [2023-01-06 02:12:54,909] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:12:54,919] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.904 seconds
[2023-01-06 02:13:25,138] {processor.py:153} INFO - Started process (PID=12809) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:13:25,141] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:13:25,141] {logging_mixin.py:115} INFO - [2023-01-06 02:13:25,141] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:13:25,979] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:13:25,980] {logging_mixin.py:115} INFO - [2023-01-06 02:13:25,980] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:13:25,981] {logging_mixin.py:115} INFO - [2023-01-06 02:13:25,981] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:13:25,988] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:13:26,019] {logging_mixin.py:115} INFO - [2023-01-06 02:13:26,018] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:13:26,048] {logging_mixin.py:115} INFO - [2023-01-06 02:13:26,048] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:13:26,060] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.927 seconds
[2023-01-06 02:13:56,209] {processor.py:153} INFO - Started process (PID=12834) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:13:56,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:13:56,211] {logging_mixin.py:115} INFO - [2023-01-06 02:13:56,210] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:13:57,042] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:13:57,043] {logging_mixin.py:115} INFO - [2023-01-06 02:13:57,043] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:13:57,044] {logging_mixin.py:115} INFO - [2023-01-06 02:13:57,044] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:13:57,051] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:13:57,073] {logging_mixin.py:115} INFO - [2023-01-06 02:13:57,073] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:13:57,093] {logging_mixin.py:115} INFO - [2023-01-06 02:13:57,093] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:13:57,103] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.899 seconds
[2023-01-06 02:14:27,280] {processor.py:153} INFO - Started process (PID=12851) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:14:27,281] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:14:27,281] {logging_mixin.py:115} INFO - [2023-01-06 02:14:27,281] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:14:28,137] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:14:28,138] {logging_mixin.py:115} INFO - [2023-01-06 02:14:28,138] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:14:28,139] {logging_mixin.py:115} INFO - [2023-01-06 02:14:28,139] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:14:28,146] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:14:28,178] {logging_mixin.py:115} INFO - [2023-01-06 02:14:28,177] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:14:28,209] {logging_mixin.py:115} INFO - [2023-01-06 02:14:28,209] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:14:28,221] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.946 seconds
[2023-01-06 02:14:58,358] {processor.py:153} INFO - Started process (PID=12876) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:14:58,359] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:14:58,359] {logging_mixin.py:115} INFO - [2023-01-06 02:14:58,359] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:14:59,204] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:14:59,205] {logging_mixin.py:115} INFO - [2023-01-06 02:14:59,205] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:14:59,206] {logging_mixin.py:115} INFO - [2023-01-06 02:14:59,206] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:14:59,213] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:14:59,235] {logging_mixin.py:115} INFO - [2023-01-06 02:14:59,235] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:14:59,256] {logging_mixin.py:115} INFO - [2023-01-06 02:14:59,256] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:14:59,266] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.912 seconds
[2023-01-06 02:15:29,433] {processor.py:153} INFO - Started process (PID=12902) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:15:29,435] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:15:29,435] {logging_mixin.py:115} INFO - [2023-01-06 02:15:29,435] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:15:30,249] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:15:30,250] {logging_mixin.py:115} INFO - [2023-01-06 02:15:30,250] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:15:30,251] {logging_mixin.py:115} INFO - [2023-01-06 02:15:30,251] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:15:30,258] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:15:30,281] {logging_mixin.py:115} INFO - [2023-01-06 02:15:30,280] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:15:30,302] {logging_mixin.py:115} INFO - [2023-01-06 02:15:30,302] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:15:30,315] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.887 seconds
[2023-01-06 02:16:00,527] {processor.py:153} INFO - Started process (PID=12928) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:16:00,528] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:16:00,528] {logging_mixin.py:115} INFO - [2023-01-06 02:16:00,528] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:16:01,350] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:16:01,351] {logging_mixin.py:115} INFO - [2023-01-06 02:16:01,351] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:16:01,352] {logging_mixin.py:115} INFO - [2023-01-06 02:16:01,351] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:16:01,359] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:16:01,382] {logging_mixin.py:115} INFO - [2023-01-06 02:16:01,382] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:16:01,403] {logging_mixin.py:115} INFO - [2023-01-06 02:16:01,403] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:16:01,413] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.890 seconds
[2023-01-06 02:16:31,607] {processor.py:153} INFO - Started process (PID=12946) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:16:31,608] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:16:31,609] {logging_mixin.py:115} INFO - [2023-01-06 02:16:31,609] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:16:32,446] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:16:32,447] {logging_mixin.py:115} INFO - [2023-01-06 02:16:32,447] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:16:32,448] {logging_mixin.py:115} INFO - [2023-01-06 02:16:32,448] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:16:32,455] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:16:32,477] {logging_mixin.py:115} INFO - [2023-01-06 02:16:32,477] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:16:32,497] {logging_mixin.py:115} INFO - [2023-01-06 02:16:32,497] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:16:32,508] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.905 seconds
[2023-01-06 02:17:02,726] {processor.py:153} INFO - Started process (PID=12971) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:17:02,727] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:17:02,727] {logging_mixin.py:115} INFO - [2023-01-06 02:17:02,727] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:17:03,545] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:17:03,546] {logging_mixin.py:115} INFO - [2023-01-06 02:17:03,546] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:17:03,547] {logging_mixin.py:115} INFO - [2023-01-06 02:17:03,547] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:17:03,554] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:17:03,580] {logging_mixin.py:115} INFO - [2023-01-06 02:17:03,580] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:17:03,600] {logging_mixin.py:115} INFO - [2023-01-06 02:17:03,600] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:17:03,610] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.889 seconds
[2023-01-06 02:17:33,808] {processor.py:153} INFO - Started process (PID=12998) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:17:33,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:17:33,810] {logging_mixin.py:115} INFO - [2023-01-06 02:17:33,810] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:17:34,648] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:17:34,650] {logging_mixin.py:115} INFO - [2023-01-06 02:17:34,649] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:17:34,650] {logging_mixin.py:115} INFO - [2023-01-06 02:17:34,650] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:17:34,658] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:17:34,688] {logging_mixin.py:115} INFO - [2023-01-06 02:17:34,687] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:17:34,715] {logging_mixin.py:115} INFO - [2023-01-06 02:17:34,715] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:17:34,726] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.922 seconds
[2023-01-06 02:18:04,933] {processor.py:153} INFO - Started process (PID=13024) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:18:04,934] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:18:04,935] {logging_mixin.py:115} INFO - [2023-01-06 02:18:04,935] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:18:05,766] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:18:05,767] {logging_mixin.py:115} INFO - [2023-01-06 02:18:05,767] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:18:05,768] {logging_mixin.py:115} INFO - [2023-01-06 02:18:05,767] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:18:05,774] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:18:05,797] {logging_mixin.py:115} INFO - [2023-01-06 02:18:05,796] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:18:05,818] {logging_mixin.py:115} INFO - [2023-01-06 02:18:05,818] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:18:05,827] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.899 seconds
[2023-01-06 02:18:36,064] {processor.py:153} INFO - Started process (PID=13042) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:18:36,065] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:18:36,066] {logging_mixin.py:115} INFO - [2023-01-06 02:18:36,066] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:18:36,923] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:18:36,925] {logging_mixin.py:115} INFO - [2023-01-06 02:18:36,925] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:18:36,925] {logging_mixin.py:115} INFO - [2023-01-06 02:18:36,925] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:18:36,932] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:18:36,957] {logging_mixin.py:115} INFO - [2023-01-06 02:18:36,956] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:18:36,977] {logging_mixin.py:115} INFO - [2023-01-06 02:18:36,977] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:18:36,987] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.929 seconds
[2023-01-06 02:19:07,186] {processor.py:153} INFO - Started process (PID=13067) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:19:07,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:19:07,187] {logging_mixin.py:115} INFO - [2023-01-06 02:19:07,187] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:19:08,027] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:19:08,029] {logging_mixin.py:115} INFO - [2023-01-06 02:19:08,029] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:19:08,029] {logging_mixin.py:115} INFO - [2023-01-06 02:19:08,029] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:19:08,036] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:19:08,059] {logging_mixin.py:115} INFO - [2023-01-06 02:19:08,059] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:19:08,080] {logging_mixin.py:115} INFO - [2023-01-06 02:19:08,080] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:19:08,090] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.908 seconds
[2023-01-06 02:19:38,245] {processor.py:153} INFO - Started process (PID=13092) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:19:38,246] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 02:19:38,246] {logging_mixin.py:115} INFO - [2023-01-06 02:19:38,246] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:19:39,077] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 02:19:39,079] {logging_mixin.py:115} INFO - [2023-01-06 02:19:39,078] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 02:19:39,079] {logging_mixin.py:115} INFO - [2023-01-06 02:19:39,079] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 02:19:39,086] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 02:19:39,109] {logging_mixin.py:115} INFO - [2023-01-06 02:19:39,109] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 02:19:39,132] {logging_mixin.py:115} INFO - [2023-01-06 02:19:39,131] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 02:19:39,141] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.901 seconds
[2023-01-06 21:30:25,402] {processor.py:153} INFO - Started process (PID=34) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:30:25,403] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:30:25,404] {logging_mixin.py:115} INFO - [2023-01-06 21:30:25,403] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:30:28,966] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:30:28,968] {logging_mixin.py:115} INFO - [2023-01-06 21:30:28,968] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:30:28,968] {logging_mixin.py:115} INFO - [2023-01-06 21:30:28,968] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:30:28,984] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:30:29,035] {logging_mixin.py:115} INFO - [2023-01-06 21:30:29,035] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:30:29,063] {logging_mixin.py:115} INFO - [2023-01-06 21:30:29,063] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:30:29,074] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 3.683 seconds
[2023-01-06 21:30:59,176] {processor.py:153} INFO - Started process (PID=60) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:30:59,180] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:30:59,181] {logging_mixin.py:115} INFO - [2023-01-06 21:30:59,180] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:31:00,014] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:31:00,016] {logging_mixin.py:115} INFO - [2023-01-06 21:31:00,016] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:31:00,017] {logging_mixin.py:115} INFO - [2023-01-06 21:31:00,016] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:31:00,028] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:31:00,057] {logging_mixin.py:115} INFO - [2023-01-06 21:31:00,057] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:31:00,086] {logging_mixin.py:115} INFO - [2023-01-06 21:31:00,085] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:31:00,098] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.926 seconds
[2023-01-06 21:31:30,413] {processor.py:153} INFO - Started process (PID=86) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:31:30,413] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:31:30,414] {logging_mixin.py:115} INFO - [2023-01-06 21:31:30,414] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:31:31,509] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:31:31,510] {logging_mixin.py:115} INFO - [2023-01-06 21:31:31,510] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:31:31,510] {logging_mixin.py:115} INFO - [2023-01-06 21:31:31,510] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:31:31,517] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:31:31,538] {logging_mixin.py:115} INFO - [2023-01-06 21:31:31,538] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:31:31,558] {logging_mixin.py:115} INFO - [2023-01-06 21:31:31,557] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:31:31,567] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.159 seconds
[2023-01-06 21:32:01,665] {processor.py:153} INFO - Started process (PID=104) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:32:01,667] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:32:01,667] {logging_mixin.py:115} INFO - [2023-01-06 21:32:01,667] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:32:02,537] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:32:02,539] {logging_mixin.py:115} INFO - [2023-01-06 21:32:02,538] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:32:02,539] {logging_mixin.py:115} INFO - [2023-01-06 21:32:02,539] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:32:02,546] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:32:02,566] {logging_mixin.py:115} INFO - [2023-01-06 21:32:02,566] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:32:02,586] {logging_mixin.py:115} INFO - [2023-01-06 21:32:02,586] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:32:02,595] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.935 seconds
[2023-01-06 21:32:32,762] {processor.py:153} INFO - Started process (PID=130) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:32:32,765] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:32:32,765] {logging_mixin.py:115} INFO - [2023-01-06 21:32:32,765] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:32:33,830] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:32:33,832] {logging_mixin.py:115} INFO - [2023-01-06 21:32:33,831] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:32:33,832] {logging_mixin.py:115} INFO - [2023-01-06 21:32:33,832] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:32:33,839] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:32:33,866] {logging_mixin.py:115} INFO - [2023-01-06 21:32:33,866] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:32:33,892] {logging_mixin.py:115} INFO - [2023-01-06 21:32:33,892] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:32:33,903] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.145 seconds
[2023-01-06 21:33:03,970] {processor.py:153} INFO - Started process (PID=155) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:33:03,971] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:33:03,971] {logging_mixin.py:115} INFO - [2023-01-06 21:33:03,971] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:33:04,748] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:33:04,749] {logging_mixin.py:115} INFO - [2023-01-06 21:33:04,749] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:33:04,750] {logging_mixin.py:115} INFO - [2023-01-06 21:33:04,750] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:33:04,756] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:33:04,781] {logging_mixin.py:115} INFO - [2023-01-06 21:33:04,781] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:33:04,809] {logging_mixin.py:115} INFO - [2023-01-06 21:33:04,809] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:33:04,820] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.854 seconds
[2023-01-06 21:33:34,917] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:33:34,921] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:33:34,922] {logging_mixin.py:115} INFO - [2023-01-06 21:33:34,922] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:33:35,781] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:33:35,782] {logging_mixin.py:115} INFO - [2023-01-06 21:33:35,782] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:33:35,783] {logging_mixin.py:115} INFO - [2023-01-06 21:33:35,782] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:33:35,789] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:33:35,810] {logging_mixin.py:115} INFO - [2023-01-06 21:33:35,810] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:33:35,830] {logging_mixin.py:115} INFO - [2023-01-06 21:33:35,830] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:33:35,839] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.926 seconds
[2023-01-06 21:34:05,994] {processor.py:153} INFO - Started process (PID=198) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:34:05,995] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:34:05,996] {logging_mixin.py:115} INFO - [2023-01-06 21:34:05,996] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:34:06,994] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:34:06,995] {logging_mixin.py:115} INFO - [2023-01-06 21:34:06,995] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:34:06,996] {logging_mixin.py:115} INFO - [2023-01-06 21:34:06,996] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:34:07,003] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:34:07,027] {logging_mixin.py:115} INFO - [2023-01-06 21:34:07,026] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:34:07,048] {logging_mixin.py:115} INFO - [2023-01-06 21:34:07,047] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:34:07,057] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.068 seconds
[2023-01-06 21:34:37,103] {processor.py:153} INFO - Started process (PID=223) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:34:37,104] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:34:37,104] {logging_mixin.py:115} INFO - [2023-01-06 21:34:37,104] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:34:37,888] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:34:37,889] {logging_mixin.py:115} INFO - [2023-01-06 21:34:37,889] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:34:37,890] {logging_mixin.py:115} INFO - [2023-01-06 21:34:37,890] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:34:37,896] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:34:37,918] {logging_mixin.py:115} INFO - [2023-01-06 21:34:37,917] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:34:37,937] {logging_mixin.py:115} INFO - [2023-01-06 21:34:37,937] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:34:37,950] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.851 seconds
[2023-01-06 21:35:08,047] {processor.py:153} INFO - Started process (PID=246) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:35:08,048] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:35:08,049] {logging_mixin.py:115} INFO - [2023-01-06 21:35:08,049] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:35:08,850] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:35:08,852] {logging_mixin.py:115} INFO - [2023-01-06 21:35:08,852] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:35:08,852] {logging_mixin.py:115} INFO - [2023-01-06 21:35:08,852] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:35:08,859] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:35:08,880] {logging_mixin.py:115} INFO - [2023-01-06 21:35:08,880] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:35:08,900] {logging_mixin.py:115} INFO - [2023-01-06 21:35:08,900] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:35:08,909] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.866 seconds
[2023-01-06 21:35:39,017] {processor.py:153} INFO - Started process (PID=262) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:35:39,018] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:35:39,018] {logging_mixin.py:115} INFO - [2023-01-06 21:35:39,018] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:35:40,372] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:35:40,374] {logging_mixin.py:115} INFO - [2023-01-06 21:35:40,374] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:35:40,375] {logging_mixin.py:115} INFO - [2023-01-06 21:35:40,375] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:35:40,394] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:35:40,454] {logging_mixin.py:115} INFO - [2023-01-06 21:35:40,454] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:35:40,499] {logging_mixin.py:115} INFO - [2023-01-06 21:35:40,499] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:35:40,542] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.530 seconds
[2023-01-06 21:36:10,646] {processor.py:153} INFO - Started process (PID=287) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:36:10,651] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:36:10,651] {logging_mixin.py:115} INFO - [2023-01-06 21:36:10,651] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:36:11,470] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:36:11,471] {logging_mixin.py:115} INFO - [2023-01-06 21:36:11,471] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:36:11,472] {logging_mixin.py:115} INFO - [2023-01-06 21:36:11,471] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:36:11,478] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:36:11,506] {logging_mixin.py:115} INFO - [2023-01-06 21:36:11,505] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:36:11,530] {logging_mixin.py:115} INFO - [2023-01-06 21:36:11,530] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:36:11,539] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.897 seconds
[2023-01-06 21:36:41,795] {processor.py:153} INFO - Started process (PID=316) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:36:41,795] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:36:41,796] {logging_mixin.py:115} INFO - [2023-01-06 21:36:41,795] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:36:42,570] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:36:42,571] {logging_mixin.py:115} INFO - [2023-01-06 21:36:42,571] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:36:42,572] {logging_mixin.py:115} INFO - [2023-01-06 21:36:42,571] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:36:42,578] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:36:42,607] {logging_mixin.py:115} INFO - [2023-01-06 21:36:42,606] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:36:42,635] {logging_mixin.py:115} INFO - [2023-01-06 21:36:42,635] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:36:42,647] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.857 seconds
[2023-01-06 21:37:12,738] {processor.py:153} INFO - Started process (PID=341) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:37:12,738] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:37:12,739] {logging_mixin.py:115} INFO - [2023-01-06 21:37:12,739] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:37:13,798] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:37:13,800] {logging_mixin.py:115} INFO - [2023-01-06 21:37:13,800] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:37:13,801] {logging_mixin.py:115} INFO - [2023-01-06 21:37:13,800] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:37:13,811] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:37:13,840] {logging_mixin.py:115} INFO - [2023-01-06 21:37:13,839] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:37:13,868] {logging_mixin.py:115} INFO - [2023-01-06 21:37:13,868] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:37:13,880] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.147 seconds
[2023-01-06 21:37:43,961] {processor.py:153} INFO - Started process (PID=359) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:37:43,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:37:43,963] {logging_mixin.py:115} INFO - [2023-01-06 21:37:43,962] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:37:45,092] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:37:45,094] {logging_mixin.py:115} INFO - [2023-01-06 21:37:45,094] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:37:45,095] {logging_mixin.py:115} INFO - [2023-01-06 21:37:45,094] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:37:45,107] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:37:45,135] {logging_mixin.py:115} INFO - [2023-01-06 21:37:45,135] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:37:45,163] {logging_mixin.py:115} INFO - [2023-01-06 21:37:45,163] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:37:45,175] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.219 seconds
[2023-01-06 21:38:15,214] {processor.py:153} INFO - Started process (PID=384) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:38:15,217] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:38:15,218] {logging_mixin.py:115} INFO - [2023-01-06 21:38:15,218] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:38:15,991] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:38:15,993] {logging_mixin.py:115} INFO - [2023-01-06 21:38:15,993] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:38:15,993] {logging_mixin.py:115} INFO - [2023-01-06 21:38:15,993] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:38:16,000] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:38:16,022] {logging_mixin.py:115} INFO - [2023-01-06 21:38:16,021] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:38:16,041] {logging_mixin.py:115} INFO - [2023-01-06 21:38:16,041] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:38:16,050] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.840 seconds
[2023-01-06 21:38:46,143] {processor.py:153} INFO - Started process (PID=408) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:38:46,144] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:38:46,145] {logging_mixin.py:115} INFO - [2023-01-06 21:38:46,144] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:38:47,174] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:38:47,176] {logging_mixin.py:115} INFO - [2023-01-06 21:38:47,176] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:38:47,176] {logging_mixin.py:115} INFO - [2023-01-06 21:38:47,176] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:38:47,187] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:38:47,220] {logging_mixin.py:115} INFO - [2023-01-06 21:38:47,220] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:38:47,249] {logging_mixin.py:115} INFO - [2023-01-06 21:38:47,249] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:38:47,261] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.122 seconds
[2023-01-06 21:39:17,363] {processor.py:153} INFO - Started process (PID=433) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:39:17,364] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:39:17,365] {logging_mixin.py:115} INFO - [2023-01-06 21:39:17,364] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:39:18,166] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:39:18,167] {logging_mixin.py:115} INFO - [2023-01-06 21:39:18,167] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:39:18,167] {logging_mixin.py:115} INFO - [2023-01-06 21:39:18,167] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:39:18,174] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:39:18,202] {logging_mixin.py:115} INFO - [2023-01-06 21:39:18,202] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:39:18,231] {logging_mixin.py:115} INFO - [2023-01-06 21:39:18,231] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:39:18,243] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.884 seconds
[2023-01-06 21:39:48,638] {processor.py:153} INFO - Started process (PID=453) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:39:48,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:39:48,640] {logging_mixin.py:115} INFO - [2023-01-06 21:39:48,639] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:39:49,726] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:39:49,727] {logging_mixin.py:115} INFO - [2023-01-06 21:39:49,727] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:39:49,728] {logging_mixin.py:115} INFO - [2023-01-06 21:39:49,728] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:39:49,735] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:39:49,756] {logging_mixin.py:115} INFO - [2023-01-06 21:39:49,756] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:39:49,776] {logging_mixin.py:115} INFO - [2023-01-06 21:39:49,775] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:39:49,785] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.153 seconds
[2023-01-06 21:40:19,889] {processor.py:153} INFO - Started process (PID=479) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:40:19,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:40:19,891] {logging_mixin.py:115} INFO - [2023-01-06 21:40:19,891] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:40:20,830] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:40:20,831] {logging_mixin.py:115} INFO - [2023-01-06 21:40:20,831] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:40:20,832] {logging_mixin.py:115} INFO - [2023-01-06 21:40:20,831] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:40:20,838] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:40:20,860] {logging_mixin.py:115} INFO - [2023-01-06 21:40:20,860] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:40:20,880] {logging_mixin.py:115} INFO - [2023-01-06 21:40:20,880] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:40:20,889] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.006 seconds
[2023-01-06 21:40:51,004] {processor.py:153} INFO - Started process (PID=504) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:40:51,005] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:40:51,006] {logging_mixin.py:115} INFO - [2023-01-06 21:40:51,006] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:40:51,905] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:40:51,907] {logging_mixin.py:115} INFO - [2023-01-06 21:40:51,907] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:40:51,907] {logging_mixin.py:115} INFO - [2023-01-06 21:40:51,907] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:40:51,914] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:40:51,936] {logging_mixin.py:115} INFO - [2023-01-06 21:40:51,935] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:40:51,956] {logging_mixin.py:115} INFO - [2023-01-06 21:40:51,956] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:40:51,965] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.965 seconds
[2023-01-06 21:41:22,080] {processor.py:153} INFO - Started process (PID=530) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:41:22,081] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:41:22,082] {logging_mixin.py:115} INFO - [2023-01-06 21:41:22,082] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:41:22,853] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:41:22,854] {logging_mixin.py:115} INFO - [2023-01-06 21:41:22,854] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:41:22,855] {logging_mixin.py:115} INFO - [2023-01-06 21:41:22,855] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:41:22,864] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:41:22,887] {logging_mixin.py:115} INFO - [2023-01-06 21:41:22,886] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:41:22,906] {logging_mixin.py:115} INFO - [2023-01-06 21:41:22,906] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:41:22,916] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.840 seconds
[2023-01-06 21:41:53,018] {processor.py:153} INFO - Started process (PID=548) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:41:53,020] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:41:53,021] {logging_mixin.py:115} INFO - [2023-01-06 21:41:53,020] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:41:54,212] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:41:54,214] {logging_mixin.py:115} INFO - [2023-01-06 21:41:54,214] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:41:54,215] {logging_mixin.py:115} INFO - [2023-01-06 21:41:54,214] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:41:54,226] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:41:54,257] {logging_mixin.py:115} INFO - [2023-01-06 21:41:54,256] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:41:54,286] {logging_mixin.py:115} INFO - [2023-01-06 21:41:54,285] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:41:54,298] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.285 seconds
[2023-01-06 21:42:24,400] {processor.py:153} INFO - Started process (PID=575) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:42:24,400] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:42:24,401] {logging_mixin.py:115} INFO - [2023-01-06 21:42:24,401] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:42:25,202] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:42:25,203] {logging_mixin.py:115} INFO - [2023-01-06 21:42:25,203] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:42:25,204] {logging_mixin.py:115} INFO - [2023-01-06 21:42:25,203] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:42:25,210] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:42:25,236] {logging_mixin.py:115} INFO - [2023-01-06 21:42:25,236] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:42:25,255] {logging_mixin.py:115} INFO - [2023-01-06 21:42:25,255] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:42:25,266] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.871 seconds
[2023-01-06 21:42:55,366] {processor.py:153} INFO - Started process (PID=599) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:42:55,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:42:55,370] {logging_mixin.py:115} INFO - [2023-01-06 21:42:55,370] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:42:56,143] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:42:56,145] {logging_mixin.py:115} INFO - [2023-01-06 21:42:56,144] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:42:56,145] {logging_mixin.py:115} INFO - [2023-01-06 21:42:56,145] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:42:56,153] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:42:56,174] {logging_mixin.py:115} INFO - [2023-01-06 21:42:56,174] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:42:56,193] {logging_mixin.py:115} INFO - [2023-01-06 21:42:56,193] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:42:56,203] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-06 21:43:26,298] {processor.py:153} INFO - Started process (PID=625) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:43:26,299] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:43:26,299] {logging_mixin.py:115} INFO - [2023-01-06 21:43:26,299] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:43:27,217] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:43:27,219] {logging_mixin.py:115} INFO - [2023-01-06 21:43:27,219] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:43:27,219] {logging_mixin.py:115} INFO - [2023-01-06 21:43:27,219] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:43:27,226] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:43:27,248] {logging_mixin.py:115} INFO - [2023-01-06 21:43:27,248] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:43:27,268] {logging_mixin.py:115} INFO - [2023-01-06 21:43:27,268] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:43:27,278] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.984 seconds
[2023-01-06 21:43:57,507] {processor.py:153} INFO - Started process (PID=644) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:43:57,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:43:57,509] {logging_mixin.py:115} INFO - [2023-01-06 21:43:57,509] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:43:58,677] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:43:58,679] {logging_mixin.py:115} INFO - [2023-01-06 21:43:58,679] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:43:58,679] {logging_mixin.py:115} INFO - [2023-01-06 21:43:58,679] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:43:58,690] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:43:58,720] {logging_mixin.py:115} INFO - [2023-01-06 21:43:58,720] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:43:58,750] {logging_mixin.py:115} INFO - [2023-01-06 21:43:58,750] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:43:58,762] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.260 seconds
[2023-01-06 21:44:28,857] {processor.py:153} INFO - Started process (PID=672) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:44:28,857] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:44:28,858] {logging_mixin.py:115} INFO - [2023-01-06 21:44:28,858] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:44:29,628] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:44:29,629] {logging_mixin.py:115} INFO - [2023-01-06 21:44:29,629] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:44:29,630] {logging_mixin.py:115} INFO - [2023-01-06 21:44:29,629] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:44:29,636] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:44:29,666] {logging_mixin.py:115} INFO - [2023-01-06 21:44:29,665] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:44:29,691] {logging_mixin.py:115} INFO - [2023-01-06 21:44:29,691] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:44:29,703] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.850 seconds
[2023-01-06 21:44:59,807] {processor.py:153} INFO - Started process (PID=695) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:44:59,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:44:59,810] {logging_mixin.py:115} INFO - [2023-01-06 21:44:59,810] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:45:00,621] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:45:00,622] {logging_mixin.py:115} INFO - [2023-01-06 21:45:00,622] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:45:00,623] {logging_mixin.py:115} INFO - [2023-01-06 21:45:00,623] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:45:00,630] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:45:00,651] {logging_mixin.py:115} INFO - [2023-01-06 21:45:00,651] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:45:00,671] {logging_mixin.py:115} INFO - [2023-01-06 21:45:00,671] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:45:00,680] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.877 seconds
[2023-01-06 21:45:30,958] {processor.py:153} INFO - Started process (PID=723) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:45:30,959] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:45:30,959] {logging_mixin.py:115} INFO - [2023-01-06 21:45:30,959] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:45:31,783] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:45:31,785] {logging_mixin.py:115} INFO - [2023-01-06 21:45:31,785] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:45:31,785] {logging_mixin.py:115} INFO - [2023-01-06 21:45:31,785] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:45:31,792] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:45:31,813] {logging_mixin.py:115} INFO - [2023-01-06 21:45:31,813] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:45:31,833] {logging_mixin.py:115} INFO - [2023-01-06 21:45:31,833] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:45:31,843] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.889 seconds
[2023-01-06 21:46:01,934] {processor.py:153} INFO - Started process (PID=739) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:46:01,936] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:46:01,936] {logging_mixin.py:115} INFO - [2023-01-06 21:46:01,936] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:46:03,012] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:46:03,014] {logging_mixin.py:115} INFO - [2023-01-06 21:46:03,014] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:46:03,015] {logging_mixin.py:115} INFO - [2023-01-06 21:46:03,014] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:46:03,026] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:46:03,055] {logging_mixin.py:115} INFO - [2023-01-06 21:46:03,055] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:46:03,084] {logging_mixin.py:115} INFO - [2023-01-06 21:46:03,084] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:46:03,096] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.166 seconds
[2023-01-06 21:46:33,199] {processor.py:153} INFO - Started process (PID=764) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:46:33,200] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:46:33,200] {logging_mixin.py:115} INFO - [2023-01-06 21:46:33,200] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:46:33,977] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:46:33,978] {logging_mixin.py:115} INFO - [2023-01-06 21:46:33,978] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:46:33,979] {logging_mixin.py:115} INFO - [2023-01-06 21:46:33,978] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:46:33,985] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:46:34,006] {logging_mixin.py:115} INFO - [2023-01-06 21:46:34,006] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:46:34,026] {logging_mixin.py:115} INFO - [2023-01-06 21:46:34,026] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:46:34,035] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-06 21:47:04,132] {processor.py:153} INFO - Started process (PID=790) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:47:04,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:47:04,133] {logging_mixin.py:115} INFO - [2023-01-06 21:47:04,133] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:47:04,900] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:47:04,902] {logging_mixin.py:115} INFO - [2023-01-06 21:47:04,902] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:47:04,902] {logging_mixin.py:115} INFO - [2023-01-06 21:47:04,902] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:47:04,909] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:47:04,931] {logging_mixin.py:115} INFO - [2023-01-06 21:47:04,930] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:47:04,958] {logging_mixin.py:115} INFO - [2023-01-06 21:47:04,958] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:47:04,967] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.840 seconds
[2023-01-06 21:47:35,070] {processor.py:153} INFO - Started process (PID=816) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:47:35,072] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:47:35,073] {logging_mixin.py:115} INFO - [2023-01-06 21:47:35,073] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:47:35,962] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:47:35,963] {logging_mixin.py:115} INFO - [2023-01-06 21:47:35,963] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:47:35,963] {logging_mixin.py:115} INFO - [2023-01-06 21:47:35,963] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:47:35,970] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:47:35,991] {logging_mixin.py:115} INFO - [2023-01-06 21:47:35,991] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:47:36,016] {logging_mixin.py:115} INFO - [2023-01-06 21:47:36,016] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:47:36,031] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.967 seconds
[2023-01-06 21:48:06,352] {processor.py:153} INFO - Started process (PID=842) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:48:06,353] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:48:06,354] {logging_mixin.py:115} INFO - [2023-01-06 21:48:06,354] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:48:07,286] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:48:07,287] {logging_mixin.py:115} INFO - [2023-01-06 21:48:07,287] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:48:07,288] {logging_mixin.py:115} INFO - [2023-01-06 21:48:07,288] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:48:07,302] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:48:07,332] {logging_mixin.py:115} INFO - [2023-01-06 21:48:07,332] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:48:07,362] {logging_mixin.py:115} INFO - [2023-01-06 21:48:07,362] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:48:07,374] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.027 seconds
[2023-01-06 21:48:37,477] {processor.py:153} INFO - Started process (PID=860) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:48:37,478] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:48:37,479] {logging_mixin.py:115} INFO - [2023-01-06 21:48:37,479] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:48:38,290] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:48:38,291] {logging_mixin.py:115} INFO - [2023-01-06 21:48:38,291] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:48:38,292] {logging_mixin.py:115} INFO - [2023-01-06 21:48:38,292] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:48:38,299] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:48:38,320] {logging_mixin.py:115} INFO - [2023-01-06 21:48:38,320] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:48:38,340] {logging_mixin.py:115} INFO - [2023-01-06 21:48:38,340] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:48:38,350] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.877 seconds
[2023-01-06 21:49:08,448] {processor.py:153} INFO - Started process (PID=884) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:49:08,449] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:49:08,449] {logging_mixin.py:115} INFO - [2023-01-06 21:49:08,449] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:49:09,233] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:49:09,235] {logging_mixin.py:115} INFO - [2023-01-06 21:49:09,235] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:49:09,235] {logging_mixin.py:115} INFO - [2023-01-06 21:49:09,235] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:49:09,242] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:49:09,263] {logging_mixin.py:115} INFO - [2023-01-06 21:49:09,263] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:49:09,283] {logging_mixin.py:115} INFO - [2023-01-06 21:49:09,283] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:49:09,292] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.848 seconds
[2023-01-06 21:49:39,387] {processor.py:153} INFO - Started process (PID=909) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:49:39,388] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:49:39,389] {logging_mixin.py:115} INFO - [2023-01-06 21:49:39,389] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:49:40,194] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:49:40,196] {logging_mixin.py:115} INFO - [2023-01-06 21:49:40,196] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:49:40,196] {logging_mixin.py:115} INFO - [2023-01-06 21:49:40,196] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:49:40,203] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:49:40,224] {logging_mixin.py:115} INFO - [2023-01-06 21:49:40,224] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:49:40,245] {logging_mixin.py:115} INFO - [2023-01-06 21:49:40,245] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:49:40,256] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.874 seconds
[2023-01-06 21:50:10,352] {processor.py:153} INFO - Started process (PID=933) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:50:10,354] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:50:10,355] {logging_mixin.py:115} INFO - [2023-01-06 21:50:10,355] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:50:11,234] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:50:11,236] {logging_mixin.py:115} INFO - [2023-01-06 21:50:11,236] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:50:11,236] {logging_mixin.py:115} INFO - [2023-01-06 21:50:11,236] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:50:11,243] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:50:11,265] {logging_mixin.py:115} INFO - [2023-01-06 21:50:11,264] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:50:11,285] {logging_mixin.py:115} INFO - [2023-01-06 21:50:11,285] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:50:11,294] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.947 seconds
[2023-01-06 21:50:41,791] {processor.py:153} INFO - Started process (PID=952) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:50:41,792] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:50:41,792] {logging_mixin.py:115} INFO - [2023-01-06 21:50:41,792] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:50:42,565] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:50:42,566] {logging_mixin.py:115} INFO - [2023-01-06 21:50:42,566] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:50:42,567] {logging_mixin.py:115} INFO - [2023-01-06 21:50:42,567] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:50:42,574] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:50:42,603] {logging_mixin.py:115} INFO - [2023-01-06 21:50:42,602] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:50:42,632] {logging_mixin.py:115} INFO - [2023-01-06 21:50:42,632] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:50:42,650] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.863 seconds
[2023-01-06 21:51:12,979] {processor.py:153} INFO - Started process (PID=979) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:51:12,980] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:51:12,981] {logging_mixin.py:115} INFO - [2023-01-06 21:51:12,981] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:51:13,792] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:51:13,794] {logging_mixin.py:115} INFO - [2023-01-06 21:51:13,794] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:51:13,795] {logging_mixin.py:115} INFO - [2023-01-06 21:51:13,794] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:51:13,805] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:51:13,828] {logging_mixin.py:115} INFO - [2023-01-06 21:51:13,828] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:51:13,848] {logging_mixin.py:115} INFO - [2023-01-06 21:51:13,848] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:51:13,857] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.882 seconds
[2023-01-06 21:51:44,060] {processor.py:153} INFO - Started process (PID=1004) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:51:44,061] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:51:44,062] {logging_mixin.py:115} INFO - [2023-01-06 21:51:44,062] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:51:44,960] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:51:44,962] {logging_mixin.py:115} INFO - [2023-01-06 21:51:44,962] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:51:44,963] {logging_mixin.py:115} INFO - [2023-01-06 21:51:44,962] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:51:44,974] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:51:45,003] {logging_mixin.py:115} INFO - [2023-01-06 21:51:45,003] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:51:45,031] {logging_mixin.py:115} INFO - [2023-01-06 21:51:45,031] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:51:45,042] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.987 seconds
[2023-01-06 21:52:15,156] {processor.py:153} INFO - Started process (PID=1030) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:52:15,157] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:52:15,158] {logging_mixin.py:115} INFO - [2023-01-06 21:52:15,158] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:52:15,991] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:52:15,992] {logging_mixin.py:115} INFO - [2023-01-06 21:52:15,992] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:52:15,993] {logging_mixin.py:115} INFO - [2023-01-06 21:52:15,993] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:52:16,000] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:52:16,021] {logging_mixin.py:115} INFO - [2023-01-06 21:52:16,021] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:52:16,041] {logging_mixin.py:115} INFO - [2023-01-06 21:52:16,041] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:52:16,050] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.900 seconds
[2023-01-06 21:52:46,228] {processor.py:153} INFO - Started process (PID=1047) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:52:46,230] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:52:46,230] {logging_mixin.py:115} INFO - [2023-01-06 21:52:46,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:52:47,283] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:52:47,284] {logging_mixin.py:115} INFO - [2023-01-06 21:52:47,284] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:52:47,285] {logging_mixin.py:115} INFO - [2023-01-06 21:52:47,285] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:52:47,292] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:52:47,314] {logging_mixin.py:115} INFO - [2023-01-06 21:52:47,314] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:52:47,334] {logging_mixin.py:115} INFO - [2023-01-06 21:52:47,334] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:52:47,345] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.122 seconds
[2023-01-06 21:53:17,440] {processor.py:153} INFO - Started process (PID=1072) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:53:17,443] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:53:17,444] {logging_mixin.py:115} INFO - [2023-01-06 21:53:17,443] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:53:18,515] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:53:18,517] {logging_mixin.py:115} INFO - [2023-01-06 21:53:18,516] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:53:18,517] {logging_mixin.py:115} INFO - [2023-01-06 21:53:18,517] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:53:18,528] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:53:18,552] {logging_mixin.py:115} INFO - [2023-01-06 21:53:18,552] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:53:18,572] {logging_mixin.py:115} INFO - [2023-01-06 21:53:18,572] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:53:18,581] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.145 seconds
[2023-01-06 21:53:48,681] {processor.py:153} INFO - Started process (PID=1098) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:53:48,682] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:53:48,683] {logging_mixin.py:115} INFO - [2023-01-06 21:53:48,683] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:53:49,455] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:53:49,456] {logging_mixin.py:115} INFO - [2023-01-06 21:53:49,456] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:53:49,457] {logging_mixin.py:115} INFO - [2023-01-06 21:53:49,456] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:53:49,463] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:53:49,485] {logging_mixin.py:115} INFO - [2023-01-06 21:53:49,484] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:53:49,504] {logging_mixin.py:115} INFO - [2023-01-06 21:53:49,504] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:53:49,514] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.837 seconds
[2023-01-06 21:54:19,614] {processor.py:153} INFO - Started process (PID=1123) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:54:19,615] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:54:19,616] {logging_mixin.py:115} INFO - [2023-01-06 21:54:19,616] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:54:20,407] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:54:20,409] {logging_mixin.py:115} INFO - [2023-01-06 21:54:20,409] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:54:20,409] {logging_mixin.py:115} INFO - [2023-01-06 21:54:20,409] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:54:20,416] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:54:20,437] {logging_mixin.py:115} INFO - [2023-01-06 21:54:20,437] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:54:20,457] {logging_mixin.py:115} INFO - [2023-01-06 21:54:20,456] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:54:20,466] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.856 seconds
[2023-01-06 21:54:50,563] {processor.py:153} INFO - Started process (PID=1141) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:54:50,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:54:50,564] {logging_mixin.py:115} INFO - [2023-01-06 21:54:50,564] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:54:51,574] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:54:51,576] {logging_mixin.py:115} INFO - [2023-01-06 21:54:51,576] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:54:51,576] {logging_mixin.py:115} INFO - [2023-01-06 21:54:51,576] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:54:51,588] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:54:51,618] {logging_mixin.py:115} INFO - [2023-01-06 21:54:51,617] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:54:51,646] {logging_mixin.py:115} INFO - [2023-01-06 21:54:51,646] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:54:51,658] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.100 seconds
[2023-01-06 21:55:21,732] {processor.py:153} INFO - Started process (PID=1168) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:55:21,733] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:55:21,734] {logging_mixin.py:115} INFO - [2023-01-06 21:55:21,734] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:55:22,517] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:55:22,518] {logging_mixin.py:115} INFO - [2023-01-06 21:55:22,518] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:55:22,519] {logging_mixin.py:115} INFO - [2023-01-06 21:55:22,519] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:55:22,526] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:55:22,547] {logging_mixin.py:115} INFO - [2023-01-06 21:55:22,547] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:55:22,567] {logging_mixin.py:115} INFO - [2023-01-06 21:55:22,567] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:55:22,577] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.849 seconds
[2023-01-06 21:55:52,643] {processor.py:153} INFO - Started process (PID=1193) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:55:52,644] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:55:52,645] {logging_mixin.py:115} INFO - [2023-01-06 21:55:52,645] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:55:53,425] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:55:53,426] {logging_mixin.py:115} INFO - [2023-01-06 21:55:53,426] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:55:53,427] {logging_mixin.py:115} INFO - [2023-01-06 21:55:53,427] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:55:53,433] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:55:53,456] {logging_mixin.py:115} INFO - [2023-01-06 21:55:53,455] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:55:53,476] {logging_mixin.py:115} INFO - [2023-01-06 21:55:53,475] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:55:53,486] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.847 seconds
[2023-01-06 21:56:23,560] {processor.py:153} INFO - Started process (PID=1219) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:56:23,561] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:56:23,562] {logging_mixin.py:115} INFO - [2023-01-06 21:56:23,562] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:56:24,359] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:56:24,361] {logging_mixin.py:115} INFO - [2023-01-06 21:56:24,361] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:56:24,362] {logging_mixin.py:115} INFO - [2023-01-06 21:56:24,362] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:56:24,373] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:56:24,406] {logging_mixin.py:115} INFO - [2023-01-06 21:56:24,406] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:56:24,435] {logging_mixin.py:115} INFO - [2023-01-06 21:56:24,435] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:56:24,447] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.892 seconds
[2023-01-06 21:56:54,519] {processor.py:153} INFO - Started process (PID=1236) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:56:54,520] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:56:54,520] {logging_mixin.py:115} INFO - [2023-01-06 21:56:54,520] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:56:55,282] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:56:55,283] {logging_mixin.py:115} INFO - [2023-01-06 21:56:55,283] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:56:55,283] {logging_mixin.py:115} INFO - [2023-01-06 21:56:55,283] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:56:55,290] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:56:55,311] {logging_mixin.py:115} INFO - [2023-01-06 21:56:55,311] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:56:55,331] {logging_mixin.py:115} INFO - [2023-01-06 21:56:55,331] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:56:55,342] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.827 seconds
[2023-01-06 21:57:25,414] {processor.py:153} INFO - Started process (PID=1262) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:57:25,415] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:57:25,416] {logging_mixin.py:115} INFO - [2023-01-06 21:57:25,416] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:57:26,183] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:57:26,184] {logging_mixin.py:115} INFO - [2023-01-06 21:57:26,184] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:57:26,185] {logging_mixin.py:115} INFO - [2023-01-06 21:57:26,184] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:57:26,191] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:57:26,213] {logging_mixin.py:115} INFO - [2023-01-06 21:57:26,213] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:57:26,233] {logging_mixin.py:115} INFO - [2023-01-06 21:57:26,233] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:57:26,242] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.832 seconds
[2023-01-06 21:57:56,336] {processor.py:153} INFO - Started process (PID=1287) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:57:56,336] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:57:56,337] {logging_mixin.py:115} INFO - [2023-01-06 21:57:56,337] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:57:57,163] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:57:57,165] {logging_mixin.py:115} INFO - [2023-01-06 21:57:57,165] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:57:57,166] {logging_mixin.py:115} INFO - [2023-01-06 21:57:57,165] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:57:57,177] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:57:57,201] {logging_mixin.py:115} INFO - [2023-01-06 21:57:57,201] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:57:57,221] {logging_mixin.py:115} INFO - [2023-01-06 21:57:57,221] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:57:57,231] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.900 seconds
[2023-01-06 21:58:27,506] {processor.py:153} INFO - Started process (PID=1312) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:58:27,507] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:58:27,508] {logging_mixin.py:115} INFO - [2023-01-06 21:58:27,508] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:58:28,270] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:58:28,271] {logging_mixin.py:115} INFO - [2023-01-06 21:58:28,271] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:58:28,271] {logging_mixin.py:115} INFO - [2023-01-06 21:58:28,271] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:58:28,278] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:58:28,300] {logging_mixin.py:115} INFO - [2023-01-06 21:58:28,299] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:58:28,319] {logging_mixin.py:115} INFO - [2023-01-06 21:58:28,319] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:58:28,329] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.827 seconds
[2023-01-06 21:58:58,418] {processor.py:153} INFO - Started process (PID=1330) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:58:58,420] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:58:58,421] {logging_mixin.py:115} INFO - [2023-01-06 21:58:58,421] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:58:59,304] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:58:59,306] {logging_mixin.py:115} INFO - [2023-01-06 21:58:59,306] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:58:59,307] {logging_mixin.py:115} INFO - [2023-01-06 21:58:59,306] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:58:59,317] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:58:59,346] {logging_mixin.py:115} INFO - [2023-01-06 21:58:59,345] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:58:59,373] {logging_mixin.py:115} INFO - [2023-01-06 21:58:59,372] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:58:59,384] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.971 seconds
[2023-01-06 21:59:29,543] {processor.py:153} INFO - Started process (PID=1354) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:59:29,544] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 21:59:29,545] {logging_mixin.py:115} INFO - [2023-01-06 21:59:29,545] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:59:30,352] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 21:59:30,354] {logging_mixin.py:115} INFO - [2023-01-06 21:59:30,353] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 21:59:30,354] {logging_mixin.py:115} INFO - [2023-01-06 21:59:30,354] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 21:59:30,361] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 21:59:30,383] {logging_mixin.py:115} INFO - [2023-01-06 21:59:30,383] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 21:59:30,408] {logging_mixin.py:115} INFO - [2023-01-06 21:59:30,408] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 21:59:30,418] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.879 seconds
[2023-01-06 22:00:00,815] {processor.py:153} INFO - Started process (PID=1380) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:00:00,817] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:00:00,817] {logging_mixin.py:115} INFO - [2023-01-06 22:00:00,817] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:00:01,592] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:00:01,593] {logging_mixin.py:115} INFO - [2023-01-06 22:00:01,593] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:00:01,593] {logging_mixin.py:115} INFO - [2023-01-06 22:00:01,593] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:00:01,601] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:00:01,622] {logging_mixin.py:115} INFO - [2023-01-06 22:00:01,622] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:00:01,642] {logging_mixin.py:115} INFO - [2023-01-06 22:00:01,642] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:00:01,651] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-06 22:00:31,769] {processor.py:153} INFO - Started process (PID=1407) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:00:31,772] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:00:31,772] {logging_mixin.py:115} INFO - [2023-01-06 22:00:31,772] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:00:32,551] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:00:32,553] {logging_mixin.py:115} INFO - [2023-01-06 22:00:32,552] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:00:32,553] {logging_mixin.py:115} INFO - [2023-01-06 22:00:32,553] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:00:32,560] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:00:32,581] {logging_mixin.py:115} INFO - [2023-01-06 22:00:32,580] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:00:32,600] {logging_mixin.py:115} INFO - [2023-01-06 22:00:32,600] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:00:32,609] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.845 seconds
[2023-01-06 22:01:02,705] {processor.py:153} INFO - Started process (PID=1424) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:01:02,706] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:01:02,707] {logging_mixin.py:115} INFO - [2023-01-06 22:01:02,706] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:01:03,518] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:01:03,519] {logging_mixin.py:115} INFO - [2023-01-06 22:01:03,519] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:01:03,520] {logging_mixin.py:115} INFO - [2023-01-06 22:01:03,519] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:01:03,526] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:01:03,547] {logging_mixin.py:115} INFO - [2023-01-06 22:01:03,547] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:01:03,572] {logging_mixin.py:115} INFO - [2023-01-06 22:01:03,571] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:01:03,586] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.886 seconds
[2023-01-06 22:01:33,908] {processor.py:153} INFO - Started process (PID=1448) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:01:33,910] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:01:33,910] {logging_mixin.py:115} INFO - [2023-01-06 22:01:33,910] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:01:34,694] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:01:34,696] {logging_mixin.py:115} INFO - [2023-01-06 22:01:34,696] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:01:34,696] {logging_mixin.py:115} INFO - [2023-01-06 22:01:34,696] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:01:34,703] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:01:34,725] {logging_mixin.py:115} INFO - [2023-01-06 22:01:34,725] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:01:34,744] {logging_mixin.py:115} INFO - [2023-01-06 22:01:34,744] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:01:34,754] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.851 seconds
[2023-01-06 22:02:04,848] {processor.py:153} INFO - Started process (PID=1474) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:02:04,848] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:02:04,849] {logging_mixin.py:115} INFO - [2023-01-06 22:02:04,849] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:02:05,610] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:02:05,611] {logging_mixin.py:115} INFO - [2023-01-06 22:02:05,611] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:02:05,611] {logging_mixin.py:115} INFO - [2023-01-06 22:02:05,611] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:02:05,618] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:02:05,640] {logging_mixin.py:115} INFO - [2023-01-06 22:02:05,639] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:02:05,659] {logging_mixin.py:115} INFO - [2023-01-06 22:02:05,659] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:02:05,669] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.826 seconds
[2023-01-06 22:02:35,759] {processor.py:153} INFO - Started process (PID=1499) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:02:35,761] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:02:35,762] {logging_mixin.py:115} INFO - [2023-01-06 22:02:35,761] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:02:36,564] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:02:36,565] {logging_mixin.py:115} INFO - [2023-01-06 22:02:36,565] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:02:36,566] {logging_mixin.py:115} INFO - [2023-01-06 22:02:36,565] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:02:36,572] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:02:36,594] {logging_mixin.py:115} INFO - [2023-01-06 22:02:36,594] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:02:36,614] {logging_mixin.py:115} INFO - [2023-01-06 22:02:36,613] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:02:36,623] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.868 seconds
[2023-01-06 22:03:06,713] {processor.py:153} INFO - Started process (PID=1525) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:03:06,714] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:03:06,715] {logging_mixin.py:115} INFO - [2023-01-06 22:03:06,715] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:03:07,504] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:03:07,505] {logging_mixin.py:115} INFO - [2023-01-06 22:03:07,505] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:03:07,505] {logging_mixin.py:115} INFO - [2023-01-06 22:03:07,505] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:03:07,512] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:03:07,533] {logging_mixin.py:115} INFO - [2023-01-06 22:03:07,533] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:03:07,553] {logging_mixin.py:115} INFO - [2023-01-06 22:03:07,553] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:03:07,562] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.854 seconds
[2023-01-06 22:03:37,655] {processor.py:153} INFO - Started process (PID=1543) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:03:37,655] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:03:37,656] {logging_mixin.py:115} INFO - [2023-01-06 22:03:37,656] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:03:38,422] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:03:38,423] {logging_mixin.py:115} INFO - [2023-01-06 22:03:38,423] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:03:38,424] {logging_mixin.py:115} INFO - [2023-01-06 22:03:38,423] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:03:38,430] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:03:38,453] {logging_mixin.py:115} INFO - [2023-01-06 22:03:38,453] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:03:38,476] {logging_mixin.py:115} INFO - [2023-01-06 22:03:38,476] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:03:38,485] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.835 seconds
[2023-01-06 22:04:08,571] {processor.py:153} INFO - Started process (PID=1567) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:04:08,572] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:04:08,573] {logging_mixin.py:115} INFO - [2023-01-06 22:04:08,573] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:04:09,365] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:04:09,366] {logging_mixin.py:115} INFO - [2023-01-06 22:04:09,366] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:04:09,367] {logging_mixin.py:115} INFO - [2023-01-06 22:04:09,366] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:04:09,373] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:04:09,394] {logging_mixin.py:115} INFO - [2023-01-06 22:04:09,394] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:04:09,414] {logging_mixin.py:115} INFO - [2023-01-06 22:04:09,414] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:04:09,423] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.856 seconds
[2023-01-06 22:04:40,032] {processor.py:153} INFO - Started process (PID=1593) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:04:40,033] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:04:40,034] {logging_mixin.py:115} INFO - [2023-01-06 22:04:40,033] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:04:40,810] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:04:40,811] {logging_mixin.py:115} INFO - [2023-01-06 22:04:40,811] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:04:40,812] {logging_mixin.py:115} INFO - [2023-01-06 22:04:40,811] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:04:40,818] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:04:40,839] {logging_mixin.py:115} INFO - [2023-01-06 22:04:40,839] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:04:40,859] {logging_mixin.py:115} INFO - [2023-01-06 22:04:40,858] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:04:40,868] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.840 seconds
[2023-01-06 22:05:10,959] {processor.py:153} INFO - Started process (PID=1618) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:05:10,961] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:05:10,961] {logging_mixin.py:115} INFO - [2023-01-06 22:05:10,961] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:05:11,750] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:05:11,751] {logging_mixin.py:115} INFO - [2023-01-06 22:05:11,751] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:05:11,752] {logging_mixin.py:115} INFO - [2023-01-06 22:05:11,752] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:05:11,758] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:05:11,779] {logging_mixin.py:115} INFO - [2023-01-06 22:05:11,779] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:05:11,799] {logging_mixin.py:115} INFO - [2023-01-06 22:05:11,798] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:05:11,808] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.853 seconds
[2023-01-06 22:05:41,912] {processor.py:153} INFO - Started process (PID=1636) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:05:41,913] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:05:41,914] {logging_mixin.py:115} INFO - [2023-01-06 22:05:41,913] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:05:42,839] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:05:42,841] {logging_mixin.py:115} INFO - [2023-01-06 22:05:42,841] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:05:42,842] {logging_mixin.py:115} INFO - [2023-01-06 22:05:42,842] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:05:42,853] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:05:42,884] {logging_mixin.py:115} INFO - [2023-01-06 22:05:42,884] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:05:42,911] {logging_mixin.py:115} INFO - [2023-01-06 22:05:42,911] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:05:42,923] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.015 seconds
[2023-01-06 22:06:12,970] {processor.py:153} INFO - Started process (PID=1661) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:06:12,972] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:06:12,972] {logging_mixin.py:115} INFO - [2023-01-06 22:06:12,972] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:06:13,765] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:06:13,767] {logging_mixin.py:115} INFO - [2023-01-06 22:06:13,766] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:06:13,767] {logging_mixin.py:115} INFO - [2023-01-06 22:06:13,767] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:06:13,774] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:06:13,795] {logging_mixin.py:115} INFO - [2023-01-06 22:06:13,795] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:06:13,814] {logging_mixin.py:115} INFO - [2023-01-06 22:06:13,814] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:06:13,823] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.857 seconds
[2023-01-06 22:06:43,919] {processor.py:153} INFO - Started process (PID=1687) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:06:43,920] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:06:43,921] {logging_mixin.py:115} INFO - [2023-01-06 22:06:43,921] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:06:44,691] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:06:44,692] {logging_mixin.py:115} INFO - [2023-01-06 22:06:44,692] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:06:44,693] {logging_mixin.py:115} INFO - [2023-01-06 22:06:44,692] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:06:44,699] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:06:44,720] {logging_mixin.py:115} INFO - [2023-01-06 22:06:44,720] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:06:44,739] {logging_mixin.py:115} INFO - [2023-01-06 22:06:44,739] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:06:44,748] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.833 seconds
[2023-01-06 22:07:14,838] {processor.py:153} INFO - Started process (PID=1712) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:07:14,838] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:07:14,839] {logging_mixin.py:115} INFO - [2023-01-06 22:07:14,839] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:07:15,610] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:07:15,612] {logging_mixin.py:115} INFO - [2023-01-06 22:07:15,611] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:07:15,612] {logging_mixin.py:115} INFO - [2023-01-06 22:07:15,612] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:07:15,619] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:07:15,640] {logging_mixin.py:115} INFO - [2023-01-06 22:07:15,640] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:07:15,660] {logging_mixin.py:115} INFO - [2023-01-06 22:07:15,660] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:07:15,670] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.837 seconds
[2023-01-06 22:07:45,761] {processor.py:153} INFO - Started process (PID=1730) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:07:45,763] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:07:45,763] {logging_mixin.py:115} INFO - [2023-01-06 22:07:45,763] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:07:46,551] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:07:46,552] {logging_mixin.py:115} INFO - [2023-01-06 22:07:46,552] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:07:46,553] {logging_mixin.py:115} INFO - [2023-01-06 22:07:46,552] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:07:46,559] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:07:46,582] {logging_mixin.py:115} INFO - [2023-01-06 22:07:46,581] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:07:46,603] {logging_mixin.py:115} INFO - [2023-01-06 22:07:46,603] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:07:46,612] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.855 seconds
[2023-01-06 22:08:16,705] {processor.py:153} INFO - Started process (PID=1756) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:08:16,706] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:08:16,707] {logging_mixin.py:115} INFO - [2023-01-06 22:08:16,707] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:08:17,461] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:08:17,463] {logging_mixin.py:115} INFO - [2023-01-06 22:08:17,462] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:08:17,463] {logging_mixin.py:115} INFO - [2023-01-06 22:08:17,463] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:08:17,470] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:08:17,491] {logging_mixin.py:115} INFO - [2023-01-06 22:08:17,491] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:08:17,511] {logging_mixin.py:115} INFO - [2023-01-06 22:08:17,510] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:08:17,520] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.819 seconds
[2023-01-06 22:08:47,608] {processor.py:153} INFO - Started process (PID=1781) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:08:47,610] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:08:47,610] {logging_mixin.py:115} INFO - [2023-01-06 22:08:47,610] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:08:48,417] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:08:48,418] {logging_mixin.py:115} INFO - [2023-01-06 22:08:48,418] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:08:48,419] {logging_mixin.py:115} INFO - [2023-01-06 22:08:48,419] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:08:48,426] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:08:48,447] {logging_mixin.py:115} INFO - [2023-01-06 22:08:48,447] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:08:48,467] {logging_mixin.py:115} INFO - [2023-01-06 22:08:48,467] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:08:48,476] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.873 seconds
[2023-01-06 22:09:18,563] {processor.py:153} INFO - Started process (PID=1807) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:09:18,565] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:09:18,565] {logging_mixin.py:115} INFO - [2023-01-06 22:09:18,565] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:09:19,324] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:09:19,325] {logging_mixin.py:115} INFO - [2023-01-06 22:09:19,325] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:09:19,326] {logging_mixin.py:115} INFO - [2023-01-06 22:09:19,326] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:09:19,333] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:09:19,354] {logging_mixin.py:115} INFO - [2023-01-06 22:09:19,354] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:09:19,374] {logging_mixin.py:115} INFO - [2023-01-06 22:09:19,373] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:09:19,383] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.824 seconds
[2023-01-06 22:09:49,450] {processor.py:153} INFO - Started process (PID=1825) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:09:49,450] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:09:49,451] {logging_mixin.py:115} INFO - [2023-01-06 22:09:49,451] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:09:50,247] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:09:50,249] {logging_mixin.py:115} INFO - [2023-01-06 22:09:50,249] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:09:50,249] {logging_mixin.py:115} INFO - [2023-01-06 22:09:50,249] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:09:50,256] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:09:50,277] {logging_mixin.py:115} INFO - [2023-01-06 22:09:50,277] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:09:50,302] {logging_mixin.py:115} INFO - [2023-01-06 22:09:50,302] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:09:50,313] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.868 seconds
[2023-01-06 22:10:20,383] {processor.py:153} INFO - Started process (PID=1851) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:10:20,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:10:20,384] {logging_mixin.py:115} INFO - [2023-01-06 22:10:20,384] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:10:21,214] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:10:21,215] {logging_mixin.py:115} INFO - [2023-01-06 22:10:21,215] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:10:21,216] {logging_mixin.py:115} INFO - [2023-01-06 22:10:21,216] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:10:21,223] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:10:21,245] {logging_mixin.py:115} INFO - [2023-01-06 22:10:21,244] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:10:21,265] {logging_mixin.py:115} INFO - [2023-01-06 22:10:21,264] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:10:21,274] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.896 seconds
[2023-01-06 22:10:51,991] {processor.py:153} INFO - Started process (PID=1876) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:10:51,992] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:10:51,992] {logging_mixin.py:115} INFO - [2023-01-06 22:10:51,992] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:10:52,770] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:10:52,771] {logging_mixin.py:115} INFO - [2023-01-06 22:10:52,771] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:10:52,772] {logging_mixin.py:115} INFO - [2023-01-06 22:10:52,772] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:10:52,779] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:10:52,800] {logging_mixin.py:115} INFO - [2023-01-06 22:10:52,800] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:10:52,820] {logging_mixin.py:115} INFO - [2023-01-06 22:10:52,820] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:10:52,830] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.844 seconds
[2023-01-06 22:11:22,920] {processor.py:153} INFO - Started process (PID=1901) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:11:22,922] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:11:22,923] {logging_mixin.py:115} INFO - [2023-01-06 22:11:22,922] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:11:23,702] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:11:23,703] {logging_mixin.py:115} INFO - [2023-01-06 22:11:23,703] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:11:23,704] {logging_mixin.py:115} INFO - [2023-01-06 22:11:23,703] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:11:23,711] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:11:23,733] {logging_mixin.py:115} INFO - [2023-01-06 22:11:23,732] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:11:23,753] {logging_mixin.py:115} INFO - [2023-01-06 22:11:23,753] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:11:23,763] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.848 seconds
[2023-01-06 22:11:53,855] {processor.py:153} INFO - Started process (PID=1919) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:11:53,856] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:11:53,856] {logging_mixin.py:115} INFO - [2023-01-06 22:11:53,856] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:11:54,761] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:11:54,763] {logging_mixin.py:115} INFO - [2023-01-06 22:11:54,763] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:11:54,764] {logging_mixin.py:115} INFO - [2023-01-06 22:11:54,763] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:11:54,775] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:11:54,805] {logging_mixin.py:115} INFO - [2023-01-06 22:11:54,804] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:11:54,834] {logging_mixin.py:115} INFO - [2023-01-06 22:11:54,834] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:11:54,847] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.996 seconds
[2023-01-06 22:12:24,894] {processor.py:153} INFO - Started process (PID=1943) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:12:24,895] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:12:24,895] {logging_mixin.py:115} INFO - [2023-01-06 22:12:24,895] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:12:25,653] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:12:25,654] {logging_mixin.py:115} INFO - [2023-01-06 22:12:25,654] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:12:25,654] {logging_mixin.py:115} INFO - [2023-01-06 22:12:25,654] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:12:25,661] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:12:25,682] {logging_mixin.py:115} INFO - [2023-01-06 22:12:25,682] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:12:25,703] {logging_mixin.py:115} INFO - [2023-01-06 22:12:25,703] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:12:25,712] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.823 seconds
[2023-01-06 22:12:55,808] {processor.py:153} INFO - Started process (PID=1968) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:12:55,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:12:55,811] {logging_mixin.py:115} INFO - [2023-01-06 22:12:55,811] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:12:56,570] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:12:56,571] {logging_mixin.py:115} INFO - [2023-01-06 22:12:56,571] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:12:56,572] {logging_mixin.py:115} INFO - [2023-01-06 22:12:56,572] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:12:56,579] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:12:56,599] {logging_mixin.py:115} INFO - [2023-01-06 22:12:56,599] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:12:56,619] {logging_mixin.py:115} INFO - [2023-01-06 22:12:56,619] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:12:56,628] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.825 seconds
[2023-01-06 22:13:26,720] {processor.py:153} INFO - Started process (PID=1996) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:13:26,721] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:13:26,722] {logging_mixin.py:115} INFO - [2023-01-06 22:13:26,722] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:13:27,494] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:13:27,495] {logging_mixin.py:115} INFO - [2023-01-06 22:13:27,495] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:13:27,495] {logging_mixin.py:115} INFO - [2023-01-06 22:13:27,495] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:13:27,502] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:13:27,523] {logging_mixin.py:115} INFO - [2023-01-06 22:13:27,523] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:13:27,543] {logging_mixin.py:115} INFO - [2023-01-06 22:13:27,543] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:13:27,552] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.836 seconds
[2023-01-06 22:13:57,643] {processor.py:153} INFO - Started process (PID=2021) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:13:57,645] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:13:57,645] {logging_mixin.py:115} INFO - [2023-01-06 22:13:57,645] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:13:58,412] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:13:58,413] {logging_mixin.py:115} INFO - [2023-01-06 22:13:58,413] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:13:58,414] {logging_mixin.py:115} INFO - [2023-01-06 22:13:58,414] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:13:58,420] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:13:58,441] {logging_mixin.py:115} INFO - [2023-01-06 22:13:58,441] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:13:58,461] {logging_mixin.py:115} INFO - [2023-01-06 22:13:58,460] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:13:58,470] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.831 seconds
[2023-01-06 22:14:28,559] {processor.py:153} INFO - Started process (PID=2038) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:14:28,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:14:28,561] {logging_mixin.py:115} INFO - [2023-01-06 22:14:28,560] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:14:29,330] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:14:29,331] {logging_mixin.py:115} INFO - [2023-01-06 22:14:29,331] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:14:29,332] {logging_mixin.py:115} INFO - [2023-01-06 22:14:29,332] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:14:29,341] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:14:29,367] {logging_mixin.py:115} INFO - [2023-01-06 22:14:29,367] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:14:29,393] {logging_mixin.py:115} INFO - [2023-01-06 22:14:29,393] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:14:29,404] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.850 seconds
[2023-01-06 22:14:59,486] {processor.py:153} INFO - Started process (PID=2063) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:14:59,487] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:14:59,488] {logging_mixin.py:115} INFO - [2023-01-06 22:14:59,488] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:15:00,340] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:15:00,342] {logging_mixin.py:115} INFO - [2023-01-06 22:15:00,342] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:15:00,342] {logging_mixin.py:115} INFO - [2023-01-06 22:15:00,342] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:15:00,349] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:15:00,370] {logging_mixin.py:115} INFO - [2023-01-06 22:15:00,370] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:15:00,390] {logging_mixin.py:115} INFO - [2023-01-06 22:15:00,390] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:15:00,399] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.918 seconds
[2023-01-06 22:15:30,490] {processor.py:153} INFO - Started process (PID=2089) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:15:30,492] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:15:30,493] {logging_mixin.py:115} INFO - [2023-01-06 22:15:30,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:15:31,280] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:15:31,282] {logging_mixin.py:115} INFO - [2023-01-06 22:15:31,282] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:15:31,282] {logging_mixin.py:115} INFO - [2023-01-06 22:15:31,282] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:15:31,289] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:15:31,309] {logging_mixin.py:115} INFO - [2023-01-06 22:15:31,309] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:15:31,329] {logging_mixin.py:115} INFO - [2023-01-06 22:15:31,329] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:15:31,338] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.853 seconds
[2023-01-06 22:16:01,411] {processor.py:153} INFO - Started process (PID=2114) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:16:01,413] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:16:01,413] {logging_mixin.py:115} INFO - [2023-01-06 22:16:01,413] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:16:02,237] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:16:02,238] {logging_mixin.py:115} INFO - [2023-01-06 22:16:02,238] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:16:02,238] {logging_mixin.py:115} INFO - [2023-01-06 22:16:02,238] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:16:02,245] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:16:02,267] {logging_mixin.py:115} INFO - [2023-01-06 22:16:02,267] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:16:02,290] {logging_mixin.py:115} INFO - [2023-01-06 22:16:02,290] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:16:02,299] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.894 seconds
[2023-01-06 22:16:32,363] {processor.py:153} INFO - Started process (PID=2132) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:16:32,363] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:16:32,364] {logging_mixin.py:115} INFO - [2023-01-06 22:16:32,364] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:16:33,159] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:16:33,160] {logging_mixin.py:115} INFO - [2023-01-06 22:16:33,160] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:16:33,161] {logging_mixin.py:115} INFO - [2023-01-06 22:16:33,161] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:16:33,168] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:16:33,189] {logging_mixin.py:115} INFO - [2023-01-06 22:16:33,189] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:16:33,208] {logging_mixin.py:115} INFO - [2023-01-06 22:16:33,208] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:16:33,218] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.859 seconds
[2023-01-06 22:17:03,293] {processor.py:153} INFO - Started process (PID=2157) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:17:03,295] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:17:03,295] {logging_mixin.py:115} INFO - [2023-01-06 22:17:03,295] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:17:04,056] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:17:04,057] {logging_mixin.py:115} INFO - [2023-01-06 22:17:04,057] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:17:04,058] {logging_mixin.py:115} INFO - [2023-01-06 22:17:04,058] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:17:04,064] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:17:04,086] {logging_mixin.py:115} INFO - [2023-01-06 22:17:04,085] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:17:04,105] {logging_mixin.py:115} INFO - [2023-01-06 22:17:04,105] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:17:04,114] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.825 seconds
[2023-01-06 22:17:35,030] {processor.py:153} INFO - Started process (PID=2182) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:17:35,030] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:17:35,031] {logging_mixin.py:115} INFO - [2023-01-06 22:17:35,031] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:17:35,788] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:17:35,789] {logging_mixin.py:115} INFO - [2023-01-06 22:17:35,789] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:17:35,790] {logging_mixin.py:115} INFO - [2023-01-06 22:17:35,789] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:17:35,796] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:17:35,818] {logging_mixin.py:115} INFO - [2023-01-06 22:17:35,818] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:17:35,837] {logging_mixin.py:115} INFO - [2023-01-06 22:17:35,837] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:17:35,847] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.822 seconds
[2023-01-06 22:18:05,942] {processor.py:153} INFO - Started process (PID=2205) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:18:05,943] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:18:05,944] {logging_mixin.py:115} INFO - [2023-01-06 22:18:05,944] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:18:06,715] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:18:06,716] {logging_mixin.py:115} INFO - [2023-01-06 22:18:06,716] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:18:06,716] {logging_mixin.py:115} INFO - [2023-01-06 22:18:06,716] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:18:06,723] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:18:06,745] {logging_mixin.py:115} INFO - [2023-01-06 22:18:06,744] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:18:06,764] {logging_mixin.py:115} INFO - [2023-01-06 22:18:06,764] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:18:06,773] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.837 seconds
[2023-01-06 22:18:36,868] {processor.py:153} INFO - Started process (PID=2223) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:18:36,870] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:18:36,870] {logging_mixin.py:115} INFO - [2023-01-06 22:18:36,870] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:18:37,671] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:18:37,673] {logging_mixin.py:115} INFO - [2023-01-06 22:18:37,673] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:18:37,673] {logging_mixin.py:115} INFO - [2023-01-06 22:18:37,673] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:18:37,680] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:18:37,706] {logging_mixin.py:115} INFO - [2023-01-06 22:18:37,706] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:18:37,730] {logging_mixin.py:115} INFO - [2023-01-06 22:18:37,730] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:18:37,742] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.880 seconds
[2023-01-06 22:19:07,834] {processor.py:153} INFO - Started process (PID=2247) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:19:07,835] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:19:07,836] {logging_mixin.py:115} INFO - [2023-01-06 22:19:07,836] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:19:08,619] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:19:08,620] {logging_mixin.py:115} INFO - [2023-01-06 22:19:08,620] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:19:08,621] {logging_mixin.py:115} INFO - [2023-01-06 22:19:08,621] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:19:08,627] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:19:08,648] {logging_mixin.py:115} INFO - [2023-01-06 22:19:08,648] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:19:08,668] {logging_mixin.py:115} INFO - [2023-01-06 22:19:08,668] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:19:08,677] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.847 seconds
[2023-01-06 22:19:38,768] {processor.py:153} INFO - Started process (PID=2271) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:19:38,768] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:19:38,769] {logging_mixin.py:115} INFO - [2023-01-06 22:19:38,769] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:19:39,523] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:19:39,524] {logging_mixin.py:115} INFO - [2023-01-06 22:19:39,524] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:19:39,525] {logging_mixin.py:115} INFO - [2023-01-06 22:19:39,524] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:19:39,531] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:19:39,552] {logging_mixin.py:115} INFO - [2023-01-06 22:19:39,552] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:19:39,572] {logging_mixin.py:115} INFO - [2023-01-06 22:19:39,572] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:19:39,583] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.819 seconds
[2023-01-06 22:20:09,671] {processor.py:153} INFO - Started process (PID=2297) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:20:09,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:20:09,673] {logging_mixin.py:115} INFO - [2023-01-06 22:20:09,673] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:20:10,431] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:20:10,433] {logging_mixin.py:115} INFO - [2023-01-06 22:20:10,432] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:20:10,433] {logging_mixin.py:115} INFO - [2023-01-06 22:20:10,433] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:20:10,440] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:20:10,461] {logging_mixin.py:115} INFO - [2023-01-06 22:20:10,461] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:20:10,481] {logging_mixin.py:115} INFO - [2023-01-06 22:20:10,481] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:20:10,490] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.824 seconds
[2023-01-06 22:20:40,589] {processor.py:153} INFO - Started process (PID=2314) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:20:40,589] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:20:40,590] {logging_mixin.py:115} INFO - [2023-01-06 22:20:40,590] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:20:41,359] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:20:41,361] {logging_mixin.py:115} INFO - [2023-01-06 22:20:41,361] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:20:41,361] {logging_mixin.py:115} INFO - [2023-01-06 22:20:41,361] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:20:41,368] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:20:41,389] {logging_mixin.py:115} INFO - [2023-01-06 22:20:41,389] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:20:41,409] {logging_mixin.py:115} INFO - [2023-01-06 22:20:41,409] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:20:41,418] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.834 seconds
[2023-01-06 22:21:11,484] {processor.py:153} INFO - Started process (PID=2339) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:21:11,486] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:21:11,486] {logging_mixin.py:115} INFO - [2023-01-06 22:21:11,486] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:21:12,238] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:21:12,239] {logging_mixin.py:115} INFO - [2023-01-06 22:21:12,239] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:21:12,240] {logging_mixin.py:115} INFO - [2023-01-06 22:21:12,240] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:21:12,246] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:21:12,270] {logging_mixin.py:115} INFO - [2023-01-06 22:21:12,270] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:21:12,290] {logging_mixin.py:115} INFO - [2023-01-06 22:21:12,290] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:21:12,300] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.820 seconds
[2023-01-06 22:21:42,368] {processor.py:153} INFO - Started process (PID=2363) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:21:42,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:21:42,370] {logging_mixin.py:115} INFO - [2023-01-06 22:21:42,370] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:21:43,121] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:21:43,122] {logging_mixin.py:115} INFO - [2023-01-06 22:21:43,122] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:21:43,122] {logging_mixin.py:115} INFO - [2023-01-06 22:21:43,122] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:21:43,129] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:21:43,151] {logging_mixin.py:115} INFO - [2023-01-06 22:21:43,150] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:21:43,170] {logging_mixin.py:115} INFO - [2023-01-06 22:21:43,170] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:21:43,179] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.815 seconds
[2023-01-06 22:22:13,244] {processor.py:153} INFO - Started process (PID=2388) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:22:13,245] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:22:13,245] {logging_mixin.py:115} INFO - [2023-01-06 22:22:13,245] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:22:13,999] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:22:14,000] {logging_mixin.py:115} INFO - [2023-01-06 22:22:14,000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:22:14,001] {logging_mixin.py:115} INFO - [2023-01-06 22:22:14,000] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:22:14,007] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:22:14,028] {logging_mixin.py:115} INFO - [2023-01-06 22:22:14,028] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:22:14,048] {logging_mixin.py:115} INFO - [2023-01-06 22:22:14,047] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:22:14,057] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.817 seconds
[2023-01-06 22:22:44,091] {processor.py:153} INFO - Started process (PID=2407) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:22:44,092] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:22:44,093] {logging_mixin.py:115} INFO - [2023-01-06 22:22:44,093] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:22:44,956] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:22:44,957] {logging_mixin.py:115} INFO - [2023-01-06 22:22:44,957] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:22:44,958] {logging_mixin.py:115} INFO - [2023-01-06 22:22:44,957] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:22:44,964] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:22:44,985] {logging_mixin.py:115} INFO - [2023-01-06 22:22:44,985] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:22:45,005] {logging_mixin.py:115} INFO - [2023-01-06 22:22:45,005] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:22:45,014] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.927 seconds
[2023-01-06 22:23:15,043] {processor.py:153} INFO - Started process (PID=2433) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:23:15,044] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:23:15,045] {logging_mixin.py:115} INFO - [2023-01-06 22:23:15,044] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:23:15,808] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:23:15,810] {logging_mixin.py:115} INFO - [2023-01-06 22:23:15,810] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:23:15,810] {logging_mixin.py:115} INFO - [2023-01-06 22:23:15,810] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:23:15,817] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:23:15,838] {logging_mixin.py:115} INFO - [2023-01-06 22:23:15,837] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:23:15,857] {logging_mixin.py:115} INFO - [2023-01-06 22:23:15,857] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:23:15,866] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.827 seconds
[2023-01-06 22:23:45,960] {processor.py:153} INFO - Started process (PID=2457) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:23:45,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:23:45,963] {logging_mixin.py:115} INFO - [2023-01-06 22:23:45,963] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:23:46,738] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:23:46,739] {logging_mixin.py:115} INFO - [2023-01-06 22:23:46,739] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:23:46,739] {logging_mixin.py:115} INFO - [2023-01-06 22:23:46,739] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:23:46,746] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:23:46,767] {logging_mixin.py:115} INFO - [2023-01-06 22:23:46,767] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:23:46,786] {logging_mixin.py:115} INFO - [2023-01-06 22:23:46,786] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:23:46,795] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.839 seconds
[2023-01-06 22:24:16,885] {processor.py:153} INFO - Started process (PID=2482) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:24:16,886] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:24:16,887] {logging_mixin.py:115} INFO - [2023-01-06 22:24:16,887] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:24:17,656] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:24:17,658] {logging_mixin.py:115} INFO - [2023-01-06 22:24:17,658] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:24:17,658] {logging_mixin.py:115} INFO - [2023-01-06 22:24:17,658] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:24:17,665] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:24:17,690] {logging_mixin.py:115} INFO - [2023-01-06 22:24:17,689] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:24:17,713] {logging_mixin.py:115} INFO - [2023-01-06 22:24:17,713] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:24:17,723] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.843 seconds
[2023-01-06 22:24:47,824] {processor.py:153} INFO - Started process (PID=2500) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:24:47,825] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:24:47,825] {logging_mixin.py:115} INFO - [2023-01-06 22:24:47,825] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:24:48,627] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:24:48,628] {logging_mixin.py:115} INFO - [2023-01-06 22:24:48,628] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:24:48,629] {logging_mixin.py:115} INFO - [2023-01-06 22:24:48,629] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:24:48,635] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:24:48,656] {logging_mixin.py:115} INFO - [2023-01-06 22:24:48,656] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:24:48,676] {logging_mixin.py:115} INFO - [2023-01-06 22:24:48,676] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:24:48,685] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.866 seconds
[2023-01-06 22:25:18,765] {processor.py:153} INFO - Started process (PID=2527) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:25:18,765] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:25:18,766] {logging_mixin.py:115} INFO - [2023-01-06 22:25:18,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:25:19,525] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:25:19,526] {logging_mixin.py:115} INFO - [2023-01-06 22:25:19,526] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:25:19,526] {logging_mixin.py:115} INFO - [2023-01-06 22:25:19,526] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:25:19,533] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:25:19,554] {logging_mixin.py:115} INFO - [2023-01-06 22:25:19,553] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:25:19,573] {logging_mixin.py:115} INFO - [2023-01-06 22:25:19,573] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:25:19,583] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.823 seconds
[2023-01-06 22:25:49,660] {processor.py:153} INFO - Started process (PID=2551) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:25:49,661] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:25:49,662] {logging_mixin.py:115} INFO - [2023-01-06 22:25:49,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:25:50,446] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:25:50,447] {logging_mixin.py:115} INFO - [2023-01-06 22:25:50,447] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:25:50,448] {logging_mixin.py:115} INFO - [2023-01-06 22:25:50,447] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:25:50,454] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:25:50,480] {logging_mixin.py:115} INFO - [2023-01-06 22:25:50,479] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:25:50,499] {logging_mixin.py:115} INFO - [2023-01-06 22:25:50,499] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:25:50,508] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.853 seconds
[2023-01-06 22:26:21,312] {processor.py:153} INFO - Started process (PID=2576) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:26:21,312] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:26:21,313] {logging_mixin.py:115} INFO - [2023-01-06 22:26:21,313] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:26:22,063] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:26:22,064] {logging_mixin.py:115} INFO - [2023-01-06 22:26:22,064] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:26:22,065] {logging_mixin.py:115} INFO - [2023-01-06 22:26:22,064] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:26:22,071] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:26:22,093] {logging_mixin.py:115} INFO - [2023-01-06 22:26:22,092] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:26:22,114] {logging_mixin.py:115} INFO - [2023-01-06 22:26:22,114] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:26:22,123] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.816 seconds
[2023-01-06 22:26:52,213] {processor.py:153} INFO - Started process (PID=2593) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:26:52,215] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:26:52,215] {logging_mixin.py:115} INFO - [2023-01-06 22:26:52,215] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:26:52,988] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:26:52,989] {logging_mixin.py:115} INFO - [2023-01-06 22:26:52,989] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:26:52,990] {logging_mixin.py:115} INFO - [2023-01-06 22:26:52,989] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:26:52,996] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:26:53,018] {logging_mixin.py:115} INFO - [2023-01-06 22:26:53,018] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:26:53,039] {logging_mixin.py:115} INFO - [2023-01-06 22:26:53,039] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:26:53,050] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.842 seconds
[2023-01-06 22:27:23,142] {processor.py:153} INFO - Started process (PID=2618) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:27:23,143] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:27:23,144] {logging_mixin.py:115} INFO - [2023-01-06 22:27:23,144] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:27:23,902] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:27:23,904] {logging_mixin.py:115} INFO - [2023-01-06 22:27:23,904] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:27:23,904] {logging_mixin.py:115} INFO - [2023-01-06 22:27:23,904] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:27:23,911] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:27:23,933] {logging_mixin.py:115} INFO - [2023-01-06 22:27:23,932] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:27:23,956] {logging_mixin.py:115} INFO - [2023-01-06 22:27:23,955] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:27:23,965] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.828 seconds
[2023-01-06 22:27:54,064] {processor.py:153} INFO - Started process (PID=2644) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:27:54,064] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:27:54,065] {logging_mixin.py:115} INFO - [2023-01-06 22:27:54,065] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:27:54,820] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:27:54,821] {logging_mixin.py:115} INFO - [2023-01-06 22:27:54,821] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:27:54,821] {logging_mixin.py:115} INFO - [2023-01-06 22:27:54,821] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:27:54,828] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:27:54,850] {logging_mixin.py:115} INFO - [2023-01-06 22:27:54,850] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:27:54,870] {logging_mixin.py:115} INFO - [2023-01-06 22:27:54,869] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:27:54,879] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.820 seconds
[2023-01-06 22:28:25,346] {processor.py:153} INFO - Started process (PID=2670) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:28:25,347] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:28:25,348] {logging_mixin.py:115} INFO - [2023-01-06 22:28:25,348] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:28:26,106] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:28:26,107] {logging_mixin.py:115} INFO - [2023-01-06 22:28:26,107] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:28:26,108] {logging_mixin.py:115} INFO - [2023-01-06 22:28:26,108] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:28:26,114] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:28:26,136] {logging_mixin.py:115} INFO - [2023-01-06 22:28:26,136] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:28:26,155] {logging_mixin.py:115} INFO - [2023-01-06 22:28:26,155] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:28:26,164] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.823 seconds
[2023-01-06 22:28:56,258] {processor.py:153} INFO - Started process (PID=2696) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:28:56,259] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:28:56,260] {logging_mixin.py:115} INFO - [2023-01-06 22:28:56,260] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:28:57,268] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:28:57,270] {logging_mixin.py:115} INFO - [2023-01-06 22:28:57,270] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:28:57,270] {logging_mixin.py:115} INFO - [2023-01-06 22:28:57,270] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:28:57,277] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:28:57,298] {logging_mixin.py:115} INFO - [2023-01-06 22:28:57,298] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:28:57,318] {logging_mixin.py:115} INFO - [2023-01-06 22:28:57,318] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:28:57,327] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.073 seconds
[2023-01-06 22:29:27,399] {processor.py:153} INFO - Started process (PID=2714) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:29:27,400] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:29:27,400] {logging_mixin.py:115} INFO - [2023-01-06 22:29:27,400] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:29:28,169] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:29:28,170] {logging_mixin.py:115} INFO - [2023-01-06 22:29:28,170] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:29:28,171] {logging_mixin.py:115} INFO - [2023-01-06 22:29:28,171] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:29:28,177] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:29:28,198] {logging_mixin.py:115} INFO - [2023-01-06 22:29:28,198] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:29:28,218] {logging_mixin.py:115} INFO - [2023-01-06 22:29:28,218] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:29:28,227] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.832 seconds
[2023-01-06 22:29:58,323] {processor.py:153} INFO - Started process (PID=2737) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:29:58,324] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:29:58,325] {logging_mixin.py:115} INFO - [2023-01-06 22:29:58,324] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:29:59,105] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:29:59,106] {logging_mixin.py:115} INFO - [2023-01-06 22:29:59,106] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:29:59,107] {logging_mixin.py:115} INFO - [2023-01-06 22:29:59,106] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:29:59,113] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:29:59,134] {logging_mixin.py:115} INFO - [2023-01-06 22:29:59,134] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:29:59,153] {logging_mixin.py:115} INFO - [2023-01-06 22:29:59,153] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:29:59,162] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.843 seconds
[2023-01-06 22:30:29,255] {processor.py:153} INFO - Started process (PID=2763) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:30:29,256] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:30:29,257] {logging_mixin.py:115} INFO - [2023-01-06 22:30:29,257] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:30:30,055] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:30:30,056] {logging_mixin.py:115} INFO - [2023-01-06 22:30:30,056] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:30:30,057] {logging_mixin.py:115} INFO - [2023-01-06 22:30:30,056] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:30:30,063] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:30:30,085] {logging_mixin.py:115} INFO - [2023-01-06 22:30:30,085] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:30:30,104] {logging_mixin.py:115} INFO - [2023-01-06 22:30:30,104] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:30:30,114] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.863 seconds
[2023-01-06 22:31:00,223] {processor.py:153} INFO - Started process (PID=2788) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:31:00,226] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:31:00,226] {logging_mixin.py:115} INFO - [2023-01-06 22:31:00,226] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:31:00,984] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:31:00,986] {logging_mixin.py:115} INFO - [2023-01-06 22:31:00,986] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:31:00,986] {logging_mixin.py:115} INFO - [2023-01-06 22:31:00,986] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:31:00,993] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:31:01,013] {logging_mixin.py:115} INFO - [2023-01-06 22:31:01,013] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:31:01,032] {logging_mixin.py:115} INFO - [2023-01-06 22:31:01,032] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:31:01,041] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.823 seconds
[2023-01-06 22:31:31,129] {processor.py:153} INFO - Started process (PID=2806) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:31:31,131] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:31:31,131] {logging_mixin.py:115} INFO - [2023-01-06 22:31:31,131] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:31:31,965] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:31:31,967] {logging_mixin.py:115} INFO - [2023-01-06 22:31:31,966] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:31:31,967] {logging_mixin.py:115} INFO - [2023-01-06 22:31:31,967] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:31:31,974] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:31:32,001] {logging_mixin.py:115} INFO - [2023-01-06 22:31:32,001] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:31:32,028] {logging_mixin.py:115} INFO - [2023-01-06 22:31:32,028] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:31:32,039] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.915 seconds
[2023-01-06 22:32:02,131] {processor.py:153} INFO - Started process (PID=2831) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:32:02,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:32:02,134] {logging_mixin.py:115} INFO - [2023-01-06 22:32:02,134] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:32:02,932] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:32:02,934] {logging_mixin.py:115} INFO - [2023-01-06 22:32:02,934] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:32:02,934] {logging_mixin.py:115} INFO - [2023-01-06 22:32:02,934] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:32:02,941] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:32:02,963] {logging_mixin.py:115} INFO - [2023-01-06 22:32:02,963] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:32:02,982] {logging_mixin.py:115} INFO - [2023-01-06 22:32:02,982] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:32:02,991] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.864 seconds
[2023-01-06 22:32:33,080] {processor.py:153} INFO - Started process (PID=2854) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:32:33,082] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:32:33,082] {logging_mixin.py:115} INFO - [2023-01-06 22:32:33,082] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:32:33,875] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:32:33,876] {logging_mixin.py:115} INFO - [2023-01-06 22:32:33,876] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:32:33,876] {logging_mixin.py:115} INFO - [2023-01-06 22:32:33,876] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:32:33,883] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:32:33,904] {logging_mixin.py:115} INFO - [2023-01-06 22:32:33,903] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:32:33,923] {logging_mixin.py:115} INFO - [2023-01-06 22:32:33,923] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:32:33,932] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.856 seconds
[2023-01-06 22:33:04,006] {processor.py:153} INFO - Started process (PID=2879) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:33:04,008] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:33:04,009] {logging_mixin.py:115} INFO - [2023-01-06 22:33:04,009] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:33:04,772] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:33:04,774] {logging_mixin.py:115} INFO - [2023-01-06 22:33:04,774] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:33:04,774] {logging_mixin.py:115} INFO - [2023-01-06 22:33:04,774] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:33:04,781] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:33:04,802] {logging_mixin.py:115} INFO - [2023-01-06 22:33:04,802] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:33:04,822] {logging_mixin.py:115} INFO - [2023-01-06 22:33:04,821] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:33:04,830] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.829 seconds
[2023-01-06 22:33:34,902] {processor.py:153} INFO - Started process (PID=2897) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:33:34,903] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:33:34,904] {logging_mixin.py:115} INFO - [2023-01-06 22:33:34,904] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:33:35,971] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:33:35,972] {logging_mixin.py:115} INFO - [2023-01-06 22:33:35,972] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:33:35,973] {logging_mixin.py:115} INFO - [2023-01-06 22:33:35,972] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:33:35,981] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:33:36,010] {logging_mixin.py:115} INFO - [2023-01-06 22:33:36,009] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:33:36,039] {logging_mixin.py:115} INFO - [2023-01-06 22:33:36,038] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:33:36,051] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.155 seconds
[2023-01-06 22:34:06,121] {processor.py:153} INFO - Started process (PID=2922) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:34:06,122] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:34:06,122] {logging_mixin.py:115} INFO - [2023-01-06 22:34:06,122] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:34:06,913] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:34:06,915] {logging_mixin.py:115} INFO - [2023-01-06 22:34:06,915] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:34:06,915] {logging_mixin.py:115} INFO - [2023-01-06 22:34:06,915] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:34:06,922] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:34:06,943] {logging_mixin.py:115} INFO - [2023-01-06 22:34:06,942] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:34:06,962] {logging_mixin.py:115} INFO - [2023-01-06 22:34:06,962] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:34:06,971] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.855 seconds
[2023-01-06 22:34:37,037] {processor.py:153} INFO - Started process (PID=2947) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:34:37,037] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:34:37,038] {logging_mixin.py:115} INFO - [2023-01-06 22:34:37,038] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:34:37,788] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:34:37,789] {logging_mixin.py:115} INFO - [2023-01-06 22:34:37,789] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:34:37,789] {logging_mixin.py:115} INFO - [2023-01-06 22:34:37,789] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:34:37,796] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:34:37,817] {logging_mixin.py:115} INFO - [2023-01-06 22:34:37,817] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:34:37,837] {logging_mixin.py:115} INFO - [2023-01-06 22:34:37,837] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:34:37,847] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.814 seconds
[2023-01-06 22:35:07,922] {processor.py:153} INFO - Started process (PID=2973) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:35:07,923] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:35:07,923] {logging_mixin.py:115} INFO - [2023-01-06 22:35:07,923] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:35:08,722] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:35:08,723] {logging_mixin.py:115} INFO - [2023-01-06 22:35:08,723] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:35:08,724] {logging_mixin.py:115} INFO - [2023-01-06 22:35:08,723] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:35:08,730] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:35:08,752] {logging_mixin.py:115} INFO - [2023-01-06 22:35:08,752] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:35:08,772] {logging_mixin.py:115} INFO - [2023-01-06 22:35:08,772] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:35:08,782] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.866 seconds
[2023-01-06 22:35:38,889] {processor.py:153} INFO - Started process (PID=2991) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:35:38,889] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:35:38,890] {logging_mixin.py:115} INFO - [2023-01-06 22:35:38,890] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:35:39,650] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:35:39,651] {logging_mixin.py:115} INFO - [2023-01-06 22:35:39,651] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:35:39,652] {logging_mixin.py:115} INFO - [2023-01-06 22:35:39,652] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:35:39,658] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:35:39,680] {logging_mixin.py:115} INFO - [2023-01-06 22:35:39,680] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:35:39,699] {logging_mixin.py:115} INFO - [2023-01-06 22:35:39,699] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:35:39,708] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.825 seconds
[2023-01-06 22:36:09,802] {processor.py:153} INFO - Started process (PID=3015) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:36:09,803] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:36:09,804] {logging_mixin.py:115} INFO - [2023-01-06 22:36:09,804] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:36:10,553] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:36:10,554] {logging_mixin.py:115} INFO - [2023-01-06 22:36:10,554] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:36:10,555] {logging_mixin.py:115} INFO - [2023-01-06 22:36:10,554] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:36:10,561] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:36:10,583] {logging_mixin.py:115} INFO - [2023-01-06 22:36:10,583] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:36:10,603] {logging_mixin.py:115} INFO - [2023-01-06 22:36:10,603] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:36:10,612] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.816 seconds
[2023-01-06 22:36:40,705] {processor.py:153} INFO - Started process (PID=3040) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:36:40,707] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:36:40,707] {logging_mixin.py:115} INFO - [2023-01-06 22:36:40,707] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:36:41,481] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:36:41,482] {logging_mixin.py:115} INFO - [2023-01-06 22:36:41,482] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:36:41,483] {logging_mixin.py:115} INFO - [2023-01-06 22:36:41,483] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:36:41,490] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:36:41,510] {logging_mixin.py:115} INFO - [2023-01-06 22:36:41,510] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:36:41,530] {logging_mixin.py:115} INFO - [2023-01-06 22:36:41,530] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:36:41,539] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-06 22:37:12,082] {processor.py:153} INFO - Started process (PID=3066) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:37:12,083] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:37:12,084] {logging_mixin.py:115} INFO - [2023-01-06 22:37:12,084] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:37:12,867] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:37:12,868] {logging_mixin.py:115} INFO - [2023-01-06 22:37:12,868] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:37:12,869] {logging_mixin.py:115} INFO - [2023-01-06 22:37:12,869] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:37:12,876] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:37:12,896] {logging_mixin.py:115} INFO - [2023-01-06 22:37:12,896] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:37:12,916] {logging_mixin.py:115} INFO - [2023-01-06 22:37:12,916] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:37:12,925] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.848 seconds
[2023-01-06 22:37:43,021] {processor.py:153} INFO - Started process (PID=3084) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:37:43,022] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:37:43,023] {logging_mixin.py:115} INFO - [2023-01-06 22:37:43,022] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:37:43,807] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:37:43,808] {logging_mixin.py:115} INFO - [2023-01-06 22:37:43,808] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:37:43,809] {logging_mixin.py:115} INFO - [2023-01-06 22:37:43,808] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:37:43,819] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:37:43,848] {logging_mixin.py:115} INFO - [2023-01-06 22:37:43,847] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:37:43,875] {logging_mixin.py:115} INFO - [2023-01-06 22:37:43,875] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:37:43,886] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.871 seconds
[2023-01-06 22:38:13,977] {processor.py:153} INFO - Started process (PID=3109) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:38:13,978] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:38:13,979] {logging_mixin.py:115} INFO - [2023-01-06 22:38:13,979] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:38:14,745] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:38:14,747] {logging_mixin.py:115} INFO - [2023-01-06 22:38:14,746] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:38:14,747] {logging_mixin.py:115} INFO - [2023-01-06 22:38:14,747] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:38:14,754] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:38:14,780] {logging_mixin.py:115} INFO - [2023-01-06 22:38:14,780] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:38:14,801] {logging_mixin.py:115} INFO - [2023-01-06 22:38:14,801] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:38:14,811] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.839 seconds
[2023-01-06 22:38:44,903] {processor.py:153} INFO - Started process (PID=3134) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:38:44,904] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:38:44,905] {logging_mixin.py:115} INFO - [2023-01-06 22:38:44,905] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:38:45,670] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:38:45,671] {logging_mixin.py:115} INFO - [2023-01-06 22:38:45,671] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:38:45,671] {logging_mixin.py:115} INFO - [2023-01-06 22:38:45,671] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:38:45,678] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:38:45,700] {logging_mixin.py:115} INFO - [2023-01-06 22:38:45,699] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:38:45,719] {logging_mixin.py:115} INFO - [2023-01-06 22:38:45,719] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:38:45,728] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.831 seconds
[2023-01-06 22:39:15,815] {processor.py:153} INFO - Started process (PID=3160) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:39:15,817] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:39:15,817] {logging_mixin.py:115} INFO - [2023-01-06 22:39:15,817] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:39:16,580] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:39:16,581] {logging_mixin.py:115} INFO - [2023-01-06 22:39:16,581] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:39:16,581] {logging_mixin.py:115} INFO - [2023-01-06 22:39:16,581] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:39:16,588] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:39:16,608] {logging_mixin.py:115} INFO - [2023-01-06 22:39:16,608] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:39:16,627] {logging_mixin.py:115} INFO - [2023-01-06 22:39:16,627] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:39:16,637] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.827 seconds
[2023-01-06 22:39:47,187] {processor.py:153} INFO - Started process (PID=3184) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:39:47,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:39:47,188] {logging_mixin.py:115} INFO - [2023-01-06 22:39:47,188] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:39:48,263] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:39:48,264] {logging_mixin.py:115} INFO - [2023-01-06 22:39:48,264] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:39:48,265] {logging_mixin.py:115} INFO - [2023-01-06 22:39:48,264] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:39:48,271] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:39:48,295] {logging_mixin.py:115} INFO - [2023-01-06 22:39:48,295] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:39:48,315] {logging_mixin.py:115} INFO - [2023-01-06 22:39:48,315] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:39:48,325] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.144 seconds
[2023-01-06 22:40:18,390] {processor.py:153} INFO - Started process (PID=3202) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:40:18,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:40:18,392] {logging_mixin.py:115} INFO - [2023-01-06 22:40:18,392] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:40:19,156] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:40:19,157] {logging_mixin.py:115} INFO - [2023-01-06 22:40:19,157] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:40:19,158] {logging_mixin.py:115} INFO - [2023-01-06 22:40:19,158] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:40:19,167] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:40:19,191] {logging_mixin.py:115} INFO - [2023-01-06 22:40:19,191] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:40:19,213] {logging_mixin.py:115} INFO - [2023-01-06 22:40:19,213] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:40:19,225] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.840 seconds
[2023-01-06 22:40:49,293] {processor.py:153} INFO - Started process (PID=3227) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:40:49,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:40:49,295] {logging_mixin.py:115} INFO - [2023-01-06 22:40:49,295] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:40:50,059] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:40:50,061] {logging_mixin.py:115} INFO - [2023-01-06 22:40:50,061] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:40:50,061] {logging_mixin.py:115} INFO - [2023-01-06 22:40:50,061] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:40:50,068] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:40:50,089] {logging_mixin.py:115} INFO - [2023-01-06 22:40:50,089] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:40:50,109] {logging_mixin.py:115} INFO - [2023-01-06 22:40:50,109] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:40:50,119] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.830 seconds
[2023-01-06 22:41:20,212] {processor.py:153} INFO - Started process (PID=3252) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:41:20,214] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:41:20,214] {logging_mixin.py:115} INFO - [2023-01-06 22:41:20,214] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:41:20,992] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:41:20,993] {logging_mixin.py:115} INFO - [2023-01-06 22:41:20,993] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:41:20,994] {logging_mixin.py:115} INFO - [2023-01-06 22:41:20,993] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:41:21,000] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:41:21,021] {logging_mixin.py:115} INFO - [2023-01-06 22:41:21,021] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:41:21,040] {logging_mixin.py:115} INFO - [2023-01-06 22:41:21,040] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:41:21,049] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-06 22:41:51,140] {processor.py:153} INFO - Started process (PID=3278) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:41:51,143] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:41:51,143] {logging_mixin.py:115} INFO - [2023-01-06 22:41:51,143] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:41:51,921] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:41:51,923] {logging_mixin.py:115} INFO - [2023-01-06 22:41:51,923] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:41:51,923] {logging_mixin.py:115} INFO - [2023-01-06 22:41:51,923] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:41:51,930] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:41:51,951] {logging_mixin.py:115} INFO - [2023-01-06 22:41:51,951] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:41:51,970] {logging_mixin.py:115} INFO - [2023-01-06 22:41:51,970] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:41:51,979] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.844 seconds
[2023-01-06 22:42:22,070] {processor.py:153} INFO - Started process (PID=3296) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:42:22,071] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:42:22,071] {logging_mixin.py:115} INFO - [2023-01-06 22:42:22,071] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:42:22,840] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:42:22,841] {logging_mixin.py:115} INFO - [2023-01-06 22:42:22,841] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:42:22,842] {logging_mixin.py:115} INFO - [2023-01-06 22:42:22,841] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:42:22,848] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:42:22,869] {logging_mixin.py:115} INFO - [2023-01-06 22:42:22,869] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:42:22,889] {logging_mixin.py:115} INFO - [2023-01-06 22:42:22,889] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:42:22,898] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.833 seconds
[2023-01-06 22:42:52,993] {processor.py:153} INFO - Started process (PID=3322) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:42:52,994] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:42:52,995] {logging_mixin.py:115} INFO - [2023-01-06 22:42:52,995] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:42:53,797] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:42:53,798] {logging_mixin.py:115} INFO - [2023-01-06 22:42:53,798] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:42:53,799] {logging_mixin.py:115} INFO - [2023-01-06 22:42:53,798] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:42:53,805] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:42:53,826] {logging_mixin.py:115} INFO - [2023-01-06 22:42:53,826] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:42:53,846] {logging_mixin.py:115} INFO - [2023-01-06 22:42:53,846] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:42:53,855] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.867 seconds
[2023-01-06 22:43:23,925] {processor.py:153} INFO - Started process (PID=3347) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:43:23,926] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:43:23,927] {logging_mixin.py:115} INFO - [2023-01-06 22:43:23,927] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:43:24,700] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:43:24,702] {logging_mixin.py:115} INFO - [2023-01-06 22:43:24,702] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:43:24,702] {logging_mixin.py:115} INFO - [2023-01-06 22:43:24,702] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:43:24,709] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:43:24,730] {logging_mixin.py:115} INFO - [2023-01-06 22:43:24,730] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:43:24,750] {logging_mixin.py:115} INFO - [2023-01-06 22:43:24,750] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:43:24,760] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.839 seconds
[2023-01-06 22:43:54,831] {processor.py:153} INFO - Started process (PID=3372) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:43:54,832] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:43:54,833] {logging_mixin.py:115} INFO - [2023-01-06 22:43:54,833] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:43:55,615] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:43:55,616] {logging_mixin.py:115} INFO - [2023-01-06 22:43:55,616] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:43:55,617] {logging_mixin.py:115} INFO - [2023-01-06 22:43:55,617] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:43:55,624] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:43:55,644] {logging_mixin.py:115} INFO - [2023-01-06 22:43:55,644] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:43:55,664] {logging_mixin.py:115} INFO - [2023-01-06 22:43:55,664] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:43:55,673] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.846 seconds
[2023-01-06 22:44:25,742] {processor.py:153} INFO - Started process (PID=3391) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:44:25,743] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:44:25,744] {logging_mixin.py:115} INFO - [2023-01-06 22:44:25,743] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:44:26,696] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:44:26,698] {logging_mixin.py:115} INFO - [2023-01-06 22:44:26,698] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:44:26,698] {logging_mixin.py:115} INFO - [2023-01-06 22:44:26,698] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:44:26,705] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:44:26,727] {logging_mixin.py:115} INFO - [2023-01-06 22:44:26,727] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:44:26,747] {logging_mixin.py:115} INFO - [2023-01-06 22:44:26,747] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:44:26,756] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.019 seconds
[2023-01-06 22:44:56,822] {processor.py:153} INFO - Started process (PID=3415) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:44:56,825] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:44:56,825] {logging_mixin.py:115} INFO - [2023-01-06 22:44:56,825] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:44:57,575] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:44:57,576] {logging_mixin.py:115} INFO - [2023-01-06 22:44:57,576] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:44:57,577] {logging_mixin.py:115} INFO - [2023-01-06 22:44:57,577] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:44:57,584] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:44:57,605] {logging_mixin.py:115} INFO - [2023-01-06 22:44:57,605] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:44:57,625] {logging_mixin.py:115} INFO - [2023-01-06 22:44:57,625] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:44:57,635] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.818 seconds
[2023-01-06 22:45:27,724] {processor.py:153} INFO - Started process (PID=3441) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:45:27,725] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:45:27,725] {logging_mixin.py:115} INFO - [2023-01-06 22:45:27,725] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:45:28,495] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:45:28,497] {logging_mixin.py:115} INFO - [2023-01-06 22:45:28,497] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:45:28,497] {logging_mixin.py:115} INFO - [2023-01-06 22:45:28,497] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:45:28,504] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:45:28,525] {logging_mixin.py:115} INFO - [2023-01-06 22:45:28,525] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:45:28,544] {logging_mixin.py:115} INFO - [2023-01-06 22:45:28,544] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:45:28,553] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.834 seconds
[2023-01-06 22:45:58,880] {processor.py:153} INFO - Started process (PID=3466) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:45:58,881] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:45:58,882] {logging_mixin.py:115} INFO - [2023-01-06 22:45:58,881] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:45:59,701] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:45:59,703] {logging_mixin.py:115} INFO - [2023-01-06 22:45:59,703] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:45:59,703] {logging_mixin.py:115} INFO - [2023-01-06 22:45:59,703] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:45:59,710] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:45:59,731] {logging_mixin.py:115} INFO - [2023-01-06 22:45:59,731] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:45:59,751] {logging_mixin.py:115} INFO - [2023-01-06 22:45:59,751] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:45:59,761] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.886 seconds
[2023-01-06 22:46:29,858] {processor.py:153} INFO - Started process (PID=3484) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:46:29,859] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:46:29,860] {logging_mixin.py:115} INFO - [2023-01-06 22:46:29,860] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:46:30,631] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:46:30,632] {logging_mixin.py:115} INFO - [2023-01-06 22:46:30,632] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:46:30,633] {logging_mixin.py:115} INFO - [2023-01-06 22:46:30,633] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:46:30,639] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:46:30,661] {logging_mixin.py:115} INFO - [2023-01-06 22:46:30,660] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:46:30,681] {logging_mixin.py:115} INFO - [2023-01-06 22:46:30,681] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:46:30,690] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.837 seconds
[2023-01-06 22:47:00,783] {processor.py:153} INFO - Started process (PID=3509) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:47:00,783] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:47:00,784] {logging_mixin.py:115} INFO - [2023-01-06 22:47:00,784] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:47:01,540] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:47:01,542] {logging_mixin.py:115} INFO - [2023-01-06 22:47:01,542] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:47:01,542] {logging_mixin.py:115} INFO - [2023-01-06 22:47:01,542] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:47:01,549] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:47:01,570] {logging_mixin.py:115} INFO - [2023-01-06 22:47:01,570] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:47:01,590] {logging_mixin.py:115} INFO - [2023-01-06 22:47:01,590] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:47:01,599] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.821 seconds
[2023-01-06 22:47:31,691] {processor.py:153} INFO - Started process (PID=3535) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:47:31,693] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:47:31,694] {logging_mixin.py:115} INFO - [2023-01-06 22:47:31,694] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:47:32,471] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:47:32,472] {logging_mixin.py:115} INFO - [2023-01-06 22:47:32,472] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:47:32,473] {logging_mixin.py:115} INFO - [2023-01-06 22:47:32,473] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:47:32,479] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:47:32,503] {logging_mixin.py:115} INFO - [2023-01-06 22:47:32,503] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:47:32,523] {logging_mixin.py:115} INFO - [2023-01-06 22:47:32,523] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:47:32,532] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.847 seconds
[2023-01-06 22:48:02,619] {processor.py:153} INFO - Started process (PID=3560) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:48:02,620] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:48:02,621] {logging_mixin.py:115} INFO - [2023-01-06 22:48:02,621] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:48:03,379] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:48:03,380] {logging_mixin.py:115} INFO - [2023-01-06 22:48:03,380] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:48:03,381] {logging_mixin.py:115} INFO - [2023-01-06 22:48:03,381] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:48:03,387] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:48:03,408] {logging_mixin.py:115} INFO - [2023-01-06 22:48:03,408] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:48:03,428] {logging_mixin.py:115} INFO - [2023-01-06 22:48:03,428] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:48:03,437] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.822 seconds
[2023-01-06 22:48:33,507] {processor.py:153} INFO - Started process (PID=3578) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:48:33,509] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:48:33,510] {logging_mixin.py:115} INFO - [2023-01-06 22:48:33,510] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:48:34,316] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:48:34,317] {logging_mixin.py:115} INFO - [2023-01-06 22:48:34,317] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:48:34,318] {logging_mixin.py:115} INFO - [2023-01-06 22:48:34,317] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:48:34,324] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:48:34,346] {logging_mixin.py:115} INFO - [2023-01-06 22:48:34,346] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:48:34,366] {logging_mixin.py:115} INFO - [2023-01-06 22:48:34,366] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:48:34,375] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.872 seconds
[2023-01-06 22:49:04,446] {processor.py:153} INFO - Started process (PID=3603) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:49:04,446] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:49:04,447] {logging_mixin.py:115} INFO - [2023-01-06 22:49:04,447] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:49:05,286] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:49:05,288] {logging_mixin.py:115} INFO - [2023-01-06 22:49:05,288] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:49:05,288] {logging_mixin.py:115} INFO - [2023-01-06 22:49:05,288] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:49:05,295] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:49:05,316] {logging_mixin.py:115} INFO - [2023-01-06 22:49:05,315] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:49:05,335] {logging_mixin.py:115} INFO - [2023-01-06 22:49:05,335] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:49:05,345] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.904 seconds
[2023-01-06 22:49:35,412] {processor.py:153} INFO - Started process (PID=3628) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:49:35,413] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:49:35,414] {logging_mixin.py:115} INFO - [2023-01-06 22:49:35,414] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:49:36,183] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:49:36,184] {logging_mixin.py:115} INFO - [2023-01-06 22:49:36,184] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:49:36,185] {logging_mixin.py:115} INFO - [2023-01-06 22:49:36,184] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:49:36,191] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:49:36,212] {logging_mixin.py:115} INFO - [2023-01-06 22:49:36,211] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:49:36,231] {logging_mixin.py:115} INFO - [2023-01-06 22:49:36,231] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:49:36,240] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.833 seconds
[2023-01-06 22:50:06,309] {processor.py:153} INFO - Started process (PID=3653) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:50:06,312] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:50:06,312] {logging_mixin.py:115} INFO - [2023-01-06 22:50:06,312] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:50:07,074] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:50:07,075] {logging_mixin.py:115} INFO - [2023-01-06 22:50:07,075] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:50:07,076] {logging_mixin.py:115} INFO - [2023-01-06 22:50:07,076] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:50:07,082] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:50:07,103] {logging_mixin.py:115} INFO - [2023-01-06 22:50:07,103] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:50:07,123] {logging_mixin.py:115} INFO - [2023-01-06 22:50:07,123] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:50:07,132] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.828 seconds
[2023-01-06 22:50:37,232] {processor.py:153} INFO - Started process (PID=3671) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:50:37,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:50:37,233] {logging_mixin.py:115} INFO - [2023-01-06 22:50:37,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:50:38,198] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:50:38,200] {logging_mixin.py:115} INFO - [2023-01-06 22:50:38,200] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:50:38,200] {logging_mixin.py:115} INFO - [2023-01-06 22:50:38,200] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:50:38,211] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:50:38,239] {logging_mixin.py:115} INFO - [2023-01-06 22:50:38,239] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:50:38,265] {logging_mixin.py:115} INFO - [2023-01-06 22:50:38,265] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:50:38,275] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.048 seconds
[2023-01-06 22:51:08,345] {processor.py:153} INFO - Started process (PID=3697) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:51:08,346] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:51:08,347] {logging_mixin.py:115} INFO - [2023-01-06 22:51:08,347] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:51:09,107] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:51:09,108] {logging_mixin.py:115} INFO - [2023-01-06 22:51:09,108] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:51:09,109] {logging_mixin.py:115} INFO - [2023-01-06 22:51:09,108] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:51:09,115] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:51:09,136] {logging_mixin.py:115} INFO - [2023-01-06 22:51:09,136] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:51:09,156] {logging_mixin.py:115} INFO - [2023-01-06 22:51:09,156] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:51:09,165] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.825 seconds
[2023-01-06 22:51:39,260] {processor.py:153} INFO - Started process (PID=3722) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:51:39,261] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:51:39,262] {logging_mixin.py:115} INFO - [2023-01-06 22:51:39,262] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:51:40,021] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:51:40,022] {logging_mixin.py:115} INFO - [2023-01-06 22:51:40,022] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:51:40,023] {logging_mixin.py:115} INFO - [2023-01-06 22:51:40,022] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:51:40,029] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:51:40,050] {logging_mixin.py:115} INFO - [2023-01-06 22:51:40,050] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:51:40,069] {logging_mixin.py:115} INFO - [2023-01-06 22:51:40,069] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:51:40,078] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.823 seconds
[2023-01-06 22:52:10,173] {processor.py:153} INFO - Started process (PID=3745) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:52:10,174] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:52:10,175] {logging_mixin.py:115} INFO - [2023-01-06 22:52:10,175] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:52:10,972] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:52:10,973] {logging_mixin.py:115} INFO - [2023-01-06 22:52:10,973] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:52:10,974] {logging_mixin.py:115} INFO - [2023-01-06 22:52:10,973] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:52:10,980] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:52:11,001] {logging_mixin.py:115} INFO - [2023-01-06 22:52:11,001] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:52:11,020] {logging_mixin.py:115} INFO - [2023-01-06 22:52:11,020] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:52:11,029] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.861 seconds
[2023-01-06 22:52:41,126] {processor.py:153} INFO - Started process (PID=3763) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:52:41,127] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:52:41,127] {logging_mixin.py:115} INFO - [2023-01-06 22:52:41,127] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:52:41,936] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:52:41,938] {logging_mixin.py:115} INFO - [2023-01-06 22:52:41,938] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:52:41,938] {logging_mixin.py:115} INFO - [2023-01-06 22:52:41,938] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:52:41,945] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:52:41,973] {logging_mixin.py:115} INFO - [2023-01-06 22:52:41,973] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:52:41,997] {logging_mixin.py:115} INFO - [2023-01-06 22:52:41,997] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:52:42,008] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.887 seconds
[2023-01-06 22:53:12,107] {processor.py:153} INFO - Started process (PID=3789) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:53:12,108] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:53:12,108] {logging_mixin.py:115} INFO - [2023-01-06 22:53:12,108] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:53:12,866] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:53:12,868] {logging_mixin.py:115} INFO - [2023-01-06 22:53:12,868] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:53:12,868] {logging_mixin.py:115} INFO - [2023-01-06 22:53:12,868] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:53:12,875] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:53:12,896] {logging_mixin.py:115} INFO - [2023-01-06 22:53:12,895] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:53:12,915] {logging_mixin.py:115} INFO - [2023-01-06 22:53:12,915] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:53:12,924] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.822 seconds
[2023-01-06 22:53:43,013] {processor.py:153} INFO - Started process (PID=3815) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:53:43,014] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:53:43,014] {logging_mixin.py:115} INFO - [2023-01-06 22:53:43,014] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:53:43,812] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:53:43,813] {logging_mixin.py:115} INFO - [2023-01-06 22:53:43,813] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:53:43,814] {logging_mixin.py:115} INFO - [2023-01-06 22:53:43,813] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:53:43,820] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:53:43,842] {logging_mixin.py:115} INFO - [2023-01-06 22:53:43,842] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:53:43,863] {logging_mixin.py:115} INFO - [2023-01-06 22:53:43,862] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:53:43,872] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.864 seconds
[2023-01-06 22:54:13,952] {processor.py:153} INFO - Started process (PID=3840) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:54:13,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:54:13,954] {logging_mixin.py:115} INFO - [2023-01-06 22:54:13,954] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:54:14,720] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:54:14,721] {logging_mixin.py:115} INFO - [2023-01-06 22:54:14,721] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:54:14,722] {logging_mixin.py:115} INFO - [2023-01-06 22:54:14,721] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:54:14,728] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:54:14,750] {logging_mixin.py:115} INFO - [2023-01-06 22:54:14,750] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:54:14,769] {logging_mixin.py:115} INFO - [2023-01-06 22:54:14,769] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:54:14,778] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.831 seconds
[2023-01-06 22:54:44,845] {processor.py:153} INFO - Started process (PID=3858) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:54:44,846] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:54:44,847] {logging_mixin.py:115} INFO - [2023-01-06 22:54:44,847] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:54:45,628] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:54:45,629] {logging_mixin.py:115} INFO - [2023-01-06 22:54:45,629] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:54:45,630] {logging_mixin.py:115} INFO - [2023-01-06 22:54:45,630] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:54:45,637] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:54:45,658] {logging_mixin.py:115} INFO - [2023-01-06 22:54:45,658] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:54:45,678] {logging_mixin.py:115} INFO - [2023-01-06 22:54:45,678] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-06 22:54:45,686] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.846 seconds
[2023-01-06 22:55:15,755] {processor.py:153} INFO - Started process (PID=3883) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:55:15,756] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:55:15,757] {logging_mixin.py:115} INFO - [2023-01-06 22:55:15,756] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:55:16,578] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:55:16,579] {logging_mixin.py:115} INFO - [2023-01-06 22:55:16,579] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:55:16,580] {logging_mixin.py:115} INFO - [2023-01-06 22:55:16,580] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:55:16,587] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:55:16,609] {logging_mixin.py:115} INFO - [2023-01-06 22:55:16,608] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:55:16,637] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.885 seconds
[2023-01-06 22:55:46,708] {processor.py:153} INFO - Started process (PID=3908) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:55:46,709] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:55:46,710] {logging_mixin.py:115} INFO - [2023-01-06 22:55:46,710] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:55:47,470] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:55:47,472] {logging_mixin.py:115} INFO - [2023-01-06 22:55:47,472] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:55:47,472] {logging_mixin.py:115} INFO - [2023-01-06 22:55:47,472] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:55:47,479] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:55:47,499] {logging_mixin.py:115} INFO - [2023-01-06 22:55:47,499] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:55:47,525] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.821 seconds
[2023-01-06 22:56:17,589] {processor.py:153} INFO - Started process (PID=3933) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:56:17,589] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:56:17,590] {logging_mixin.py:115} INFO - [2023-01-06 22:56:17,590] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:56:18,339] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:56:18,340] {logging_mixin.py:115} INFO - [2023-01-06 22:56:18,340] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:56:18,341] {logging_mixin.py:115} INFO - [2023-01-06 22:56:18,341] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:56:18,348] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:56:18,373] {logging_mixin.py:115} INFO - [2023-01-06 22:56:18,373] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:56:18,400] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.815 seconds
[2023-01-06 22:56:48,452] {processor.py:153} INFO - Started process (PID=3950) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:56:48,454] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:56:48,454] {logging_mixin.py:115} INFO - [2023-01-06 22:56:48,454] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:56:49,505] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:56:49,506] {logging_mixin.py:115} INFO - [2023-01-06 22:56:49,506] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:56:49,507] {logging_mixin.py:115} INFO - [2023-01-06 22:56:49,507] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:56:49,519] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:56:49,550] {logging_mixin.py:115} INFO - [2023-01-06 22:56:49,550] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:56:49,587] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.140 seconds
[2023-01-06 22:57:19,655] {processor.py:153} INFO - Started process (PID=3974) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:57:19,655] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:57:19,656] {logging_mixin.py:115} INFO - [2023-01-06 22:57:19,656] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:57:20,404] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:57:20,405] {logging_mixin.py:115} INFO - [2023-01-06 22:57:20,405] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:57:20,405] {logging_mixin.py:115} INFO - [2023-01-06 22:57:20,405] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:57:20,412] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:57:20,433] {logging_mixin.py:115} INFO - [2023-01-06 22:57:20,433] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:57:20,460] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.810 seconds
[2023-01-06 22:57:50,698] {processor.py:153} INFO - Started process (PID=4000) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:57:50,700] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:57:50,701] {logging_mixin.py:115} INFO - [2023-01-06 22:57:50,701] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:57:51,445] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:57:51,446] {logging_mixin.py:115} INFO - [2023-01-06 22:57:51,446] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:57:51,446] {logging_mixin.py:115} INFO - [2023-01-06 22:57:51,446] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:57:51,453] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:57:51,474] {logging_mixin.py:115} INFO - [2023-01-06 22:57:51,474] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:57:51,501] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.807 seconds
[2023-01-06 22:58:21,564] {processor.py:153} INFO - Started process (PID=4027) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:58:21,565] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:58:21,565] {logging_mixin.py:115} INFO - [2023-01-06 22:58:21,565] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:58:22,396] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:58:22,398] {logging_mixin.py:115} INFO - [2023-01-06 22:58:22,398] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:58:22,399] {logging_mixin.py:115} INFO - [2023-01-06 22:58:22,399] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:58:22,410] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:58:22,439] {logging_mixin.py:115} INFO - [2023-01-06 22:58:22,439] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:58:22,477] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.918 seconds
[2023-01-06 22:58:52,543] {processor.py:153} INFO - Started process (PID=4044) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:58:52,544] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:58:52,545] {logging_mixin.py:115} INFO - [2023-01-06 22:58:52,545] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:58:53,386] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:58:53,387] {logging_mixin.py:115} INFO - [2023-01-06 22:58:53,387] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:58:53,388] {logging_mixin.py:115} INFO - [2023-01-06 22:58:53,388] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:58:53,395] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:58:53,418] {logging_mixin.py:115} INFO - [2023-01-06 22:58:53,417] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:58:53,444] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.905 seconds
[2023-01-06 22:59:23,473] {processor.py:153} INFO - Started process (PID=4068) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:59:23,474] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:59:23,475] {logging_mixin.py:115} INFO - [2023-01-06 22:59:23,475] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:59:24,270] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:59:24,271] {logging_mixin.py:115} INFO - [2023-01-06 22:59:24,271] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:59:24,272] {logging_mixin.py:115} INFO - [2023-01-06 22:59:24,272] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:59:24,281] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:59:24,304] {logging_mixin.py:115} INFO - [2023-01-06 22:59:24,304] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:59:24,332] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.863 seconds
[2023-01-06 22:59:54,426] {processor.py:153} INFO - Started process (PID=4093) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:59:54,427] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 22:59:54,428] {logging_mixin.py:115} INFO - [2023-01-06 22:59:54,428] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:59:55,235] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 22:59:55,237] {logging_mixin.py:115} INFO - [2023-01-06 22:59:55,236] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 22:59:55,237] {logging_mixin.py:115} INFO - [2023-01-06 22:59:55,237] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 22:59:55,244] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 22:59:55,265] {logging_mixin.py:115} INFO - [2023-01-06 22:59:55,264] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 22:59:55,285] {logging_mixin.py:115} INFO - [2023-01-06 22:59:55,284] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 22:59:55,294] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.874 seconds
[2023-01-06 23:00:25,386] {processor.py:153} INFO - Started process (PID=4118) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:00:25,389] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:00:25,389] {logging_mixin.py:115} INFO - [2023-01-06 23:00:25,389] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:00:26,154] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:00:26,155] {logging_mixin.py:115} INFO - [2023-01-06 23:00:26,155] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:00:26,155] {logging_mixin.py:115} INFO - [2023-01-06 23:00:26,155] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:00:26,162] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:00:26,183] {logging_mixin.py:115} INFO - [2023-01-06 23:00:26,183] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:00:26,203] {logging_mixin.py:115} INFO - [2023-01-06 23:00:26,203] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:00:26,213] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.831 seconds
[2023-01-06 23:00:56,299] {processor.py:153} INFO - Started process (PID=4143) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:00:56,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:00:56,301] {logging_mixin.py:115} INFO - [2023-01-06 23:00:56,301] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:00:57,068] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:00:57,069] {logging_mixin.py:115} INFO - [2023-01-06 23:00:57,069] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:00:57,069] {logging_mixin.py:115} INFO - [2023-01-06 23:00:57,069] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:00:57,077] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:00:57,104] {logging_mixin.py:115} INFO - [2023-01-06 23:00:57,103] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:00:57,123] {logging_mixin.py:115} INFO - [2023-01-06 23:00:57,123] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:00:57,132] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.837 seconds
[2023-01-06 23:01:27,219] {processor.py:153} INFO - Started process (PID=4162) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:01:27,220] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:01:27,221] {logging_mixin.py:115} INFO - [2023-01-06 23:01:27,221] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:01:27,979] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:01:27,980] {logging_mixin.py:115} INFO - [2023-01-06 23:01:27,980] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:01:27,981] {logging_mixin.py:115} INFO - [2023-01-06 23:01:27,980] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:01:27,987] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:01:28,012] {logging_mixin.py:115} INFO - [2023-01-06 23:01:28,012] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:01:28,034] {logging_mixin.py:115} INFO - [2023-01-06 23:01:28,034] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:01:28,046] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.831 seconds
[2023-01-06 23:01:58,114] {processor.py:153} INFO - Started process (PID=4187) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:01:58,115] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:01:58,116] {logging_mixin.py:115} INFO - [2023-01-06 23:01:58,116] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:01:58,879] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:01:58,880] {logging_mixin.py:115} INFO - [2023-01-06 23:01:58,880] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:01:58,881] {logging_mixin.py:115} INFO - [2023-01-06 23:01:58,880] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:01:58,888] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:01:58,908] {logging_mixin.py:115} INFO - [2023-01-06 23:01:58,908] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:01:58,928] {logging_mixin.py:115} INFO - [2023-01-06 23:01:58,928] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:01:58,937] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.827 seconds
[2023-01-06 23:02:29,001] {processor.py:153} INFO - Started process (PID=4212) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:02:29,001] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:02:29,002] {logging_mixin.py:115} INFO - [2023-01-06 23:02:29,002] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:02:29,750] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:02:29,751] {logging_mixin.py:115} INFO - [2023-01-06 23:02:29,751] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:02:29,751] {logging_mixin.py:115} INFO - [2023-01-06 23:02:29,751] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:02:29,758] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:02:29,779] {logging_mixin.py:115} INFO - [2023-01-06 23:02:29,779] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:02:29,799] {logging_mixin.py:115} INFO - [2023-01-06 23:02:29,799] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:02:29,809] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.813 seconds
[2023-01-06 23:02:59,878] {processor.py:153} INFO - Started process (PID=4239) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:02:59,879] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:02:59,880] {logging_mixin.py:115} INFO - [2023-01-06 23:02:59,880] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:03:00,974] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:03:00,976] {logging_mixin.py:115} INFO - [2023-01-06 23:03:00,975] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:03:00,976] {logging_mixin.py:115} INFO - [2023-01-06 23:03:00,976] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:03:00,987] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:03:01,017] {logging_mixin.py:115} INFO - [2023-01-06 23:03:01,017] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:03:01,049] {logging_mixin.py:115} INFO - [2023-01-06 23:03:01,048] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:03:01,061] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.188 seconds
[2023-01-06 23:03:31,129] {processor.py:153} INFO - Started process (PID=4256) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:03:31,129] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:03:31,130] {logging_mixin.py:115} INFO - [2023-01-06 23:03:31,130] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:03:31,898] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:03:31,899] {logging_mixin.py:115} INFO - [2023-01-06 23:03:31,899] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:03:31,899] {logging_mixin.py:115} INFO - [2023-01-06 23:03:31,899] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:03:31,906] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:03:31,927] {logging_mixin.py:115} INFO - [2023-01-06 23:03:31,927] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:03:31,947] {logging_mixin.py:115} INFO - [2023-01-06 23:03:31,947] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:03:31,956] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.832 seconds
[2023-01-06 23:04:02,018] {processor.py:153} INFO - Started process (PID=4280) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:04:02,019] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:04:02,020] {logging_mixin.py:115} INFO - [2023-01-06 23:04:02,020] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:04:02,796] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:04:02,797] {logging_mixin.py:115} INFO - [2023-01-06 23:04:02,797] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:04:02,797] {logging_mixin.py:115} INFO - [2023-01-06 23:04:02,797] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:04:02,804] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:04:02,825] {logging_mixin.py:115} INFO - [2023-01-06 23:04:02,825] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:04:02,844] {logging_mixin.py:115} INFO - [2023-01-06 23:04:02,844] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:04:02,853] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.840 seconds
[2023-01-06 23:04:32,922] {processor.py:153} INFO - Started process (PID=4305) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:04:32,922] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:04:32,923] {logging_mixin.py:115} INFO - [2023-01-06 23:04:32,923] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:04:33,715] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:04:33,717] {logging_mixin.py:115} INFO - [2023-01-06 23:04:33,717] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:04:33,717] {logging_mixin.py:115} INFO - [2023-01-06 23:04:33,717] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:04:33,724] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:04:33,745] {logging_mixin.py:115} INFO - [2023-01-06 23:04:33,745] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:04:33,765] {logging_mixin.py:115} INFO - [2023-01-06 23:04:33,764] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:04:33,775] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.857 seconds
[2023-01-06 23:05:03,866] {processor.py:153} INFO - Started process (PID=4330) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:05:03,867] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:05:03,868] {logging_mixin.py:115} INFO - [2023-01-06 23:05:03,868] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:05:04,640] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:05:04,641] {logging_mixin.py:115} INFO - [2023-01-06 23:05:04,641] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:05:04,641] {logging_mixin.py:115} INFO - [2023-01-06 23:05:04,641] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:05:04,648] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:05:04,674] {logging_mixin.py:115} INFO - [2023-01-06 23:05:04,673] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:05:04,697] {logging_mixin.py:115} INFO - [2023-01-06 23:05:04,697] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:05:04,706] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.845 seconds
[2023-01-06 23:05:34,810] {processor.py:153} INFO - Started process (PID=4348) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:05:34,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:05:34,812] {logging_mixin.py:115} INFO - [2023-01-06 23:05:34,812] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:05:35,564] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:05:35,565] {logging_mixin.py:115} INFO - [2023-01-06 23:05:35,565] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:05:35,566] {logging_mixin.py:115} INFO - [2023-01-06 23:05:35,566] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:05:35,574] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:05:35,614] {logging_mixin.py:115} INFO - [2023-01-06 23:05:35,614] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:05:35,643] {logging_mixin.py:115} INFO - [2023-01-06 23:05:35,643] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:05:35,655] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.850 seconds
[2023-01-06 23:06:05,754] {processor.py:153} INFO - Started process (PID=4373) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:06:05,755] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:06:05,756] {logging_mixin.py:115} INFO - [2023-01-06 23:06:05,756] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:06:06,524] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:06:06,526] {logging_mixin.py:115} INFO - [2023-01-06 23:06:06,526] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:06:06,527] {logging_mixin.py:115} INFO - [2023-01-06 23:06:06,527] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:06:06,533] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:06:06,555] {logging_mixin.py:115} INFO - [2023-01-06 23:06:06,554] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:06:06,574] {logging_mixin.py:115} INFO - [2023-01-06 23:06:06,574] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:06:06,584] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.835 seconds
[2023-01-06 23:06:36,671] {processor.py:153} INFO - Started process (PID=4398) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:06:36,673] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:06:36,674] {logging_mixin.py:115} INFO - [2023-01-06 23:06:36,674] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:06:37,431] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:06:37,432] {logging_mixin.py:115} INFO - [2023-01-06 23:06:37,432] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:06:37,432] {logging_mixin.py:115} INFO - [2023-01-06 23:06:37,432] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:06:37,439] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:06:37,460] {logging_mixin.py:115} INFO - [2023-01-06 23:06:37,459] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:06:37,479] {logging_mixin.py:115} INFO - [2023-01-06 23:06:37,479] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:06:37,489] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.824 seconds
[2023-01-06 23:07:07,570] {processor.py:153} INFO - Started process (PID=4424) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:07:07,571] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:07:07,572] {logging_mixin.py:115} INFO - [2023-01-06 23:07:07,572] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:07:08,363] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:07:08,365] {logging_mixin.py:115} INFO - [2023-01-06 23:07:08,365] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:07:08,365] {logging_mixin.py:115} INFO - [2023-01-06 23:07:08,365] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:07:08,372] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:07:08,393] {logging_mixin.py:115} INFO - [2023-01-06 23:07:08,393] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:07:08,413] {logging_mixin.py:115} INFO - [2023-01-06 23:07:08,413] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:07:08,423] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.858 seconds
[2023-01-06 23:07:38,496] {processor.py:153} INFO - Started process (PID=4442) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:07:38,497] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:07:38,497] {logging_mixin.py:115} INFO - [2023-01-06 23:07:38,497] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:07:39,322] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:07:39,324] {logging_mixin.py:115} INFO - [2023-01-06 23:07:39,324] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:07:39,324] {logging_mixin.py:115} INFO - [2023-01-06 23:07:39,324] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:07:39,331] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:07:39,353] {logging_mixin.py:115} INFO - [2023-01-06 23:07:39,353] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:07:39,373] {logging_mixin.py:115} INFO - [2023-01-06 23:07:39,373] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:07:39,383] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.894 seconds
[2023-01-06 23:08:09,452] {processor.py:153} INFO - Started process (PID=4468) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:08:09,453] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:08:09,454] {logging_mixin.py:115} INFO - [2023-01-06 23:08:09,454] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:08:10,198] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:08:10,200] {logging_mixin.py:115} INFO - [2023-01-06 23:08:10,200] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:08:10,200] {logging_mixin.py:115} INFO - [2023-01-06 23:08:10,200] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:08:10,207] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:08:10,229] {logging_mixin.py:115} INFO - [2023-01-06 23:08:10,228] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:08:10,248] {logging_mixin.py:115} INFO - [2023-01-06 23:08:10,248] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:08:10,258] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.812 seconds
[2023-01-06 23:08:40,326] {processor.py:153} INFO - Started process (PID=4493) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:08:40,327] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:08:40,327] {logging_mixin.py:115} INFO - [2023-01-06 23:08:40,327] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:08:41,102] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:08:41,104] {logging_mixin.py:115} INFO - [2023-01-06 23:08:41,103] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:08:41,104] {logging_mixin.py:115} INFO - [2023-01-06 23:08:41,104] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:08:41,111] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:08:41,131] {logging_mixin.py:115} INFO - [2023-01-06 23:08:41,131] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:08:41,151] {logging_mixin.py:115} INFO - [2023-01-06 23:08:41,151] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:08:41,161] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.840 seconds
[2023-01-06 23:09:11,228] {processor.py:153} INFO - Started process (PID=4518) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:09:11,229] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:09:11,229] {logging_mixin.py:115} INFO - [2023-01-06 23:09:11,229] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:09:12,090] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:09:12,091] {logging_mixin.py:115} INFO - [2023-01-06 23:09:12,091] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:09:12,092] {logging_mixin.py:115} INFO - [2023-01-06 23:09:12,092] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:09:12,102] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:09:12,123] {logging_mixin.py:115} INFO - [2023-01-06 23:09:12,123] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:09:12,143] {logging_mixin.py:115} INFO - [2023-01-06 23:09:12,143] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:09:12,153] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.931 seconds
[2023-01-06 23:09:42,219] {processor.py:153} INFO - Started process (PID=4537) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:09:42,220] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:09:42,221] {logging_mixin.py:115} INFO - [2023-01-06 23:09:42,221] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:09:43,008] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:09:43,010] {logging_mixin.py:115} INFO - [2023-01-06 23:09:43,010] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:09:43,010] {logging_mixin.py:115} INFO - [2023-01-06 23:09:43,010] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:09:43,018] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:09:43,039] {logging_mixin.py:115} INFO - [2023-01-06 23:09:43,039] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:09:43,059] {logging_mixin.py:115} INFO - [2023-01-06 23:09:43,059] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:09:43,069] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.855 seconds
[2023-01-06 23:10:13,104] {processor.py:153} INFO - Started process (PID=4563) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:10:13,105] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:10:13,106] {logging_mixin.py:115} INFO - [2023-01-06 23:10:13,105] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:10:13,877] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:10:13,879] {logging_mixin.py:115} INFO - [2023-01-06 23:10:13,879] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:10:13,879] {logging_mixin.py:115} INFO - [2023-01-06 23:10:13,879] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:10:13,886] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:10:13,906] {logging_mixin.py:115} INFO - [2023-01-06 23:10:13,906] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:10:13,926] {logging_mixin.py:115} INFO - [2023-01-06 23:10:13,926] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:10:13,936] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.837 seconds
[2023-01-06 23:10:44,041] {processor.py:153} INFO - Started process (PID=4590) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:10:44,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:10:44,043] {logging_mixin.py:115} INFO - [2023-01-06 23:10:44,043] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:10:44,806] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:10:44,808] {logging_mixin.py:115} INFO - [2023-01-06 23:10:44,807] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:10:44,808] {logging_mixin.py:115} INFO - [2023-01-06 23:10:44,808] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:10:44,815] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:10:44,842] {logging_mixin.py:115} INFO - [2023-01-06 23:10:44,842] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:10:44,868] {logging_mixin.py:115} INFO - [2023-01-06 23:10:44,868] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:10:44,878] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.843 seconds
[2023-01-06 23:11:14,975] {processor.py:153} INFO - Started process (PID=4616) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:11:14,976] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:11:14,976] {logging_mixin.py:115} INFO - [2023-01-06 23:11:14,976] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:11:15,740] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:11:15,741] {logging_mixin.py:115} INFO - [2023-01-06 23:11:15,741] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:11:15,741] {logging_mixin.py:115} INFO - [2023-01-06 23:11:15,741] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:11:15,748] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:11:15,768] {logging_mixin.py:115} INFO - [2023-01-06 23:11:15,768] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:11:15,788] {logging_mixin.py:115} INFO - [2023-01-06 23:11:15,787] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:11:15,797] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.827 seconds
[2023-01-06 23:11:45,883] {processor.py:153} INFO - Started process (PID=4634) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:11:45,884] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:11:45,885] {logging_mixin.py:115} INFO - [2023-01-06 23:11:45,885] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:11:46,653] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:11:46,655] {logging_mixin.py:115} INFO - [2023-01-06 23:11:46,654] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:11:46,655] {logging_mixin.py:115} INFO - [2023-01-06 23:11:46,655] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:11:46,662] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:11:46,683] {logging_mixin.py:115} INFO - [2023-01-06 23:11:46,683] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:11:46,703] {logging_mixin.py:115} INFO - [2023-01-06 23:11:46,703] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:11:46,716] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.838 seconds
[2023-01-06 23:12:16,809] {processor.py:153} INFO - Started process (PID=4660) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:12:16,810] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:12:16,811] {logging_mixin.py:115} INFO - [2023-01-06 23:12:16,810] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:12:17,596] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:12:17,597] {logging_mixin.py:115} INFO - [2023-01-06 23:12:17,597] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:12:17,598] {logging_mixin.py:115} INFO - [2023-01-06 23:12:17,597] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:12:17,604] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:12:17,625] {logging_mixin.py:115} INFO - [2023-01-06 23:12:17,625] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:12:17,644] {logging_mixin.py:115} INFO - [2023-01-06 23:12:17,644] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:12:17,654] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.849 seconds
[2023-01-06 23:12:47,720] {processor.py:153} INFO - Started process (PID=4684) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:12:47,721] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:12:47,722] {logging_mixin.py:115} INFO - [2023-01-06 23:12:47,722] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:12:48,470] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:12:48,471] {logging_mixin.py:115} INFO - [2023-01-06 23:12:48,471] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:12:48,472] {logging_mixin.py:115} INFO - [2023-01-06 23:12:48,471] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:12:48,480] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:12:48,501] {logging_mixin.py:115} INFO - [2023-01-06 23:12:48,500] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:12:48,520] {logging_mixin.py:115} INFO - [2023-01-06 23:12:48,520] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:12:48,530] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.815 seconds
[2023-01-06 23:13:18,600] {processor.py:153} INFO - Started process (PID=4709) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:13:18,600] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:13:18,601] {logging_mixin.py:115} INFO - [2023-01-06 23:13:18,601] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:13:19,358] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:13:19,360] {logging_mixin.py:115} INFO - [2023-01-06 23:13:19,360] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:13:19,360] {logging_mixin.py:115} INFO - [2023-01-06 23:13:19,360] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:13:19,367] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:13:19,388] {logging_mixin.py:115} INFO - [2023-01-06 23:13:19,388] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:13:19,408] {logging_mixin.py:115} INFO - [2023-01-06 23:13:19,408] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:13:19,418] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.823 seconds
[2023-01-06 23:13:49,483] {processor.py:153} INFO - Started process (PID=4727) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:13:49,485] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:13:49,486] {logging_mixin.py:115} INFO - [2023-01-06 23:13:49,486] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:13:50,251] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:13:50,253] {logging_mixin.py:115} INFO - [2023-01-06 23:13:50,252] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:13:50,253] {logging_mixin.py:115} INFO - [2023-01-06 23:13:50,253] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:13:50,260] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:13:50,280] {logging_mixin.py:115} INFO - [2023-01-06 23:13:50,280] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:13:50,304] {logging_mixin.py:115} INFO - [2023-01-06 23:13:50,304] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:13:50,320] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-06 23:14:20,400] {processor.py:153} INFO - Started process (PID=4753) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:14:20,400] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:14:20,401] {logging_mixin.py:115} INFO - [2023-01-06 23:14:20,401] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:14:21,157] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:14:21,158] {logging_mixin.py:115} INFO - [2023-01-06 23:14:21,158] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:14:21,159] {logging_mixin.py:115} INFO - [2023-01-06 23:14:21,158] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:14:21,165] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:14:21,186] {logging_mixin.py:115} INFO - [2023-01-06 23:14:21,186] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:14:21,206] {logging_mixin.py:115} INFO - [2023-01-06 23:14:21,205] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:14:21,216] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.820 seconds
[2023-01-06 23:14:51,319] {processor.py:153} INFO - Started process (PID=4778) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:14:51,320] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:14:51,320] {logging_mixin.py:115} INFO - [2023-01-06 23:14:51,320] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:14:52,087] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:14:52,088] {logging_mixin.py:115} INFO - [2023-01-06 23:14:52,088] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:14:52,089] {logging_mixin.py:115} INFO - [2023-01-06 23:14:52,088] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:14:52,095] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:14:52,116] {logging_mixin.py:115} INFO - [2023-01-06 23:14:52,116] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:14:52,136] {logging_mixin.py:115} INFO - [2023-01-06 23:14:52,135] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:14:52,145] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.831 seconds
[2023-01-06 23:15:22,236] {processor.py:153} INFO - Started process (PID=4804) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:15:22,236] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:15:22,237] {logging_mixin.py:115} INFO - [2023-01-06 23:15:22,237] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:15:23,081] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:15:23,082] {logging_mixin.py:115} INFO - [2023-01-06 23:15:23,082] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:15:23,083] {logging_mixin.py:115} INFO - [2023-01-06 23:15:23,082] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:15:23,089] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:15:23,111] {logging_mixin.py:115} INFO - [2023-01-06 23:15:23,111] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:15:23,130] {logging_mixin.py:115} INFO - [2023-01-06 23:15:23,130] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:15:23,140] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.909 seconds
[2023-01-06 23:15:53,244] {processor.py:153} INFO - Started process (PID=4822) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:15:53,245] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:15:53,246] {logging_mixin.py:115} INFO - [2023-01-06 23:15:53,246] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:15:53,998] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:15:54,000] {logging_mixin.py:115} INFO - [2023-01-06 23:15:53,999] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:15:54,000] {logging_mixin.py:115} INFO - [2023-01-06 23:15:54,000] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:15:54,008] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:15:54,029] {logging_mixin.py:115} INFO - [2023-01-06 23:15:54,029] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:15:54,049] {logging_mixin.py:115} INFO - [2023-01-06 23:15:54,049] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:15:54,059] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.820 seconds
[2023-01-06 23:16:24,148] {processor.py:153} INFO - Started process (PID=4846) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:16:24,150] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:16:24,150] {logging_mixin.py:115} INFO - [2023-01-06 23:16:24,150] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:16:24,933] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:16:24,934] {logging_mixin.py:115} INFO - [2023-01-06 23:16:24,934] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:16:24,934] {logging_mixin.py:115} INFO - [2023-01-06 23:16:24,934] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:16:24,941] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:16:24,962] {logging_mixin.py:115} INFO - [2023-01-06 23:16:24,962] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:16:24,982] {logging_mixin.py:115} INFO - [2023-01-06 23:16:24,982] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:16:24,991] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.848 seconds
[2023-01-06 23:16:55,077] {processor.py:153} INFO - Started process (PID=4871) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:16:55,080] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:16:55,080] {logging_mixin.py:115} INFO - [2023-01-06 23:16:55,080] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:16:55,844] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:16:55,845] {logging_mixin.py:115} INFO - [2023-01-06 23:16:55,845] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:16:55,845] {logging_mixin.py:115} INFO - [2023-01-06 23:16:55,845] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:16:55,852] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:16:55,872] {logging_mixin.py:115} INFO - [2023-01-06 23:16:55,872] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:16:55,891] {logging_mixin.py:115} INFO - [2023-01-06 23:16:55,891] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:16:55,901] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.829 seconds
[2023-01-06 23:17:25,972] {processor.py:153} INFO - Started process (PID=4897) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:17:25,973] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:17:25,974] {logging_mixin.py:115} INFO - [2023-01-06 23:17:25,974] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:17:26,742] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:17:26,743] {logging_mixin.py:115} INFO - [2023-01-06 23:17:26,743] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:17:26,743] {logging_mixin.py:115} INFO - [2023-01-06 23:17:26,743] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:17:26,750] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:17:26,776] {logging_mixin.py:115} INFO - [2023-01-06 23:17:26,776] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:17:26,798] {logging_mixin.py:115} INFO - [2023-01-06 23:17:26,798] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:17:26,810] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.842 seconds
[2023-01-06 23:17:56,884] {processor.py:153} INFO - Started process (PID=4915) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:17:56,885] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:17:56,885] {logging_mixin.py:115} INFO - [2023-01-06 23:17:56,885] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:17:57,646] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:17:57,647] {logging_mixin.py:115} INFO - [2023-01-06 23:17:57,647] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:17:57,647] {logging_mixin.py:115} INFO - [2023-01-06 23:17:57,647] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:17:57,654] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:17:57,676] {logging_mixin.py:115} INFO - [2023-01-06 23:17:57,675] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:17:57,695] {logging_mixin.py:115} INFO - [2023-01-06 23:17:57,695] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:17:57,705] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.826 seconds
[2023-01-06 23:18:28,463] {processor.py:153} INFO - Started process (PID=4939) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:18:28,464] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:18:28,465] {logging_mixin.py:115} INFO - [2023-01-06 23:18:28,464] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:18:29,289] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:18:29,291] {logging_mixin.py:115} INFO - [2023-01-06 23:18:29,290] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:18:29,291] {logging_mixin.py:115} INFO - [2023-01-06 23:18:29,291] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:18:29,302] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:18:29,330] {logging_mixin.py:115} INFO - [2023-01-06 23:18:29,329] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:18:29,360] {logging_mixin.py:115} INFO - [2023-01-06 23:18:29,360] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:18:29,374] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.915 seconds
[2023-01-06 23:18:59,468] {processor.py:153} INFO - Started process (PID=4964) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:18:59,469] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:18:59,470] {logging_mixin.py:115} INFO - [2023-01-06 23:18:59,470] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:19:00,241] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:19:00,242] {logging_mixin.py:115} INFO - [2023-01-06 23:19:00,242] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:19:00,243] {logging_mixin.py:115} INFO - [2023-01-06 23:19:00,242] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:19:00,250] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:19:00,270] {logging_mixin.py:115} INFO - [2023-01-06 23:19:00,270] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:19:00,290] {logging_mixin.py:115} INFO - [2023-01-06 23:19:00,290] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:19:00,300] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.836 seconds
[2023-01-06 23:19:30,395] {processor.py:153} INFO - Started process (PID=4990) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:19:30,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:19:30,397] {logging_mixin.py:115} INFO - [2023-01-06 23:19:30,397] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:19:31,230] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:19:31,231] {logging_mixin.py:115} INFO - [2023-01-06 23:19:31,231] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:19:31,232] {logging_mixin.py:115} INFO - [2023-01-06 23:19:31,231] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:19:31,238] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:19:31,260] {logging_mixin.py:115} INFO - [2023-01-06 23:19:31,260] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:19:31,280] {logging_mixin.py:115} INFO - [2023-01-06 23:19:31,280] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:19:31,290] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.903 seconds
[2023-01-06 23:20:01,385] {processor.py:153} INFO - Started process (PID=5009) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:20:01,386] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:20:01,387] {logging_mixin.py:115} INFO - [2023-01-06 23:20:01,387] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:20:02,170] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:20:02,171] {logging_mixin.py:115} INFO - [2023-01-06 23:20:02,171] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:20:02,171] {logging_mixin.py:115} INFO - [2023-01-06 23:20:02,171] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:20:02,178] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:20:02,199] {logging_mixin.py:115} INFO - [2023-01-06 23:20:02,199] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:20:02,218] {logging_mixin.py:115} INFO - [2023-01-06 23:20:02,218] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:20:02,228] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.848 seconds
[2023-01-06 23:20:32,494] {processor.py:153} INFO - Started process (PID=5035) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:20:32,495] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:20:32,496] {logging_mixin.py:115} INFO - [2023-01-06 23:20:32,496] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:20:33,259] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:20:33,260] {logging_mixin.py:115} INFO - [2023-01-06 23:20:33,260] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:20:33,261] {logging_mixin.py:115} INFO - [2023-01-06 23:20:33,261] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:20:33,270] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:20:33,291] {logging_mixin.py:115} INFO - [2023-01-06 23:20:33,291] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:20:33,311] {logging_mixin.py:115} INFO - [2023-01-06 23:20:33,310] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:20:33,320] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.831 seconds
[2023-01-06 23:21:03,426] {processor.py:153} INFO - Started process (PID=5062) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:21:03,429] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:21:03,429] {logging_mixin.py:115} INFO - [2023-01-06 23:21:03,429] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:21:04,198] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:21:04,199] {logging_mixin.py:115} INFO - [2023-01-06 23:21:04,199] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:21:04,199] {logging_mixin.py:115} INFO - [2023-01-06 23:21:04,199] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:21:04,206] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:21:04,227] {logging_mixin.py:115} INFO - [2023-01-06 23:21:04,227] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:21:04,247] {logging_mixin.py:115} INFO - [2023-01-06 23:21:04,246] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:21:04,257] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.835 seconds
[2023-01-06 23:21:34,349] {processor.py:153} INFO - Started process (PID=5089) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:21:34,350] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:21:34,351] {logging_mixin.py:115} INFO - [2023-01-06 23:21:34,351] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:21:35,236] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:21:35,237] {logging_mixin.py:115} INFO - [2023-01-06 23:21:35,237] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:21:35,238] {logging_mixin.py:115} INFO - [2023-01-06 23:21:35,237] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:21:35,246] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:21:35,267] {logging_mixin.py:115} INFO - [2023-01-06 23:21:35,266] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:21:35,286] {logging_mixin.py:115} INFO - [2023-01-06 23:21:35,286] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:21:35,296] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.953 seconds
[2023-01-06 23:22:05,391] {processor.py:153} INFO - Started process (PID=5109) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:22:05,392] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:22:05,393] {logging_mixin.py:115} INFO - [2023-01-06 23:22:05,393] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:22:06,165] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:22:06,167] {logging_mixin.py:115} INFO - [2023-01-06 23:22:06,167] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:22:06,167] {logging_mixin.py:115} INFO - [2023-01-06 23:22:06,167] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:22:06,174] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:22:06,195] {logging_mixin.py:115} INFO - [2023-01-06 23:22:06,195] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:22:06,214] {logging_mixin.py:115} INFO - [2023-01-06 23:22:06,214] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:22:06,226] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.839 seconds
[2023-01-06 23:22:36,762] {processor.py:153} INFO - Started process (PID=5135) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:22:36,763] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:22:36,763] {logging_mixin.py:115} INFO - [2023-01-06 23:22:36,763] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:22:37,538] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:22:37,540] {logging_mixin.py:115} INFO - [2023-01-06 23:22:37,540] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:22:37,540] {logging_mixin.py:115} INFO - [2023-01-06 23:22:37,540] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:22:37,547] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:22:37,570] {logging_mixin.py:115} INFO - [2023-01-06 23:22:37,570] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:22:37,596] {logging_mixin.py:115} INFO - [2023-01-06 23:22:37,595] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:22:37,610] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.853 seconds
[2023-01-06 23:23:07,848] {processor.py:153} INFO - Started process (PID=5161) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:23:07,848] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:23:07,849] {logging_mixin.py:115} INFO - [2023-01-06 23:23:07,849] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:23:08,622] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:23:08,623] {logging_mixin.py:115} INFO - [2023-01-06 23:23:08,623] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:23:08,624] {logging_mixin.py:115} INFO - [2023-01-06 23:23:08,623] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:23:08,630] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:23:08,651] {logging_mixin.py:115} INFO - [2023-01-06 23:23:08,651] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:23:08,671] {logging_mixin.py:115} INFO - [2023-01-06 23:23:08,671] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:23:08,682] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.838 seconds
[2023-01-06 23:23:38,778] {processor.py:153} INFO - Started process (PID=5186) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:23:38,780] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:23:38,780] {logging_mixin.py:115} INFO - [2023-01-06 23:23:38,780] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:23:39,587] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:23:39,588] {logging_mixin.py:115} INFO - [2023-01-06 23:23:39,588] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:23:39,588] {logging_mixin.py:115} INFO - [2023-01-06 23:23:39,588] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:23:39,595] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:23:39,615] {logging_mixin.py:115} INFO - [2023-01-06 23:23:39,615] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:23:39,634] {logging_mixin.py:115} INFO - [2023-01-06 23:23:39,634] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:23:39,644] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.872 seconds
[2023-01-06 23:24:09,739] {processor.py:153} INFO - Started process (PID=5205) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:24:09,741] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:24:09,741] {logging_mixin.py:115} INFO - [2023-01-06 23:24:09,741] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:24:10,508] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:24:10,510] {logging_mixin.py:115} INFO - [2023-01-06 23:24:10,509] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:24:10,510] {logging_mixin.py:115} INFO - [2023-01-06 23:24:10,510] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:24:10,517] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:24:10,538] {logging_mixin.py:115} INFO - [2023-01-06 23:24:10,537] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:24:10,557] {logging_mixin.py:115} INFO - [2023-01-06 23:24:10,557] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:24:10,567] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.832 seconds
[2023-01-06 23:24:40,656] {processor.py:153} INFO - Started process (PID=5229) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:24:40,657] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:24:40,658] {logging_mixin.py:115} INFO - [2023-01-06 23:24:40,658] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:24:41,436] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:24:41,438] {logging_mixin.py:115} INFO - [2023-01-06 23:24:41,438] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:24:41,438] {logging_mixin.py:115} INFO - [2023-01-06 23:24:41,438] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:24:41,445] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:24:41,465] {logging_mixin.py:115} INFO - [2023-01-06 23:24:41,465] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:24:41,484] {logging_mixin.py:115} INFO - [2023-01-06 23:24:41,484] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:24:41,494] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.843 seconds
[2023-01-06 23:25:11,581] {processor.py:153} INFO - Started process (PID=5254) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:25:11,582] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:25:11,582] {logging_mixin.py:115} INFO - [2023-01-06 23:25:11,582] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:25:12,351] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:25:12,352] {logging_mixin.py:115} INFO - [2023-01-06 23:25:12,352] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:25:12,352] {logging_mixin.py:115} INFO - [2023-01-06 23:25:12,352] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:25:12,359] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:25:12,379] {logging_mixin.py:115} INFO - [2023-01-06 23:25:12,379] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:25:12,399] {logging_mixin.py:115} INFO - [2023-01-06 23:25:12,399] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:25:12,409] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.832 seconds
[2023-01-06 23:25:42,500] {processor.py:153} INFO - Started process (PID=5279) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:25:42,501] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:25:42,502] {logging_mixin.py:115} INFO - [2023-01-06 23:25:42,502] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:25:43,425] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:25:43,427] {logging_mixin.py:115} INFO - [2023-01-06 23:25:43,427] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:25:43,427] {logging_mixin.py:115} INFO - [2023-01-06 23:25:43,427] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:25:43,435] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:25:43,464] {logging_mixin.py:115} INFO - [2023-01-06 23:25:43,463] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:25:43,491] {logging_mixin.py:115} INFO - [2023-01-06 23:25:43,491] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:25:43,503] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.010 seconds
[2023-01-06 23:26:13,576] {processor.py:153} INFO - Started process (PID=5298) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:26:13,576] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:26:13,577] {logging_mixin.py:115} INFO - [2023-01-06 23:26:13,577] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:26:14,353] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:26:14,354] {logging_mixin.py:115} INFO - [2023-01-06 23:26:14,354] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:26:14,355] {logging_mixin.py:115} INFO - [2023-01-06 23:26:14,355] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:26:14,361] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:26:14,382] {logging_mixin.py:115} INFO - [2023-01-06 23:26:14,382] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:26:14,401] {logging_mixin.py:115} INFO - [2023-01-06 23:26:14,401] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:26:14,411] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.840 seconds
[2023-01-06 23:26:44,643] {processor.py:153} INFO - Started process (PID=5322) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:26:44,644] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:26:44,645] {logging_mixin.py:115} INFO - [2023-01-06 23:26:44,645] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:26:45,440] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:26:45,441] {logging_mixin.py:115} INFO - [2023-01-06 23:26:45,441] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:26:45,442] {logging_mixin.py:115} INFO - [2023-01-06 23:26:45,441] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:26:45,448] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:26:45,468] {logging_mixin.py:115} INFO - [2023-01-06 23:26:45,468] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:26:45,488] {logging_mixin.py:115} INFO - [2023-01-06 23:26:45,488] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:26:45,497] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.859 seconds
[2023-01-06 23:27:15,592] {processor.py:153} INFO - Started process (PID=5348) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:27:15,592] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:27:15,593] {logging_mixin.py:115} INFO - [2023-01-06 23:27:15,593] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:27:16,398] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:27:16,399] {logging_mixin.py:115} INFO - [2023-01-06 23:27:16,399] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:27:16,400] {logging_mixin.py:115} INFO - [2023-01-06 23:27:16,399] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:27:16,406] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:27:16,428] {logging_mixin.py:115} INFO - [2023-01-06 23:27:16,427] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:27:16,447] {logging_mixin.py:115} INFO - [2023-01-06 23:27:16,447] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:27:16,457] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.870 seconds
[2023-01-06 23:27:46,550] {processor.py:153} INFO - Started process (PID=5365) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:27:46,551] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:27:46,552] {logging_mixin.py:115} INFO - [2023-01-06 23:27:46,552] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:27:47,346] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:27:47,347] {logging_mixin.py:115} INFO - [2023-01-06 23:27:47,347] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:27:47,348] {logging_mixin.py:115} INFO - [2023-01-06 23:27:47,347] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:27:47,354] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:27:47,382] {logging_mixin.py:115} INFO - [2023-01-06 23:27:47,382] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:27:47,404] {logging_mixin.py:115} INFO - [2023-01-06 23:27:47,404] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:27:47,415] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.870 seconds
[2023-01-06 23:28:17,807] {processor.py:153} INFO - Started process (PID=5392) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:28:17,808] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:28:17,809] {logging_mixin.py:115} INFO - [2023-01-06 23:28:17,809] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:28:18,562] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:28:18,564] {logging_mixin.py:115} INFO - [2023-01-06 23:28:18,564] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:28:18,564] {logging_mixin.py:115} INFO - [2023-01-06 23:28:18,564] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:28:18,571] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:28:18,591] {logging_mixin.py:115} INFO - [2023-01-06 23:28:18,591] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:28:18,611] {logging_mixin.py:115} INFO - [2023-01-06 23:28:18,611] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:28:18,622] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.819 seconds
[2023-01-06 23:28:48,714] {processor.py:153} INFO - Started process (PID=5417) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:28:48,715] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:28:48,715] {logging_mixin.py:115} INFO - [2023-01-06 23:28:48,715] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:28:49,500] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:28:49,502] {logging_mixin.py:115} INFO - [2023-01-06 23:28:49,502] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:28:49,502] {logging_mixin.py:115} INFO - [2023-01-06 23:28:49,502] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:28:49,510] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:28:49,535] {logging_mixin.py:115} INFO - [2023-01-06 23:28:49,535] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:28:49,556] {logging_mixin.py:115} INFO - [2023-01-06 23:28:49,556] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:28:49,569] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.860 seconds
[2023-01-06 23:29:19,669] {processor.py:153} INFO - Started process (PID=5443) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:29:19,670] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:29:19,671] {logging_mixin.py:115} INFO - [2023-01-06 23:29:19,671] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:29:20,455] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:29:20,456] {logging_mixin.py:115} INFO - [2023-01-06 23:29:20,456] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:29:20,457] {logging_mixin.py:115} INFO - [2023-01-06 23:29:20,456] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:29:20,463] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:29:20,484] {logging_mixin.py:115} INFO - [2023-01-06 23:29:20,484] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:29:20,503] {logging_mixin.py:115} INFO - [2023-01-06 23:29:20,503] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:29:20,513] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.849 seconds
[2023-01-06 23:29:50,602] {processor.py:153} INFO - Started process (PID=5461) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:29:50,603] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:29:50,603] {logging_mixin.py:115} INFO - [2023-01-06 23:29:50,603] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:29:51,387] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:29:51,388] {logging_mixin.py:115} INFO - [2023-01-06 23:29:51,388] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:29:51,389] {logging_mixin.py:115} INFO - [2023-01-06 23:29:51,389] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:29:51,399] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:29:51,426] {logging_mixin.py:115} INFO - [2023-01-06 23:29:51,425] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:29:51,450] {logging_mixin.py:115} INFO - [2023-01-06 23:29:51,450] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:29:51,464] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.867 seconds
[2023-01-06 23:30:21,556] {processor.py:153} INFO - Started process (PID=5488) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:30:21,557] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:30:21,558] {logging_mixin.py:115} INFO - [2023-01-06 23:30:21,558] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:30:22,319] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:30:22,320] {logging_mixin.py:115} INFO - [2023-01-06 23:30:22,320] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:30:22,321] {logging_mixin.py:115} INFO - [2023-01-06 23:30:22,320] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:30:22,327] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:30:22,348] {logging_mixin.py:115} INFO - [2023-01-06 23:30:22,347] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:30:22,367] {logging_mixin.py:115} INFO - [2023-01-06 23:30:22,367] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:30:22,378] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.826 seconds
[2023-01-06 23:30:52,464] {processor.py:153} INFO - Started process (PID=5516) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:30:52,465] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:30:52,466] {logging_mixin.py:115} INFO - [2023-01-06 23:30:52,465] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:30:53,210] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:30:53,212] {logging_mixin.py:115} INFO - [2023-01-06 23:30:53,212] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:30:53,212] {logging_mixin.py:115} INFO - [2023-01-06 23:30:53,212] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:30:53,219] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:30:53,239] {logging_mixin.py:115} INFO - [2023-01-06 23:30:53,239] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:30:53,259] {logging_mixin.py:115} INFO - [2023-01-06 23:30:53,259] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:30:53,269] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.809 seconds
[2023-01-06 23:31:23,942] {processor.py:153} INFO - Started process (PID=5542) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:31:23,943] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:31:23,944] {logging_mixin.py:115} INFO - [2023-01-06 23:31:23,944] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:31:24,706] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:31:24,707] {logging_mixin.py:115} INFO - [2023-01-06 23:31:24,707] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:31:24,708] {logging_mixin.py:115} INFO - [2023-01-06 23:31:24,707] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:31:24,714] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:31:24,735] {logging_mixin.py:115} INFO - [2023-01-06 23:31:24,735] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:31:24,754] {logging_mixin.py:115} INFO - [2023-01-06 23:31:24,754] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:31:24,764] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.826 seconds
[2023-01-06 23:31:54,852] {processor.py:153} INFO - Started process (PID=5560) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:31:54,853] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:31:54,853] {logging_mixin.py:115} INFO - [2023-01-06 23:31:54,853] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:31:55,661] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:31:55,662] {logging_mixin.py:115} INFO - [2023-01-06 23:31:55,662] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:31:55,663] {logging_mixin.py:115} INFO - [2023-01-06 23:31:55,663] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:31:55,670] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:31:55,691] {logging_mixin.py:115} INFO - [2023-01-06 23:31:55,690] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:31:55,718] {logging_mixin.py:115} INFO - [2023-01-06 23:31:55,718] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:31:55,732] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.885 seconds
[2023-01-06 23:32:25,829] {processor.py:153} INFO - Started process (PID=5584) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:32:25,830] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:32:25,830] {logging_mixin.py:115} INFO - [2023-01-06 23:32:25,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:32:26,592] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:32:26,593] {logging_mixin.py:115} INFO - [2023-01-06 23:32:26,593] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:32:26,593] {logging_mixin.py:115} INFO - [2023-01-06 23:32:26,593] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:32:26,600] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:32:26,621] {logging_mixin.py:115} INFO - [2023-01-06 23:32:26,620] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:32:26,640] {logging_mixin.py:115} INFO - [2023-01-06 23:32:26,640] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:32:26,650] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.826 seconds
[2023-01-06 23:32:56,740] {processor.py:153} INFO - Started process (PID=5611) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:32:56,741] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:32:56,742] {logging_mixin.py:115} INFO - [2023-01-06 23:32:56,742] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:32:57,497] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:32:57,498] {logging_mixin.py:115} INFO - [2023-01-06 23:32:57,498] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:32:57,499] {logging_mixin.py:115} INFO - [2023-01-06 23:32:57,499] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:32:57,506] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:32:57,526] {logging_mixin.py:115} INFO - [2023-01-06 23:32:57,526] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:32:57,546] {logging_mixin.py:115} INFO - [2023-01-06 23:32:57,545] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:32:57,556] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.820 seconds
[2023-01-06 23:33:27,656] {processor.py:153} INFO - Started process (PID=5637) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:33:27,657] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:33:27,658] {logging_mixin.py:115} INFO - [2023-01-06 23:33:27,658] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:33:28,541] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:33:28,542] {logging_mixin.py:115} INFO - [2023-01-06 23:33:28,542] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:33:28,543] {logging_mixin.py:115} INFO - [2023-01-06 23:33:28,543] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:33:28,550] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:33:28,570] {logging_mixin.py:115} INFO - [2023-01-06 23:33:28,570] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:33:28,590] {logging_mixin.py:115} INFO - [2023-01-06 23:33:28,590] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:33:28,600] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.949 seconds
[2023-01-06 23:33:58,690] {processor.py:153} INFO - Started process (PID=5654) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:33:58,691] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:33:58,692] {logging_mixin.py:115} INFO - [2023-01-06 23:33:58,692] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:33:59,458] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:33:59,459] {logging_mixin.py:115} INFO - [2023-01-06 23:33:59,459] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:33:59,460] {logging_mixin.py:115} INFO - [2023-01-06 23:33:59,459] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:33:59,466] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:33:59,487] {logging_mixin.py:115} INFO - [2023-01-06 23:33:59,487] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:33:59,506] {logging_mixin.py:115} INFO - [2023-01-06 23:33:59,506] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:33:59,516] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.831 seconds
[2023-01-06 23:34:29,601] {processor.py:153} INFO - Started process (PID=5679) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:34:29,602] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:34:29,603] {logging_mixin.py:115} INFO - [2023-01-06 23:34:29,603] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:34:30,349] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:34:30,351] {logging_mixin.py:115} INFO - [2023-01-06 23:34:30,351] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:34:30,351] {logging_mixin.py:115} INFO - [2023-01-06 23:34:30,351] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:34:30,358] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:34:30,379] {logging_mixin.py:115} INFO - [2023-01-06 23:34:30,379] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:34:30,398] {logging_mixin.py:115} INFO - [2023-01-06 23:34:30,398] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:34:30,409] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.812 seconds
[2023-01-06 23:35:00,482] {processor.py:153} INFO - Started process (PID=5704) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:35:00,483] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:35:00,484] {logging_mixin.py:115} INFO - [2023-01-06 23:35:00,484] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:35:01,287] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:35:01,289] {logging_mixin.py:115} INFO - [2023-01-06 23:35:01,289] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:35:01,289] {logging_mixin.py:115} INFO - [2023-01-06 23:35:01,289] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:35:01,298] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:35:01,324] {logging_mixin.py:115} INFO - [2023-01-06 23:35:01,324] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:35:01,344] {logging_mixin.py:115} INFO - [2023-01-06 23:35:01,344] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:35:01,354] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.877 seconds
[2023-01-06 23:35:31,420] {processor.py:153} INFO - Started process (PID=5728) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:35:31,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:35:31,421] {logging_mixin.py:115} INFO - [2023-01-06 23:35:31,421] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:35:32,250] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:35:32,251] {logging_mixin.py:115} INFO - [2023-01-06 23:35:32,251] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:35:32,252] {logging_mixin.py:115} INFO - [2023-01-06 23:35:32,252] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:35:32,258] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:35:32,279] {logging_mixin.py:115} INFO - [2023-01-06 23:35:32,279] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:35:32,298] {logging_mixin.py:115} INFO - [2023-01-06 23:35:32,298] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:35:32,308] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.893 seconds
[2023-01-06 23:36:02,378] {processor.py:153} INFO - Started process (PID=5746) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:36:02,379] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:36:02,380] {logging_mixin.py:115} INFO - [2023-01-06 23:36:02,380] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:36:03,201] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:36:03,203] {logging_mixin.py:115} INFO - [2023-01-06 23:36:03,203] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:36:03,203] {logging_mixin.py:115} INFO - [2023-01-06 23:36:03,203] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:36:03,210] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:36:03,231] {logging_mixin.py:115} INFO - [2023-01-06 23:36:03,231] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:36:03,252] {logging_mixin.py:115} INFO - [2023-01-06 23:36:03,252] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:36:03,261] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.888 seconds
[2023-01-06 23:36:33,329] {processor.py:153} INFO - Started process (PID=5771) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:36:33,330] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:36:33,331] {logging_mixin.py:115} INFO - [2023-01-06 23:36:33,331] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:36:34,167] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:36:34,169] {logging_mixin.py:115} INFO - [2023-01-06 23:36:34,169] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:36:34,169] {logging_mixin.py:115} INFO - [2023-01-06 23:36:34,169] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:36:34,176] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:36:34,197] {logging_mixin.py:115} INFO - [2023-01-06 23:36:34,196] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:36:34,218] {logging_mixin.py:115} INFO - [2023-01-06 23:36:34,217] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:36:34,227] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.902 seconds
[2023-01-06 23:37:04,295] {processor.py:153} INFO - Started process (PID=5796) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:37:04,298] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:37:04,299] {logging_mixin.py:115} INFO - [2023-01-06 23:37:04,299] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:37:05,043] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:37:05,044] {logging_mixin.py:115} INFO - [2023-01-06 23:37:05,044] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:37:05,044] {logging_mixin.py:115} INFO - [2023-01-06 23:37:05,044] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:37:05,051] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:37:05,072] {logging_mixin.py:115} INFO - [2023-01-06 23:37:05,072] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:37:05,093] {logging_mixin.py:115} INFO - [2023-01-06 23:37:05,093] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:37:05,102] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.812 seconds
[2023-01-06 23:37:35,168] {processor.py:153} INFO - Started process (PID=5821) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:37:35,168] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:37:35,170] {logging_mixin.py:115} INFO - [2023-01-06 23:37:35,170] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:37:35,955] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:37:35,956] {logging_mixin.py:115} INFO - [2023-01-06 23:37:35,956] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:37:35,956] {logging_mixin.py:115} INFO - [2023-01-06 23:37:35,956] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:37:35,963] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:37:35,984] {logging_mixin.py:115} INFO - [2023-01-06 23:37:35,984] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:37:36,005] {logging_mixin.py:115} INFO - [2023-01-06 23:37:36,005] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:37:36,014] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.851 seconds
[2023-01-06 23:38:06,082] {processor.py:153} INFO - Started process (PID=5839) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:38:06,083] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:38:06,085] {logging_mixin.py:115} INFO - [2023-01-06 23:38:06,085] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:38:06,993] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:38:06,994] {logging_mixin.py:115} INFO - [2023-01-06 23:38:06,994] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:38:06,994] {logging_mixin.py:115} INFO - [2023-01-06 23:38:06,994] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:38:07,001] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:38:07,022] {logging_mixin.py:115} INFO - [2023-01-06 23:38:07,022] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:38:07,042] {logging_mixin.py:115} INFO - [2023-01-06 23:38:07,042] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:38:07,052] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.974 seconds
[2023-01-06 23:38:37,116] {processor.py:153} INFO - Started process (PID=5864) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:38:37,116] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:38:37,118] {logging_mixin.py:115} INFO - [2023-01-06 23:38:37,118] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:38:37,892] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:38:37,894] {logging_mixin.py:115} INFO - [2023-01-06 23:38:37,894] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:38:37,894] {logging_mixin.py:115} INFO - [2023-01-06 23:38:37,894] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:38:37,901] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:38:37,921] {logging_mixin.py:115} INFO - [2023-01-06 23:38:37,921] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:38:37,941] {logging_mixin.py:115} INFO - [2023-01-06 23:38:37,941] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:38:37,950] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.839 seconds
[2023-01-06 23:39:08,034] {processor.py:153} INFO - Started process (PID=5890) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:39:08,036] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:39:08,037] {logging_mixin.py:115} INFO - [2023-01-06 23:39:08,037] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:39:08,836] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:39:08,838] {logging_mixin.py:115} INFO - [2023-01-06 23:39:08,838] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:39:08,838] {logging_mixin.py:115} INFO - [2023-01-06 23:39:08,838] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:39:08,845] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:39:08,866] {logging_mixin.py:115} INFO - [2023-01-06 23:39:08,865] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:39:08,886] {logging_mixin.py:115} INFO - [2023-01-06 23:39:08,886] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:39:08,895] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.866 seconds
[2023-01-06 23:39:38,989] {processor.py:153} INFO - Started process (PID=5914) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:39:38,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:39:38,991] {logging_mixin.py:115} INFO - [2023-01-06 23:39:38,991] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:39:39,951] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:39:39,952] {logging_mixin.py:115} INFO - [2023-01-06 23:39:39,952] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:39:39,952] {logging_mixin.py:115} INFO - [2023-01-06 23:39:39,952] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:39:39,959] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:39:39,980] {logging_mixin.py:115} INFO - [2023-01-06 23:39:39,980] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:39:40,000] {logging_mixin.py:115} INFO - [2023-01-06 23:39:40,000] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:39:40,009] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.026 seconds
[2023-01-06 23:40:10,045] {processor.py:153} INFO - Started process (PID=5934) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:40:10,046] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:40:10,048] {logging_mixin.py:115} INFO - [2023-01-06 23:40:10,048] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:40:10,837] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:40:10,839] {logging_mixin.py:115} INFO - [2023-01-06 23:40:10,838] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:40:10,839] {logging_mixin.py:115} INFO - [2023-01-06 23:40:10,839] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:40:10,846] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:40:10,868] {logging_mixin.py:115} INFO - [2023-01-06 23:40:10,867] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:40:10,888] {logging_mixin.py:115} INFO - [2023-01-06 23:40:10,888] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:40:10,898] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.857 seconds
[2023-01-06 23:40:41,004] {processor.py:153} INFO - Started process (PID=5958) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:40:41,004] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:40:41,005] {logging_mixin.py:115} INFO - [2023-01-06 23:40:41,005] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:40:41,769] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:40:41,770] {logging_mixin.py:115} INFO - [2023-01-06 23:40:41,770] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:40:41,771] {logging_mixin.py:115} INFO - [2023-01-06 23:40:41,770] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:40:41,778] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:40:41,800] {logging_mixin.py:115} INFO - [2023-01-06 23:40:41,800] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:40:41,821] {logging_mixin.py:115} INFO - [2023-01-06 23:40:41,821] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:40:41,830] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.831 seconds
[2023-01-06 23:41:11,922] {processor.py:153} INFO - Started process (PID=5982) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:41:11,923] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:41:11,924] {logging_mixin.py:115} INFO - [2023-01-06 23:41:11,924] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:41:12,703] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:41:12,705] {logging_mixin.py:115} INFO - [2023-01-06 23:41:12,705] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:41:12,705] {logging_mixin.py:115} INFO - [2023-01-06 23:41:12,705] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:41:12,712] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:41:12,733] {logging_mixin.py:115} INFO - [2023-01-06 23:41:12,733] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:41:12,754] {logging_mixin.py:115} INFO - [2023-01-06 23:41:12,753] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:41:12,763] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.845 seconds
[2023-01-06 23:41:42,848] {processor.py:153} INFO - Started process (PID=6007) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:41:42,849] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:41:42,849] {logging_mixin.py:115} INFO - [2023-01-06 23:41:42,849] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:41:43,600] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:41:43,602] {logging_mixin.py:115} INFO - [2023-01-06 23:41:43,601] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:41:43,602] {logging_mixin.py:115} INFO - [2023-01-06 23:41:43,602] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:41:43,608] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:41:43,629] {logging_mixin.py:115} INFO - [2023-01-06 23:41:43,629] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:41:43,650] {logging_mixin.py:115} INFO - [2023-01-06 23:41:43,650] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:41:43,659] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.816 seconds
[2023-01-06 23:42:13,742] {processor.py:153} INFO - Started process (PID=6025) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:42:13,746] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:42:13,747] {logging_mixin.py:115} INFO - [2023-01-06 23:42:13,747] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:42:14,554] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:42:14,556] {logging_mixin.py:115} INFO - [2023-01-06 23:42:14,555] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:42:14,556] {logging_mixin.py:115} INFO - [2023-01-06 23:42:14,556] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:42:14,563] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:42:14,584] {logging_mixin.py:115} INFO - [2023-01-06 23:42:14,584] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:42:14,605] {logging_mixin.py:115} INFO - [2023-01-06 23:42:14,605] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:42:14,614] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.878 seconds
[2023-01-06 23:42:44,695] {processor.py:153} INFO - Started process (PID=6049) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:42:44,696] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:42:44,696] {logging_mixin.py:115} INFO - [2023-01-06 23:42:44,696] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:42:45,470] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:42:45,471] {logging_mixin.py:115} INFO - [2023-01-06 23:42:45,471] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:42:45,472] {logging_mixin.py:115} INFO - [2023-01-06 23:42:45,472] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:42:45,478] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:42:45,504] {logging_mixin.py:115} INFO - [2023-01-06 23:42:45,504] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:42:45,532] {logging_mixin.py:115} INFO - [2023-01-06 23:42:45,532] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:42:45,545] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.855 seconds
[2023-01-06 23:43:15,619] {processor.py:153} INFO - Started process (PID=6074) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:43:15,620] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:43:15,620] {logging_mixin.py:115} INFO - [2023-01-06 23:43:15,620] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:43:16,375] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:43:16,377] {logging_mixin.py:115} INFO - [2023-01-06 23:43:16,376] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:43:16,377] {logging_mixin.py:115} INFO - [2023-01-06 23:43:16,377] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:43:16,384] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:43:16,405] {logging_mixin.py:115} INFO - [2023-01-06 23:43:16,405] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:43:16,425] {logging_mixin.py:115} INFO - [2023-01-06 23:43:16,425] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:43:16,434] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.820 seconds
[2023-01-06 23:43:46,499] {processor.py:153} INFO - Started process (PID=6099) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:43:46,502] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:43:46,503] {logging_mixin.py:115} INFO - [2023-01-06 23:43:46,502] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:43:47,300] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:43:47,301] {logging_mixin.py:115} INFO - [2023-01-06 23:43:47,301] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:43:47,302] {logging_mixin.py:115} INFO - [2023-01-06 23:43:47,301] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:43:47,308] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:43:47,329] {logging_mixin.py:115} INFO - [2023-01-06 23:43:47,328] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:43:47,349] {logging_mixin.py:115} INFO - [2023-01-06 23:43:47,349] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:43:47,358] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.864 seconds
[2023-01-06 23:44:17,437] {processor.py:153} INFO - Started process (PID=6117) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:44:17,438] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:44:17,439] {logging_mixin.py:115} INFO - [2023-01-06 23:44:17,439] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:44:18,645] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:44:18,647] {logging_mixin.py:115} INFO - [2023-01-06 23:44:18,647] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:44:18,647] {logging_mixin.py:115} INFO - [2023-01-06 23:44:18,647] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:44:18,664] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:44:18,727] {logging_mixin.py:115} INFO - [2023-01-06 23:44:18,725] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:44:18,767] {logging_mixin.py:115} INFO - [2023-01-06 23:44:18,766] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:44:18,778] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.348 seconds
[2023-01-06 23:44:48,858] {processor.py:153} INFO - Started process (PID=6142) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:44:48,860] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:44:48,860] {logging_mixin.py:115} INFO - [2023-01-06 23:44:48,860] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:44:49,641] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:44:49,642] {logging_mixin.py:115} INFO - [2023-01-06 23:44:49,642] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:44:49,642] {logging_mixin.py:115} INFO - [2023-01-06 23:44:49,642] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:44:49,649] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:44:49,670] {logging_mixin.py:115} INFO - [2023-01-06 23:44:49,669] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:44:49,690] {logging_mixin.py:115} INFO - [2023-01-06 23:44:49,690] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:44:49,699] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.845 seconds
[2023-01-06 23:45:20,526] {processor.py:153} INFO - Started process (PID=6167) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:45:20,528] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:45:20,528] {logging_mixin.py:115} INFO - [2023-01-06 23:45:20,528] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:45:21,274] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:45:21,275] {logging_mixin.py:115} INFO - [2023-01-06 23:45:21,275] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:45:21,276] {logging_mixin.py:115} INFO - [2023-01-06 23:45:21,275] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:45:21,282] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:45:21,303] {logging_mixin.py:115} INFO - [2023-01-06 23:45:21,303] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:45:21,323] {logging_mixin.py:115} INFO - [2023-01-06 23:45:21,323] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:45:21,336] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.815 seconds
[2023-01-06 23:45:51,443] {processor.py:153} INFO - Started process (PID=6192) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:45:51,444] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:45:51,445] {logging_mixin.py:115} INFO - [2023-01-06 23:45:51,445] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:45:52,209] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:45:52,211] {logging_mixin.py:115} INFO - [2023-01-06 23:45:52,211] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:45:52,212] {logging_mixin.py:115} INFO - [2023-01-06 23:45:52,211] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:45:52,223] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:45:52,245] {logging_mixin.py:115} INFO - [2023-01-06 23:45:52,244] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:45:52,265] {logging_mixin.py:115} INFO - [2023-01-06 23:45:52,265] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:45:52,275] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.836 seconds
[2023-01-06 23:46:22,368] {processor.py:153} INFO - Started process (PID=6209) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:46:22,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:46:22,370] {logging_mixin.py:115} INFO - [2023-01-06 23:46:22,370] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:46:23,177] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:46:23,179] {logging_mixin.py:115} INFO - [2023-01-06 23:46:23,178] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:46:23,179] {logging_mixin.py:115} INFO - [2023-01-06 23:46:23,179] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:46:23,186] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:46:23,207] {logging_mixin.py:115} INFO - [2023-01-06 23:46:23,207] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:46:23,228] {logging_mixin.py:115} INFO - [2023-01-06 23:46:23,227] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:46:23,237] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.874 seconds
[2023-01-06 23:46:53,333] {processor.py:153} INFO - Started process (PID=6234) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:46:53,334] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:46:53,334] {logging_mixin.py:115} INFO - [2023-01-06 23:46:53,334] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:46:54,076] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:46:54,077] {logging_mixin.py:115} INFO - [2023-01-06 23:46:54,077] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:46:54,077] {logging_mixin.py:115} INFO - [2023-01-06 23:46:54,077] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:46:54,084] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:46:54,105] {logging_mixin.py:115} INFO - [2023-01-06 23:46:54,105] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:46:54,125] {logging_mixin.py:115} INFO - [2023-01-06 23:46:54,125] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:46:54,134] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.805 seconds
[2023-01-06 23:47:24,224] {processor.py:153} INFO - Started process (PID=6258) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:47:24,225] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:47:24,226] {logging_mixin.py:115} INFO - [2023-01-06 23:47:24,226] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:47:25,008] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:47:25,009] {logging_mixin.py:115} INFO - [2023-01-06 23:47:25,009] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:47:25,010] {logging_mixin.py:115} INFO - [2023-01-06 23:47:25,010] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:47:25,016] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:47:25,040] {logging_mixin.py:115} INFO - [2023-01-06 23:47:25,040] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:47:25,061] {logging_mixin.py:115} INFO - [2023-01-06 23:47:25,060] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:47:25,069] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.850 seconds
[2023-01-06 23:47:55,145] {processor.py:153} INFO - Started process (PID=6282) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:47:55,146] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:47:55,148] {logging_mixin.py:115} INFO - [2023-01-06 23:47:55,148] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:47:55,913] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:47:55,914] {logging_mixin.py:115} INFO - [2023-01-06 23:47:55,914] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:47:55,915] {logging_mixin.py:115} INFO - [2023-01-06 23:47:55,914] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:47:55,921] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:47:55,942] {logging_mixin.py:115} INFO - [2023-01-06 23:47:55,942] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:47:55,963] {logging_mixin.py:115} INFO - [2023-01-06 23:47:55,963] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:47:55,971] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.831 seconds
[2023-01-06 23:48:26,039] {processor.py:153} INFO - Started process (PID=6300) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:48:26,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:48:26,041] {logging_mixin.py:115} INFO - [2023-01-06 23:48:26,041] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:48:26,841] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:48:26,842] {logging_mixin.py:115} INFO - [2023-01-06 23:48:26,842] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:48:26,843] {logging_mixin.py:115} INFO - [2023-01-06 23:48:26,842] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:48:26,849] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:48:26,870] {logging_mixin.py:115} INFO - [2023-01-06 23:48:26,870] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:48:26,891] {logging_mixin.py:115} INFO - [2023-01-06 23:48:26,891] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:48:26,900] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.866 seconds
[2023-01-06 23:48:56,969] {processor.py:153} INFO - Started process (PID=6326) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:48:56,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:48:56,971] {logging_mixin.py:115} INFO - [2023-01-06 23:48:56,971] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:48:57,741] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:48:57,744] {logging_mixin.py:115} INFO - [2023-01-06 23:48:57,743] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:48:57,744] {logging_mixin.py:115} INFO - [2023-01-06 23:48:57,744] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:48:57,751] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:48:57,774] {logging_mixin.py:115} INFO - [2023-01-06 23:48:57,774] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:48:57,795] {logging_mixin.py:115} INFO - [2023-01-06 23:48:57,794] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:48:57,804] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.839 seconds
[2023-01-06 23:49:27,872] {processor.py:153} INFO - Started process (PID=6352) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:49:27,873] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:49:27,874] {logging_mixin.py:115} INFO - [2023-01-06 23:49:27,874] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:49:28,636] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:49:28,637] {logging_mixin.py:115} INFO - [2023-01-06 23:49:28,637] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:49:28,638] {logging_mixin.py:115} INFO - [2023-01-06 23:49:28,637] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:49:28,644] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:49:28,666] {logging_mixin.py:115} INFO - [2023-01-06 23:49:28,666] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:49:28,687] {logging_mixin.py:115} INFO - [2023-01-06 23:49:28,687] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:49:28,696] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.828 seconds
[2023-01-06 23:49:59,704] {processor.py:153} INFO - Started process (PID=6375) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:49:59,704] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:49:59,705] {logging_mixin.py:115} INFO - [2023-01-06 23:49:59,705] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:50:00,463] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:50:00,464] {logging_mixin.py:115} INFO - [2023-01-06 23:50:00,464] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:50:00,465] {logging_mixin.py:115} INFO - [2023-01-06 23:50:00,465] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:50:00,472] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:50:00,497] {logging_mixin.py:115} INFO - [2023-01-06 23:50:00,497] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:50:00,521] {logging_mixin.py:115} INFO - [2023-01-06 23:50:00,521] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:50:00,532] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.833 seconds
[2023-01-06 23:50:30,628] {processor.py:153} INFO - Started process (PID=6399) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:50:30,629] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:50:30,630] {logging_mixin.py:115} INFO - [2023-01-06 23:50:30,630] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:50:31,458] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:50:31,459] {logging_mixin.py:115} INFO - [2023-01-06 23:50:31,459] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:50:31,460] {logging_mixin.py:115} INFO - [2023-01-06 23:50:31,459] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:50:31,466] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:50:31,487] {logging_mixin.py:115} INFO - [2023-01-06 23:50:31,487] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:50:31,507] {logging_mixin.py:115} INFO - [2023-01-06 23:50:31,507] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:50:31,516] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.893 seconds
[2023-01-06 23:51:01,622] {processor.py:153} INFO - Started process (PID=6418) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:51:01,623] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:51:01,624] {logging_mixin.py:115} INFO - [2023-01-06 23:51:01,624] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:51:02,401] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:51:02,402] {logging_mixin.py:115} INFO - [2023-01-06 23:51:02,402] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:51:02,403] {logging_mixin.py:115} INFO - [2023-01-06 23:51:02,402] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:51:02,409] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:51:02,438] {logging_mixin.py:115} INFO - [2023-01-06 23:51:02,438] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:51:02,466] {logging_mixin.py:115} INFO - [2023-01-06 23:51:02,466] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:51:02,475] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.857 seconds
[2023-01-06 23:51:32,566] {processor.py:153} INFO - Started process (PID=6444) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:51:32,567] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:51:32,567] {logging_mixin.py:115} INFO - [2023-01-06 23:51:32,567] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:51:33,344] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:51:33,346] {logging_mixin.py:115} INFO - [2023-01-06 23:51:33,345] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:51:33,346] {logging_mixin.py:115} INFO - [2023-01-06 23:51:33,346] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:51:33,353] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:51:33,374] {logging_mixin.py:115} INFO - [2023-01-06 23:51:33,374] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:51:33,395] {logging_mixin.py:115} INFO - [2023-01-06 23:51:33,394] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:51:33,403] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.842 seconds
[2023-01-06 23:52:03,495] {processor.py:153} INFO - Started process (PID=6470) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:52:03,497] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:52:03,497] {logging_mixin.py:115} INFO - [2023-01-06 23:52:03,497] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:52:04,289] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:52:04,291] {logging_mixin.py:115} INFO - [2023-01-06 23:52:04,290] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:52:04,291] {logging_mixin.py:115} INFO - [2023-01-06 23:52:04,291] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:52:04,301] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:52:04,336] {logging_mixin.py:115} INFO - [2023-01-06 23:52:04,336] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:52:04,359] {logging_mixin.py:115} INFO - [2023-01-06 23:52:04,359] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:52:04,368] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.877 seconds
[2023-01-06 23:52:34,471] {processor.py:153} INFO - Started process (PID=6496) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:52:34,472] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:52:34,473] {logging_mixin.py:115} INFO - [2023-01-06 23:52:34,473] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:52:35,288] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:52:35,289] {logging_mixin.py:115} INFO - [2023-01-06 23:52:35,289] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:52:35,290] {logging_mixin.py:115} INFO - [2023-01-06 23:52:35,289] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:52:35,296] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:52:35,317] {logging_mixin.py:115} INFO - [2023-01-06 23:52:35,317] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:52:35,338] {logging_mixin.py:115} INFO - [2023-01-06 23:52:35,337] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:52:35,347] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.881 seconds
[2023-01-06 23:53:05,440] {processor.py:153} INFO - Started process (PID=6514) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:53:05,441] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:53:05,441] {logging_mixin.py:115} INFO - [2023-01-06 23:53:05,441] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:53:06,223] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:53:06,225] {logging_mixin.py:115} INFO - [2023-01-06 23:53:06,225] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:53:06,225] {logging_mixin.py:115} INFO - [2023-01-06 23:53:06,225] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:53:06,232] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:53:06,253] {logging_mixin.py:115} INFO - [2023-01-06 23:53:06,252] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:53:06,273] {logging_mixin.py:115} INFO - [2023-01-06 23:53:06,273] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:53:06,282] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.846 seconds
[2023-01-06 23:53:36,378] {processor.py:153} INFO - Started process (PID=6539) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:53:36,379] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:53:36,380] {logging_mixin.py:115} INFO - [2023-01-06 23:53:36,380] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:53:37,138] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:53:37,139] {logging_mixin.py:115} INFO - [2023-01-06 23:53:37,139] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:53:37,139] {logging_mixin.py:115} INFO - [2023-01-06 23:53:37,139] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:53:37,146] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:53:37,167] {logging_mixin.py:115} INFO - [2023-01-06 23:53:37,167] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:53:37,187] {logging_mixin.py:115} INFO - [2023-01-06 23:53:37,187] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:53:37,196] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.824 seconds
[2023-01-06 23:54:07,715] {processor.py:153} INFO - Started process (PID=6566) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:54:07,717] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:54:07,717] {logging_mixin.py:115} INFO - [2023-01-06 23:54:07,717] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:54:08,467] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:54:08,468] {logging_mixin.py:115} INFO - [2023-01-06 23:54:08,468] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:54:08,468] {logging_mixin.py:115} INFO - [2023-01-06 23:54:08,468] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:54:08,475] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:54:08,496] {logging_mixin.py:115} INFO - [2023-01-06 23:54:08,496] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:54:08,517] {logging_mixin.py:115} INFO - [2023-01-06 23:54:08,517] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:54:08,526] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.815 seconds
[2023-01-06 23:54:38,819] {processor.py:153} INFO - Started process (PID=6591) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:54:38,819] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:54:38,820] {logging_mixin.py:115} INFO - [2023-01-06 23:54:38,820] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:54:39,577] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:54:39,578] {logging_mixin.py:115} INFO - [2023-01-06 23:54:39,578] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:54:39,579] {logging_mixin.py:115} INFO - [2023-01-06 23:54:39,579] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:54:39,585] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:54:39,606] {logging_mixin.py:115} INFO - [2023-01-06 23:54:39,605] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:54:39,626] {logging_mixin.py:115} INFO - [2023-01-06 23:54:39,626] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:54:39,635] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.820 seconds
[2023-01-06 23:55:09,734] {processor.py:153} INFO - Started process (PID=6610) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:55:09,735] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:55:09,736] {logging_mixin.py:115} INFO - [2023-01-06 23:55:09,736] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:55:10,531] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:55:10,533] {logging_mixin.py:115} INFO - [2023-01-06 23:55:10,533] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:55:10,533] {logging_mixin.py:115} INFO - [2023-01-06 23:55:10,533] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:55:10,540] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:55:10,561] {logging_mixin.py:115} INFO - [2023-01-06 23:55:10,560] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:55:10,582] {logging_mixin.py:115} INFO - [2023-01-06 23:55:10,581] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:55:10,591] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.863 seconds
[2023-01-06 23:55:40,691] {processor.py:153} INFO - Started process (PID=6635) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:55:40,692] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:55:40,693] {logging_mixin.py:115} INFO - [2023-01-06 23:55:40,693] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:55:41,441] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:55:41,442] {logging_mixin.py:115} INFO - [2023-01-06 23:55:41,442] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:55:41,443] {logging_mixin.py:115} INFO - [2023-01-06 23:55:41,443] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:55:41,449] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:55:41,470] {logging_mixin.py:115} INFO - [2023-01-06 23:55:41,470] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:55:41,490] {logging_mixin.py:115} INFO - [2023-01-06 23:55:41,490] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:55:41,499] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.813 seconds
[2023-01-06 23:56:11,815] {processor.py:153} INFO - Started process (PID=6660) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:56:11,816] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:56:11,817] {logging_mixin.py:115} INFO - [2023-01-06 23:56:11,817] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:56:12,569] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:56:12,571] {logging_mixin.py:115} INFO - [2023-01-06 23:56:12,571] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:56:12,571] {logging_mixin.py:115} INFO - [2023-01-06 23:56:12,571] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:56:12,578] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:56:12,598] {logging_mixin.py:115} INFO - [2023-01-06 23:56:12,598] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:56:12,619] {logging_mixin.py:115} INFO - [2023-01-06 23:56:12,619] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:56:12,628] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.818 seconds
[2023-01-06 23:56:42,715] {processor.py:153} INFO - Started process (PID=6685) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:56:42,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:56:42,716] {logging_mixin.py:115} INFO - [2023-01-06 23:56:42,716] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:56:43,492] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:56:43,494] {logging_mixin.py:115} INFO - [2023-01-06 23:56:43,494] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:56:43,494] {logging_mixin.py:115} INFO - [2023-01-06 23:56:43,494] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:56:43,501] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:56:43,522] {logging_mixin.py:115} INFO - [2023-01-06 23:56:43,522] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:56:43,542] {logging_mixin.py:115} INFO - [2023-01-06 23:56:43,542] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:56:43,551] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.841 seconds
[2023-01-06 23:57:13,643] {processor.py:153} INFO - Started process (PID=6703) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:57:13,644] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:57:13,644] {logging_mixin.py:115} INFO - [2023-01-06 23:57:13,644] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:57:14,429] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:57:14,431] {logging_mixin.py:115} INFO - [2023-01-06 23:57:14,430] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:57:14,431] {logging_mixin.py:115} INFO - [2023-01-06 23:57:14,431] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:57:14,439] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:57:14,462] {logging_mixin.py:115} INFO - [2023-01-06 23:57:14,462] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:57:14,484] {logging_mixin.py:115} INFO - [2023-01-06 23:57:14,484] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:57:14,498] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.860 seconds
[2023-01-06 23:57:44,588] {processor.py:153} INFO - Started process (PID=6728) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:57:44,589] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:57:44,589] {logging_mixin.py:115} INFO - [2023-01-06 23:57:44,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:57:45,349] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:57:45,350] {logging_mixin.py:115} INFO - [2023-01-06 23:57:45,350] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:57:45,351] {logging_mixin.py:115} INFO - [2023-01-06 23:57:45,351] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:57:45,357] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:57:45,378] {logging_mixin.py:115} INFO - [2023-01-06 23:57:45,378] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:57:45,400] {logging_mixin.py:115} INFO - [2023-01-06 23:57:45,400] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:57:45,409] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.826 seconds
[2023-01-06 23:58:15,475] {processor.py:153} INFO - Started process (PID=6753) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:58:15,476] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:58:15,476] {logging_mixin.py:115} INFO - [2023-01-06 23:58:15,476] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:58:16,218] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:58:16,219] {logging_mixin.py:115} INFO - [2023-01-06 23:58:16,219] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:58:16,220] {logging_mixin.py:115} INFO - [2023-01-06 23:58:16,220] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:58:16,227] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:58:16,248] {logging_mixin.py:115} INFO - [2023-01-06 23:58:16,248] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:58:16,269] {logging_mixin.py:115} INFO - [2023-01-06 23:58:16,269] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:58:16,278] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.808 seconds
[2023-01-06 23:58:46,344] {processor.py:153} INFO - Started process (PID=6778) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:58:46,345] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:58:46,346] {logging_mixin.py:115} INFO - [2023-01-06 23:58:46,346] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:58:47,093] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:58:47,094] {logging_mixin.py:115} INFO - [2023-01-06 23:58:47,094] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:58:47,095] {logging_mixin.py:115} INFO - [2023-01-06 23:58:47,095] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:58:47,101] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:58:47,122] {logging_mixin.py:115} INFO - [2023-01-06 23:58:47,122] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:58:47,142] {logging_mixin.py:115} INFO - [2023-01-06 23:58:47,142] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:58:47,151] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.811 seconds
[2023-01-06 23:59:17,216] {processor.py:153} INFO - Started process (PID=6796) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:59:17,217] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:59:17,217] {logging_mixin.py:115} INFO - [2023-01-06 23:59:17,217] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:59:17,972] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:59:17,974] {logging_mixin.py:115} INFO - [2023-01-06 23:59:17,974] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:59:17,974] {logging_mixin.py:115} INFO - [2023-01-06 23:59:17,974] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:59:17,981] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:59:18,002] {logging_mixin.py:115} INFO - [2023-01-06 23:59:18,001] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:59:18,022] {logging_mixin.py:115} INFO - [2023-01-06 23:59:18,022] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:59:18,031] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.819 seconds
[2023-01-06 23:59:48,099] {processor.py:153} INFO - Started process (PID=6821) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:59:48,100] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-06 23:59:48,101] {logging_mixin.py:115} INFO - [2023-01-06 23:59:48,101] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:59:48,864] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-06 23:59:48,866] {logging_mixin.py:115} INFO - [2023-01-06 23:59:48,865] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-06 23:59:48,866] {logging_mixin.py:115} INFO - [2023-01-06 23:59:48,866] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-06 23:59:48,873] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-06 23:59:48,899] {logging_mixin.py:115} INFO - [2023-01-06 23:59:48,899] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-06 23:59:48,920] {logging_mixin.py:115} INFO - [2023-01-06 23:59:48,920] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-06T22:55:00+00:00, run_after=2023-01-07T22:55:00+00:00
[2023-01-06 23:59:48,930] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.835 seconds

[2023-01-05 00:00:21,205] {processor.py:153} INFO - Started process (PID=968) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:00:21,206] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:00:21,207] {logging_mixin.py:115} INFO - [2023-01-05 00:00:21,207] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:00:22,102] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:00:22,103] {logging_mixin.py:115} INFO - [2023-01-05 00:00:22,103] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:00:22,104] {logging_mixin.py:115} INFO - [2023-01-05 00:00:22,103] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:00:22,110] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:00:22,163] {logging_mixin.py:115} INFO - [2023-01-05 00:00:22,163] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:00:22,190] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.988 seconds
[2023-01-05 00:00:52,279] {processor.py:153} INFO - Started process (PID=992) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:00:52,280] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:00:52,281] {logging_mixin.py:115} INFO - [2023-01-05 00:00:52,281] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:00:53,773] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:00:53,775] {logging_mixin.py:115} INFO - [2023-01-05 00:00:53,775] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:00:53,776] {logging_mixin.py:115} INFO - [2023-01-05 00:00:53,776] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:00:53,787] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:00:53,820] {logging_mixin.py:115} INFO - [2023-01-05 00:00:53,820] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:00:53,847] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.573 seconds
[2023-01-05 00:01:23,937] {processor.py:153} INFO - Started process (PID=1009) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:01:23,939] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:01:23,939] {logging_mixin.py:115} INFO - [2023-01-05 00:01:23,939] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:01:24,826] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:01:24,827] {logging_mixin.py:115} INFO - [2023-01-05 00:01:24,827] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:01:24,828] {logging_mixin.py:115} INFO - [2023-01-05 00:01:24,827] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:01:24,834] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:01:24,856] {logging_mixin.py:115} INFO - [2023-01-05 00:01:24,856] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:01:24,883] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.950 seconds
[2023-01-05 00:01:54,962] {processor.py:153} INFO - Started process (PID=1034) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:01:54,963] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:01:54,964] {logging_mixin.py:115} INFO - [2023-01-05 00:01:54,964] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:01:55,879] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:01:55,880] {logging_mixin.py:115} INFO - [2023-01-05 00:01:55,880] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:01:55,881] {logging_mixin.py:115} INFO - [2023-01-05 00:01:55,881] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:01:55,888] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:01:55,910] {logging_mixin.py:115} INFO - [2023-01-05 00:01:55,909] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:01:55,937] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.979 seconds
[2023-01-05 00:02:26,021] {processor.py:153} INFO - Started process (PID=1057) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:02:26,023] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:02:26,023] {logging_mixin.py:115} INFO - [2023-01-05 00:02:26,023] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:02:26,938] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:02:26,939] {logging_mixin.py:115} INFO - [2023-01-05 00:02:26,939] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:02:26,940] {logging_mixin.py:115} INFO - [2023-01-05 00:02:26,940] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:02:26,947] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:02:26,969] {logging_mixin.py:115} INFO - [2023-01-05 00:02:26,969] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:02:26,996] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.980 seconds
[2023-01-05 00:02:57,103] {processor.py:153} INFO - Started process (PID=1073) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:02:57,103] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:02:57,104] {logging_mixin.py:115} INFO - [2023-01-05 00:02:57,104] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:02:58,261] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:02:58,263] {logging_mixin.py:115} INFO - [2023-01-05 00:02:58,263] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:02:58,264] {logging_mixin.py:115} INFO - [2023-01-05 00:02:58,263] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:02:58,275] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:02:58,313] {logging_mixin.py:115} INFO - [2023-01-05 00:02:58,313] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:02:58,355] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.257 seconds
[2023-01-05 00:03:28,445] {processor.py:153} INFO - Started process (PID=1096) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:03:28,448] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:03:28,449] {logging_mixin.py:115} INFO - [2023-01-05 00:03:28,448] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:03:29,349] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:03:29,350] {logging_mixin.py:115} INFO - [2023-01-05 00:03:29,350] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:03:29,351] {logging_mixin.py:115} INFO - [2023-01-05 00:03:29,350] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:03:29,357] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:03:29,380] {logging_mixin.py:115} INFO - [2023-01-05 00:03:29,380] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:03:29,408] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.968 seconds
[2023-01-05 00:03:59,479] {processor.py:153} INFO - Started process (PID=1119) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:03:59,479] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:03:59,480] {logging_mixin.py:115} INFO - [2023-01-05 00:03:59,480] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:04:00,537] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:04:00,538] {logging_mixin.py:115} INFO - [2023-01-05 00:04:00,538] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:04:00,539] {logging_mixin.py:115} INFO - [2023-01-05 00:04:00,539] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:04:00,546] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:04:00,568] {logging_mixin.py:115} INFO - [2023-01-05 00:04:00,568] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:04:00,595] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.121 seconds
[2023-01-05 00:04:30,665] {processor.py:153} INFO - Started process (PID=1142) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:04:30,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:04:30,667] {logging_mixin.py:115} INFO - [2023-01-05 00:04:30,666] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:04:31,545] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:04:31,546] {logging_mixin.py:115} INFO - [2023-01-05 00:04:31,546] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:04:31,547] {logging_mixin.py:115} INFO - [2023-01-05 00:04:31,547] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:04:31,554] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:04:31,575] {logging_mixin.py:115} INFO - [2023-01-05 00:04:31,575] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:04:31,603] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.943 seconds
[2023-01-05 00:05:01,671] {processor.py:153} INFO - Started process (PID=1158) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:05:01,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:05:01,673] {logging_mixin.py:115} INFO - [2023-01-05 00:05:01,672] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:05:02,847] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:05:02,848] {logging_mixin.py:115} INFO - [2023-01-05 00:05:02,848] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:05:02,849] {logging_mixin.py:115} INFO - [2023-01-05 00:05:02,849] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:05:02,860] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:05:02,891] {logging_mixin.py:115} INFO - [2023-01-05 00:05:02,890] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:05:02,929] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.263 seconds
[2023-01-05 00:05:33,005] {processor.py:153} INFO - Started process (PID=1182) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:05:33,007] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:05:33,008] {logging_mixin.py:115} INFO - [2023-01-05 00:05:33,007] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:05:33,975] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:05:33,976] {logging_mixin.py:115} INFO - [2023-01-05 00:05:33,976] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:05:33,977] {logging_mixin.py:115} INFO - [2023-01-05 00:05:33,977] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:05:33,984] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:05:34,012] {logging_mixin.py:115} INFO - [2023-01-05 00:05:34,012] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:05:34,042] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.042 seconds
[2023-01-05 00:06:04,075] {processor.py:153} INFO - Started process (PID=1205) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:06:04,076] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:06:04,077] {logging_mixin.py:115} INFO - [2023-01-05 00:06:04,077] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:06:04,949] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:06:04,951] {logging_mixin.py:115} INFO - [2023-01-05 00:06:04,951] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:06:04,952] {logging_mixin.py:115} INFO - [2023-01-05 00:06:04,952] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:06:04,963] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:06:04,986] {logging_mixin.py:115} INFO - [2023-01-05 00:06:04,986] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:06:05,014] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.944 seconds
[2023-01-05 00:06:35,116] {processor.py:153} INFO - Started process (PID=1227) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:06:35,117] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:06:35,118] {logging_mixin.py:115} INFO - [2023-01-05 00:06:35,118] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:06:36,026] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:06:36,028] {logging_mixin.py:115} INFO - [2023-01-05 00:06:36,028] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:06:36,028] {logging_mixin.py:115} INFO - [2023-01-05 00:06:36,028] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:06:36,035] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:06:36,058] {logging_mixin.py:115} INFO - [2023-01-05 00:06:36,058] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:06:36,085] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.974 seconds
[2023-01-05 00:07:06,180] {processor.py:153} INFO - Started process (PID=1244) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:07:06,181] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:07:06,181] {logging_mixin.py:115} INFO - [2023-01-05 00:07:06,181] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:07:07,095] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:07:07,097] {logging_mixin.py:115} INFO - [2023-01-05 00:07:07,097] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:07:07,097] {logging_mixin.py:115} INFO - [2023-01-05 00:07:07,097] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:07:07,104] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:07:07,133] {logging_mixin.py:115} INFO - [2023-01-05 00:07:07,133] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:07:07,177] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.001 seconds
[2023-01-05 00:07:37,278] {processor.py:153} INFO - Started process (PID=1267) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:07:37,279] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:07:37,280] {logging_mixin.py:115} INFO - [2023-01-05 00:07:37,280] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:07:38,177] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:07:38,178] {logging_mixin.py:115} INFO - [2023-01-05 00:07:38,178] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:07:38,179] {logging_mixin.py:115} INFO - [2023-01-05 00:07:38,178] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:07:38,185] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:07:38,207] {logging_mixin.py:115} INFO - [2023-01-05 00:07:38,207] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:07:38,234] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.961 seconds
[2023-01-05 00:08:08,328] {processor.py:153} INFO - Started process (PID=1290) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:08:08,332] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:08:08,333] {logging_mixin.py:115} INFO - [2023-01-05 00:08:08,333] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:08:09,222] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:08:09,223] {logging_mixin.py:115} INFO - [2023-01-05 00:08:09,223] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:08:09,224] {logging_mixin.py:115} INFO - [2023-01-05 00:08:09,224] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:08:09,231] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:08:09,253] {logging_mixin.py:115} INFO - [2023-01-05 00:08:09,253] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:08:09,280] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.956 seconds
[2023-01-05 00:08:39,377] {processor.py:153} INFO - Started process (PID=1315) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:08:39,378] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:08:39,378] {logging_mixin.py:115} INFO - [2023-01-05 00:08:39,378] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:08:40,366] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:08:40,367] {logging_mixin.py:115} INFO - [2023-01-05 00:08:40,367] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:08:40,368] {logging_mixin.py:115} INFO - [2023-01-05 00:08:40,367] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:08:40,375] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:08:40,401] {logging_mixin.py:115} INFO - [2023-01-05 00:08:40,400] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:08:40,433] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.060 seconds
[2023-01-05 00:09:10,501] {processor.py:153} INFO - Started process (PID=1330) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:09:10,502] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:09:10,503] {logging_mixin.py:115} INFO - [2023-01-05 00:09:10,503] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:09:11,430] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:09:11,432] {logging_mixin.py:115} INFO - [2023-01-05 00:09:11,432] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:09:11,432] {logging_mixin.py:115} INFO - [2023-01-05 00:09:11,432] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:09:11,439] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:09:11,464] {logging_mixin.py:115} INFO - [2023-01-05 00:09:11,463] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:09:11,494] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.998 seconds
[2023-01-05 00:09:41,574] {processor.py:153} INFO - Started process (PID=1353) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:09:41,575] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:09:41,575] {logging_mixin.py:115} INFO - [2023-01-05 00:09:41,575] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:09:42,494] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:09:42,496] {logging_mixin.py:115} INFO - [2023-01-05 00:09:42,496] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:09:42,496] {logging_mixin.py:115} INFO - [2023-01-05 00:09:42,496] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:09:42,503] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:09:42,526] {logging_mixin.py:115} INFO - [2023-01-05 00:09:42,526] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:09:42,554] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.984 seconds
[2023-01-05 00:10:12,639] {processor.py:153} INFO - Started process (PID=1378) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:10:12,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:10:12,641] {logging_mixin.py:115} INFO - [2023-01-05 00:10:12,640] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:10:13,562] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:10:13,564] {logging_mixin.py:115} INFO - [2023-01-05 00:10:13,564] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:10:13,564] {logging_mixin.py:115} INFO - [2023-01-05 00:10:13,564] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:10:13,573] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:10:13,596] {logging_mixin.py:115} INFO - [2023-01-05 00:10:13,596] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:10:13,625] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.990 seconds
[2023-01-05 00:10:43,714] {processor.py:153} INFO - Started process (PID=1396) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:10:43,714] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:10:43,715] {logging_mixin.py:115} INFO - [2023-01-05 00:10:43,715] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:10:44,693] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:10:44,695] {logging_mixin.py:115} INFO - [2023-01-05 00:10:44,695] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:10:44,695] {logging_mixin.py:115} INFO - [2023-01-05 00:10:44,695] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:10:44,702] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:10:44,727] {logging_mixin.py:115} INFO - [2023-01-05 00:10:44,726] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:10:44,763] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.053 seconds
[2023-01-05 00:11:14,848] {processor.py:153} INFO - Started process (PID=1421) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:11:14,850] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:11:14,851] {logging_mixin.py:115} INFO - [2023-01-05 00:11:14,851] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:11:15,830] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:11:15,832] {logging_mixin.py:115} INFO - [2023-01-05 00:11:15,832] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:11:15,832] {logging_mixin.py:115} INFO - [2023-01-05 00:11:15,832] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:11:15,839] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:11:15,864] {logging_mixin.py:115} INFO - [2023-01-05 00:11:15,864] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:11:15,893] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.051 seconds
[2023-01-05 00:11:45,970] {processor.py:153} INFO - Started process (PID=1444) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:11:45,971] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:11:45,971] {logging_mixin.py:115} INFO - [2023-01-05 00:11:45,971] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:11:46,884] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:11:46,886] {logging_mixin.py:115} INFO - [2023-01-05 00:11:46,886] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:11:46,886] {logging_mixin.py:115} INFO - [2023-01-05 00:11:46,886] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:11:46,893] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:11:46,915] {logging_mixin.py:115} INFO - [2023-01-05 00:11:46,915] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:11:46,942] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.977 seconds
[2023-01-05 00:12:16,994] {processor.py:153} INFO - Started process (PID=1467) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:12:16,995] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:12:16,996] {logging_mixin.py:115} INFO - [2023-01-05 00:12:16,996] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:12:17,919] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:12:17,921] {logging_mixin.py:115} INFO - [2023-01-05 00:12:17,921] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:12:17,922] {logging_mixin.py:115} INFO - [2023-01-05 00:12:17,921] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:12:17,928] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:12:17,951] {logging_mixin.py:115} INFO - [2023-01-05 00:12:17,951] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:12:17,979] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.990 seconds
[2023-01-05 00:12:48,076] {processor.py:153} INFO - Started process (PID=1485) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:12:48,077] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:12:48,077] {logging_mixin.py:115} INFO - [2023-01-05 00:12:48,077] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:12:49,069] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:12:49,071] {logging_mixin.py:115} INFO - [2023-01-05 00:12:49,071] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:12:49,071] {logging_mixin.py:115} INFO - [2023-01-05 00:12:49,071] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:12:49,078] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:12:49,101] {logging_mixin.py:115} INFO - [2023-01-05 00:12:49,100] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:12:49,143] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.072 seconds
[2023-01-05 00:13:19,218] {processor.py:153} INFO - Started process (PID=1507) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:13:19,219] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:13:19,219] {logging_mixin.py:115} INFO - [2023-01-05 00:13:19,219] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:13:20,110] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:13:20,111] {logging_mixin.py:115} INFO - [2023-01-05 00:13:20,111] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:13:20,111] {logging_mixin.py:115} INFO - [2023-01-05 00:13:20,111] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:13:20,118] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:13:20,140] {logging_mixin.py:115} INFO - [2023-01-05 00:13:20,140] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:13:20,168] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.954 seconds
[2023-01-05 00:13:50,219] {processor.py:153} INFO - Started process (PID=1531) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:13:50,223] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:13:50,223] {logging_mixin.py:115} INFO - [2023-01-05 00:13:50,223] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:13:51,126] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:13:51,127] {logging_mixin.py:115} INFO - [2023-01-05 00:13:51,127] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:13:51,128] {logging_mixin.py:115} INFO - [2023-01-05 00:13:51,127] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:13:51,135] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:13:51,157] {logging_mixin.py:115} INFO - [2023-01-05 00:13:51,156] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:13:51,184] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.970 seconds
[2023-01-05 00:14:21,287] {processor.py:153} INFO - Started process (PID=1553) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:14:21,288] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:14:21,289] {logging_mixin.py:115} INFO - [2023-01-05 00:14:21,289] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:14:22,479] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:14:22,481] {logging_mixin.py:115} INFO - [2023-01-05 00:14:22,481] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:14:22,481] {logging_mixin.py:115} INFO - [2023-01-05 00:14:22,481] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:14:22,488] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:14:22,518] {logging_mixin.py:115} INFO - [2023-01-05 00:14:22,517] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:14:22,555] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.274 seconds
[2023-01-05 00:14:52,624] {processor.py:153} INFO - Started process (PID=1569) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:14:52,628] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:14:52,629] {logging_mixin.py:115} INFO - [2023-01-05 00:14:52,628] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:14:53,518] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:14:53,519] {logging_mixin.py:115} INFO - [2023-01-05 00:14:53,519] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:14:53,520] {logging_mixin.py:115} INFO - [2023-01-05 00:14:53,519] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:14:53,526] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:14:53,548] {logging_mixin.py:115} INFO - [2023-01-05 00:14:53,548] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:14:53,575] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.956 seconds
[2023-01-05 00:15:23,644] {processor.py:153} INFO - Started process (PID=1592) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:15:23,646] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:15:23,647] {logging_mixin.py:115} INFO - [2023-01-05 00:15:23,647] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:15:24,509] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:15:24,512] {logging_mixin.py:115} INFO - [2023-01-05 00:15:24,510] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:15:24,512] {logging_mixin.py:115} INFO - [2023-01-05 00:15:24,512] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:15:24,519] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:15:24,541] {logging_mixin.py:115} INFO - [2023-01-05 00:15:24,541] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:15:24,567] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.927 seconds
[2023-01-05 00:15:54,660] {processor.py:153} INFO - Started process (PID=1615) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:15:54,661] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:15:54,662] {logging_mixin.py:115} INFO - [2023-01-05 00:15:54,661] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:15:55,584] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:15:55,586] {logging_mixin.py:115} INFO - [2023-01-05 00:15:55,586] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:15:55,586] {logging_mixin.py:115} INFO - [2023-01-05 00:15:55,586] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:15:55,593] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:15:55,621] {logging_mixin.py:115} INFO - [2023-01-05 00:15:55,620] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:15:55,657] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.001 seconds
[2023-01-05 00:16:25,729] {processor.py:153} INFO - Started process (PID=1637) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:16:25,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:16:25,731] {logging_mixin.py:115} INFO - [2023-01-05 00:16:25,731] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:16:26,650] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:16:26,652] {logging_mixin.py:115} INFO - [2023-01-05 00:16:26,652] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:16:26,652] {logging_mixin.py:115} INFO - [2023-01-05 00:16:26,652] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:16:26,659] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:16:26,681] {logging_mixin.py:115} INFO - [2023-01-05 00:16:26,681] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:16:26,709] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.984 seconds
[2023-01-05 00:16:56,799] {processor.py:153} INFO - Started process (PID=1653) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:16:56,799] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:16:56,800] {logging_mixin.py:115} INFO - [2023-01-05 00:16:56,800] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:16:57,658] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:16:57,660] {logging_mixin.py:115} INFO - [2023-01-05 00:16:57,659] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:16:57,660] {logging_mixin.py:115} INFO - [2023-01-05 00:16:57,660] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:16:57,667] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:16:57,688] {logging_mixin.py:115} INFO - [2023-01-05 00:16:57,688] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:16:57,717] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.922 seconds
[2023-01-05 00:17:27,816] {processor.py:153} INFO - Started process (PID=1677) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:17:27,817] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:17:27,818] {logging_mixin.py:115} INFO - [2023-01-05 00:17:27,818] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:17:28,730] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:17:28,731] {logging_mixin.py:115} INFO - [2023-01-05 00:17:28,731] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:17:28,732] {logging_mixin.py:115} INFO - [2023-01-05 00:17:28,731] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:17:28,738] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:17:28,761] {logging_mixin.py:115} INFO - [2023-01-05 00:17:28,761] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:17:28,789] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.978 seconds
[2023-01-05 00:17:58,899] {processor.py:153} INFO - Started process (PID=1700) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:17:58,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:17:58,901] {logging_mixin.py:115} INFO - [2023-01-05 00:17:58,900] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:17:59,774] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:17:59,775] {logging_mixin.py:115} INFO - [2023-01-05 00:17:59,775] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:17:59,776] {logging_mixin.py:115} INFO - [2023-01-05 00:17:59,775] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:17:59,782] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:17:59,804] {logging_mixin.py:115} INFO - [2023-01-05 00:17:59,804] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:17:59,832] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.938 seconds
[2023-01-05 00:18:29,926] {processor.py:153} INFO - Started process (PID=1722) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:18:29,928] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:18:29,929] {logging_mixin.py:115} INFO - [2023-01-05 00:18:29,928] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:18:30,822] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:18:30,824] {logging_mixin.py:115} INFO - [2023-01-05 00:18:30,824] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:18:30,824] {logging_mixin.py:115} INFO - [2023-01-05 00:18:30,824] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:18:30,831] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:18:30,855] {logging_mixin.py:115} INFO - [2023-01-05 00:18:30,855] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:18:30,883] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.962 seconds
[2023-01-05 00:19:00,981] {processor.py:153} INFO - Started process (PID=1738) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:19:00,981] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:19:00,982] {logging_mixin.py:115} INFO - [2023-01-05 00:19:00,982] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:19:01,888] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:19:01,889] {logging_mixin.py:115} INFO - [2023-01-05 00:19:01,889] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:19:01,890] {logging_mixin.py:115} INFO - [2023-01-05 00:19:01,889] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:19:01,896] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:19:01,924] {logging_mixin.py:115} INFO - [2023-01-05 00:19:01,924] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:19:01,960] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.985 seconds
[2023-01-05 00:19:32,048] {processor.py:153} INFO - Started process (PID=1762) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:19:32,050] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:19:32,050] {logging_mixin.py:115} INFO - [2023-01-05 00:19:32,050] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:19:32,921] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:19:32,922] {logging_mixin.py:115} INFO - [2023-01-05 00:19:32,922] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:19:32,922] {logging_mixin.py:115} INFO - [2023-01-05 00:19:32,922] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:19:32,929] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:19:32,951] {logging_mixin.py:115} INFO - [2023-01-05 00:19:32,951] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:19:32,979] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.936 seconds
[2023-01-05 00:20:03,078] {processor.py:153} INFO - Started process (PID=1785) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:20:03,078] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:20:03,079] {logging_mixin.py:115} INFO - [2023-01-05 00:20:03,079] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:20:03,965] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:20:03,967] {logging_mixin.py:115} INFO - [2023-01-05 00:20:03,966] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:20:03,967] {logging_mixin.py:115} INFO - [2023-01-05 00:20:03,967] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:20:03,974] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:20:03,995] {logging_mixin.py:115} INFO - [2023-01-05 00:20:03,995] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:20:04,022] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.949 seconds
[2023-01-05 00:20:34,122] {processor.py:153} INFO - Started process (PID=1801) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:20:34,124] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:20:34,124] {logging_mixin.py:115} INFO - [2023-01-05 00:20:34,124] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:20:35,307] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:20:35,309] {logging_mixin.py:115} INFO - [2023-01-05 00:20:35,309] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:20:35,310] {logging_mixin.py:115} INFO - [2023-01-05 00:20:35,310] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:20:35,321] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:20:35,355] {logging_mixin.py:115} INFO - [2023-01-05 00:20:35,354] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:20:35,393] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.277 seconds
[2023-01-05 00:21:05,468] {processor.py:153} INFO - Started process (PID=1825) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:21:05,469] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:21:05,470] {logging_mixin.py:115} INFO - [2023-01-05 00:21:05,469] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:21:06,357] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:21:06,359] {logging_mixin.py:115} INFO - [2023-01-05 00:21:06,358] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:21:06,359] {logging_mixin.py:115} INFO - [2023-01-05 00:21:06,359] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:21:06,369] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:21:06,391] {logging_mixin.py:115} INFO - [2023-01-05 00:21:06,391] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:21:06,419] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.955 seconds
[2023-01-05 00:21:36,489] {processor.py:153} INFO - Started process (PID=1849) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:21:36,491] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:21:36,491] {logging_mixin.py:115} INFO - [2023-01-05 00:21:36,491] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:21:37,365] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:21:37,366] {logging_mixin.py:115} INFO - [2023-01-05 00:21:37,366] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:21:37,366] {logging_mixin.py:115} INFO - [2023-01-05 00:21:37,366] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:21:37,373] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:21:37,395] {logging_mixin.py:115} INFO - [2023-01-05 00:21:37,395] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:21:37,423] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.938 seconds
[2023-01-05 00:22:07,489] {processor.py:153} INFO - Started process (PID=1872) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:22:07,492] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:22:07,493] {logging_mixin.py:115} INFO - [2023-01-05 00:22:07,493] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:22:08,368] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:22:08,369] {logging_mixin.py:115} INFO - [2023-01-05 00:22:08,369] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:22:08,370] {logging_mixin.py:115} INFO - [2023-01-05 00:22:08,369] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:22:08,376] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:22:08,399] {logging_mixin.py:115} INFO - [2023-01-05 00:22:08,398] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:22:08,426] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.942 seconds
[2023-01-05 00:22:38,493] {processor.py:153} INFO - Started process (PID=1887) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:22:38,494] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:22:38,495] {logging_mixin.py:115} INFO - [2023-01-05 00:22:38,495] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:22:39,477] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:22:39,479] {logging_mixin.py:115} INFO - [2023-01-05 00:22:39,479] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:22:39,480] {logging_mixin.py:115} INFO - [2023-01-05 00:22:39,480] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:22:39,491] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:22:39,522] {logging_mixin.py:115} INFO - [2023-01-05 00:22:39,521] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:22:39,561] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.072 seconds
[2023-01-05 00:23:09,637] {processor.py:153} INFO - Started process (PID=1911) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:23:09,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:23:09,639] {logging_mixin.py:115} INFO - [2023-01-05 00:23:09,639] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:23:10,520] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:23:10,522] {logging_mixin.py:115} INFO - [2023-01-05 00:23:10,521] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:23:10,522] {logging_mixin.py:115} INFO - [2023-01-05 00:23:10,522] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:23:10,529] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:23:10,552] {logging_mixin.py:115} INFO - [2023-01-05 00:23:10,551] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:23:10,580] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.947 seconds
[2023-01-05 00:23:40,636] {processor.py:153} INFO - Started process (PID=1934) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:23:40,637] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:23:40,637] {logging_mixin.py:115} INFO - [2023-01-05 00:23:40,637] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:23:41,514] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:23:41,516] {logging_mixin.py:115} INFO - [2023-01-05 00:23:41,516] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:23:41,517] {logging_mixin.py:115} INFO - [2023-01-05 00:23:41,516] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:23:41,528] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:23:41,551] {logging_mixin.py:115} INFO - [2023-01-05 00:23:41,551] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:23:41,577] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.946 seconds
[2023-01-05 00:24:11,679] {processor.py:153} INFO - Started process (PID=1957) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:24:11,680] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:24:11,681] {logging_mixin.py:115} INFO - [2023-01-05 00:24:11,681] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:24:12,553] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:24:12,554] {logging_mixin.py:115} INFO - [2023-01-05 00:24:12,554] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:24:12,554] {logging_mixin.py:115} INFO - [2023-01-05 00:24:12,554] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:24:12,561] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:24:12,583] {logging_mixin.py:115} INFO - [2023-01-05 00:24:12,583] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:24:12,611] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.937 seconds
[2023-01-05 00:24:42,711] {processor.py:153} INFO - Started process (PID=1974) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:24:42,712] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:24:42,712] {logging_mixin.py:115} INFO - [2023-01-05 00:24:42,712] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:24:43,741] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:24:43,743] {logging_mixin.py:115} INFO - [2023-01-05 00:24:43,743] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:24:43,743] {logging_mixin.py:115} INFO - [2023-01-05 00:24:43,743] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:24:43,755] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:24:43,789] {logging_mixin.py:115} INFO - [2023-01-05 00:24:43,788] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:24:43,826] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.120 seconds
[2023-01-05 00:25:13,900] {processor.py:153} INFO - Started process (PID=2000) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:25:13,902] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:25:13,902] {logging_mixin.py:115} INFO - [2023-01-05 00:25:13,902] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:25:14,905] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:25:14,906] {logging_mixin.py:115} INFO - [2023-01-05 00:25:14,906] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:25:14,907] {logging_mixin.py:115} INFO - [2023-01-05 00:25:14,907] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:25:14,914] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:25:14,936] {logging_mixin.py:115} INFO - [2023-01-05 00:25:14,936] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:25:14,963] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.067 seconds
[2023-01-05 00:25:45,037] {processor.py:153} INFO - Started process (PID=2023) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:25:45,038] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:25:45,039] {logging_mixin.py:115} INFO - [2023-01-05 00:25:45,039] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:25:45,901] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:25:45,903] {logging_mixin.py:115} INFO - [2023-01-05 00:25:45,903] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:25:45,903] {logging_mixin.py:115} INFO - [2023-01-05 00:25:45,903] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:25:45,910] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:25:45,931] {logging_mixin.py:115} INFO - [2023-01-05 00:25:45,931] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:25:45,958] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.925 seconds
[2023-01-05 00:26:16,040] {processor.py:153} INFO - Started process (PID=2047) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:26:16,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:26:16,042] {logging_mixin.py:115} INFO - [2023-01-05 00:26:16,042] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:26:16,906] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:26:16,908] {logging_mixin.py:115} INFO - [2023-01-05 00:26:16,908] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:26:16,908] {logging_mixin.py:115} INFO - [2023-01-05 00:26:16,908] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:26:16,915] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:26:16,936] {logging_mixin.py:115} INFO - [2023-01-05 00:26:16,936] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:26:16,963] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.926 seconds
[2023-01-05 00:26:47,059] {processor.py:153} INFO - Started process (PID=2062) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:26:47,060] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:26:47,060] {logging_mixin.py:115} INFO - [2023-01-05 00:26:47,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:26:47,943] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:26:47,944] {logging_mixin.py:115} INFO - [2023-01-05 00:26:47,944] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:26:47,945] {logging_mixin.py:115} INFO - [2023-01-05 00:26:47,944] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:26:47,951] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:26:47,973] {logging_mixin.py:115} INFO - [2023-01-05 00:26:47,973] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:26:48,000] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.946 seconds
[2023-01-05 00:27:18,097] {processor.py:153} INFO - Started process (PID=2084) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:27:18,099] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:27:18,099] {logging_mixin.py:115} INFO - [2023-01-05 00:27:18,099] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:27:18,983] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:27:18,985] {logging_mixin.py:115} INFO - [2023-01-05 00:27:18,985] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:27:18,985] {logging_mixin.py:115} INFO - [2023-01-05 00:27:18,985] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:27:18,992] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:27:19,014] {logging_mixin.py:115} INFO - [2023-01-05 00:27:19,013] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:27:19,041] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.948 seconds
[2023-01-05 00:27:49,152] {processor.py:153} INFO - Started process (PID=2107) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:27:49,153] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:27:49,154] {logging_mixin.py:115} INFO - [2023-01-05 00:27:49,154] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:27:50,026] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:27:50,027] {logging_mixin.py:115} INFO - [2023-01-05 00:27:50,027] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:27:50,028] {logging_mixin.py:115} INFO - [2023-01-05 00:27:50,027] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:27:50,034] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:27:50,056] {logging_mixin.py:115} INFO - [2023-01-05 00:27:50,056] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:27:50,083] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.935 seconds
[2023-01-05 00:28:20,213] {processor.py:153} INFO - Started process (PID=2131) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:28:20,214] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:28:20,215] {logging_mixin.py:115} INFO - [2023-01-05 00:28:20,215] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:28:21,226] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:28:21,228] {logging_mixin.py:115} INFO - [2023-01-05 00:28:21,228] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:28:21,228] {logging_mixin.py:115} INFO - [2023-01-05 00:28:21,228] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:28:21,235] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:28:21,257] {logging_mixin.py:115} INFO - [2023-01-05 00:28:21,257] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:28:21,284] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.077 seconds
[2023-01-05 00:28:51,350] {processor.py:153} INFO - Started process (PID=2147) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:28:51,350] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:28:51,351] {logging_mixin.py:115} INFO - [2023-01-05 00:28:51,351] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:28:52,235] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:28:52,236] {logging_mixin.py:115} INFO - [2023-01-05 00:28:52,236] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:28:52,237] {logging_mixin.py:115} INFO - [2023-01-05 00:28:52,237] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:28:52,244] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:28:52,265] {logging_mixin.py:115} INFO - [2023-01-05 00:28:52,265] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:28:52,293] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.947 seconds
[2023-01-05 00:29:22,351] {processor.py:153} INFO - Started process (PID=2171) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:29:22,352] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:29:22,353] {logging_mixin.py:115} INFO - [2023-01-05 00:29:22,352] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:29:23,252] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:29:23,253] {logging_mixin.py:115} INFO - [2023-01-05 00:29:23,253] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:29:23,254] {logging_mixin.py:115} INFO - [2023-01-05 00:29:23,253] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:29:23,260] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:29:23,282] {logging_mixin.py:115} INFO - [2023-01-05 00:29:23,282] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:29:23,308] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.962 seconds
[2023-01-05 00:29:53,400] {processor.py:153} INFO - Started process (PID=2195) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:29:53,401] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:29:53,402] {logging_mixin.py:115} INFO - [2023-01-05 00:29:53,402] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:29:54,272] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:29:54,274] {logging_mixin.py:115} INFO - [2023-01-05 00:29:54,273] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:29:54,274] {logging_mixin.py:115} INFO - [2023-01-05 00:29:54,274] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:29:54,281] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:29:54,302] {logging_mixin.py:115} INFO - [2023-01-05 00:29:54,302] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:29:54,329] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.933 seconds
[2023-01-05 00:30:24,426] {processor.py:153} INFO - Started process (PID=2219) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:30:24,427] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:30:24,428] {logging_mixin.py:115} INFO - [2023-01-05 00:30:24,428] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:30:25,468] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:30:25,469] {logging_mixin.py:115} INFO - [2023-01-05 00:30:25,469] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:30:25,470] {logging_mixin.py:115} INFO - [2023-01-05 00:30:25,470] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:30:25,476] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:30:25,506] {logging_mixin.py:115} INFO - [2023-01-05 00:30:25,506] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:30:25,543] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.122 seconds
[2023-01-05 00:30:55,611] {processor.py:153} INFO - Started process (PID=2236) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:30:55,612] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:30:55,612] {logging_mixin.py:115} INFO - [2023-01-05 00:30:55,612] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:30:56,463] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:30:56,464] {logging_mixin.py:115} INFO - [2023-01-05 00:30:56,464] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:30:56,465] {logging_mixin.py:115} INFO - [2023-01-05 00:30:56,464] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:30:56,471] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:30:56,500] {logging_mixin.py:115} INFO - [2023-01-05 00:30:56,500] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:30:56,528] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.922 seconds
[2023-01-05 00:31:26,579] {processor.py:153} INFO - Started process (PID=2260) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:31:26,582] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:31:26,582] {logging_mixin.py:115} INFO - [2023-01-05 00:31:26,582] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:31:27,454] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:31:27,455] {logging_mixin.py:115} INFO - [2023-01-05 00:31:27,455] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:31:27,456] {logging_mixin.py:115} INFO - [2023-01-05 00:31:27,455] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:31:27,462] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:31:27,485] {logging_mixin.py:115} INFO - [2023-01-05 00:31:27,484] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:31:27,512] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.938 seconds
[2023-01-05 00:31:57,609] {processor.py:153} INFO - Started process (PID=2283) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:31:57,609] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:31:57,610] {logging_mixin.py:115} INFO - [2023-01-05 00:31:57,610] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:31:58,476] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:31:58,478] {logging_mixin.py:115} INFO - [2023-01-05 00:31:58,478] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:31:58,478] {logging_mixin.py:115} INFO - [2023-01-05 00:31:58,478] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:31:58,485] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:31:58,508] {logging_mixin.py:115} INFO - [2023-01-05 00:31:58,507] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:31:58,535] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.931 seconds
[2023-01-05 00:32:28,638] {processor.py:153} INFO - Started process (PID=2300) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:32:28,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:32:28,640] {logging_mixin.py:115} INFO - [2023-01-05 00:32:28,640] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:32:29,751] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:32:29,752] {logging_mixin.py:115} INFO - [2023-01-05 00:32:29,752] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:32:29,753] {logging_mixin.py:115} INFO - [2023-01-05 00:32:29,753] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:32:29,760] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:32:29,782] {logging_mixin.py:115} INFO - [2023-01-05 00:32:29,782] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:32:29,809] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.175 seconds
[2023-01-05 00:32:59,875] {processor.py:153} INFO - Started process (PID=2324) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:32:59,876] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:32:59,877] {logging_mixin.py:115} INFO - [2023-01-05 00:32:59,877] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:33:00,756] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:33:00,757] {logging_mixin.py:115} INFO - [2023-01-05 00:33:00,757] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:33:00,758] {logging_mixin.py:115} INFO - [2023-01-05 00:33:00,757] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:33:00,764] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:33:00,787] {logging_mixin.py:115} INFO - [2023-01-05 00:33:00,786] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:33:00,814] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.943 seconds
[2023-01-05 00:33:30,888] {processor.py:153} INFO - Started process (PID=2348) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:33:30,889] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:33:30,890] {logging_mixin.py:115} INFO - [2023-01-05 00:33:30,890] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:33:31,773] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:33:31,774] {logging_mixin.py:115} INFO - [2023-01-05 00:33:31,774] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:33:31,775] {logging_mixin.py:115} INFO - [2023-01-05 00:33:31,774] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:33:31,781] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:33:31,807] {logging_mixin.py:115} INFO - [2023-01-05 00:33:31,806] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:33:31,837] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.953 seconds
[2023-01-05 00:34:01,886] {processor.py:153} INFO - Started process (PID=2372) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:34:01,889] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:34:01,890] {logging_mixin.py:115} INFO - [2023-01-05 00:34:01,890] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:34:02,774] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:34:02,775] {logging_mixin.py:115} INFO - [2023-01-05 00:34:02,775] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:34:02,775] {logging_mixin.py:115} INFO - [2023-01-05 00:34:02,775] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:34:02,782] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:34:02,804] {logging_mixin.py:115} INFO - [2023-01-05 00:34:02,804] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:34:02,831] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.949 seconds
[2023-01-05 00:34:32,926] {processor.py:153} INFO - Started process (PID=2389) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:34:32,929] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:34:32,930] {logging_mixin.py:115} INFO - [2023-01-05 00:34:32,930] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:34:33,898] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:34:33,899] {logging_mixin.py:115} INFO - [2023-01-05 00:34:33,899] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:34:33,900] {logging_mixin.py:115} INFO - [2023-01-05 00:34:33,899] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:34:33,906] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:34:33,929] {logging_mixin.py:115} INFO - [2023-01-05 00:34:33,929] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:34:33,956] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.035 seconds
[2023-01-05 00:35:04,011] {processor.py:153} INFO - Started process (PID=2412) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:35:04,012] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:35:04,012] {logging_mixin.py:115} INFO - [2023-01-05 00:35:04,012] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:35:04,897] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:35:04,898] {logging_mixin.py:115} INFO - [2023-01-05 00:35:04,898] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:35:04,899] {logging_mixin.py:115} INFO - [2023-01-05 00:35:04,898] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:35:04,905] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:35:04,927] {logging_mixin.py:115} INFO - [2023-01-05 00:35:04,927] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:35:04,955] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.948 seconds
[2023-01-05 00:35:35,052] {processor.py:153} INFO - Started process (PID=2435) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:35:35,054] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:35:35,054] {logging_mixin.py:115} INFO - [2023-01-05 00:35:35,054] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:35:35,928] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:35:35,929] {logging_mixin.py:115} INFO - [2023-01-05 00:35:35,929] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:35:35,930] {logging_mixin.py:115} INFO - [2023-01-05 00:35:35,930] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:35:35,937] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:35:35,958] {logging_mixin.py:115} INFO - [2023-01-05 00:35:35,958] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:35:35,985] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.938 seconds
[2023-01-05 00:36:06,085] {processor.py:153} INFO - Started process (PID=2459) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:36:06,086] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:36:06,086] {logging_mixin.py:115} INFO - [2023-01-05 00:36:06,086] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:36:06,962] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:36:06,963] {logging_mixin.py:115} INFO - [2023-01-05 00:36:06,963] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:36:06,964] {logging_mixin.py:115} INFO - [2023-01-05 00:36:06,963] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:36:06,970] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:36:06,992] {logging_mixin.py:115} INFO - [2023-01-05 00:36:06,991] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:36:07,018] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.939 seconds
[2023-01-05 00:36:37,114] {processor.py:153} INFO - Started process (PID=2477) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:36:37,115] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:36:37,116] {logging_mixin.py:115} INFO - [2023-01-05 00:36:37,116] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:36:38,046] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:36:38,048] {logging_mixin.py:115} INFO - [2023-01-05 00:36:38,048] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:36:38,049] {logging_mixin.py:115} INFO - [2023-01-05 00:36:38,048] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:36:38,056] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:36:38,090] {logging_mixin.py:115} INFO - [2023-01-05 00:36:38,089] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:36:38,125] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.016 seconds
[2023-01-05 00:37:08,204] {processor.py:153} INFO - Started process (PID=2500) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:37:08,205] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:37:08,205] {logging_mixin.py:115} INFO - [2023-01-05 00:37:08,205] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:37:09,094] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:37:09,095] {logging_mixin.py:115} INFO - [2023-01-05 00:37:09,095] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:37:09,096] {logging_mixin.py:115} INFO - [2023-01-05 00:37:09,096] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:37:09,103] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:37:09,124] {logging_mixin.py:115} INFO - [2023-01-05 00:37:09,124] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:37:09,152] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.952 seconds
[2023-01-05 00:37:39,265] {processor.py:153} INFO - Started process (PID=2523) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:37:39,266] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:37:39,267] {logging_mixin.py:115} INFO - [2023-01-05 00:37:39,267] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:37:40,161] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:37:40,162] {logging_mixin.py:115} INFO - [2023-01-05 00:37:40,162] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:37:40,163] {logging_mixin.py:115} INFO - [2023-01-05 00:37:40,163] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:37:40,170] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:37:40,192] {logging_mixin.py:115} INFO - [2023-01-05 00:37:40,191] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:37:40,219] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.958 seconds
[2023-01-05 00:38:10,316] {processor.py:153} INFO - Started process (PID=2547) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:38:10,317] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:38:10,317] {logging_mixin.py:115} INFO - [2023-01-05 00:38:10,317] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:38:11,201] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:38:11,202] {logging_mixin.py:115} INFO - [2023-01-05 00:38:11,202] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:38:11,202] {logging_mixin.py:115} INFO - [2023-01-05 00:38:11,202] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:38:11,209] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:38:11,232] {logging_mixin.py:115} INFO - [2023-01-05 00:38:11,232] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:38:11,259] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.947 seconds
[2023-01-05 00:38:41,366] {processor.py:153} INFO - Started process (PID=2564) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:38:41,367] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:38:41,369] {logging_mixin.py:115} INFO - [2023-01-05 00:38:41,368] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:38:42,942] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:38:42,944] {logging_mixin.py:115} INFO - [2023-01-05 00:38:42,944] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:38:42,945] {logging_mixin.py:115} INFO - [2023-01-05 00:38:42,944] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:38:42,956] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:38:42,993] {logging_mixin.py:115} INFO - [2023-01-05 00:38:42,992] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:38:43,037] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.676 seconds
[2023-01-05 00:39:13,144] {processor.py:153} INFO - Started process (PID=2586) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:39:13,146] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:39:13,146] {logging_mixin.py:115} INFO - [2023-01-05 00:39:13,146] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:39:14,036] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:39:14,037] {logging_mixin.py:115} INFO - [2023-01-05 00:39:14,037] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:39:14,038] {logging_mixin.py:115} INFO - [2023-01-05 00:39:14,038] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:39:14,045] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:39:14,068] {logging_mixin.py:115} INFO - [2023-01-05 00:39:14,068] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:39:14,095] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.956 seconds
[2023-01-05 00:39:44,187] {processor.py:153} INFO - Started process (PID=2611) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:39:44,188] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:39:44,189] {logging_mixin.py:115} INFO - [2023-01-05 00:39:44,188] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:39:45,057] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:39:45,058] {logging_mixin.py:115} INFO - [2023-01-05 00:39:45,058] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:39:45,059] {logging_mixin.py:115} INFO - [2023-01-05 00:39:45,059] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:39:45,066] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:39:45,098] {logging_mixin.py:115} INFO - [2023-01-05 00:39:45,098] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:39:45,133] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.951 seconds
[2023-01-05 00:40:15,231] {processor.py:153} INFO - Started process (PID=2634) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:40:15,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:40:15,233] {logging_mixin.py:115} INFO - [2023-01-05 00:40:15,232] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:40:16,106] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:40:16,107] {logging_mixin.py:115} INFO - [2023-01-05 00:40:16,107] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:40:16,108] {logging_mixin.py:115} INFO - [2023-01-05 00:40:16,107] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:40:16,116] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:40:16,138] {logging_mixin.py:115} INFO - [2023-01-05 00:40:16,137] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:40:16,165] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.939 seconds
[2023-01-05 00:40:32,229] {processor.py:153} INFO - Started process (PID=2643) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:40:32,230] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:40:32,231] {logging_mixin.py:115} INFO - [2023-01-05 00:40:32,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:40:33,111] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:40:33,113] {logging_mixin.py:115} INFO - [2023-01-05 00:40:33,113] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:40:33,113] {logging_mixin.py:115} INFO - [2023-01-05 00:40:33,113] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:40:33,120] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:40:33,173] {logging_mixin.py:115} INFO - [2023-01-05 00:40:33,172] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:40:33,202] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.978 seconds
[2023-01-05 00:41:03,295] {processor.py:153} INFO - Started process (PID=2666) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:41:03,296] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:41:03,297] {logging_mixin.py:115} INFO - [2023-01-05 00:41:03,296] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:41:04,171] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:41:04,172] {logging_mixin.py:115} INFO - [2023-01-05 00:41:04,172] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:41:04,173] {logging_mixin.py:115} INFO - [2023-01-05 00:41:04,172] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:41:04,179] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:41:04,201] {logging_mixin.py:115} INFO - [2023-01-05 00:41:04,201] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:41:04,229] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.939 seconds
[2023-01-05 00:41:34,320] {processor.py:153} INFO - Started process (PID=2688) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:41:34,321] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:41:34,322] {logging_mixin.py:115} INFO - [2023-01-05 00:41:34,321] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:41:35,349] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:41:35,350] {logging_mixin.py:115} INFO - [2023-01-05 00:41:35,350] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:41:35,351] {logging_mixin.py:115} INFO - [2023-01-05 00:41:35,350] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:41:35,359] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:41:35,384] {logging_mixin.py:115} INFO - [2023-01-05 00:41:35,384] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:41:35,411] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.096 seconds
[2023-01-05 00:42:05,484] {processor.py:153} INFO - Started process (PID=2703) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:42:05,485] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:42:05,486] {logging_mixin.py:115} INFO - [2023-01-05 00:42:05,486] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:42:06,373] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:42:06,374] {logging_mixin.py:115} INFO - [2023-01-05 00:42:06,374] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:42:06,375] {logging_mixin.py:115} INFO - [2023-01-05 00:42:06,374] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:42:06,381] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:42:06,404] {logging_mixin.py:115} INFO - [2023-01-05 00:42:06,404] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:42:06,433] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.954 seconds
[2023-01-05 00:42:36,486] {processor.py:153} INFO - Started process (PID=2726) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:42:36,486] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:42:36,487] {logging_mixin.py:115} INFO - [2023-01-05 00:42:36,487] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:42:37,382] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:42:37,384] {logging_mixin.py:115} INFO - [2023-01-05 00:42:37,384] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:42:37,384] {logging_mixin.py:115} INFO - [2023-01-05 00:42:37,384] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:42:37,391] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:42:37,414] {logging_mixin.py:115} INFO - [2023-01-05 00:42:37,414] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:42:37,443] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.962 seconds
[2023-01-05 00:43:07,544] {processor.py:153} INFO - Started process (PID=2749) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:43:07,546] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:43:07,547] {logging_mixin.py:115} INFO - [2023-01-05 00:43:07,547] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:43:08,479] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:43:08,481] {logging_mixin.py:115} INFO - [2023-01-05 00:43:08,481] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:43:08,482] {logging_mixin.py:115} INFO - [2023-01-05 00:43:08,482] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:43:08,489] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:43:08,512] {logging_mixin.py:115} INFO - [2023-01-05 00:43:08,512] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:43:08,539] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.001 seconds
[2023-01-05 00:43:38,620] {processor.py:153} INFO - Started process (PID=2771) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:43:38,621] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:43:38,621] {logging_mixin.py:115} INFO - [2023-01-05 00:43:38,621] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:43:39,637] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:43:39,639] {logging_mixin.py:115} INFO - [2023-01-05 00:43:39,638] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:43:39,639] {logging_mixin.py:115} INFO - [2023-01-05 00:43:39,639] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:43:39,648] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:43:39,671] {logging_mixin.py:115} INFO - [2023-01-05 00:43:39,670] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:43:39,698] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.083 seconds
[2023-01-05 00:44:09,764] {processor.py:153} INFO - Started process (PID=2787) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:44:09,765] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:44:09,766] {logging_mixin.py:115} INFO - [2023-01-05 00:44:09,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:44:10,629] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:44:10,631] {logging_mixin.py:115} INFO - [2023-01-05 00:44:10,630] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:44:10,631] {logging_mixin.py:115} INFO - [2023-01-05 00:44:10,631] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:44:10,638] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:44:10,660] {logging_mixin.py:115} INFO - [2023-01-05 00:44:10,660] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:44:10,687] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.928 seconds
[2023-01-05 00:44:40,762] {processor.py:153} INFO - Started process (PID=2811) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:44:40,762] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:44:40,763] {logging_mixin.py:115} INFO - [2023-01-05 00:44:40,763] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:44:41,669] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:44:41,671] {logging_mixin.py:115} INFO - [2023-01-05 00:44:41,671] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:44:41,671] {logging_mixin.py:115} INFO - [2023-01-05 00:44:41,671] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:44:41,678] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:44:41,704] {logging_mixin.py:115} INFO - [2023-01-05 00:44:41,704] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:44:41,736] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.979 seconds
[2023-01-05 00:45:11,828] {processor.py:153} INFO - Started process (PID=2834) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:45:11,830] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:45:11,830] {logging_mixin.py:115} INFO - [2023-01-05 00:45:11,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:45:12,753] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:45:12,755] {logging_mixin.py:115} INFO - [2023-01-05 00:45:12,755] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:45:12,755] {logging_mixin.py:115} INFO - [2023-01-05 00:45:12,755] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:45:12,762] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:45:12,784] {logging_mixin.py:115} INFO - [2023-01-05 00:45:12,784] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:45:12,812] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.988 seconds
[2023-01-05 00:45:42,902] {processor.py:153} INFO - Started process (PID=2855) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:45:42,902] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:45:42,903] {logging_mixin.py:115} INFO - [2023-01-05 00:45:42,903] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:45:44,032] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:45:44,033] {logging_mixin.py:115} INFO - [2023-01-05 00:45:44,033] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:45:44,034] {logging_mixin.py:115} INFO - [2023-01-05 00:45:44,033] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:45:44,041] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:45:44,063] {logging_mixin.py:115} INFO - [2023-01-05 00:45:44,063] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:45:44,099] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.202 seconds
[2023-01-05 00:46:14,168] {processor.py:153} INFO - Started process (PID=2872) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:46:14,169] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:46:14,169] {logging_mixin.py:115} INFO - [2023-01-05 00:46:14,169] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:46:15,120] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:46:15,122] {logging_mixin.py:115} INFO - [2023-01-05 00:46:15,122] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:46:15,123] {logging_mixin.py:115} INFO - [2023-01-05 00:46:15,122] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:46:15,134] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:46:15,164] {logging_mixin.py:115} INFO - [2023-01-05 00:46:15,164] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:46:15,198] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.035 seconds
[2023-01-05 00:46:45,242] {processor.py:153} INFO - Started process (PID=2895) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:46:45,242] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:46:45,243] {logging_mixin.py:115} INFO - [2023-01-05 00:46:45,243] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:46:46,107] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:46:46,108] {logging_mixin.py:115} INFO - [2023-01-05 00:46:46,108] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:46:46,109] {logging_mixin.py:115} INFO - [2023-01-05 00:46:46,108] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:46:46,115] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:46:46,137] {logging_mixin.py:115} INFO - [2023-01-05 00:46:46,137] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:46:46,164] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.927 seconds
[2023-01-05 00:47:16,260] {processor.py:153} INFO - Started process (PID=2919) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:47:16,261] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:47:16,262] {logging_mixin.py:115} INFO - [2023-01-05 00:47:16,262] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:47:17,136] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:47:17,138] {logging_mixin.py:115} INFO - [2023-01-05 00:47:17,137] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:47:17,138] {logging_mixin.py:115} INFO - [2023-01-05 00:47:17,138] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:47:17,145] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:47:17,167] {logging_mixin.py:115} INFO - [2023-01-05 00:47:17,167] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:47:17,194] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.939 seconds
[2023-01-05 00:47:47,309] {processor.py:153} INFO - Started process (PID=2942) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:47:47,310] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:47:47,310] {logging_mixin.py:115} INFO - [2023-01-05 00:47:47,310] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:47:48,511] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:47:48,513] {logging_mixin.py:115} INFO - [2023-01-05 00:47:48,513] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:47:48,514] {logging_mixin.py:115} INFO - [2023-01-05 00:47:48,513] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:47:48,525] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:47:48,557] {logging_mixin.py:115} INFO - [2023-01-05 00:47:48,556] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:47:48,595] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.291 seconds
[2023-01-05 00:48:18,674] {processor.py:153} INFO - Started process (PID=2958) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:48:18,674] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:48:18,675] {logging_mixin.py:115} INFO - [2023-01-05 00:48:18,675] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:48:19,536] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:48:19,537] {logging_mixin.py:115} INFO - [2023-01-05 00:48:19,537] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:48:19,538] {logging_mixin.py:115} INFO - [2023-01-05 00:48:19,538] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:48:19,545] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:48:19,567] {logging_mixin.py:115} INFO - [2023-01-05 00:48:19,566] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:48:19,593] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.924 seconds
[2023-01-05 00:48:49,672] {processor.py:153} INFO - Started process (PID=2983) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:48:49,675] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:48:49,676] {logging_mixin.py:115} INFO - [2023-01-05 00:48:49,676] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:48:50,555] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:48:50,557] {logging_mixin.py:115} INFO - [2023-01-05 00:48:50,557] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:48:50,557] {logging_mixin.py:115} INFO - [2023-01-05 00:48:50,557] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:48:50,564] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:48:50,586] {logging_mixin.py:115} INFO - [2023-01-05 00:48:50,586] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:48:50,613] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.945 seconds
[2023-01-05 00:49:20,683] {processor.py:153} INFO - Started process (PID=3007) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:49:20,686] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:49:20,687] {logging_mixin.py:115} INFO - [2023-01-05 00:49:20,687] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:49:21,627] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:49:21,628] {logging_mixin.py:115} INFO - [2023-01-05 00:49:21,628] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:49:21,629] {logging_mixin.py:115} INFO - [2023-01-05 00:49:21,628] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:49:21,635] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:49:21,658] {logging_mixin.py:115} INFO - [2023-01-05 00:49:21,657] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:49:21,686] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.008 seconds
[2023-01-05 00:49:51,764] {processor.py:153} INFO - Started process (PID=3031) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:49:51,764] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:49:51,765] {logging_mixin.py:115} INFO - [2023-01-05 00:49:51,765] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:49:52,732] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:49:52,734] {logging_mixin.py:115} INFO - [2023-01-05 00:49:52,734] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:49:52,735] {logging_mixin.py:115} INFO - [2023-01-05 00:49:52,734] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:49:52,746] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:49:52,779] {logging_mixin.py:115} INFO - [2023-01-05 00:49:52,779] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:49:52,809] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.052 seconds
[2023-01-05 00:50:22,876] {processor.py:153} INFO - Started process (PID=3046) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:50:22,877] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:50:22,878] {logging_mixin.py:115} INFO - [2023-01-05 00:50:22,878] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:50:23,736] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:50:23,738] {logging_mixin.py:115} INFO - [2023-01-05 00:50:23,738] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:50:23,739] {logging_mixin.py:115} INFO - [2023-01-05 00:50:23,738] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:50:23,750] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:50:23,773] {logging_mixin.py:115} INFO - [2023-01-05 00:50:23,773] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:50:23,800] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.929 seconds
[2023-01-05 00:50:53,901] {processor.py:153} INFO - Started process (PID=3069) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:50:53,902] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:50:53,902] {logging_mixin.py:115} INFO - [2023-01-05 00:50:53,902] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:50:54,830] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:50:54,831] {logging_mixin.py:115} INFO - [2023-01-05 00:50:54,831] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:50:54,832] {logging_mixin.py:115} INFO - [2023-01-05 00:50:54,832] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:50:54,839] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:50:54,866] {logging_mixin.py:115} INFO - [2023-01-05 00:50:54,866] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:50:54,903] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.006 seconds
[2023-01-05 00:51:24,983] {processor.py:153} INFO - Started process (PID=3091) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:51:24,984] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:51:24,985] {logging_mixin.py:115} INFO - [2023-01-05 00:51:24,985] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:51:25,858] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:51:25,859] {logging_mixin.py:115} INFO - [2023-01-05 00:51:25,859] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:51:25,860] {logging_mixin.py:115} INFO - [2023-01-05 00:51:25,859] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:51:25,866] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:51:25,888] {logging_mixin.py:115} INFO - [2023-01-05 00:51:25,888] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:51:25,915] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.937 seconds
[2023-01-05 00:51:56,012] {processor.py:153} INFO - Started process (PID=3115) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:51:56,013] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:51:56,014] {logging_mixin.py:115} INFO - [2023-01-05 00:51:56,014] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:51:57,090] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:51:57,092] {logging_mixin.py:115} INFO - [2023-01-05 00:51:57,092] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:51:57,092] {logging_mixin.py:115} INFO - [2023-01-05 00:51:57,092] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:51:57,099] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:51:57,123] {logging_mixin.py:115} INFO - [2023-01-05 00:51:57,122] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:51:57,151] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.143 seconds
[2023-01-05 00:52:27,229] {processor.py:153} INFO - Started process (PID=3131) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:52:27,235] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:52:27,236] {logging_mixin.py:115} INFO - [2023-01-05 00:52:27,236] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:52:28,218] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:52:28,220] {logging_mixin.py:115} INFO - [2023-01-05 00:52:28,220] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:52:28,220] {logging_mixin.py:115} INFO - [2023-01-05 00:52:28,220] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:52:28,227] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:52:28,250] {logging_mixin.py:115} INFO - [2023-01-05 00:52:28,249] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:52:28,286] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.063 seconds
[2023-01-05 00:52:58,363] {processor.py:153} INFO - Started process (PID=3155) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:52:58,364] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:52:58,364] {logging_mixin.py:115} INFO - [2023-01-05 00:52:58,364] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:52:59,244] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:52:59,245] {logging_mixin.py:115} INFO - [2023-01-05 00:52:59,245] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:52:59,246] {logging_mixin.py:115} INFO - [2023-01-05 00:52:59,245] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:52:59,252] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:52:59,274] {logging_mixin.py:115} INFO - [2023-01-05 00:52:59,274] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:52:59,301] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.943 seconds
[2023-01-05 00:53:29,365] {processor.py:153} INFO - Started process (PID=3178) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:53:29,365] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:53:29,366] {logging_mixin.py:115} INFO - [2023-01-05 00:53:29,366] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:53:30,253] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:53:30,255] {logging_mixin.py:115} INFO - [2023-01-05 00:53:30,255] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:53:30,255] {logging_mixin.py:115} INFO - [2023-01-05 00:53:30,255] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:53:30,262] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:53:30,285] {logging_mixin.py:115} INFO - [2023-01-05 00:53:30,284] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:53:30,305] {logging_mixin.py:115} INFO - [2023-01-05 00:53:30,305] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T00:00:00+00:00, run_after=2023-01-05T01:00:00+00:00
[2023-01-05 00:53:30,315] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.954 seconds
[2023-01-05 00:54:00,412] {processor.py:153} INFO - Started process (PID=3194) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:54:00,413] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:54:00,414] {logging_mixin.py:115} INFO - [2023-01-05 00:54:00,414] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:54:01,303] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:54:01,305] {logging_mixin.py:115} INFO - [2023-01-05 00:54:01,305] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:54:01,305] {logging_mixin.py:115} INFO - [2023-01-05 00:54:01,305] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:54:01,312] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:54:01,335] {logging_mixin.py:115} INFO - [2023-01-05 00:54:01,335] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:54:01,356] {logging_mixin.py:115} INFO - [2023-01-05 00:54:01,355] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T00:00:00+00:00, run_after=2023-01-05T01:00:00+00:00
[2023-01-05 00:54:01,365] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.958 seconds
[2023-01-05 00:54:31,463] {processor.py:153} INFO - Started process (PID=3218) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:54:31,464] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:54:31,465] {logging_mixin.py:115} INFO - [2023-01-05 00:54:31,464] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:54:32,330] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:54:32,331] {logging_mixin.py:115} INFO - [2023-01-05 00:54:32,331] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:54:32,332] {logging_mixin.py:115} INFO - [2023-01-05 00:54:32,331] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:54:32,338] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:54:32,361] {logging_mixin.py:115} INFO - [2023-01-05 00:54:32,361] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:54:32,382] {logging_mixin.py:115} INFO - [2023-01-05 00:54:32,381] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T00:00:00+00:00, run_after=2023-01-05T01:00:00+00:00
[2023-01-05 00:54:32,391] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.932 seconds
[2023-01-05 00:55:02,493] {processor.py:153} INFO - Started process (PID=3241) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:55:02,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:55:02,494] {logging_mixin.py:115} INFO - [2023-01-05 00:55:02,494] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:55:03,375] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:55:03,376] {logging_mixin.py:115} INFO - [2023-01-05 00:55:03,376] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:55:03,377] {logging_mixin.py:115} INFO - [2023-01-05 00:55:03,376] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:55:03,383] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:55:03,406] {logging_mixin.py:115} INFO - [2023-01-05 00:55:03,406] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:55:03,426] {logging_mixin.py:115} INFO - [2023-01-05 00:55:03,426] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T00:00:00+00:00, run_after=2023-01-05T01:00:00+00:00
[2023-01-05 00:55:03,436] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.948 seconds
[2023-01-05 00:55:33,532] {processor.py:153} INFO - Started process (PID=3263) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:55:33,534] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:55:33,534] {logging_mixin.py:115} INFO - [2023-01-05 00:55:33,534] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:55:34,420] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:55:34,421] {logging_mixin.py:115} INFO - [2023-01-05 00:55:34,421] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:55:34,422] {logging_mixin.py:115} INFO - [2023-01-05 00:55:34,421] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:55:34,428] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:55:34,451] {logging_mixin.py:115} INFO - [2023-01-05 00:55:34,450] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:55:34,472] {logging_mixin.py:115} INFO - [2023-01-05 00:55:34,472] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T00:00:00+00:00, run_after=2023-01-05T01:00:00+00:00
[2023-01-05 00:55:34,481] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.953 seconds
[2023-01-05 00:56:04,577] {processor.py:153} INFO - Started process (PID=3277) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:56:04,578] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:56:04,578] {logging_mixin.py:115} INFO - [2023-01-05 00:56:04,578] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:56:05,471] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:56:05,473] {logging_mixin.py:115} INFO - [2023-01-05 00:56:05,472] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:56:05,473] {logging_mixin.py:115} INFO - [2023-01-05 00:56:05,473] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:56:05,481] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:56:05,513] {logging_mixin.py:115} INFO - [2023-01-05 00:56:05,512] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:56:05,535] {logging_mixin.py:115} INFO - [2023-01-05 00:56:05,535] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T00:00:00+00:00, run_after=2023-01-05T01:00:00+00:00
[2023-01-05 00:56:05,547] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.975 seconds
[2023-01-05 00:56:35,639] {processor.py:153} INFO - Started process (PID=3300) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:56:35,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:56:35,640] {logging_mixin.py:115} INFO - [2023-01-05 00:56:35,640] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:56:36,503] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:56:36,505] {logging_mixin.py:115} INFO - [2023-01-05 00:56:36,504] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:56:36,505] {logging_mixin.py:115} INFO - [2023-01-05 00:56:36,505] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:56:36,512] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:56:36,534] {logging_mixin.py:115} INFO - [2023-01-05 00:56:36,533] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:56:36,554] {logging_mixin.py:115} INFO - [2023-01-05 00:56:36,554] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T00:00:00+00:00, run_after=2023-01-05T01:00:00+00:00
[2023-01-05 00:56:36,563] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.929 seconds
[2023-01-05 00:57:06,661] {processor.py:153} INFO - Started process (PID=3322) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:57:06,662] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:57:06,663] {logging_mixin.py:115} INFO - [2023-01-05 00:57:06,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:57:07,534] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:57:07,535] {logging_mixin.py:115} INFO - [2023-01-05 00:57:07,535] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:57:07,536] {logging_mixin.py:115} INFO - [2023-01-05 00:57:07,535] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:57:07,542] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:57:07,565] {logging_mixin.py:115} INFO - [2023-01-05 00:57:07,565] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:57:07,586] {logging_mixin.py:115} INFO - [2023-01-05 00:57:07,586] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T00:00:00+00:00, run_after=2023-01-05T01:00:00+00:00
[2023-01-05 00:57:07,595] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.939 seconds
[2023-01-05 00:57:37,705] {processor.py:153} INFO - Started process (PID=3345) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:57:37,709] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:57:37,710] {logging_mixin.py:115} INFO - [2023-01-05 00:57:37,710] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:57:38,602] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:57:38,603] {logging_mixin.py:115} INFO - [2023-01-05 00:57:38,603] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:57:38,603] {logging_mixin.py:115} INFO - [2023-01-05 00:57:38,603] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:57:38,610] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:57:38,632] {logging_mixin.py:115} INFO - [2023-01-05 00:57:38,632] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:57:38,653] {logging_mixin.py:115} INFO - [2023-01-05 00:57:38,653] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T00:00:00+00:00, run_after=2023-01-05T01:00:00+00:00
[2023-01-05 00:57:38,663] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.963 seconds
[2023-01-05 00:58:08,758] {processor.py:153} INFO - Started process (PID=3361) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:58:08,759] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:58:08,759] {logging_mixin.py:115} INFO - [2023-01-05 00:58:08,759] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:58:09,629] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:58:09,630] {logging_mixin.py:115} INFO - [2023-01-05 00:58:09,630] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:58:09,631] {logging_mixin.py:115} INFO - [2023-01-05 00:58:09,630] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:58:09,638] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:58:09,661] {logging_mixin.py:115} INFO - [2023-01-05 00:58:09,660] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:58:09,682] {logging_mixin.py:115} INFO - [2023-01-05 00:58:09,681] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T00:00:00+00:00, run_after=2023-01-05T01:00:00+00:00
[2023-01-05 00:58:09,691] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.938 seconds
[2023-01-05 00:58:39,795] {processor.py:153} INFO - Started process (PID=3384) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:58:39,797] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:58:39,797] {logging_mixin.py:115} INFO - [2023-01-05 00:58:39,797] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:58:40,702] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:58:40,704] {logging_mixin.py:115} INFO - [2023-01-05 00:58:40,704] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:58:40,705] {logging_mixin.py:115} INFO - [2023-01-05 00:58:40,704] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:58:40,716] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:58:40,740] {logging_mixin.py:115} INFO - [2023-01-05 00:58:40,740] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:58:40,761] {logging_mixin.py:115} INFO - [2023-01-05 00:58:40,761] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T00:00:00+00:00, run_after=2023-01-05T01:00:00+00:00
[2023-01-05 00:58:40,770] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.979 seconds
[2023-01-05 00:59:10,863] {processor.py:153} INFO - Started process (PID=3407) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:59:10,863] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:59:10,864] {logging_mixin.py:115} INFO - [2023-01-05 00:59:10,864] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:59:11,756] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:59:11,757] {logging_mixin.py:115} INFO - [2023-01-05 00:59:11,757] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:59:11,758] {logging_mixin.py:115} INFO - [2023-01-05 00:59:11,758] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:59:11,765] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:59:11,788] {logging_mixin.py:115} INFO - [2023-01-05 00:59:11,788] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:59:11,809] {logging_mixin.py:115} INFO - [2023-01-05 00:59:11,809] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T00:00:00+00:00, run_after=2023-01-05T01:00:00+00:00
[2023-01-05 00:59:11,818] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.960 seconds
[2023-01-05 00:59:41,915] {processor.py:153} INFO - Started process (PID=3429) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:59:41,916] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 00:59:41,916] {logging_mixin.py:115} INFO - [2023-01-05 00:59:41,916] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:59:42,798] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 00:59:42,800] {logging_mixin.py:115} INFO - [2023-01-05 00:59:42,800] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 00:59:42,800] {logging_mixin.py:115} INFO - [2023-01-05 00:59:42,800] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 00:59:42,807] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 00:59:42,829] {logging_mixin.py:115} INFO - [2023-01-05 00:59:42,828] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 00:59:42,849] {logging_mixin.py:115} INFO - [2023-01-05 00:59:42,849] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T00:00:00+00:00, run_after=2023-01-05T01:00:00+00:00
[2023-01-05 00:59:42,859] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.948 seconds
[2023-01-05 02:51:32,761] {processor.py:153} INFO - Started process (PID=32) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:51:32,766] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:51:32,766] {logging_mixin.py:115} INFO - [2023-01-05 02:51:32,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:51:37,666] {logging_mixin.py:115} INFO - [2023-01-05 02:51:37,663] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipeline_dag.py", line 59, in <module>
    python_callable=Load_Current_BTC_End_of_Day_Prices_Into_GCS.main,
NameError: name 'Load_Current_BTC_End_of_Day_Prices_Into_GCS' is not defined
[2023-01-05 02:51:37,666] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:51:37,706] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 4.956 seconds
[2023-01-05 02:52:07,873] {processor.py:153} INFO - Started process (PID=56) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:52:07,879] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:52:07,880] {logging_mixin.py:115} INFO - [2023-01-05 02:52:07,880] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:52:08,935] {logging_mixin.py:115} INFO - [2023-01-05 02:52:08,934] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipeline_dag.py", line 59, in <module>
    python_callable=Load_Current_BTC_End_of_Day_Prices_Into_GCS.main,
NameError: name 'Load_Current_BTC_End_of_Day_Prices_Into_GCS' is not defined
[2023-01-05 02:52:08,935] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:52:08,957] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.089 seconds
[2023-01-05 02:52:39,048] {processor.py:153} INFO - Started process (PID=75) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:52:39,048] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:52:39,049] {logging_mixin.py:115} INFO - [2023-01-05 02:52:39,049] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:52:40,561] {logging_mixin.py:115} INFO - [2023-01-05 02:52:40,559] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipeline_dag.py", line 59, in <module>
    python_callable=Load_Current_BTC_End_of_Day_Prices_Into_GCS.main,
NameError: name 'Load_Current_BTC_End_of_Day_Prices_Into_GCS' is not defined
[2023-01-05 02:52:40,562] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:52:40,610] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.568 seconds
[2023-01-05 02:53:11,140] {processor.py:153} INFO - Started process (PID=101) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:53:11,141] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:53:11,142] {logging_mixin.py:115} INFO - [2023-01-05 02:53:11,142] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:53:12,162] {logging_mixin.py:115} INFO - [2023-01-05 02:53:12,161] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipeline_dag.py", line 59, in <module>
    python_callable=Load_Current_BTC_End_of_Day_Prices_Into_GCS.main,
NameError: name 'Load_Current_BTC_End_of_Day_Prices_Into_GCS' is not defined
[2023-01-05 02:53:12,162] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:53:12,183] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.048 seconds
[2023-01-05 02:53:42,285] {processor.py:153} INFO - Started process (PID=126) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:53:42,286] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:53:42,287] {logging_mixin.py:115} INFO - [2023-01-05 02:53:42,286] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:53:43,327] {logging_mixin.py:115} INFO - [2023-01-05 02:53:43,325] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipeline_dag.py", line 59, in <module>
    python_callable=Load_Current_BTC_End_of_Day_Prices_Into_GCS.main,
NameError: name 'Load_Current_BTC_End_of_Day_Prices_Into_GCS' is not defined
[2023-01-05 02:53:43,327] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:53:43,350] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.070 seconds
[2023-01-05 02:54:13,463] {processor.py:153} INFO - Started process (PID=150) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:54:13,464] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:54:13,465] {logging_mixin.py:115} INFO - [2023-01-05 02:54:13,465] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:54:14,465] {logging_mixin.py:115} INFO - [2023-01-05 02:54:14,464] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipeline_dag.py", line 59, in <module>
    python_callable=Load_Current_BTC_End_of_Day_Prices_Into_GCS.main,
NameError: name 'Load_Current_BTC_End_of_Day_Prices_Into_GCS' is not defined
[2023-01-05 02:54:14,466] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:54:14,485] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.028 seconds
[2023-01-05 02:54:44,652] {processor.py:153} INFO - Started process (PID=171) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:54:44,653] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:54:44,654] {logging_mixin.py:115} INFO - [2023-01-05 02:54:44,654] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:54:45,655] {logging_mixin.py:115} INFO - [2023-01-05 02:54:45,654] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipeline_dag.py", line 59, in <module>
    python_callable=Load_Current_BTC_End_of_Day_Prices_Into_GCS.main,
NameError: name 'Load_Current_BTC_End_of_Day_Prices_Into_GCS' is not defined
[2023-01-05 02:54:45,656] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:54:45,678] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.031 seconds
[2023-01-05 02:55:15,763] {processor.py:153} INFO - Started process (PID=196) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:55:15,765] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:55:15,766] {logging_mixin.py:115} INFO - [2023-01-05 02:55:15,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:55:16,756] {logging_mixin.py:115} INFO - [2023-01-05 02:55:16,755] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipeline_dag.py", line 59, in <module>
    python_callable=Load_Current_BTC_End_of_Day_Prices_Into_GCS.main,
NameError: name 'Load_Current_BTC_End_of_Day_Prices_Into_GCS' is not defined
[2023-01-05 02:55:16,756] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:55:16,777] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.018 seconds
[2023-01-05 02:55:46,861] {processor.py:153} INFO - Started process (PID=222) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:55:46,862] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:55:46,863] {logging_mixin.py:115} INFO - [2023-01-05 02:55:46,863] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:55:47,870] {logging_mixin.py:115} INFO - [2023-01-05 02:55:47,869] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipeline_dag.py", line 59, in <module>
    python_callable=Load_Current_BTC_End_of_Day_Prices_Into_GCS.main,
NameError: name 'Load_Current_BTC_End_of_Day_Prices_Into_GCS' is not defined
[2023-01-05 02:55:47,870] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:55:47,889] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.033 seconds
[2023-01-05 02:56:17,984] {processor.py:153} INFO - Started process (PID=239) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:56:17,987] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:56:17,987] {logging_mixin.py:115} INFO - [2023-01-05 02:56:17,987] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:56:19,382] {logging_mixin.py:115} INFO - [2023-01-05 02:56:19,381] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipeline_dag.py", line 59, in <module>
    python_callable=Load_Current_BTC_End_of_Day_Prices_Into_GCS.main,
NameError: name 'Load_Current_BTC_End_of_Day_Prices_Into_GCS' is not defined
[2023-01-05 02:56:19,383] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:56:19,410] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.430 seconds
[2023-01-05 02:56:45,228] {processor.py:153} INFO - Started process (PID=264) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:56:45,229] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:56:45,230] {logging_mixin.py:115} INFO - [2023-01-05 02:56:45,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:56:46,247] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:56:46,249] {logging_mixin.py:115} INFO - [2023-01-05 02:56:46,249] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:56:46,250] {logging_mixin.py:115} INFO - [2023-01-05 02:56:46,249] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:56:46,257] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:56:46,315] {logging_mixin.py:115} INFO - [2023-01-05 02:56:46,315] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:56:46,335] {logging_mixin.py:115} INFO - [2023-01-05 02:56:46,335] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 02:56:46,352] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.130 seconds
[2023-01-05 02:57:16,386] {processor.py:153} INFO - Started process (PID=281) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:57:16,387] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:57:16,388] {logging_mixin.py:115} INFO - [2023-01-05 02:57:16,387] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:57:17,456] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:57:17,458] {logging_mixin.py:115} INFO - [2023-01-05 02:57:17,457] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:57:17,458] {logging_mixin.py:115} INFO - [2023-01-05 02:57:17,458] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:57:17,465] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:57:17,491] {logging_mixin.py:115} INFO - [2023-01-05 02:57:17,491] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:57:17,514] {logging_mixin.py:115} INFO - [2023-01-05 02:57:17,513] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 02:57:17,525] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.144 seconds
[2023-01-05 02:57:47,627] {processor.py:153} INFO - Started process (PID=308) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:57:47,628] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:57:47,629] {logging_mixin.py:115} INFO - [2023-01-05 02:57:47,628] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:57:48,623] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:57:48,625] {logging_mixin.py:115} INFO - [2023-01-05 02:57:48,625] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:57:48,625] {logging_mixin.py:115} INFO - [2023-01-05 02:57:48,625] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:57:48,632] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:57:48,657] {logging_mixin.py:115} INFO - [2023-01-05 02:57:48,657] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:57:48,679] {logging_mixin.py:115} INFO - [2023-01-05 02:57:48,679] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 02:57:48,690] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.069 seconds
[2023-01-05 02:58:19,707] {processor.py:153} INFO - Started process (PID=335) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:58:19,708] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:58:19,709] {logging_mixin.py:115} INFO - [2023-01-05 02:58:19,709] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:58:20,698] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:58:20,699] {logging_mixin.py:115} INFO - [2023-01-05 02:58:20,699] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:58:20,700] {logging_mixin.py:115} INFO - [2023-01-05 02:58:20,699] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:58:20,707] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:58:20,732] {logging_mixin.py:115} INFO - [2023-01-05 02:58:20,732] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:58:20,755] {logging_mixin.py:115} INFO - [2023-01-05 02:58:20,754] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 02:58:20,765] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.063 seconds
[2023-01-05 02:58:50,841] {processor.py:153} INFO - Started process (PID=360) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:58:50,842] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:58:50,842] {logging_mixin.py:115} INFO - [2023-01-05 02:58:50,842] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:58:51,857] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:58:51,858] {logging_mixin.py:115} INFO - [2023-01-05 02:58:51,858] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:58:51,859] {logging_mixin.py:115} INFO - [2023-01-05 02:58:51,859] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:58:51,866] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:58:51,889] {logging_mixin.py:115} INFO - [2023-01-05 02:58:51,889] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:58:51,911] {logging_mixin.py:115} INFO - [2023-01-05 02:58:51,911] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 02:58:51,921] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.085 seconds
[2023-01-05 02:59:21,992] {processor.py:153} INFO - Started process (PID=378) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:59:21,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:59:21,994] {logging_mixin.py:115} INFO - [2023-01-05 02:59:21,994] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:59:22,979] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:59:22,981] {logging_mixin.py:115} INFO - [2023-01-05 02:59:22,980] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:59:22,981] {logging_mixin.py:115} INFO - [2023-01-05 02:59:22,981] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:59:22,988] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:59:23,014] {logging_mixin.py:115} INFO - [2023-01-05 02:59:23,013] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:59:23,036] {logging_mixin.py:115} INFO - [2023-01-05 02:59:23,036] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 02:59:23,046] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.059 seconds
[2023-01-05 02:59:53,121] {processor.py:153} INFO - Started process (PID=403) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:59:53,122] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:59:53,123] {logging_mixin.py:115} INFO - [2023-01-05 02:59:53,123] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:59:54,124] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:59:54,126] {logging_mixin.py:115} INFO - [2023-01-05 02:59:54,125] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:59:54,126] {logging_mixin.py:115} INFO - [2023-01-05 02:59:54,126] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:59:54,133] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 02:59:54,158] {logging_mixin.py:115} INFO - [2023-01-05 02:59:54,157] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:59:54,179] {logging_mixin.py:115} INFO - [2023-01-05 02:59:54,179] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 02:59:54,189] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.074 seconds
[2023-01-05 03:00:25,200] {processor.py:153} INFO - Started process (PID=429) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:00:25,204] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:00:25,204] {logging_mixin.py:115} INFO - [2023-01-05 03:00:25,204] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:00:26,180] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:00:26,182] {logging_mixin.py:115} INFO - [2023-01-05 03:00:26,181] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:00:26,182] {logging_mixin.py:115} INFO - [2023-01-05 03:00:26,182] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:00:26,194] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:00:26,218] {logging_mixin.py:115} INFO - [2023-01-05 03:00:26,217] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:00:26,239] {logging_mixin.py:115} INFO - [2023-01-05 03:00:26,239] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:00:26,249] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.053 seconds
[2023-01-05 03:00:56,344] {processor.py:153} INFO - Started process (PID=453) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:00:56,344] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:00:56,345] {logging_mixin.py:115} INFO - [2023-01-05 03:00:56,345] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:00:57,332] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:00:57,334] {logging_mixin.py:115} INFO - [2023-01-05 03:00:57,334] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:00:57,334] {logging_mixin.py:115} INFO - [2023-01-05 03:00:57,334] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:00:57,342] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:00:57,368] {logging_mixin.py:115} INFO - [2023-01-05 03:00:57,367] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:00:57,390] {logging_mixin.py:115} INFO - [2023-01-05 03:00:57,390] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:00:57,401] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.063 seconds
[2023-01-05 03:01:27,494] {processor.py:153} INFO - Started process (PID=471) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:01:27,495] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:01:27,496] {logging_mixin.py:115} INFO - [2023-01-05 03:01:27,496] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:01:28,488] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:01:28,490] {logging_mixin.py:115} INFO - [2023-01-05 03:01:28,490] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:01:28,491] {logging_mixin.py:115} INFO - [2023-01-05 03:01:28,490] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:01:28,501] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:01:28,526] {logging_mixin.py:115} INFO - [2023-01-05 03:01:28,525] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:01:28,547] {logging_mixin.py:115} INFO - [2023-01-05 03:01:28,547] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:01:28,558] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.070 seconds
[2023-01-05 03:01:58,633] {processor.py:153} INFO - Started process (PID=495) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:01:58,634] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:01:58,635] {logging_mixin.py:115} INFO - [2023-01-05 03:01:58,635] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:01:59,623] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:01:59,625] {logging_mixin.py:115} INFO - [2023-01-05 03:01:59,625] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:01:59,626] {logging_mixin.py:115} INFO - [2023-01-05 03:01:59,625] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:01:59,633] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:01:59,658] {logging_mixin.py:115} INFO - [2023-01-05 03:01:59,657] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:01:59,680] {logging_mixin.py:115} INFO - [2023-01-05 03:01:59,680] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:01:59,691] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.064 seconds
[2023-01-05 03:02:29,765] {processor.py:153} INFO - Started process (PID=518) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:02:29,766] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:02:29,766] {logging_mixin.py:115} INFO - [2023-01-05 03:02:29,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:02:30,779] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:02:30,781] {logging_mixin.py:115} INFO - [2023-01-05 03:02:30,781] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:02:30,781] {logging_mixin.py:115} INFO - [2023-01-05 03:02:30,781] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:02:30,789] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:02:30,814] {logging_mixin.py:115} INFO - [2023-01-05 03:02:30,813] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:02:30,836] {logging_mixin.py:115} INFO - [2023-01-05 03:02:30,836] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:02:30,846] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.087 seconds
[2023-01-05 03:03:00,920] {processor.py:153} INFO - Started process (PID=535) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:03:00,922] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:03:00,923] {logging_mixin.py:115} INFO - [2023-01-05 03:03:00,923] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:03:01,935] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:03:01,937] {logging_mixin.py:115} INFO - [2023-01-05 03:03:01,937] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:03:01,937] {logging_mixin.py:115} INFO - [2023-01-05 03:03:01,937] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:03:01,944] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:03:01,968] {logging_mixin.py:115} INFO - [2023-01-05 03:03:01,968] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:03:01,990] {logging_mixin.py:115} INFO - [2023-01-05 03:03:01,990] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:03:02,000] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.085 seconds
[2023-01-05 03:03:32,078] {processor.py:153} INFO - Started process (PID=561) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:03:32,080] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:03:32,081] {logging_mixin.py:115} INFO - [2023-01-05 03:03:32,080] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:03:33,069] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:03:33,070] {logging_mixin.py:115} INFO - [2023-01-05 03:03:33,070] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:03:33,071] {logging_mixin.py:115} INFO - [2023-01-05 03:03:33,071] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:03:33,078] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:03:33,103] {logging_mixin.py:115} INFO - [2023-01-05 03:03:33,102] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:03:33,124] {logging_mixin.py:115} INFO - [2023-01-05 03:03:33,124] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:03:33,135] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.062 seconds
[2023-01-05 03:04:03,209] {processor.py:153} INFO - Started process (PID=586) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:04:03,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:04:03,210] {logging_mixin.py:115} INFO - [2023-01-05 03:04:03,210] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:04:04,223] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:04:04,225] {logging_mixin.py:115} INFO - [2023-01-05 03:04:04,224] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:04:04,225] {logging_mixin.py:115} INFO - [2023-01-05 03:04:04,225] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:04:04,236] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:04:04,273] {logging_mixin.py:115} INFO - [2023-01-05 03:04:04,273] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:04:04,305] {logging_mixin.py:115} INFO - [2023-01-05 03:04:04,305] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:04:04,316] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.113 seconds
[2023-01-05 03:04:34,416] {processor.py:153} INFO - Started process (PID=611) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:04:34,417] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:04:34,418] {logging_mixin.py:115} INFO - [2023-01-05 03:04:34,418] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:04:35,581] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:04:35,583] {logging_mixin.py:115} INFO - [2023-01-05 03:04:35,583] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:04:35,583] {logging_mixin.py:115} INFO - [2023-01-05 03:04:35,583] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:04:35,591] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:04:35,615] {logging_mixin.py:115} INFO - [2023-01-05 03:04:35,615] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:04:35,639] {logging_mixin.py:115} INFO - [2023-01-05 03:04:35,639] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:04:35,650] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.241 seconds
[2023-01-05 03:05:06,606] {processor.py:153} INFO - Started process (PID=629) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:05:06,607] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:05:06,608] {logging_mixin.py:115} INFO - [2023-01-05 03:05:06,608] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:05:07,615] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:05:07,616] {logging_mixin.py:115} INFO - [2023-01-05 03:05:07,616] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:05:07,617] {logging_mixin.py:115} INFO - [2023-01-05 03:05:07,617] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:05:07,624] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:05:07,650] {logging_mixin.py:115} INFO - [2023-01-05 03:05:07,649] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:05:07,673] {logging_mixin.py:115} INFO - [2023-01-05 03:05:07,673] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:05:07,685] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.083 seconds
[2023-01-05 03:05:37,765] {processor.py:153} INFO - Started process (PID=653) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:05:37,766] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:05:37,766] {logging_mixin.py:115} INFO - [2023-01-05 03:05:37,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:05:38,875] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:05:38,877] {logging_mixin.py:115} INFO - [2023-01-05 03:05:38,877] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:05:38,878] {logging_mixin.py:115} INFO - [2023-01-05 03:05:38,877] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:05:38,885] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:05:38,912] {logging_mixin.py:115} INFO - [2023-01-05 03:05:38,911] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:05:38,936] {logging_mixin.py:115} INFO - [2023-01-05 03:05:38,935] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:05:38,946] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.190 seconds
[2023-01-05 03:06:09,848] {processor.py:153} INFO - Started process (PID=676) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:06:09,850] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:06:09,851] {logging_mixin.py:115} INFO - [2023-01-05 03:06:09,851] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:06:10,846] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:06:10,848] {logging_mixin.py:115} INFO - [2023-01-05 03:06:10,848] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:06:10,848] {logging_mixin.py:115} INFO - [2023-01-05 03:06:10,848] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:06:10,856] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:06:10,881] {logging_mixin.py:115} INFO - [2023-01-05 03:06:10,881] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:06:10,904] {logging_mixin.py:115} INFO - [2023-01-05 03:06:10,904] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:06:10,915] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.073 seconds
[2023-01-05 03:06:40,964] {processor.py:153} INFO - Started process (PID=701) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:06:40,964] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:06:40,965] {logging_mixin.py:115} INFO - [2023-01-05 03:06:40,965] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:06:42,201] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:06:42,203] {logging_mixin.py:115} INFO - [2023-01-05 03:06:42,203] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:06:42,203] {logging_mixin.py:115} INFO - [2023-01-05 03:06:42,203] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:06:42,210] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:06:42,235] {logging_mixin.py:115} INFO - [2023-01-05 03:06:42,235] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:06:42,259] {logging_mixin.py:115} INFO - [2023-01-05 03:06:42,258] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:06:42,270] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.312 seconds
[2023-01-05 03:07:12,349] {processor.py:153} INFO - Started process (PID=719) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:07:12,351] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:07:12,351] {logging_mixin.py:115} INFO - [2023-01-05 03:07:12,351] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:07:13,369] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:07:13,370] {logging_mixin.py:115} INFO - [2023-01-05 03:07:13,370] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:07:13,371] {logging_mixin.py:115} INFO - [2023-01-05 03:07:13,370] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:07:13,378] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:07:13,406] {logging_mixin.py:115} INFO - [2023-01-05 03:07:13,405] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:07:13,428] {logging_mixin.py:115} INFO - [2023-01-05 03:07:13,428] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:07:13,440] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.096 seconds
[2023-01-05 03:07:44,440] {processor.py:153} INFO - Started process (PID=746) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:07:44,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:07:44,442] {logging_mixin.py:115} INFO - [2023-01-05 03:07:44,442] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:07:45,430] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:07:45,432] {logging_mixin.py:115} INFO - [2023-01-05 03:07:45,431] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:07:45,432] {logging_mixin.py:115} INFO - [2023-01-05 03:07:45,432] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:07:45,439] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:07:45,464] {logging_mixin.py:115} INFO - [2023-01-05 03:07:45,463] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:07:45,486] {logging_mixin.py:115} INFO - [2023-01-05 03:07:45,485] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:07:45,497] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.061 seconds
[2023-01-05 03:08:15,582] {processor.py:153} INFO - Started process (PID=773) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:08:15,583] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:08:15,584] {logging_mixin.py:115} INFO - [2023-01-05 03:08:15,584] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:08:16,610] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:08:16,612] {logging_mixin.py:115} INFO - [2023-01-05 03:08:16,612] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:08:16,612] {logging_mixin.py:115} INFO - [2023-01-05 03:08:16,612] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:08:16,620] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:08:16,648] {logging_mixin.py:115} INFO - [2023-01-05 03:08:16,647] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:08:16,681] {logging_mixin.py:115} INFO - [2023-01-05 03:08:16,680] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:08:16,693] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.116 seconds
[2023-01-05 03:08:46,789] {processor.py:153} INFO - Started process (PID=791) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:08:46,789] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:08:46,790] {logging_mixin.py:115} INFO - [2023-01-05 03:08:46,790] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:08:47,801] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:08:47,802] {logging_mixin.py:115} INFO - [2023-01-05 03:08:47,802] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:08:47,803] {logging_mixin.py:115} INFO - [2023-01-05 03:08:47,803] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:08:47,810] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:08:47,835] {logging_mixin.py:115} INFO - [2023-01-05 03:08:47,835] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:08:47,857] {logging_mixin.py:115} INFO - [2023-01-05 03:08:47,857] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:08:47,868] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.084 seconds
[2023-01-05 03:09:17,948] {processor.py:153} INFO - Started process (PID=815) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:09:17,949] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:09:17,950] {logging_mixin.py:115} INFO - [2023-01-05 03:09:17,950] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:09:18,916] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:09:18,917] {logging_mixin.py:115} INFO - [2023-01-05 03:09:18,917] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:09:18,918] {logging_mixin.py:115} INFO - [2023-01-05 03:09:18,917] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:09:18,925] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:09:18,949] {logging_mixin.py:115} INFO - [2023-01-05 03:09:18,948] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:09:18,971] {logging_mixin.py:115} INFO - [2023-01-05 03:09:18,971] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:09:18,981] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.038 seconds
[2023-01-05 03:09:49,032] {processor.py:153} INFO - Started process (PID=841) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:09:49,035] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:09:49,036] {logging_mixin.py:115} INFO - [2023-01-05 03:09:49,036] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:09:50,036] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:09:50,038] {logging_mixin.py:115} INFO - [2023-01-05 03:09:50,038] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:09:50,038] {logging_mixin.py:115} INFO - [2023-01-05 03:09:50,038] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:09:50,046] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:09:50,071] {logging_mixin.py:115} INFO - [2023-01-05 03:09:50,070] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:09:50,092] {logging_mixin.py:115} INFO - [2023-01-05 03:09:50,092] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:09:50,103] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.075 seconds
[2023-01-05 03:10:20,181] {processor.py:153} INFO - Started process (PID=866) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:10:20,182] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:10:20,183] {logging_mixin.py:115} INFO - [2023-01-05 03:10:20,183] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:10:21,541] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:10:21,543] {logging_mixin.py:115} INFO - [2023-01-05 03:10:21,543] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:10:21,543] {logging_mixin.py:115} INFO - [2023-01-05 03:10:21,543] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:10:21,551] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:10:21,584] {logging_mixin.py:115} INFO - [2023-01-05 03:10:21,584] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:10:21,612] {logging_mixin.py:115} INFO - [2023-01-05 03:10:21,612] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:10:21,624] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.450 seconds
[2023-01-05 03:10:51,705] {processor.py:153} INFO - Started process (PID=884) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:10:51,706] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:10:51,707] {logging_mixin.py:115} INFO - [2023-01-05 03:10:51,707] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:10:52,715] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:10:52,716] {logging_mixin.py:115} INFO - [2023-01-05 03:10:52,716] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:10:52,717] {logging_mixin.py:115} INFO - [2023-01-05 03:10:52,717] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:10:52,724] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:10:52,749] {logging_mixin.py:115} INFO - [2023-01-05 03:10:52,748] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:10:52,770] {logging_mixin.py:115} INFO - [2023-01-05 03:10:52,770] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:10:52,780] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.081 seconds
[2023-01-05 03:11:22,856] {processor.py:153} INFO - Started process (PID=909) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:11:22,857] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:11:22,857] {logging_mixin.py:115} INFO - [2023-01-05 03:11:22,857] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:11:23,945] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:11:23,947] {logging_mixin.py:115} INFO - [2023-01-05 03:11:23,947] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:11:23,948] {logging_mixin.py:115} INFO - [2023-01-05 03:11:23,948] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:11:23,960] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:11:23,987] {logging_mixin.py:115} INFO - [2023-01-05 03:11:23,987] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:11:24,010] {logging_mixin.py:115} INFO - [2023-01-05 03:11:24,010] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:11:24,021] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.170 seconds
[2023-01-05 03:11:54,136] {processor.py:153} INFO - Started process (PID=934) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:11:54,137] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:11:54,138] {logging_mixin.py:115} INFO - [2023-01-05 03:11:54,138] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:11:55,134] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:11:55,136] {logging_mixin.py:115} INFO - [2023-01-05 03:11:55,136] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:11:55,136] {logging_mixin.py:115} INFO - [2023-01-05 03:11:55,136] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:11:55,143] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:11:55,168] {logging_mixin.py:115} INFO - [2023-01-05 03:11:55,167] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:11:55,191] {logging_mixin.py:115} INFO - [2023-01-05 03:11:55,191] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:11:55,201] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.071 seconds
[2023-01-05 03:12:25,299] {processor.py:153} INFO - Started process (PID=951) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:12:25,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:12:25,301] {logging_mixin.py:115} INFO - [2023-01-05 03:12:25,301] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:12:26,318] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:12:26,320] {logging_mixin.py:115} INFO - [2023-01-05 03:12:26,320] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:12:26,320] {logging_mixin.py:115} INFO - [2023-01-05 03:12:26,320] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:12:26,329] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:12:26,358] {logging_mixin.py:115} INFO - [2023-01-05 03:12:26,358] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:12:26,383] {logging_mixin.py:115} INFO - [2023-01-05 03:12:26,383] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:12:26,394] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.101 seconds
[2023-01-05 03:12:57,390] {processor.py:153} INFO - Started process (PID=976) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:12:57,394] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:12:57,394] {logging_mixin.py:115} INFO - [2023-01-05 03:12:57,394] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:12:58,407] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:12:58,409] {logging_mixin.py:115} INFO - [2023-01-05 03:12:58,409] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:12:58,410] {logging_mixin.py:115} INFO - [2023-01-05 03:12:58,409] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:12:58,417] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:12:58,442] {logging_mixin.py:115} INFO - [2023-01-05 03:12:58,442] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:12:58,467] {logging_mixin.py:115} INFO - [2023-01-05 03:12:58,467] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:12:58,479] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.093 seconds
[2023-01-05 03:13:28,537] {processor.py:153} INFO - Started process (PID=1000) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:13:28,538] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:13:28,539] {logging_mixin.py:115} INFO - [2023-01-05 03:13:28,538] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:13:29,558] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:13:29,560] {logging_mixin.py:115} INFO - [2023-01-05 03:13:29,559] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:13:29,560] {logging_mixin.py:115} INFO - [2023-01-05 03:13:29,560] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:13:29,567] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:13:29,597] {logging_mixin.py:115} INFO - [2023-01-05 03:13:29,596] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:13:29,630] {logging_mixin.py:115} INFO - [2023-01-05 03:13:29,629] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:13:29,644] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.113 seconds
[2023-01-05 03:13:49,601] {processor.py:153} INFO - Started process (PID=1018) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:13:49,602] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:13:49,602] {logging_mixin.py:115} INFO - [2023-01-05 03:13:49,602] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:13:50,608] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:13:50,610] {logging_mixin.py:115} INFO - [2023-01-05 03:13:50,610] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:13:50,611] {logging_mixin.py:115} INFO - [2023-01-05 03:13:50,610] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:13:50,618] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:13:50,677] {logging_mixin.py:115} INFO - [2023-01-05 03:13:50,676] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:13:50,698] {logging_mixin.py:115} INFO - [2023-01-05 03:13:50,697] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:13:50,713] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.118 seconds
[2023-01-05 03:14:20,765] {processor.py:153} INFO - Started process (PID=1036) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:14:20,767] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:14:20,768] {logging_mixin.py:115} INFO - [2023-01-05 03:14:20,768] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:14:21,786] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:14:21,788] {logging_mixin.py:115} INFO - [2023-01-05 03:14:21,787] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:14:21,788] {logging_mixin.py:115} INFO - [2023-01-05 03:14:21,788] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:14:21,795] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:14:21,821] {logging_mixin.py:115} INFO - [2023-01-05 03:14:21,820] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:14:21,843] {logging_mixin.py:115} INFO - [2023-01-05 03:14:21,843] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:14:21,853] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.093 seconds
[2023-01-05 03:14:51,939] {processor.py:153} INFO - Started process (PID=1061) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:14:51,940] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:14:51,941] {logging_mixin.py:115} INFO - [2023-01-05 03:14:51,941] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:14:52,955] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:14:52,957] {logging_mixin.py:115} INFO - [2023-01-05 03:14:52,957] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:14:52,958] {logging_mixin.py:115} INFO - [2023-01-05 03:14:52,957] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:14:52,965] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:14:52,991] {logging_mixin.py:115} INFO - [2023-01-05 03:14:52,990] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:14:53,013] {logging_mixin.py:115} INFO - [2023-01-05 03:14:53,012] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:14:53,023] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.089 seconds
[2023-01-05 03:15:23,104] {processor.py:153} INFO - Started process (PID=1086) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:15:23,106] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:15:23,106] {logging_mixin.py:115} INFO - [2023-01-05 03:15:23,106] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:15:24,170] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:15:24,172] {logging_mixin.py:115} INFO - [2023-01-05 03:15:24,171] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:15:24,172] {logging_mixin.py:115} INFO - [2023-01-05 03:15:24,172] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:15:24,179] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:15:24,204] {logging_mixin.py:115} INFO - [2023-01-05 03:15:24,204] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:15:24,227] {logging_mixin.py:115} INFO - [2023-01-05 03:15:24,226] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:15:24,237] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.138 seconds
[2023-01-05 03:15:54,313] {processor.py:153} INFO - Started process (PID=1105) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:15:54,314] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:15:54,314] {logging_mixin.py:115} INFO - [2023-01-05 03:15:54,314] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:15:55,305] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:15:55,306] {logging_mixin.py:115} INFO - [2023-01-05 03:15:55,306] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:15:55,307] {logging_mixin.py:115} INFO - [2023-01-05 03:15:55,307] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:15:55,314] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:15:55,347] {logging_mixin.py:115} INFO - [2023-01-05 03:15:55,346] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:15:55,379] {logging_mixin.py:115} INFO - [2023-01-05 03:15:55,379] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:15:55,395] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.087 seconds
[2023-01-05 03:16:25,479] {processor.py:153} INFO - Started process (PID=1132) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:16:25,481] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:16:25,481] {logging_mixin.py:115} INFO - [2023-01-05 03:16:25,481] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:16:26,456] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:16:26,457] {logging_mixin.py:115} INFO - [2023-01-05 03:16:26,457] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:16:26,458] {logging_mixin.py:115} INFO - [2023-01-05 03:16:26,458] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:16:26,467] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:16:26,500] {logging_mixin.py:115} INFO - [2023-01-05 03:16:26,500] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:16:26,523] {logging_mixin.py:115} INFO - [2023-01-05 03:16:26,523] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:16:26,533] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.059 seconds
[2023-01-05 03:16:56,623] {processor.py:153} INFO - Started process (PID=1159) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:16:56,624] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:16:56,625] {logging_mixin.py:115} INFO - [2023-01-05 03:16:56,625] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:16:57,604] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:16:57,606] {logging_mixin.py:115} INFO - [2023-01-05 03:16:57,605] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:16:57,606] {logging_mixin.py:115} INFO - [2023-01-05 03:16:57,606] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:16:57,614] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:16:57,639] {logging_mixin.py:115} INFO - [2023-01-05 03:16:57,639] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:16:57,662] {logging_mixin.py:115} INFO - [2023-01-05 03:16:57,662] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:16:57,673] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.055 seconds
[2023-01-05 03:17:27,748] {processor.py:153} INFO - Started process (PID=1184) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:17:27,750] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:17:27,750] {logging_mixin.py:115} INFO - [2023-01-05 03:17:27,750] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:17:28,871] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:17:28,873] {logging_mixin.py:115} INFO - [2023-01-05 03:17:28,873] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:17:28,873] {logging_mixin.py:115} INFO - [2023-01-05 03:17:28,873] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:17:28,881] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:17:28,907] {logging_mixin.py:115} INFO - [2023-01-05 03:17:28,906] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:17:28,929] {logging_mixin.py:115} INFO - [2023-01-05 03:17:28,928] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:17:28,939] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.197 seconds
[2023-01-05 03:17:59,016] {processor.py:153} INFO - Started process (PID=1201) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:17:59,017] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:17:59,018] {logging_mixin.py:115} INFO - [2023-01-05 03:17:59,018] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:18:00,018] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:18:00,019] {logging_mixin.py:115} INFO - [2023-01-05 03:18:00,019] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:18:00,020] {logging_mixin.py:115} INFO - [2023-01-05 03:18:00,020] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:18:00,027] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:18:00,052] {logging_mixin.py:115} INFO - [2023-01-05 03:18:00,051] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:18:00,074] {logging_mixin.py:115} INFO - [2023-01-05 03:18:00,074] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:18:00,084] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.074 seconds
[2023-01-05 03:18:30,174] {processor.py:153} INFO - Started process (PID=1227) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:18:30,177] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:18:30,178] {logging_mixin.py:115} INFO - [2023-01-05 03:18:30,178] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:18:31,235] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:18:31,237] {logging_mixin.py:115} INFO - [2023-01-05 03:18:31,237] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:18:31,237] {logging_mixin.py:115} INFO - [2023-01-05 03:18:31,237] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:18:31,244] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:18:31,273] {logging_mixin.py:115} INFO - [2023-01-05 03:18:31,272] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:18:31,295] {logging_mixin.py:115} INFO - [2023-01-05 03:18:31,295] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:18:31,305] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.136 seconds
[2023-01-05 03:19:02,285] {processor.py:153} INFO - Started process (PID=1251) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:19:02,286] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:19:02,286] {logging_mixin.py:115} INFO - [2023-01-05 03:19:02,286] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:19:03,304] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:19:03,305] {logging_mixin.py:115} INFO - [2023-01-05 03:19:03,305] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:19:03,306] {logging_mixin.py:115} INFO - [2023-01-05 03:19:03,305] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:19:03,313] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:19:03,339] {logging_mixin.py:115} INFO - [2023-01-05 03:19:03,339] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:19:03,361] {logging_mixin.py:115} INFO - [2023-01-05 03:19:03,361] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:19:03,372] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.092 seconds
[2023-01-05 03:19:34,390] {processor.py:153} INFO - Started process (PID=1276) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:19:34,392] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:19:34,393] {logging_mixin.py:115} INFO - [2023-01-05 03:19:34,392] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:19:35,608] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:19:35,610] {logging_mixin.py:115} INFO - [2023-01-05 03:19:35,609] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:19:35,610] {logging_mixin.py:115} INFO - [2023-01-05 03:19:35,610] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:19:35,617] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:19:35,643] {logging_mixin.py:115} INFO - [2023-01-05 03:19:35,642] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:19:35,666] {logging_mixin.py:115} INFO - [2023-01-05 03:19:35,666] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:19:35,678] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.293 seconds
[2023-01-05 03:20:05,754] {processor.py:153} INFO - Started process (PID=1294) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:20:05,755] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:20:05,755] {logging_mixin.py:115} INFO - [2023-01-05 03:20:05,755] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:20:06,742] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:20:06,743] {logging_mixin.py:115} INFO - [2023-01-05 03:20:06,743] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:20:06,744] {logging_mixin.py:115} INFO - [2023-01-05 03:20:06,744] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:20:06,751] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:20:06,776] {logging_mixin.py:115} INFO - [2023-01-05 03:20:06,775] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:20:06,797] {logging_mixin.py:115} INFO - [2023-01-05 03:20:06,797] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:20:06,808] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.059 seconds
[2023-01-05 03:20:36,847] {processor.py:153} INFO - Started process (PID=1319) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:20:36,851] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:20:36,852] {logging_mixin.py:115} INFO - [2023-01-05 03:20:36,852] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:20:37,860] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:20:37,861] {logging_mixin.py:115} INFO - [2023-01-05 03:20:37,861] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:20:37,862] {logging_mixin.py:115} INFO - [2023-01-05 03:20:37,862] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:20:37,869] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:20:37,895] {logging_mixin.py:115} INFO - [2023-01-05 03:20:37,894] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:20:37,918] {logging_mixin.py:115} INFO - [2023-01-05 03:20:37,917] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:20:37,929] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.087 seconds
[2023-01-05 03:21:08,006] {processor.py:153} INFO - Started process (PID=1345) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:21:08,007] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:21:08,008] {logging_mixin.py:115} INFO - [2023-01-05 03:21:08,008] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:21:09,156] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:21:09,158] {logging_mixin.py:115} INFO - [2023-01-05 03:21:09,158] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:21:09,158] {logging_mixin.py:115} INFO - [2023-01-05 03:21:09,158] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:21:09,166] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:21:09,191] {logging_mixin.py:115} INFO - [2023-01-05 03:21:09,190] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:21:09,218] {logging_mixin.py:115} INFO - [2023-01-05 03:21:09,217] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:21:09,228] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.228 seconds
[2023-01-05 03:21:40,105] {processor.py:153} INFO - Started process (PID=1363) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:21:40,106] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:21:40,107] {logging_mixin.py:115} INFO - [2023-01-05 03:21:40,107] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:21:41,116] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:21:41,118] {logging_mixin.py:115} INFO - [2023-01-05 03:21:41,118] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:21:41,119] {logging_mixin.py:115} INFO - [2023-01-05 03:21:41,118] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:21:41,126] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:21:41,151] {logging_mixin.py:115} INFO - [2023-01-05 03:21:41,150] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:21:41,173] {logging_mixin.py:115} INFO - [2023-01-05 03:21:41,173] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:21:41,184] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.084 seconds
[2023-01-05 03:22:12,196] {processor.py:153} INFO - Started process (PID=1388) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:22:12,198] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:22:12,198] {logging_mixin.py:115} INFO - [2023-01-05 03:22:12,198] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:22:13,186] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:22:13,188] {logging_mixin.py:115} INFO - [2023-01-05 03:22:13,187] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:22:13,188] {logging_mixin.py:115} INFO - [2023-01-05 03:22:13,188] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:22:13,195] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:22:13,221] {logging_mixin.py:115} INFO - [2023-01-05 03:22:13,220] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:22:13,243] {logging_mixin.py:115} INFO - [2023-01-05 03:22:13,242] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:22:13,253] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.063 seconds
[2023-01-05 03:22:43,331] {processor.py:153} INFO - Started process (PID=1413) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:22:43,334] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:22:43,335] {logging_mixin.py:115} INFO - [2023-01-05 03:22:43,335] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:22:44,313] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:22:44,315] {logging_mixin.py:115} INFO - [2023-01-05 03:22:44,315] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:22:44,316] {logging_mixin.py:115} INFO - [2023-01-05 03:22:44,315] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:22:44,323] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:22:44,350] {logging_mixin.py:115} INFO - [2023-01-05 03:22:44,350] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:22:44,373] {logging_mixin.py:115} INFO - [2023-01-05 03:22:44,373] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:22:44,384] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.059 seconds
[2023-01-05 03:23:14,467] {processor.py:153} INFO - Started process (PID=1437) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:23:14,469] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:23:14,469] {logging_mixin.py:115} INFO - [2023-01-05 03:23:14,469] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:23:15,558] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:23:15,560] {logging_mixin.py:115} INFO - [2023-01-05 03:23:15,560] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:23:15,560] {logging_mixin.py:115} INFO - [2023-01-05 03:23:15,560] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:23:15,568] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:23:15,594] {logging_mixin.py:115} INFO - [2023-01-05 03:23:15,593] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:23:15,619] {logging_mixin.py:115} INFO - [2023-01-05 03:23:15,618] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:23:15,639] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.180 seconds
[2023-01-05 03:23:45,694] {processor.py:153} INFO - Started process (PID=1455) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:23:45,695] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:23:45,696] {logging_mixin.py:115} INFO - [2023-01-05 03:23:45,695] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:23:46,713] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:23:46,715] {logging_mixin.py:115} INFO - [2023-01-05 03:23:46,715] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:23:46,715] {logging_mixin.py:115} INFO - [2023-01-05 03:23:46,715] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:23:46,723] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:23:46,749] {logging_mixin.py:115} INFO - [2023-01-05 03:23:46,748] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:23:46,772] {logging_mixin.py:115} INFO - [2023-01-05 03:23:46,772] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:23:46,783] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.096 seconds
[2023-01-05 03:24:16,863] {processor.py:153} INFO - Started process (PID=1480) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:24:16,864] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:24:16,865] {logging_mixin.py:115} INFO - [2023-01-05 03:24:16,865] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:24:17,870] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:24:17,871] {logging_mixin.py:115} INFO - [2023-01-05 03:24:17,871] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:24:17,872] {logging_mixin.py:115} INFO - [2023-01-05 03:24:17,872] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:24:17,879] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:24:17,905] {logging_mixin.py:115} INFO - [2023-01-05 03:24:17,904] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:24:17,927] {logging_mixin.py:115} INFO - [2023-01-05 03:24:17,927] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:24:17,938] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.081 seconds
[2023-01-05 03:24:48,948] {processor.py:153} INFO - Started process (PID=1506) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:24:48,952] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:24:48,953] {logging_mixin.py:115} INFO - [2023-01-05 03:24:48,953] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:24:49,982] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:24:49,984] {logging_mixin.py:115} INFO - [2023-01-05 03:24:49,983] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:24:49,984] {logging_mixin.py:115} INFO - [2023-01-05 03:24:49,984] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:24:49,991] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:24:50,018] {logging_mixin.py:115} INFO - [2023-01-05 03:24:50,017] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:24:50,041] {logging_mixin.py:115} INFO - [2023-01-05 03:24:50,041] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:24:50,053] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.111 seconds
[2023-01-05 03:25:21,042] {processor.py:153} INFO - Started process (PID=1531) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:25:21,043] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:25:21,044] {logging_mixin.py:115} INFO - [2023-01-05 03:25:21,044] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:25:22,147] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:25:22,149] {logging_mixin.py:115} INFO - [2023-01-05 03:25:22,149] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:25:22,150] {logging_mixin.py:115} INFO - [2023-01-05 03:25:22,149] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:25:22,157] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:25:22,182] {logging_mixin.py:115} INFO - [2023-01-05 03:25:22,182] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:25:22,204] {logging_mixin.py:115} INFO - [2023-01-05 03:25:22,204] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:25:22,215] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.180 seconds
[2023-01-05 03:25:53,136] {processor.py:153} INFO - Started process (PID=1550) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:25:53,138] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:25:53,139] {logging_mixin.py:115} INFO - [2023-01-05 03:25:53,138] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:25:54,172] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:25:54,174] {logging_mixin.py:115} INFO - [2023-01-05 03:25:54,174] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:25:54,174] {logging_mixin.py:115} INFO - [2023-01-05 03:25:54,174] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:25:54,182] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:25:54,208] {logging_mixin.py:115} INFO - [2023-01-05 03:25:54,208] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:25:54,233] {logging_mixin.py:115} INFO - [2023-01-05 03:25:54,233] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:25:54,245] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.114 seconds
[2023-01-05 03:26:25,248] {processor.py:153} INFO - Started process (PID=1574) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:26:25,250] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:26:25,250] {logging_mixin.py:115} INFO - [2023-01-05 03:26:25,250] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:26:26,251] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:26:26,253] {logging_mixin.py:115} INFO - [2023-01-05 03:26:26,253] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:26:26,253] {logging_mixin.py:115} INFO - [2023-01-05 03:26:26,253] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:26:26,261] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:26:26,287] {logging_mixin.py:115} INFO - [2023-01-05 03:26:26,287] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:26:26,310] {logging_mixin.py:115} INFO - [2023-01-05 03:26:26,310] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:26:26,322] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.079 seconds
[2023-01-05 03:26:56,356] {processor.py:153} INFO - Started process (PID=1600) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:26:56,358] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:26:56,359] {logging_mixin.py:115} INFO - [2023-01-05 03:26:56,359] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:26:57,371] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:26:57,372] {logging_mixin.py:115} INFO - [2023-01-05 03:26:57,372] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:26:57,373] {logging_mixin.py:115} INFO - [2023-01-05 03:26:57,372] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:26:57,380] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:26:57,409] {logging_mixin.py:115} INFO - [2023-01-05 03:26:57,408] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:26:57,436] {logging_mixin.py:115} INFO - [2023-01-05 03:26:57,436] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:26:57,452] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.101 seconds
[2023-01-05 03:27:28,455] {processor.py:153} INFO - Started process (PID=1625) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:27:28,457] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:27:28,458] {logging_mixin.py:115} INFO - [2023-01-05 03:27:28,458] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:27:29,655] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:27:29,656] {logging_mixin.py:115} INFO - [2023-01-05 03:27:29,656] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:27:29,657] {logging_mixin.py:115} INFO - [2023-01-05 03:27:29,657] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:27:29,664] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:27:29,689] {logging_mixin.py:115} INFO - [2023-01-05 03:27:29,688] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:27:29,712] {logging_mixin.py:115} INFO - [2023-01-05 03:27:29,712] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:27:29,724] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.275 seconds
[2023-01-05 03:27:59,816] {processor.py:153} INFO - Started process (PID=1644) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:27:59,817] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:27:59,818] {logging_mixin.py:115} INFO - [2023-01-05 03:27:59,818] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:28:00,849] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:28:00,850] {logging_mixin.py:115} INFO - [2023-01-05 03:28:00,850] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:28:00,851] {logging_mixin.py:115} INFO - [2023-01-05 03:28:00,851] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:28:00,858] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:28:00,884] {logging_mixin.py:115} INFO - [2023-01-05 03:28:00,884] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:28:00,909] {logging_mixin.py:115} INFO - [2023-01-05 03:28:00,908] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:28:00,920] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.109 seconds
[2023-01-05 03:28:04,959] {processor.py:153} INFO - Started process (PID=1653) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:28:04,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:28:04,963] {logging_mixin.py:115} INFO - [2023-01-05 03:28:04,962] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:28:06,006] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:28:06,007] {logging_mixin.py:115} INFO - [2023-01-05 03:28:06,007] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:28:06,008] {logging_mixin.py:115} INFO - [2023-01-05 03:28:06,007] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:28:06,015] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:28:06,076] {logging_mixin.py:115} INFO - [2023-01-05 03:28:06,076] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:28:06,098] {logging_mixin.py:115} INFO - [2023-01-05 03:28:06,097] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:28:06,115] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.161 seconds
[2023-01-05 03:28:37,047] {processor.py:153} INFO - Started process (PID=1671) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:28:37,048] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:28:37,049] {logging_mixin.py:115} INFO - [2023-01-05 03:28:37,049] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:28:38,175] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:28:38,177] {logging_mixin.py:115} INFO - [2023-01-05 03:28:38,177] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:28:38,178] {logging_mixin.py:115} INFO - [2023-01-05 03:28:38,177] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:28:38,185] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:28:38,210] {logging_mixin.py:115} INFO - [2023-01-05 03:28:38,209] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:28:38,233] {logging_mixin.py:115} INFO - [2023-01-05 03:28:38,233] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:28:38,244] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.202 seconds
[2023-01-05 03:29:08,326] {processor.py:153} INFO - Started process (PID=1695) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:29:08,327] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:29:08,328] {logging_mixin.py:115} INFO - [2023-01-05 03:29:08,328] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:29:09,373] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:29:09,374] {logging_mixin.py:115} INFO - [2023-01-05 03:29:09,374] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:29:09,375] {logging_mixin.py:115} INFO - [2023-01-05 03:29:09,374] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:29:09,382] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:29:09,407] {logging_mixin.py:115} INFO - [2023-01-05 03:29:09,407] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:29:09,431] {logging_mixin.py:115} INFO - [2023-01-05 03:29:09,431] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:29:09,442] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.122 seconds
[2023-01-05 03:29:40,418] {processor.py:153} INFO - Started process (PID=1721) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:29:40,419] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:29:40,420] {logging_mixin.py:115} INFO - [2023-01-05 03:29:40,420] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:29:41,424] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:29:41,426] {logging_mixin.py:115} INFO - [2023-01-05 03:29:41,426] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:29:41,426] {logging_mixin.py:115} INFO - [2023-01-05 03:29:41,426] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:29:41,434] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:29:41,460] {logging_mixin.py:115} INFO - [2023-01-05 03:29:41,459] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:29:41,483] {logging_mixin.py:115} INFO - [2023-01-05 03:29:41,483] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:29:41,494] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.081 seconds
[2023-01-05 03:30:11,540] {processor.py:153} INFO - Started process (PID=1746) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:30:11,541] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:30:11,542] {logging_mixin.py:115} INFO - [2023-01-05 03:30:11,542] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:30:12,596] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:30:12,598] {logging_mixin.py:115} INFO - [2023-01-05 03:30:12,598] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:30:12,599] {logging_mixin.py:115} INFO - [2023-01-05 03:30:12,599] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:30:12,607] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:30:12,633] {logging_mixin.py:115} INFO - [2023-01-05 03:30:12,633] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:30:12,655] {logging_mixin.py:115} INFO - [2023-01-05 03:30:12,655] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:30:12,666] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.131 seconds
[2023-01-05 03:30:43,655] {processor.py:153} INFO - Started process (PID=1764) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:30:43,655] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:30:43,656] {logging_mixin.py:115} INFO - [2023-01-05 03:30:43,656] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:30:44,729] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:30:44,731] {logging_mixin.py:115} INFO - [2023-01-05 03:30:44,731] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:30:44,732] {logging_mixin.py:115} INFO - [2023-01-05 03:30:44,732] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:30:44,745] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:30:44,780] {logging_mixin.py:115} INFO - [2023-01-05 03:30:44,780] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:30:44,816] {logging_mixin.py:115} INFO - [2023-01-05 03:30:44,816] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:30:44,833] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.183 seconds
[2023-01-05 03:31:15,778] {processor.py:153} INFO - Started process (PID=1789) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:31:15,780] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:31:15,781] {logging_mixin.py:115} INFO - [2023-01-05 03:31:15,781] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:31:16,797] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:31:16,798] {logging_mixin.py:115} INFO - [2023-01-05 03:31:16,798] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:31:16,799] {logging_mixin.py:115} INFO - [2023-01-05 03:31:16,799] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:31:16,806] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:31:16,832] {logging_mixin.py:115} INFO - [2023-01-05 03:31:16,832] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:31:16,856] {logging_mixin.py:115} INFO - [2023-01-05 03:31:16,856] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:31:16,866] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.093 seconds
[2023-01-05 03:31:46,983] {processor.py:153} INFO - Started process (PID=1815) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:31:46,985] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:31:46,986] {logging_mixin.py:115} INFO - [2023-01-05 03:31:46,986] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:31:47,996] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:31:47,998] {logging_mixin.py:115} INFO - [2023-01-05 03:31:47,998] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:31:47,999] {logging_mixin.py:115} INFO - [2023-01-05 03:31:47,998] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:31:48,006] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:31:48,032] {logging_mixin.py:115} INFO - [2023-01-05 03:31:48,032] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:31:48,055] {logging_mixin.py:115} INFO - [2023-01-05 03:31:48,055] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:31:48,066] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.088 seconds
[2023-01-05 03:32:18,116] {processor.py:153} INFO - Started process (PID=1840) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:32:18,117] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:32:18,117] {logging_mixin.py:115} INFO - [2023-01-05 03:32:18,117] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:32:19,497] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:32:19,500] {logging_mixin.py:115} INFO - [2023-01-05 03:32:19,499] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:32:19,501] {logging_mixin.py:115} INFO - [2023-01-05 03:32:19,500] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:32:19,510] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:32:19,560] {logging_mixin.py:115} INFO - [2023-01-05 03:32:19,560] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:32:19,593] {logging_mixin.py:115} INFO - [2023-01-05 03:32:19,593] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:32:19,607] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.498 seconds
[2023-01-05 03:32:50,199] {processor.py:153} INFO - Started process (PID=1858) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:32:50,201] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:32:50,201] {logging_mixin.py:115} INFO - [2023-01-05 03:32:50,201] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:32:51,201] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:32:51,202] {logging_mixin.py:115} INFO - [2023-01-05 03:32:51,202] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:32:51,203] {logging_mixin.py:115} INFO - [2023-01-05 03:32:51,203] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:32:51,210] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:32:51,235] {logging_mixin.py:115} INFO - [2023-01-05 03:32:51,234] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:32:51,258] {logging_mixin.py:115} INFO - [2023-01-05 03:32:51,257] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:32:51,268] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.074 seconds
[2023-01-05 03:33:21,365] {processor.py:153} INFO - Started process (PID=1884) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:33:21,367] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:33:21,367] {logging_mixin.py:115} INFO - [2023-01-05 03:33:21,367] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:33:22,384] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:33:22,385] {logging_mixin.py:115} INFO - [2023-01-05 03:33:22,385] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:33:22,386] {logging_mixin.py:115} INFO - [2023-01-05 03:33:22,386] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:33:22,393] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:33:22,419] {logging_mixin.py:115} INFO - [2023-01-05 03:33:22,419] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:33:22,443] {logging_mixin.py:115} INFO - [2023-01-05 03:33:22,442] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:33:22,455] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.095 seconds
[2023-01-05 03:33:53,459] {processor.py:153} INFO - Started process (PID=1911) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:33:53,460] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:33:53,460] {logging_mixin.py:115} INFO - [2023-01-05 03:33:53,460] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:33:54,467] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:33:54,469] {logging_mixin.py:115} INFO - [2023-01-05 03:33:54,469] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:33:54,470] {logging_mixin.py:115} INFO - [2023-01-05 03:33:54,469] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:33:54,477] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:33:54,502] {logging_mixin.py:115} INFO - [2023-01-05 03:33:54,501] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:33:54,524] {logging_mixin.py:115} INFO - [2023-01-05 03:33:54,524] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:33:54,535] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.081 seconds
[2023-01-05 03:34:24,614] {processor.py:153} INFO - Started process (PID=1935) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:34:24,617] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:34:24,618] {logging_mixin.py:115} INFO - [2023-01-05 03:34:24,618] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:34:25,704] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:34:25,706] {logging_mixin.py:115} INFO - [2023-01-05 03:34:25,706] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:34:25,706] {logging_mixin.py:115} INFO - [2023-01-05 03:34:25,706] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:34:25,714] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:34:25,744] {logging_mixin.py:115} INFO - [2023-01-05 03:34:25,743] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:34:25,768] {logging_mixin.py:115} INFO - [2023-01-05 03:34:25,768] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:34:25,780] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.172 seconds
[2023-01-05 03:34:55,856] {processor.py:153} INFO - Started process (PID=1953) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:34:55,857] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:34:55,858] {logging_mixin.py:115} INFO - [2023-01-05 03:34:55,857] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:34:56,870] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:34:56,871] {logging_mixin.py:115} INFO - [2023-01-05 03:34:56,871] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:34:56,872] {logging_mixin.py:115} INFO - [2023-01-05 03:34:56,872] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:34:56,879] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:34:56,905] {logging_mixin.py:115} INFO - [2023-01-05 03:34:56,904] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:34:56,928] {logging_mixin.py:115} INFO - [2023-01-05 03:34:56,927] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:34:56,938] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.088 seconds
[2023-01-05 03:35:27,044] {processor.py:153} INFO - Started process (PID=1978) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:35:27,046] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:35:27,046] {logging_mixin.py:115} INFO - [2023-01-05 03:35:27,046] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:35:28,074] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:35:28,076] {logging_mixin.py:115} INFO - [2023-01-05 03:35:28,076] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:35:28,077] {logging_mixin.py:115} INFO - [2023-01-05 03:35:28,076] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:35:28,084] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:35:28,111] {logging_mixin.py:115} INFO - [2023-01-05 03:35:28,111] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:35:28,136] {logging_mixin.py:115} INFO - [2023-01-05 03:35:28,136] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:35:28,147] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.108 seconds
[2023-01-05 03:35:58,178] {processor.py:153} INFO - Started process (PID=2004) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:35:58,178] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:35:58,179] {logging_mixin.py:115} INFO - [2023-01-05 03:35:58,179] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:35:59,172] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:35:59,174] {logging_mixin.py:115} INFO - [2023-01-05 03:35:59,173] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:35:59,174] {logging_mixin.py:115} INFO - [2023-01-05 03:35:59,174] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:35:59,181] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:35:59,206] {logging_mixin.py:115} INFO - [2023-01-05 03:35:59,206] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:35:59,229] {logging_mixin.py:115} INFO - [2023-01-05 03:35:59,229] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:35:59,240] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.067 seconds
[2023-01-05 03:36:29,317] {processor.py:153} INFO - Started process (PID=2022) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:36:29,318] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:36:29,319] {logging_mixin.py:115} INFO - [2023-01-05 03:36:29,319] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:36:30,403] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:36:30,405] {logging_mixin.py:115} INFO - [2023-01-05 03:36:30,405] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:36:30,406] {logging_mixin.py:115} INFO - [2023-01-05 03:36:30,405] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:36:30,421] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:36:30,458] {logging_mixin.py:115} INFO - [2023-01-05 03:36:30,457] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:36:30,501] {logging_mixin.py:115} INFO - [2023-01-05 03:36:30,501] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:36:30,516] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.204 seconds
[2023-01-05 03:37:01,425] {processor.py:153} INFO - Started process (PID=2050) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:37:01,427] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:37:01,428] {logging_mixin.py:115} INFO - [2023-01-05 03:37:01,427] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:37:02,425] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:37:02,426] {logging_mixin.py:115} INFO - [2023-01-05 03:37:02,426] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:37:02,427] {logging_mixin.py:115} INFO - [2023-01-05 03:37:02,427] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:37:02,439] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:37:02,467] {logging_mixin.py:115} INFO - [2023-01-05 03:37:02,467] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:37:02,490] {logging_mixin.py:115} INFO - [2023-01-05 03:37:02,490] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:37:02,503] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.083 seconds
[2023-01-05 03:37:32,535] {processor.py:153} INFO - Started process (PID=2075) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:37:32,536] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:37:32,536] {logging_mixin.py:115} INFO - [2023-01-05 03:37:32,536] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:37:33,580] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:37:33,582] {logging_mixin.py:115} INFO - [2023-01-05 03:37:33,581] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:37:33,582] {logging_mixin.py:115} INFO - [2023-01-05 03:37:33,582] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:37:33,590] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:37:33,621] {logging_mixin.py:115} INFO - [2023-01-05 03:37:33,621] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:37:33,646] {logging_mixin.py:115} INFO - [2023-01-05 03:37:33,646] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:37:33,657] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.127 seconds
[2023-01-05 03:38:03,740] {processor.py:153} INFO - Started process (PID=2100) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:38:03,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:38:03,744] {logging_mixin.py:115} INFO - [2023-01-05 03:38:03,744] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:38:04,824] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:38:04,825] {logging_mixin.py:115} INFO - [2023-01-05 03:38:04,825] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:38:04,826] {logging_mixin.py:115} INFO - [2023-01-05 03:38:04,826] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:38:04,833] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:38:04,859] {logging_mixin.py:115} INFO - [2023-01-05 03:38:04,859] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:38:04,882] {logging_mixin.py:115} INFO - [2023-01-05 03:38:04,882] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 03:38:04,892] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.157 seconds
[2023-01-05 03:38:12,768] {processor.py:153} INFO - Started process (PID=2102) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:38:12,769] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:38:12,769] {logging_mixin.py:115} INFO - [2023-01-05 03:38:12,769] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:38:13,763] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:38:13,765] {logging_mixin.py:115} INFO - [2023-01-05 03:38:13,764] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:38:13,765] {logging_mixin.py:115} INFO - [2023-01-05 03:38:13,765] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:38:13,772] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:38:13,834] {logging_mixin.py:115} INFO - [2023-01-05 03:38:13,834] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:38:13,855] {logging_mixin.py:115} INFO - [2023-01-05 03:38:13,855] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:38:13,872] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.109 seconds
[2023-01-05 03:38:43,950] {processor.py:153} INFO - Started process (PID=2129) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:38:43,953] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:38:43,954] {logging_mixin.py:115} INFO - [2023-01-05 03:38:43,954] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:38:45,000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:38:45,002] {logging_mixin.py:115} INFO - [2023-01-05 03:38:45,002] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:38:45,003] {logging_mixin.py:115} INFO - [2023-01-05 03:38:45,003] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:38:45,015] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:38:45,050] {logging_mixin.py:115} INFO - [2023-01-05 03:38:45,050] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:38:45,075] {logging_mixin.py:115} INFO - [2023-01-05 03:38:45,075] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:38:45,088] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.143 seconds
[2023-01-05 03:39:16,010] {processor.py:153} INFO - Started process (PID=2156) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:39:16,010] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:39:16,011] {logging_mixin.py:115} INFO - [2023-01-05 03:39:16,011] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:39:17,018] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:39:17,019] {logging_mixin.py:115} INFO - [2023-01-05 03:39:17,019] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:39:17,020] {logging_mixin.py:115} INFO - [2023-01-05 03:39:17,020] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:39:17,027] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:39:17,055] {logging_mixin.py:115} INFO - [2023-01-05 03:39:17,054] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:39:17,078] {logging_mixin.py:115} INFO - [2023-01-05 03:39:17,078] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:39:17,089] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.084 seconds
[2023-01-05 03:39:47,191] {processor.py:153} INFO - Started process (PID=2175) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:39:47,193] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:39:47,193] {logging_mixin.py:115} INFO - [2023-01-05 03:39:47,193] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:39:48,313] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:39:48,315] {logging_mixin.py:115} INFO - [2023-01-05 03:39:48,315] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:39:48,316] {logging_mixin.py:115} INFO - [2023-01-05 03:39:48,315] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:39:48,323] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:39:48,349] {logging_mixin.py:115} INFO - [2023-01-05 03:39:48,349] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:39:48,372] {logging_mixin.py:115} INFO - [2023-01-05 03:39:48,372] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:39:48,384] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.197 seconds
[2023-01-05 03:40:18,465] {processor.py:153} INFO - Started process (PID=2201) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:40:18,466] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:40:18,466] {logging_mixin.py:115} INFO - [2023-01-05 03:40:18,466] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:40:19,472] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:40:19,473] {logging_mixin.py:115} INFO - [2023-01-05 03:40:19,473] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:40:19,474] {logging_mixin.py:115} INFO - [2023-01-05 03:40:19,474] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:40:19,482] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:40:19,507] {logging_mixin.py:115} INFO - [2023-01-05 03:40:19,507] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:40:19,531] {logging_mixin.py:115} INFO - [2023-01-05 03:40:19,531] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:40:19,543] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.083 seconds
[2023-01-05 03:40:50,558] {processor.py:153} INFO - Started process (PID=2227) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:40:50,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:40:50,561] {logging_mixin.py:115} INFO - [2023-01-05 03:40:50,560] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:40:51,556] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:40:51,558] {logging_mixin.py:115} INFO - [2023-01-05 03:40:51,557] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:40:51,558] {logging_mixin.py:115} INFO - [2023-01-05 03:40:51,558] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:40:51,565] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:40:51,590] {logging_mixin.py:115} INFO - [2023-01-05 03:40:51,589] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:40:51,612] {logging_mixin.py:115} INFO - [2023-01-05 03:40:51,612] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:40:51,623] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.071 seconds
[2023-01-05 03:41:21,723] {processor.py:153} INFO - Started process (PID=2253) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:41:21,723] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:41:21,724] {logging_mixin.py:115} INFO - [2023-01-05 03:41:21,724] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:41:22,700] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:41:22,701] {logging_mixin.py:115} INFO - [2023-01-05 03:41:22,701] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:41:22,702] {logging_mixin.py:115} INFO - [2023-01-05 03:41:22,701] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:41:22,709] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:41:22,735] {logging_mixin.py:115} INFO - [2023-01-05 03:41:22,735] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:41:22,757] {logging_mixin.py:115} INFO - [2023-01-05 03:41:22,757] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:41:22,768] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.050 seconds
[2023-01-05 03:41:52,820] {processor.py:153} INFO - Started process (PID=2271) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:41:52,822] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:41:52,823] {logging_mixin.py:115} INFO - [2023-01-05 03:41:52,823] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:41:53,945] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:41:53,946] {logging_mixin.py:115} INFO - [2023-01-05 03:41:53,946] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:41:53,947] {logging_mixin.py:115} INFO - [2023-01-05 03:41:53,946] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:41:53,954] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:41:53,978] {logging_mixin.py:115} INFO - [2023-01-05 03:41:53,978] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:41:54,000] {logging_mixin.py:115} INFO - [2023-01-05 03:41:54,000] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:41:54,010] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.195 seconds
[2023-01-05 03:42:24,090] {processor.py:153} INFO - Started process (PID=2295) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:42:24,092] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:42:24,092] {logging_mixin.py:115} INFO - [2023-01-05 03:42:24,092] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:42:25,121] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:42:25,122] {logging_mixin.py:115} INFO - [2023-01-05 03:42:25,122] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:42:25,123] {logging_mixin.py:115} INFO - [2023-01-05 03:42:25,122] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:42:25,130] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:42:25,155] {logging_mixin.py:115} INFO - [2023-01-05 03:42:25,154] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:42:25,178] {logging_mixin.py:115} INFO - [2023-01-05 03:42:25,178] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:42:25,188] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.104 seconds
[2023-01-05 03:42:55,264] {processor.py:153} INFO - Started process (PID=2320) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:42:55,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:42:55,266] {logging_mixin.py:115} INFO - [2023-01-05 03:42:55,266] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:42:56,254] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:42:56,255] {logging_mixin.py:115} INFO - [2023-01-05 03:42:56,255] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:42:56,256] {logging_mixin.py:115} INFO - [2023-01-05 03:42:56,255] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:42:56,263] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:42:56,288] {logging_mixin.py:115} INFO - [2023-01-05 03:42:56,288] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:42:56,311] {logging_mixin.py:115} INFO - [2023-01-05 03:42:56,311] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:42:56,321] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.062 seconds
[2023-01-05 03:43:26,421] {processor.py:153} INFO - Started process (PID=2338) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:43:26,423] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:43:26,424] {logging_mixin.py:115} INFO - [2023-01-05 03:43:26,424] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:43:27,464] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:43:27,465] {logging_mixin.py:115} INFO - [2023-01-05 03:43:27,465] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:43:27,466] {logging_mixin.py:115} INFO - [2023-01-05 03:43:27,466] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:43:27,473] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:43:27,502] {logging_mixin.py:115} INFO - [2023-01-05 03:43:27,502] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:43:27,534] {logging_mixin.py:115} INFO - [2023-01-05 03:43:27,534] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:43:27,546] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.130 seconds
[2023-01-05 03:43:57,607] {processor.py:153} INFO - Started process (PID=2363) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:43:57,609] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:43:57,609] {logging_mixin.py:115} INFO - [2023-01-05 03:43:57,609] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:43:58,626] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:43:58,627] {logging_mixin.py:115} INFO - [2023-01-05 03:43:58,627] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:43:58,628] {logging_mixin.py:115} INFO - [2023-01-05 03:43:58,628] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:43:58,635] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:43:58,660] {logging_mixin.py:115} INFO - [2023-01-05 03:43:58,659] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:43:58,683] {logging_mixin.py:115} INFO - [2023-01-05 03:43:58,683] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:43:58,694] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.092 seconds
[2023-01-05 03:44:29,706] {processor.py:153} INFO - Started process (PID=2388) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:44:29,707] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:44:29,708] {logging_mixin.py:115} INFO - [2023-01-05 03:44:29,708] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:44:30,728] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:44:30,730] {logging_mixin.py:115} INFO - [2023-01-05 03:44:30,730] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:44:30,730] {logging_mixin.py:115} INFO - [2023-01-05 03:44:30,730] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:44:30,738] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:44:30,763] {logging_mixin.py:115} INFO - [2023-01-05 03:44:30,763] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:44:30,785] {logging_mixin.py:115} INFO - [2023-01-05 03:44:30,785] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:44:30,796] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.095 seconds
[2023-01-05 03:45:00,852] {processor.py:153} INFO - Started process (PID=2413) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:45:00,853] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:45:00,854] {logging_mixin.py:115} INFO - [2023-01-05 03:45:00,854] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:45:02,298] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:45:02,300] {logging_mixin.py:115} INFO - [2023-01-05 03:45:02,299] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:45:02,300] {logging_mixin.py:115} INFO - [2023-01-05 03:45:02,300] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:45:02,308] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:45:02,336] {logging_mixin.py:115} INFO - [2023-01-05 03:45:02,336] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:45:02,361] {logging_mixin.py:115} INFO - [2023-01-05 03:45:02,361] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:45:02,372] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.527 seconds
[2023-01-05 03:45:32,931] {processor.py:153} INFO - Started process (PID=2432) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:45:32,933] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:45:32,933] {logging_mixin.py:115} INFO - [2023-01-05 03:45:32,933] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:45:33,939] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:45:33,941] {logging_mixin.py:115} INFO - [2023-01-05 03:45:33,940] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:45:33,941] {logging_mixin.py:115} INFO - [2023-01-05 03:45:33,941] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:45:33,949] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:45:33,974] {logging_mixin.py:115} INFO - [2023-01-05 03:45:33,974] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:45:33,998] {logging_mixin.py:115} INFO - [2023-01-05 03:45:33,998] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:45:34,009] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.082 seconds
[2023-01-05 03:46:05,018] {processor.py:153} INFO - Started process (PID=2456) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:46:05,019] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:46:05,020] {logging_mixin.py:115} INFO - [2023-01-05 03:46:05,020] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:46:06,063] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:46:06,064] {logging_mixin.py:115} INFO - [2023-01-05 03:46:06,064] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:46:06,065] {logging_mixin.py:115} INFO - [2023-01-05 03:46:06,065] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:46:06,072] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:46:06,098] {logging_mixin.py:115} INFO - [2023-01-05 03:46:06,097] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:46:06,120] {logging_mixin.py:115} INFO - [2023-01-05 03:46:06,120] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:46:06,131] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.118 seconds
[2023-01-05 03:46:36,230] {processor.py:153} INFO - Started process (PID=2482) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:46:36,233] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:46:36,234] {logging_mixin.py:115} INFO - [2023-01-05 03:46:36,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:46:37,278] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:46:37,279] {logging_mixin.py:115} INFO - [2023-01-05 03:46:37,279] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:46:37,280] {logging_mixin.py:115} INFO - [2023-01-05 03:46:37,280] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:46:37,287] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:46:37,311] {logging_mixin.py:115} INFO - [2023-01-05 03:46:37,311] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:46:37,333] {logging_mixin.py:115} INFO - [2023-01-05 03:46:37,333] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:46:37,344] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.119 seconds
[2023-01-05 03:47:08,335] {processor.py:153} INFO - Started process (PID=2508) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:47:08,337] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:47:08,338] {logging_mixin.py:115} INFO - [2023-01-05 03:47:08,338] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:47:09,664] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:47:09,666] {logging_mixin.py:115} INFO - [2023-01-05 03:47:09,666] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:47:09,666] {logging_mixin.py:115} INFO - [2023-01-05 03:47:09,666] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:47:09,674] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:47:09,706] {logging_mixin.py:115} INFO - [2023-01-05 03:47:09,705] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:47:09,733] {logging_mixin.py:115} INFO - [2023-01-05 03:47:09,733] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:47:09,745] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.415 seconds
[2023-01-05 03:47:40,414] {processor.py:153} INFO - Started process (PID=2526) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:47:40,415] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:47:40,416] {logging_mixin.py:115} INFO - [2023-01-05 03:47:40,416] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:47:41,402] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:47:41,404] {logging_mixin.py:115} INFO - [2023-01-05 03:47:41,404] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:47:41,404] {logging_mixin.py:115} INFO - [2023-01-05 03:47:41,404] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:47:41,411] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:47:41,436] {logging_mixin.py:115} INFO - [2023-01-05 03:47:41,436] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:47:41,457] {logging_mixin.py:115} INFO - [2023-01-05 03:47:41,457] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:47:41,468] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.058 seconds
[2023-01-05 03:48:12,499] {processor.py:153} INFO - Started process (PID=2552) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:48:12,500] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:48:12,501] {logging_mixin.py:115} INFO - [2023-01-05 03:48:12,501] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:48:13,492] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:48:13,494] {logging_mixin.py:115} INFO - [2023-01-05 03:48:13,494] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:48:13,494] {logging_mixin.py:115} INFO - [2023-01-05 03:48:13,494] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:48:13,501] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:48:13,526] {logging_mixin.py:115} INFO - [2023-01-05 03:48:13,525] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:48:13,548] {logging_mixin.py:115} INFO - [2023-01-05 03:48:13,548] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:48:13,558] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.064 seconds
[2023-01-05 03:48:44,584] {processor.py:153} INFO - Started process (PID=2577) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:48:44,585] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:48:44,586] {logging_mixin.py:115} INFO - [2023-01-05 03:48:44,585] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:48:45,629] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:48:45,630] {logging_mixin.py:115} INFO - [2023-01-05 03:48:45,630] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:48:45,631] {logging_mixin.py:115} INFO - [2023-01-05 03:48:45,631] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:48:45,638] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:48:45,664] {logging_mixin.py:115} INFO - [2023-01-05 03:48:45,664] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:48:45,687] {logging_mixin.py:115} INFO - [2023-01-05 03:48:45,686] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:48:45,698] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.120 seconds
[2023-01-05 03:49:16,674] {processor.py:153} INFO - Started process (PID=2602) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:49:16,675] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:49:16,675] {logging_mixin.py:115} INFO - [2023-01-05 03:49:16,675] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:49:17,670] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:49:17,672] {logging_mixin.py:115} INFO - [2023-01-05 03:49:17,671] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:49:17,672] {logging_mixin.py:115} INFO - [2023-01-05 03:49:17,672] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:49:17,683] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:49:17,710] {logging_mixin.py:115} INFO - [2023-01-05 03:49:17,710] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:49:17,733] {logging_mixin.py:115} INFO - [2023-01-05 03:49:17,733] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:49:17,744] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.075 seconds
[2023-01-05 03:49:47,824] {processor.py:153} INFO - Started process (PID=2620) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:49:47,826] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:49:47,827] {logging_mixin.py:115} INFO - [2023-01-05 03:49:47,827] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:49:49,086] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:49:49,088] {logging_mixin.py:115} INFO - [2023-01-05 03:49:49,088] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:49:49,089] {logging_mixin.py:115} INFO - [2023-01-05 03:49:49,088] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:49:49,100] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:49:49,141] {logging_mixin.py:115} INFO - [2023-01-05 03:49:49,141] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:49:49,184] {logging_mixin.py:115} INFO - [2023-01-05 03:49:49,183] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:49:49,199] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.381 seconds
[2023-01-05 03:50:19,316] {processor.py:153} INFO - Started process (PID=2644) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:50:19,317] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:50:19,317] {logging_mixin.py:115} INFO - [2023-01-05 03:50:19,317] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:50:20,282] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:50:20,284] {logging_mixin.py:115} INFO - [2023-01-05 03:50:20,284] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:50:20,285] {logging_mixin.py:115} INFO - [2023-01-05 03:50:20,284] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:50:20,292] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:50:20,322] {logging_mixin.py:115} INFO - [2023-01-05 03:50:20,321] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:50:20,346] {logging_mixin.py:115} INFO - [2023-01-05 03:50:20,346] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:50:20,357] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.046 seconds
[2023-01-05 03:50:50,400] {processor.py:153} INFO - Started process (PID=2670) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:50:50,405] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:50:50,406] {logging_mixin.py:115} INFO - [2023-01-05 03:50:50,406] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:50:51,467] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:50:51,468] {logging_mixin.py:115} INFO - [2023-01-05 03:50:51,468] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:50:51,469] {logging_mixin.py:115} INFO - [2023-01-05 03:50:51,468] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:50:51,476] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:50:51,500] {logging_mixin.py:115} INFO - [2023-01-05 03:50:51,500] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:50:51,522] {logging_mixin.py:115} INFO - [2023-01-05 03:50:51,522] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:50:51,533] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.138 seconds
[2023-01-05 03:51:22,521] {processor.py:153} INFO - Started process (PID=2689) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:51:22,522] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:51:22,523] {logging_mixin.py:115} INFO - [2023-01-05 03:51:22,523] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:51:23,801] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:51:23,803] {logging_mixin.py:115} INFO - [2023-01-05 03:51:23,803] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:51:23,804] {logging_mixin.py:115} INFO - [2023-01-05 03:51:23,804] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:51:23,816] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:51:23,853] {logging_mixin.py:115} INFO - [2023-01-05 03:51:23,852] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:51:23,888] {logging_mixin.py:115} INFO - [2023-01-05 03:51:23,888] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:51:23,902] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.388 seconds
[2023-01-05 03:51:53,994] {processor.py:153} INFO - Started process (PID=2713) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:51:53,995] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:51:53,995] {logging_mixin.py:115} INFO - [2023-01-05 03:51:53,995] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:51:55,026] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:51:55,027] {logging_mixin.py:115} INFO - [2023-01-05 03:51:55,027] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:51:55,028] {logging_mixin.py:115} INFO - [2023-01-05 03:51:55,027] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:51:55,035] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:51:55,059] {logging_mixin.py:115} INFO - [2023-01-05 03:51:55,059] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:51:55,081] {logging_mixin.py:115} INFO - [2023-01-05 03:51:55,081] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:51:55,091] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.102 seconds
[2023-01-05 03:52:25,169] {processor.py:153} INFO - Started process (PID=2737) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:52:25,170] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:52:25,171] {logging_mixin.py:115} INFO - [2023-01-05 03:52:25,171] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:52:26,197] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:52:26,199] {logging_mixin.py:115} INFO - [2023-01-05 03:52:26,199] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:52:26,200] {logging_mixin.py:115} INFO - [2023-01-05 03:52:26,200] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:52:26,212] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:52:26,246] {logging_mixin.py:115} INFO - [2023-01-05 03:52:26,245] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:52:26,278] {logging_mixin.py:115} INFO - [2023-01-05 03:52:26,277] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:52:26,290] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.127 seconds
[2023-01-05 03:52:56,415] {processor.py:153} INFO - Started process (PID=2762) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:52:56,416] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:52:56,416] {logging_mixin.py:115} INFO - [2023-01-05 03:52:56,416] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:52:57,446] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:52:57,448] {logging_mixin.py:115} INFO - [2023-01-05 03:52:57,448] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:52:57,448] {logging_mixin.py:115} INFO - [2023-01-05 03:52:57,448] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:52:57,456] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:52:57,480] {logging_mixin.py:115} INFO - [2023-01-05 03:52:57,480] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:52:57,502] {logging_mixin.py:115} INFO - [2023-01-05 03:52:57,502] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:52:57,512] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.104 seconds
[2023-01-05 03:53:27,587] {processor.py:153} INFO - Started process (PID=2781) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:53:27,588] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:53:27,589] {logging_mixin.py:115} INFO - [2023-01-05 03:53:27,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:53:28,535] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:53:28,536] {logging_mixin.py:115} INFO - [2023-01-05 03:53:28,536] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:53:28,536] {logging_mixin.py:115} INFO - [2023-01-05 03:53:28,536] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:53:28,543] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:53:28,567] {logging_mixin.py:115} INFO - [2023-01-05 03:53:28,567] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:53:28,588] {logging_mixin.py:115} INFO - [2023-01-05 03:53:28,588] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:53:28,598] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.017 seconds
[2023-01-05 03:53:58,677] {processor.py:153} INFO - Started process (PID=2805) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:53:58,678] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:53:58,678] {logging_mixin.py:115} INFO - [2023-01-05 03:53:58,678] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:53:59,640] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:53:59,642] {logging_mixin.py:115} INFO - [2023-01-05 03:53:59,642] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:53:59,642] {logging_mixin.py:115} INFO - [2023-01-05 03:53:59,642] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:53:59,649] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:53:59,673] {logging_mixin.py:115} INFO - [2023-01-05 03:53:59,673] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:53:59,695] {logging_mixin.py:115} INFO - [2023-01-05 03:53:59,695] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:53:59,706] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.033 seconds
[2023-01-05 03:54:29,767] {processor.py:153} INFO - Started process (PID=2831) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:54:29,770] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:54:29,771] {logging_mixin.py:115} INFO - [2023-01-05 03:54:29,770] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:54:30,726] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:54:30,727] {logging_mixin.py:115} INFO - [2023-01-05 03:54:30,727] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:54:30,728] {logging_mixin.py:115} INFO - [2023-01-05 03:54:30,728] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:54:30,735] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:54:30,759] {logging_mixin.py:115} INFO - [2023-01-05 03:54:30,759] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:54:30,781] {logging_mixin.py:115} INFO - [2023-01-05 03:54:30,781] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:54:30,792] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.030 seconds
[2023-01-05 03:55:00,937] {processor.py:153} INFO - Started process (PID=2855) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:55:00,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:55:00,970] {logging_mixin.py:115} INFO - [2023-01-05 03:55:00,970] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:55:02,505] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:55:02,507] {logging_mixin.py:115} INFO - [2023-01-05 03:55:02,507] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:55:02,508] {logging_mixin.py:115} INFO - [2023-01-05 03:55:02,508] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:55:02,521] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:55:02,558] {logging_mixin.py:115} INFO - [2023-01-05 03:55:02,557] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:55:02,592] {logging_mixin.py:115} INFO - [2023-01-05 03:55:02,592] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:55:02,605] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.709 seconds
[2023-01-05 03:55:32,689] {processor.py:153} INFO - Started process (PID=2874) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:55:32,690] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:55:32,691] {logging_mixin.py:115} INFO - [2023-01-05 03:55:32,691] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:55:33,913] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:55:33,915] {logging_mixin.py:115} INFO - [2023-01-05 03:55:33,915] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:55:33,915] {logging_mixin.py:115} INFO - [2023-01-05 03:55:33,915] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:55:33,927] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 03:55:33,953] {logging_mixin.py:115} INFO - [2023-01-05 03:55:33,952] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:55:33,975] {logging_mixin.py:115} INFO - [2023-01-05 03:55:33,975] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 03:55:33,985] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.302 seconds
[2023-01-05 21:29:52,123] {processor.py:153} INFO - Started process (PID=34) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:29:52,136] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:29:52,136] {logging_mixin.py:115} INFO - [2023-01-05 21:29:52,136] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:29:55,963] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:29:55,965] {logging_mixin.py:115} INFO - [2023-01-05 21:29:55,965] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:29:55,965] {logging_mixin.py:115} INFO - [2023-01-05 21:29:55,965] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:29:55,982] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:29:56,039] {logging_mixin.py:115} INFO - [2023-01-05 21:29:56,038] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:29:56,078] {logging_mixin.py:115} INFO - [2023-01-05 21:29:56,077] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:29:56,284] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 4.166 seconds
[2023-01-05 21:30:26,369] {processor.py:153} INFO - Started process (PID=59) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:30:26,370] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:30:26,370] {logging_mixin.py:115} INFO - [2023-01-05 21:30:26,370] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:30:27,536] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:30:27,537] {logging_mixin.py:115} INFO - [2023-01-05 21:30:27,537] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:30:27,538] {logging_mixin.py:115} INFO - [2023-01-05 21:30:27,537] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:30:27,545] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:30:27,568] {logging_mixin.py:115} INFO - [2023-01-05 21:30:27,568] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:30:27,593] {logging_mixin.py:115} INFO - [2023-01-05 21:30:27,593] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:30:27,606] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.243 seconds
[2023-01-05 21:30:57,685] {processor.py:153} INFO - Started process (PID=85) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:30:57,685] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:30:57,686] {logging_mixin.py:115} INFO - [2023-01-05 21:30:57,686] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:30:58,946] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:30:58,948] {logging_mixin.py:115} INFO - [2023-01-05 21:30:58,948] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:30:58,948] {logging_mixin.py:115} INFO - [2023-01-05 21:30:58,948] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:30:58,955] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:30:58,980] {logging_mixin.py:115} INFO - [2023-01-05 21:30:58,980] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:30:59,001] {logging_mixin.py:115} INFO - [2023-01-05 21:30:59,001] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:30:59,011] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.332 seconds
[2023-01-05 21:31:29,081] {processor.py:153} INFO - Started process (PID=103) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:31:29,083] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:31:29,084] {logging_mixin.py:115} INFO - [2023-01-05 21:31:29,084] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:31:30,102] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:31:30,103] {logging_mixin.py:115} INFO - [2023-01-05 21:31:30,103] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:31:30,103] {logging_mixin.py:115} INFO - [2023-01-05 21:31:30,103] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:31:30,110] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:31:30,134] {logging_mixin.py:115} INFO - [2023-01-05 21:31:30,134] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:31:30,156] {logging_mixin.py:115} INFO - [2023-01-05 21:31:30,155] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:31:30,165] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.089 seconds
[2023-01-05 21:32:00,233] {processor.py:153} INFO - Started process (PID=127) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:32:00,236] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:32:00,237] {logging_mixin.py:115} INFO - [2023-01-05 21:32:00,236] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:32:01,214] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:32:01,215] {logging_mixin.py:115} INFO - [2023-01-05 21:32:01,215] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:32:01,216] {logging_mixin.py:115} INFO - [2023-01-05 21:32:01,215] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:32:01,223] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:32:01,248] {logging_mixin.py:115} INFO - [2023-01-05 21:32:01,248] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:32:01,270] {logging_mixin.py:115} INFO - [2023-01-05 21:32:01,270] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:32:01,281] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.053 seconds
[2023-01-05 21:32:31,390] {processor.py:153} INFO - Started process (PID=153) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:32:31,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:32:31,391] {logging_mixin.py:115} INFO - [2023-01-05 21:32:31,391] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:32:32,322] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:32:32,324] {logging_mixin.py:115} INFO - [2023-01-05 21:32:32,324] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:32:32,324] {logging_mixin.py:115} INFO - [2023-01-05 21:32:32,324] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:32:32,331] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:32:32,359] {logging_mixin.py:115} INFO - [2023-01-05 21:32:32,358] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:32:32,382] {logging_mixin.py:115} INFO - [2023-01-05 21:32:32,382] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:32:32,393] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.008 seconds
[2023-01-05 21:33:02,491] {processor.py:153} INFO - Started process (PID=171) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:33:02,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:33:02,494] {logging_mixin.py:115} INFO - [2023-01-05 21:33:02,494] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:33:03,819] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:33:03,821] {logging_mixin.py:115} INFO - [2023-01-05 21:33:03,821] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:33:03,822] {logging_mixin.py:115} INFO - [2023-01-05 21:33:03,821] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:33:03,840] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:33:03,872] {logging_mixin.py:115} INFO - [2023-01-05 21:33:03,871] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:33:03,902] {logging_mixin.py:115} INFO - [2023-01-05 21:33:03,902] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:33:03,914] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.428 seconds
[2023-01-05 21:33:33,996] {processor.py:153} INFO - Started process (PID=196) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:33:33,997] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:33:33,998] {logging_mixin.py:115} INFO - [2023-01-05 21:33:33,998] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:33:34,952] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:33:34,954] {logging_mixin.py:115} INFO - [2023-01-05 21:33:34,954] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:33:34,954] {logging_mixin.py:115} INFO - [2023-01-05 21:33:34,954] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:33:34,962] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:33:34,993] {logging_mixin.py:115} INFO - [2023-01-05 21:33:34,992] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:33:35,017] {logging_mixin.py:115} INFO - [2023-01-05 21:33:35,017] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:33:35,028] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.037 seconds
[2023-01-05 21:34:05,080] {processor.py:153} INFO - Started process (PID=221) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:34:05,081] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:34:05,082] {logging_mixin.py:115} INFO - [2023-01-05 21:34:05,082] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:34:06,016] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:34:06,017] {logging_mixin.py:115} INFO - [2023-01-05 21:34:06,017] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:34:06,017] {logging_mixin.py:115} INFO - [2023-01-05 21:34:06,017] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:34:06,024] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:34:06,047] {logging_mixin.py:115} INFO - [2023-01-05 21:34:06,047] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:34:06,069] {logging_mixin.py:115} INFO - [2023-01-05 21:34:06,069] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:34:06,080] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.005 seconds
[2023-01-05 21:34:36,170] {processor.py:153} INFO - Started process (PID=246) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:34:36,170] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:34:36,171] {logging_mixin.py:115} INFO - [2023-01-05 21:34:36,171] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:34:37,100] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:34:37,101] {logging_mixin.py:115} INFO - [2023-01-05 21:34:37,101] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:34:37,102] {logging_mixin.py:115} INFO - [2023-01-05 21:34:37,102] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:34:37,113] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:34:37,137] {logging_mixin.py:115} INFO - [2023-01-05 21:34:37,137] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:34:37,158] {logging_mixin.py:115} INFO - [2023-01-05 21:34:37,158] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:34:37,168] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.002 seconds
[2023-01-05 21:35:07,261] {processor.py:153} INFO - Started process (PID=265) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:35:07,262] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:35:07,262] {logging_mixin.py:115} INFO - [2023-01-05 21:35:07,262] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:35:08,191] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:35:08,193] {logging_mixin.py:115} INFO - [2023-01-05 21:35:08,193] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:35:08,193] {logging_mixin.py:115} INFO - [2023-01-05 21:35:08,193] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:35:08,200] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:35:08,222] {logging_mixin.py:115} INFO - [2023-01-05 21:35:08,222] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:35:08,242] {logging_mixin.py:115} INFO - [2023-01-05 21:35:08,242] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:35:08,252] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-05 21:35:38,340] {processor.py:153} INFO - Started process (PID=290) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:35:38,341] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:35:38,342] {logging_mixin.py:115} INFO - [2023-01-05 21:35:38,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:35:39,263] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:35:39,265] {logging_mixin.py:115} INFO - [2023-01-05 21:35:39,265] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:35:39,265] {logging_mixin.py:115} INFO - [2023-01-05 21:35:39,265] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:35:39,272] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:35:39,296] {logging_mixin.py:115} INFO - [2023-01-05 21:35:39,296] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:35:39,317] {logging_mixin.py:115} INFO - [2023-01-05 21:35:39,317] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:35:39,327] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.992 seconds
[2023-01-05 21:36:09,424] {processor.py:153} INFO - Started process (PID=317) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:36:09,425] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:36:09,425] {logging_mixin.py:115} INFO - [2023-01-05 21:36:09,425] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:36:10,649] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:36:10,651] {logging_mixin.py:115} INFO - [2023-01-05 21:36:10,650] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:36:10,651] {logging_mixin.py:115} INFO - [2023-01-05 21:36:10,651] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:36:10,663] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:36:10,688] {logging_mixin.py:115} INFO - [2023-01-05 21:36:10,687] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:36:10,708] {logging_mixin.py:115} INFO - [2023-01-05 21:36:10,708] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:36:10,718] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.299 seconds
[2023-01-05 21:36:40,794] {processor.py:153} INFO - Started process (PID=336) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:36:40,796] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:36:40,799] {logging_mixin.py:115} INFO - [2023-01-05 21:36:40,796] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:36:42,133] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:36:42,135] {logging_mixin.py:115} INFO - [2023-01-05 21:36:42,135] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:36:42,136] {logging_mixin.py:115} INFO - [2023-01-05 21:36:42,135] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:36:42,147] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:36:42,181] {logging_mixin.py:115} INFO - [2023-01-05 21:36:42,180] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:36:42,212] {logging_mixin.py:115} INFO - [2023-01-05 21:36:42,212] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:36:42,225] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.436 seconds
[2023-01-05 21:37:12,301] {processor.py:153} INFO - Started process (PID=362) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:37:12,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:37:12,304] {logging_mixin.py:115} INFO - [2023-01-05 21:37:12,304] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:37:13,317] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:37:13,319] {logging_mixin.py:115} INFO - [2023-01-05 21:37:13,319] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:37:13,319] {logging_mixin.py:115} INFO - [2023-01-05 21:37:13,319] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:37:13,326] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:37:13,350] {logging_mixin.py:115} INFO - [2023-01-05 21:37:13,350] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:37:13,372] {logging_mixin.py:115} INFO - [2023-01-05 21:37:13,372] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:37:13,385] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.089 seconds
[2023-01-05 21:37:43,462] {processor.py:153} INFO - Started process (PID=386) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:37:43,463] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:37:43,464] {logging_mixin.py:115} INFO - [2023-01-05 21:37:43,464] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:37:44,642] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:37:44,643] {logging_mixin.py:115} INFO - [2023-01-05 21:37:44,643] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:37:44,644] {logging_mixin.py:115} INFO - [2023-01-05 21:37:44,643] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:37:44,651] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:37:44,674] {logging_mixin.py:115} INFO - [2023-01-05 21:37:44,673] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:37:44,694] {logging_mixin.py:115} INFO - [2023-01-05 21:37:44,694] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:37:44,705] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.250 seconds
[2023-01-05 21:38:14,783] {processor.py:153} INFO - Started process (PID=412) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:38:14,785] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:38:14,786] {logging_mixin.py:115} INFO - [2023-01-05 21:38:14,786] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:38:15,751] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:38:15,753] {logging_mixin.py:115} INFO - [2023-01-05 21:38:15,753] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:38:15,753] {logging_mixin.py:115} INFO - [2023-01-05 21:38:15,753] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:38:15,760] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:38:15,783] {logging_mixin.py:115} INFO - [2023-01-05 21:38:15,783] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:38:15,805] {logging_mixin.py:115} INFO - [2023-01-05 21:38:15,805] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:38:15,815] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.038 seconds
[2023-01-05 21:38:45,861] {processor.py:153} INFO - Started process (PID=428) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:38:45,864] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:38:45,864] {logging_mixin.py:115} INFO - [2023-01-05 21:38:45,864] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:38:47,050] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:38:47,052] {logging_mixin.py:115} INFO - [2023-01-05 21:38:47,052] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:38:47,053] {logging_mixin.py:115} INFO - [2023-01-05 21:38:47,052] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:38:47,065] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:38:47,099] {logging_mixin.py:115} INFO - [2023-01-05 21:38:47,098] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:38:47,136] {logging_mixin.py:115} INFO - [2023-01-05 21:38:47,135] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:38:47,150] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.294 seconds
[2023-01-05 21:39:17,231] {processor.py:153} INFO - Started process (PID=453) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:39:17,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:39:17,233] {logging_mixin.py:115} INFO - [2023-01-05 21:39:17,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:39:18,346] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:39:18,347] {logging_mixin.py:115} INFO - [2023-01-05 21:39:18,347] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:39:18,348] {logging_mixin.py:115} INFO - [2023-01-05 21:39:18,348] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:39:18,358] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:39:18,382] {logging_mixin.py:115} INFO - [2023-01-05 21:39:18,382] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:39:18,404] {logging_mixin.py:115} INFO - [2023-01-05 21:39:18,403] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:39:18,414] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.189 seconds
[2023-01-05 21:39:48,486] {processor.py:153} INFO - Started process (PID=476) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:39:48,487] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:39:48,487] {logging_mixin.py:115} INFO - [2023-01-05 21:39:48,487] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:39:49,439] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:39:49,440] {logging_mixin.py:115} INFO - [2023-01-05 21:39:49,440] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:39:49,441] {logging_mixin.py:115} INFO - [2023-01-05 21:39:49,440] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:39:49,448] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:39:49,472] {logging_mixin.py:115} INFO - [2023-01-05 21:39:49,472] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:39:49,494] {logging_mixin.py:115} INFO - [2023-01-05 21:39:49,493] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:39:49,504] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.023 seconds
[2023-01-05 21:40:19,579] {processor.py:153} INFO - Started process (PID=502) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:40:19,580] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:40:19,581] {logging_mixin.py:115} INFO - [2023-01-05 21:40:19,581] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:40:20,510] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:40:20,512] {logging_mixin.py:115} INFO - [2023-01-05 21:40:20,512] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:40:20,512] {logging_mixin.py:115} INFO - [2023-01-05 21:40:20,512] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:40:20,519] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:40:20,542] {logging_mixin.py:115} INFO - [2023-01-05 21:40:20,542] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:40:20,564] {logging_mixin.py:115} INFO - [2023-01-05 21:40:20,564] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:40:20,575] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.999 seconds
[2023-01-05 21:40:50,662] {processor.py:153} INFO - Started process (PID=520) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:40:50,663] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:40:50,664] {logging_mixin.py:115} INFO - [2023-01-05 21:40:50,664] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:40:51,947] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:40:51,949] {logging_mixin.py:115} INFO - [2023-01-05 21:40:51,949] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:40:51,950] {logging_mixin.py:115} INFO - [2023-01-05 21:40:51,949] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:40:51,962] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:40:52,002] {logging_mixin.py:115} INFO - [2023-01-05 21:40:52,001] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:40:52,041] {logging_mixin.py:115} INFO - [2023-01-05 21:40:52,040] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:40:52,069] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.413 seconds
[2023-01-05 21:41:22,167] {processor.py:153} INFO - Started process (PID=547) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:41:22,168] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:41:22,168] {logging_mixin.py:115} INFO - [2023-01-05 21:41:22,168] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:41:23,134] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:41:23,135] {logging_mixin.py:115} INFO - [2023-01-05 21:41:23,135] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:41:23,136] {logging_mixin.py:115} INFO - [2023-01-05 21:41:23,135] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:41:23,143] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:41:23,166] {logging_mixin.py:115} INFO - [2023-01-05 21:41:23,166] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:41:23,187] {logging_mixin.py:115} INFO - [2023-01-05 21:41:23,187] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:41:23,197] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.035 seconds
[2023-01-05 21:41:53,272] {processor.py:153} INFO - Started process (PID=573) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:41:53,274] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:41:53,274] {logging_mixin.py:115} INFO - [2023-01-05 21:41:53,274] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:41:54,205] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:41:54,207] {logging_mixin.py:115} INFO - [2023-01-05 21:41:54,207] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:41:54,208] {logging_mixin.py:115} INFO - [2023-01-05 21:41:54,208] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:41:54,215] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:41:54,241] {logging_mixin.py:115} INFO - [2023-01-05 21:41:54,241] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:41:54,265] {logging_mixin.py:115} INFO - [2023-01-05 21:41:54,265] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:41:54,274] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.007 seconds
[2023-01-05 21:42:24,363] {processor.py:153} INFO - Started process (PID=598) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:42:24,364] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:42:24,365] {logging_mixin.py:115} INFO - [2023-01-05 21:42:24,365] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:42:25,653] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:42:25,654] {logging_mixin.py:115} INFO - [2023-01-05 21:42:25,654] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:42:25,654] {logging_mixin.py:115} INFO - [2023-01-05 21:42:25,654] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:42:25,661] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:42:25,685] {logging_mixin.py:115} INFO - [2023-01-05 21:42:25,685] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:42:25,708] {logging_mixin.py:115} INFO - [2023-01-05 21:42:25,708] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:42:25,718] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.361 seconds
[2023-01-05 21:42:55,789] {processor.py:153} INFO - Started process (PID=618) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:42:55,790] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:42:55,791] {logging_mixin.py:115} INFO - [2023-01-05 21:42:55,791] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:42:56,718] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:42:56,720] {logging_mixin.py:115} INFO - [2023-01-05 21:42:56,719] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:42:56,720] {logging_mixin.py:115} INFO - [2023-01-05 21:42:56,720] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:42:56,727] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:42:56,749] {logging_mixin.py:115} INFO - [2023-01-05 21:42:56,749] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:42:56,770] {logging_mixin.py:115} INFO - [2023-01-05 21:42:56,770] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:42:56,780] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-05 21:43:26,866] {processor.py:153} INFO - Started process (PID=642) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:43:26,866] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:43:26,867] {logging_mixin.py:115} INFO - [2023-01-05 21:43:26,867] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:43:27,794] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:43:27,796] {logging_mixin.py:115} INFO - [2023-01-05 21:43:27,796] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:43:27,796] {logging_mixin.py:115} INFO - [2023-01-05 21:43:27,796] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:43:27,803] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:43:27,828] {logging_mixin.py:115} INFO - [2023-01-05 21:43:27,827] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:43:27,849] {logging_mixin.py:115} INFO - [2023-01-05 21:43:27,849] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:43:27,859] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.998 seconds
[2023-01-05 21:43:57,948] {processor.py:153} INFO - Started process (PID=668) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:43:57,949] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:43:57,950] {logging_mixin.py:115} INFO - [2023-01-05 21:43:57,950] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:43:58,869] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:43:58,870] {logging_mixin.py:115} INFO - [2023-01-05 21:43:58,870] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:43:58,871] {logging_mixin.py:115} INFO - [2023-01-05 21:43:58,870] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:43:58,878] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:43:58,900] {logging_mixin.py:115} INFO - [2023-01-05 21:43:58,900] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:43:58,922] {logging_mixin.py:115} INFO - [2023-01-05 21:43:58,921] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:43:58,931] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.988 seconds
[2023-01-05 21:44:29,024] {processor.py:153} INFO - Started process (PID=693) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:44:29,025] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:44:29,025] {logging_mixin.py:115} INFO - [2023-01-05 21:44:29,025] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:44:30,352] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:44:30,353] {logging_mixin.py:115} INFO - [2023-01-05 21:44:30,353] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:44:30,354] {logging_mixin.py:115} INFO - [2023-01-05 21:44:30,354] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:44:30,361] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:44:30,388] {logging_mixin.py:115} INFO - [2023-01-05 21:44:30,388] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:44:30,411] {logging_mixin.py:115} INFO - [2023-01-05 21:44:30,410] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:44:30,421] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.402 seconds
[2023-01-05 21:45:00,492] {processor.py:153} INFO - Started process (PID=711) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:45:00,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:45:00,493] {logging_mixin.py:115} INFO - [2023-01-05 21:45:00,493] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:45:01,431] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:45:01,432] {logging_mixin.py:115} INFO - [2023-01-05 21:45:01,432] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:45:01,433] {logging_mixin.py:115} INFO - [2023-01-05 21:45:01,432] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:45:01,440] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:45:01,464] {logging_mixin.py:115} INFO - [2023-01-05 21:45:01,464] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:45:01,487] {logging_mixin.py:115} INFO - [2023-01-05 21:45:01,486] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:45:01,497] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.010 seconds
[2023-01-05 21:45:31,573] {processor.py:153} INFO - Started process (PID=736) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:45:31,574] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:45:31,574] {logging_mixin.py:115} INFO - [2023-01-05 21:45:31,574] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:45:32,520] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:45:32,522] {logging_mixin.py:115} INFO - [2023-01-05 21:45:32,521] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:45:32,522] {logging_mixin.py:115} INFO - [2023-01-05 21:45:32,522] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:45:32,529] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:45:32,553] {logging_mixin.py:115} INFO - [2023-01-05 21:45:32,553] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:45:32,575] {logging_mixin.py:115} INFO - [2023-01-05 21:45:32,575] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:45:32,585] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.017 seconds
[2023-01-05 21:46:02,661] {processor.py:153} INFO - Started process (PID=761) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:46:02,662] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:46:02,663] {logging_mixin.py:115} INFO - [2023-01-05 21:46:02,663] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:46:03,577] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:46:03,578] {logging_mixin.py:115} INFO - [2023-01-05 21:46:03,578] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:46:03,579] {logging_mixin.py:115} INFO - [2023-01-05 21:46:03,578] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:46:03,586] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:46:03,611] {logging_mixin.py:115} INFO - [2023-01-05 21:46:03,610] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:46:03,633] {logging_mixin.py:115} INFO - [2023-01-05 21:46:03,632] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:46:03,643] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.986 seconds
[2023-01-05 21:46:33,735] {processor.py:153} INFO - Started process (PID=779) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:46:33,736] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:46:33,737] {logging_mixin.py:115} INFO - [2023-01-05 21:46:33,737] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:46:34,896] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:46:34,897] {logging_mixin.py:115} INFO - [2023-01-05 21:46:34,897] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:46:34,898] {logging_mixin.py:115} INFO - [2023-01-05 21:46:34,897] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:46:34,905] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:46:34,937] {logging_mixin.py:115} INFO - [2023-01-05 21:46:34,937] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:46:34,972] {logging_mixin.py:115} INFO - [2023-01-05 21:46:34,972] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:46:34,986] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.255 seconds
[2023-01-05 21:47:05,072] {processor.py:153} INFO - Started process (PID=804) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:47:05,072] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:47:05,073] {logging_mixin.py:115} INFO - [2023-01-05 21:47:05,073] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:47:06,026] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:47:06,028] {logging_mixin.py:115} INFO - [2023-01-05 21:47:06,028] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:47:06,028] {logging_mixin.py:115} INFO - [2023-01-05 21:47:06,028] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:47:06,035] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:47:06,057] {logging_mixin.py:115} INFO - [2023-01-05 21:47:06,057] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:47:06,078] {logging_mixin.py:115} INFO - [2023-01-05 21:47:06,078] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:47:06,088] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.021 seconds
[2023-01-05 21:47:36,156] {processor.py:153} INFO - Started process (PID=827) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:47:36,157] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:47:36,158] {logging_mixin.py:115} INFO - [2023-01-05 21:47:36,158] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:47:37,086] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:47:37,087] {logging_mixin.py:115} INFO - [2023-01-05 21:47:37,087] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:47:37,088] {logging_mixin.py:115} INFO - [2023-01-05 21:47:37,087] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:47:37,095] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:47:37,117] {logging_mixin.py:115} INFO - [2023-01-05 21:47:37,116] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:47:37,139] {logging_mixin.py:115} INFO - [2023-01-05 21:47:37,139] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:47:37,149] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.997 seconds
[2023-01-05 21:48:07,262] {processor.py:153} INFO - Started process (PID=851) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:48:07,263] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:48:07,276] {logging_mixin.py:115} INFO - [2023-01-05 21:48:07,275] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:48:08,894] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:48:08,895] {logging_mixin.py:115} INFO - [2023-01-05 21:48:08,895] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:48:08,896] {logging_mixin.py:115} INFO - [2023-01-05 21:48:08,896] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:48:08,903] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:48:08,932] {logging_mixin.py:115} INFO - [2023-01-05 21:48:08,932] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:48:08,962] {logging_mixin.py:115} INFO - [2023-01-05 21:48:08,962] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:48:08,974] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.718 seconds
[2023-01-05 21:48:39,048] {processor.py:153} INFO - Started process (PID=870) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:48:39,049] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:48:39,049] {logging_mixin.py:115} INFO - [2023-01-05 21:48:39,049] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:48:40,000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:48:40,001] {logging_mixin.py:115} INFO - [2023-01-05 21:48:40,001] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:48:40,002] {logging_mixin.py:115} INFO - [2023-01-05 21:48:40,001] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:48:40,009] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:48:40,033] {logging_mixin.py:115} INFO - [2023-01-05 21:48:40,033] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:48:40,056] {logging_mixin.py:115} INFO - [2023-01-05 21:48:40,056] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:48:40,066] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.022 seconds
[2023-01-05 21:49:10,134] {processor.py:153} INFO - Started process (PID=895) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:49:10,137] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:49:10,137] {logging_mixin.py:115} INFO - [2023-01-05 21:49:10,137] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:49:11,042] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:49:11,044] {logging_mixin.py:115} INFO - [2023-01-05 21:49:11,043] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:49:11,044] {logging_mixin.py:115} INFO - [2023-01-05 21:49:11,044] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:49:11,051] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:49:11,074] {logging_mixin.py:115} INFO - [2023-01-05 21:49:11,074] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:49:11,095] {logging_mixin.py:115} INFO - [2023-01-05 21:49:11,095] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:49:11,105] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.975 seconds
[2023-01-05 21:49:41,147] {processor.py:153} INFO - Started process (PID=919) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:49:41,148] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:49:41,149] {logging_mixin.py:115} INFO - [2023-01-05 21:49:41,149] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:49:42,184] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:49:42,186] {logging_mixin.py:115} INFO - [2023-01-05 21:49:42,186] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:49:42,187] {logging_mixin.py:115} INFO - [2023-01-05 21:49:42,187] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:49:42,199] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:49:42,230] {logging_mixin.py:115} INFO - [2023-01-05 21:49:42,229] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:49:42,259] {logging_mixin.py:115} INFO - [2023-01-05 21:49:42,259] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:49:42,270] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.127 seconds
[2023-01-05 21:50:12,394] {processor.py:153} INFO - Started process (PID=943) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:50:12,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:50:12,396] {logging_mixin.py:115} INFO - [2023-01-05 21:50:12,396] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:50:13,722] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:50:13,724] {logging_mixin.py:115} INFO - [2023-01-05 21:50:13,724] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:50:13,724] {logging_mixin.py:115} INFO - [2023-01-05 21:50:13,724] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:50:13,731] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:50:13,754] {logging_mixin.py:115} INFO - [2023-01-05 21:50:13,754] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:50:13,776] {logging_mixin.py:115} INFO - [2023-01-05 21:50:13,775] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:50:13,785] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.399 seconds
[2023-01-05 21:50:43,867] {processor.py:153} INFO - Started process (PID=962) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:50:43,867] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:50:43,868] {logging_mixin.py:115} INFO - [2023-01-05 21:50:43,868] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:50:44,794] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:50:44,795] {logging_mixin.py:115} INFO - [2023-01-05 21:50:44,795] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:50:44,796] {logging_mixin.py:115} INFO - [2023-01-05 21:50:44,796] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:50:44,803] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:50:44,826] {logging_mixin.py:115} INFO - [2023-01-05 21:50:44,826] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:50:44,848] {logging_mixin.py:115} INFO - [2023-01-05 21:50:44,848] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:50:44,858] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-05 21:51:14,946] {processor.py:153} INFO - Started process (PID=986) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:51:14,947] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:51:14,948] {logging_mixin.py:115} INFO - [2023-01-05 21:51:14,948] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:51:16,093] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:51:16,095] {logging_mixin.py:115} INFO - [2023-01-05 21:51:16,094] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:51:16,095] {logging_mixin.py:115} INFO - [2023-01-05 21:51:16,095] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:51:16,104] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:51:16,128] {logging_mixin.py:115} INFO - [2023-01-05 21:51:16,128] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:51:16,150] {logging_mixin.py:115} INFO - [2023-01-05 21:51:16,150] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:51:16,160] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.219 seconds
[2023-01-05 21:51:46,239] {processor.py:153} INFO - Started process (PID=1012) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:51:46,240] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:51:46,241] {logging_mixin.py:115} INFO - [2023-01-05 21:51:46,241] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:51:47,168] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:51:47,170] {logging_mixin.py:115} INFO - [2023-01-05 21:51:47,170] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:51:47,170] {logging_mixin.py:115} INFO - [2023-01-05 21:51:47,170] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:51:47,180] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:51:47,203] {logging_mixin.py:115} INFO - [2023-01-05 21:51:47,202] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:51:47,224] {logging_mixin.py:115} INFO - [2023-01-05 21:51:47,224] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:51:47,238] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.004 seconds
[2023-01-05 21:52:17,325] {processor.py:153} INFO - Started process (PID=1037) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:52:17,325] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:52:17,326] {logging_mixin.py:115} INFO - [2023-01-05 21:52:17,326] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:52:18,718] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:52:18,723] {logging_mixin.py:115} INFO - [2023-01-05 21:52:18,723] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:52:18,724] {logging_mixin.py:115} INFO - [2023-01-05 21:52:18,723] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:52:18,733] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:52:18,763] {logging_mixin.py:115} INFO - [2023-01-05 21:52:18,763] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:52:18,793] {logging_mixin.py:115} INFO - [2023-01-05 21:52:18,793] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:52:18,806] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.487 seconds
[2023-01-05 21:52:48,883] {processor.py:153} INFO - Started process (PID=1055) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:52:48,884] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:52:48,884] {logging_mixin.py:115} INFO - [2023-01-05 21:52:48,884] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:52:50,008] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:52:50,009] {logging_mixin.py:115} INFO - [2023-01-05 21:52:50,009] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:52:50,010] {logging_mixin.py:115} INFO - [2023-01-05 21:52:50,009] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:52:50,016] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:52:50,039] {logging_mixin.py:115} INFO - [2023-01-05 21:52:50,039] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:52:50,061] {logging_mixin.py:115} INFO - [2023-01-05 21:52:50,061] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:52:50,073] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.195 seconds
[2023-01-05 21:53:20,151] {processor.py:153} INFO - Started process (PID=1082) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:53:20,152] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:53:20,152] {logging_mixin.py:115} INFO - [2023-01-05 21:53:20,152] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:53:21,112] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:53:21,113] {logging_mixin.py:115} INFO - [2023-01-05 21:53:21,113] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:53:21,114] {logging_mixin.py:115} INFO - [2023-01-05 21:53:21,113] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:53:21,121] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:53:21,143] {logging_mixin.py:115} INFO - [2023-01-05 21:53:21,143] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:53:21,165] {logging_mixin.py:115} INFO - [2023-01-05 21:53:21,165] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:53:21,175] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.029 seconds
[2023-01-05 21:53:51,244] {processor.py:153} INFO - Started process (PID=1108) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:53:51,245] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:53:51,245] {logging_mixin.py:115} INFO - [2023-01-05 21:53:51,245] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:53:52,206] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:53:52,207] {logging_mixin.py:115} INFO - [2023-01-05 21:53:52,207] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:53:52,208] {logging_mixin.py:115} INFO - [2023-01-05 21:53:52,208] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:53:52,215] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:53:52,239] {logging_mixin.py:115} INFO - [2023-01-05 21:53:52,238] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:53:52,261] {logging_mixin.py:115} INFO - [2023-01-05 21:53:52,260] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:53:52,271] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.033 seconds
[2023-01-05 21:54:22,332] {processor.py:153} INFO - Started process (PID=1125) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:54:22,333] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:54:22,334] {logging_mixin.py:115} INFO - [2023-01-05 21:54:22,333] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:54:23,276] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:54:23,277] {logging_mixin.py:115} INFO - [2023-01-05 21:54:23,277] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:54:23,277] {logging_mixin.py:115} INFO - [2023-01-05 21:54:23,277] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:54:23,284] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:54:23,311] {logging_mixin.py:115} INFO - [2023-01-05 21:54:23,310] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:54:23,332] {logging_mixin.py:115} INFO - [2023-01-05 21:54:23,332] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:54:23,342] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.015 seconds
[2023-01-05 21:54:53,416] {processor.py:153} INFO - Started process (PID=1149) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:54:53,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:54:53,419] {logging_mixin.py:115} INFO - [2023-01-05 21:54:53,419] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:54:54,388] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:54:54,390] {logging_mixin.py:115} INFO - [2023-01-05 21:54:54,390] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:54:54,390] {logging_mixin.py:115} INFO - [2023-01-05 21:54:54,390] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:54:54,397] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:54:54,419] {logging_mixin.py:115} INFO - [2023-01-05 21:54:54,418] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:54:54,439] {logging_mixin.py:115} INFO - [2023-01-05 21:54:54,439] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:54:54,448] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.037 seconds
[2023-01-05 21:55:24,505] {processor.py:153} INFO - Started process (PID=1173) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:55:24,506] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:55:24,507] {logging_mixin.py:115} INFO - [2023-01-05 21:55:24,507] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:55:25,453] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:55:25,454] {logging_mixin.py:115} INFO - [2023-01-05 21:55:25,454] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:55:25,454] {logging_mixin.py:115} INFO - [2023-01-05 21:55:25,454] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:55:25,462] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:55:25,484] {logging_mixin.py:115} INFO - [2023-01-05 21:55:25,484] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:55:25,506] {logging_mixin.py:115} INFO - [2023-01-05 21:55:25,506] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:55:25,516] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.017 seconds
[2023-01-05 21:55:55,593] {processor.py:153} INFO - Started process (PID=1197) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:55:55,595] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:55:55,596] {logging_mixin.py:115} INFO - [2023-01-05 21:55:55,596] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:55:56,754] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:55:56,756] {logging_mixin.py:115} INFO - [2023-01-05 21:55:56,756] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:55:56,756] {logging_mixin.py:115} INFO - [2023-01-05 21:55:56,756] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:55:56,763] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:55:56,787] {logging_mixin.py:115} INFO - [2023-01-05 21:55:56,787] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:55:56,808] {logging_mixin.py:115} INFO - [2023-01-05 21:55:56,808] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:55:56,818] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.230 seconds
[2023-01-05 21:56:26,889] {processor.py:153} INFO - Started process (PID=1218) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:56:26,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:56:26,891] {logging_mixin.py:115} INFO - [2023-01-05 21:56:26,891] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:56:27,841] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:56:27,842] {logging_mixin.py:115} INFO - [2023-01-05 21:56:27,842] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:56:27,842] {logging_mixin.py:115} INFO - [2023-01-05 21:56:27,842] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:56:27,849] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:56:27,872] {logging_mixin.py:115} INFO - [2023-01-05 21:56:27,872] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:56:27,894] {logging_mixin.py:115} INFO - [2023-01-05 21:56:27,894] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:56:27,904] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.020 seconds
[2023-01-05 21:56:57,976] {processor.py:153} INFO - Started process (PID=1242) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:56:57,976] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:56:57,977] {logging_mixin.py:115} INFO - [2023-01-05 21:56:57,977] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:56:59,009] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:56:59,010] {logging_mixin.py:115} INFO - [2023-01-05 21:56:59,010] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:56:59,011] {logging_mixin.py:115} INFO - [2023-01-05 21:56:59,010] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:56:59,018] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:56:59,041] {logging_mixin.py:115} INFO - [2023-01-05 21:56:59,041] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:56:59,062] {logging_mixin.py:115} INFO - [2023-01-05 21:56:59,062] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:56:59,072] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.102 seconds
[2023-01-05 21:57:29,142] {processor.py:153} INFO - Started process (PID=1267) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:57:29,143] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:57:29,144] {logging_mixin.py:115} INFO - [2023-01-05 21:57:29,144] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:57:30,068] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:57:30,069] {logging_mixin.py:115} INFO - [2023-01-05 21:57:30,069] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:57:30,069] {logging_mixin.py:115} INFO - [2023-01-05 21:57:30,069] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:57:30,076] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:57:30,099] {logging_mixin.py:115} INFO - [2023-01-05 21:57:30,099] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:57:30,120] {logging_mixin.py:115} INFO - [2023-01-05 21:57:30,120] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:57:30,131] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.994 seconds
[2023-01-05 21:58:00,219] {processor.py:153} INFO - Started process (PID=1291) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:58:00,220] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:58:00,221] {logging_mixin.py:115} INFO - [2023-01-05 21:58:00,221] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:58:01,342] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:58:01,344] {logging_mixin.py:115} INFO - [2023-01-05 21:58:01,344] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:58:01,344] {logging_mixin.py:115} INFO - [2023-01-05 21:58:01,344] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:58:01,351] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:58:01,375] {logging_mixin.py:115} INFO - [2023-01-05 21:58:01,375] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:58:01,396] {logging_mixin.py:115} INFO - [2023-01-05 21:58:01,395] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:58:01,405] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.191 seconds
[2023-01-05 21:58:31,480] {processor.py:153} INFO - Started process (PID=1311) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:58:31,480] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:58:31,481] {logging_mixin.py:115} INFO - [2023-01-05 21:58:31,481] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:58:32,418] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:58:32,419] {logging_mixin.py:115} INFO - [2023-01-05 21:58:32,419] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:58:32,419] {logging_mixin.py:115} INFO - [2023-01-05 21:58:32,419] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:58:32,426] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:58:32,449] {logging_mixin.py:115} INFO - [2023-01-05 21:58:32,448] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:58:32,470] {logging_mixin.py:115} INFO - [2023-01-05 21:58:32,470] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:58:32,480] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.006 seconds
[2023-01-05 21:59:02,557] {processor.py:153} INFO - Started process (PID=1335) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:59:02,559] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:59:02,560] {logging_mixin.py:115} INFO - [2023-01-05 21:59:02,559] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:59:03,548] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:59:03,549] {logging_mixin.py:115} INFO - [2023-01-05 21:59:03,549] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:59:03,550] {logging_mixin.py:115} INFO - [2023-01-05 21:59:03,549] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:59:03,557] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:59:03,580] {logging_mixin.py:115} INFO - [2023-01-05 21:59:03,580] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:59:03,601] {logging_mixin.py:115} INFO - [2023-01-05 21:59:03,601] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:59:03,610] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.058 seconds
[2023-01-05 21:59:33,682] {processor.py:153} INFO - Started process (PID=1362) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:59:33,683] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:59:33,684] {logging_mixin.py:115} INFO - [2023-01-05 21:59:33,684] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:59:34,642] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:59:34,643] {logging_mixin.py:115} INFO - [2023-01-05 21:59:34,643] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:59:34,643] {logging_mixin.py:115} INFO - [2023-01-05 21:59:34,643] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:59:34,650] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 21:59:34,674] {logging_mixin.py:115} INFO - [2023-01-05 21:59:34,673] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:59:34,695] {logging_mixin.py:115} INFO - [2023-01-05 21:59:34,695] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 21:59:34,705] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.029 seconds
[2023-01-05 22:00:04,820] {processor.py:153} INFO - Started process (PID=1386) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:00:04,822] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:00:04,823] {logging_mixin.py:115} INFO - [2023-01-05 22:00:04,823] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:00:06,183] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:00:06,185] {logging_mixin.py:115} INFO - [2023-01-05 22:00:06,185] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:00:06,186] {logging_mixin.py:115} INFO - [2023-01-05 22:00:06,185] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:00:06,196] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:00:06,228] {logging_mixin.py:115} INFO - [2023-01-05 22:00:06,227] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:00:06,251] {logging_mixin.py:115} INFO - [2023-01-05 22:00:06,251] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:00:06,261] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.451 seconds
[2023-01-05 22:00:36,322] {processor.py:153} INFO - Started process (PID=1403) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:00:36,322] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:00:36,323] {logging_mixin.py:115} INFO - [2023-01-05 22:00:36,323] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:00:37,235] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:00:37,236] {logging_mixin.py:115} INFO - [2023-01-05 22:00:37,236] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:00:37,237] {logging_mixin.py:115} INFO - [2023-01-05 22:00:37,237] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:00:37,244] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:00:37,267] {logging_mixin.py:115} INFO - [2023-01-05 22:00:37,266] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:00:37,287] {logging_mixin.py:115} INFO - [2023-01-05 22:00:37,287] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:00:37,299] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.982 seconds
[2023-01-05 22:01:07,372] {processor.py:153} INFO - Started process (PID=1429) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:01:07,373] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:01:07,374] {logging_mixin.py:115} INFO - [2023-01-05 22:01:07,373] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:01:08,279] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:01:08,281] {logging_mixin.py:115} INFO - [2023-01-05 22:01:08,281] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:01:08,281] {logging_mixin.py:115} INFO - [2023-01-05 22:01:08,281] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:01:08,288] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:01:08,311] {logging_mixin.py:115} INFO - [2023-01-05 22:01:08,311] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:01:08,333] {logging_mixin.py:115} INFO - [2023-01-05 22:01:08,333] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:01:08,343] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.976 seconds
[2023-01-05 22:01:38,420] {processor.py:153} INFO - Started process (PID=1455) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:01:38,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:01:38,422] {logging_mixin.py:115} INFO - [2023-01-05 22:01:38,422] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:01:39,659] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:01:39,661] {logging_mixin.py:115} INFO - [2023-01-05 22:01:39,661] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:01:39,661] {logging_mixin.py:115} INFO - [2023-01-05 22:01:39,661] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:01:39,672] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:01:39,698] {logging_mixin.py:115} INFO - [2023-01-05 22:01:39,698] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:01:39,719] {logging_mixin.py:115} INFO - [2023-01-05 22:01:39,719] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:01:39,728] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.314 seconds
[2023-01-05 22:02:09,805] {processor.py:153} INFO - Started process (PID=1481) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:02:09,807] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:02:09,808] {logging_mixin.py:115} INFO - [2023-01-05 22:02:09,808] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:02:10,944] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:02:10,945] {logging_mixin.py:115} INFO - [2023-01-05 22:02:10,945] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:02:10,946] {logging_mixin.py:115} INFO - [2023-01-05 22:02:10,946] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:02:10,953] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:02:10,976] {logging_mixin.py:115} INFO - [2023-01-05 22:02:10,975] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:02:10,997] {logging_mixin.py:115} INFO - [2023-01-05 22:02:10,997] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:02:11,007] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.208 seconds
[2023-01-05 22:02:41,082] {processor.py:153} INFO - Started process (PID=1499) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:02:41,083] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:02:41,083] {logging_mixin.py:115} INFO - [2023-01-05 22:02:41,083] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:02:42,013] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:02:42,014] {logging_mixin.py:115} INFO - [2023-01-05 22:02:42,014] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:02:42,015] {logging_mixin.py:115} INFO - [2023-01-05 22:02:42,014] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:02:42,022] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:02:42,044] {logging_mixin.py:115} INFO - [2023-01-05 22:02:42,044] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:02:42,065] {logging_mixin.py:115} INFO - [2023-01-05 22:02:42,065] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:02:42,075] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.997 seconds
[2023-01-05 22:03:12,164] {processor.py:153} INFO - Started process (PID=1523) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:03:12,168] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:03:12,169] {logging_mixin.py:115} INFO - [2023-01-05 22:03:12,168] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:03:13,305] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:03:13,306] {logging_mixin.py:115} INFO - [2023-01-05 22:03:13,306] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:03:13,306] {logging_mixin.py:115} INFO - [2023-01-05 22:03:13,306] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:03:13,313] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:03:13,336] {logging_mixin.py:115} INFO - [2023-01-05 22:03:13,335] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:03:13,357] {logging_mixin.py:115} INFO - [2023-01-05 22:03:13,357] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:03:13,368] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.209 seconds
[2023-01-05 22:03:43,474] {processor.py:153} INFO - Started process (PID=1548) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:03:43,475] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:03:43,475] {logging_mixin.py:115} INFO - [2023-01-05 22:03:43,475] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:03:44,405] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:03:44,407] {logging_mixin.py:115} INFO - [2023-01-05 22:03:44,407] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:03:44,407] {logging_mixin.py:115} INFO - [2023-01-05 22:03:44,407] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:03:44,414] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:03:44,436] {logging_mixin.py:115} INFO - [2023-01-05 22:03:44,436] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:03:44,456] {logging_mixin.py:115} INFO - [2023-01-05 22:03:44,456] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:03:44,466] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-05 22:04:14,569] {processor.py:153} INFO - Started process (PID=1572) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:04:14,570] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:04:14,571] {logging_mixin.py:115} INFO - [2023-01-05 22:04:14,571] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:04:15,682] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:04:15,684] {logging_mixin.py:115} INFO - [2023-01-05 22:04:15,684] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:04:15,685] {logging_mixin.py:115} INFO - [2023-01-05 22:04:15,684] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:04:15,693] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:04:15,717] {logging_mixin.py:115} INFO - [2023-01-05 22:04:15,716] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:04:15,738] {logging_mixin.py:115} INFO - [2023-01-05 22:04:15,738] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:04:15,748] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.185 seconds
[2023-01-05 22:04:45,821] {processor.py:153} INFO - Started process (PID=1591) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:04:45,822] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:04:45,823] {logging_mixin.py:115} INFO - [2023-01-05 22:04:45,823] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:04:47,150] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:04:47,152] {logging_mixin.py:115} INFO - [2023-01-05 22:04:47,152] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:04:47,152] {logging_mixin.py:115} INFO - [2023-01-05 22:04:47,152] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:04:47,159] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:04:47,182] {logging_mixin.py:115} INFO - [2023-01-05 22:04:47,182] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:04:47,203] {logging_mixin.py:115} INFO - [2023-01-05 22:04:47,203] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:04:47,213] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.398 seconds
[2023-01-05 22:05:17,292] {processor.py:153} INFO - Started process (PID=1617) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:05:17,293] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:05:17,294] {logging_mixin.py:115} INFO - [2023-01-05 22:05:17,294] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:05:18,228] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:05:18,230] {logging_mixin.py:115} INFO - [2023-01-05 22:05:18,229] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:05:18,230] {logging_mixin.py:115} INFO - [2023-01-05 22:05:18,230] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:05:18,237] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:05:18,260] {logging_mixin.py:115} INFO - [2023-01-05 22:05:18,260] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:05:18,281] {logging_mixin.py:115} INFO - [2023-01-05 22:05:18,281] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:05:18,290] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.004 seconds
[2023-01-05 22:05:48,370] {processor.py:153} INFO - Started process (PID=1640) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:05:48,371] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:05:48,371] {logging_mixin.py:115} INFO - [2023-01-05 22:05:48,371] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:05:49,353] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:05:49,354] {logging_mixin.py:115} INFO - [2023-01-05 22:05:49,354] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:05:49,355] {logging_mixin.py:115} INFO - [2023-01-05 22:05:49,355] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:05:49,362] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:05:49,386] {logging_mixin.py:115} INFO - [2023-01-05 22:05:49,386] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:05:49,407] {logging_mixin.py:115} INFO - [2023-01-05 22:05:49,407] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:05:49,417] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.051 seconds
[2023-01-05 22:06:19,460] {processor.py:153} INFO - Started process (PID=1665) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:06:19,461] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:06:19,462] {logging_mixin.py:115} INFO - [2023-01-05 22:06:19,462] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:06:20,752] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:06:20,754] {logging_mixin.py:115} INFO - [2023-01-05 22:06:20,754] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:06:20,755] {logging_mixin.py:115} INFO - [2023-01-05 22:06:20,754] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:06:20,766] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:06:20,792] {logging_mixin.py:115} INFO - [2023-01-05 22:06:20,792] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:06:20,814] {logging_mixin.py:115} INFO - [2023-01-05 22:06:20,814] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:06:20,828] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.373 seconds
[2023-01-05 22:06:50,907] {processor.py:153} INFO - Started process (PID=1684) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:06:50,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:06:50,908] {logging_mixin.py:115} INFO - [2023-01-05 22:06:50,908] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:06:51,878] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:06:51,880] {logging_mixin.py:115} INFO - [2023-01-05 22:06:51,879] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:06:51,880] {logging_mixin.py:115} INFO - [2023-01-05 22:06:51,880] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:06:51,887] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:06:51,910] {logging_mixin.py:115} INFO - [2023-01-05 22:06:51,910] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:06:51,931] {logging_mixin.py:115} INFO - [2023-01-05 22:06:51,931] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:06:51,941] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.039 seconds
[2023-01-05 22:07:21,996] {processor.py:153} INFO - Started process (PID=1708) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:07:21,997] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:07:21,998] {logging_mixin.py:115} INFO - [2023-01-05 22:07:21,998] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:07:22,966] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:07:22,967] {logging_mixin.py:115} INFO - [2023-01-05 22:07:22,967] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:07:22,968] {logging_mixin.py:115} INFO - [2023-01-05 22:07:22,967] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:07:22,974] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:07:22,997] {logging_mixin.py:115} INFO - [2023-01-05 22:07:22,997] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:07:23,018] {logging_mixin.py:115} INFO - [2023-01-05 22:07:23,018] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:07:23,028] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.039 seconds
[2023-01-05 22:07:53,094] {processor.py:153} INFO - Started process (PID=1733) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:07:53,095] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:07:53,096] {logging_mixin.py:115} INFO - [2023-01-05 22:07:53,096] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:07:54,045] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:07:54,046] {logging_mixin.py:115} INFO - [2023-01-05 22:07:54,046] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:07:54,047] {logging_mixin.py:115} INFO - [2023-01-05 22:07:54,046] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:07:54,054] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:07:54,078] {logging_mixin.py:115} INFO - [2023-01-05 22:07:54,078] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:07:54,100] {logging_mixin.py:115} INFO - [2023-01-05 22:07:54,100] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:07:54,111] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.021 seconds
[2023-01-05 22:08:24,188] {processor.py:153} INFO - Started process (PID=1758) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:08:24,189] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:08:24,190] {logging_mixin.py:115} INFO - [2023-01-05 22:08:24,190] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:08:25,292] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:08:25,293] {logging_mixin.py:115} INFO - [2023-01-05 22:08:25,293] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:08:25,293] {logging_mixin.py:115} INFO - [2023-01-05 22:08:25,293] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:08:25,300] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:08:25,323] {logging_mixin.py:115} INFO - [2023-01-05 22:08:25,322] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:08:25,352] {logging_mixin.py:115} INFO - [2023-01-05 22:08:25,352] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:08:25,364] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.182 seconds
[2023-01-05 22:08:55,438] {processor.py:153} INFO - Started process (PID=1776) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:08:55,439] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:08:55,439] {logging_mixin.py:115} INFO - [2023-01-05 22:08:55,439] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:08:56,488] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:08:56,490] {logging_mixin.py:115} INFO - [2023-01-05 22:08:56,489] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:08:56,490] {logging_mixin.py:115} INFO - [2023-01-05 22:08:56,490] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:08:56,497] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:08:56,520] {logging_mixin.py:115} INFO - [2023-01-05 22:08:56,520] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:08:56,541] {logging_mixin.py:115} INFO - [2023-01-05 22:08:56,541] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:08:56,552] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.118 seconds
[2023-01-05 22:09:26,624] {processor.py:153} INFO - Started process (PID=1804) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:09:26,625] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:09:26,625] {logging_mixin.py:115} INFO - [2023-01-05 22:09:26,625] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:09:27,562] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:09:27,563] {logging_mixin.py:115} INFO - [2023-01-05 22:09:27,563] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:09:27,563] {logging_mixin.py:115} INFO - [2023-01-05 22:09:27,563] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:09:27,570] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:09:27,593] {logging_mixin.py:115} INFO - [2023-01-05 22:09:27,593] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:09:27,616] {logging_mixin.py:115} INFO - [2023-01-05 22:09:27,616] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:09:27,626] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.007 seconds
[2023-01-05 22:09:57,715] {processor.py:153} INFO - Started process (PID=1827) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:09:57,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:09:57,717] {logging_mixin.py:115} INFO - [2023-01-05 22:09:57,716] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:09:58,765] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:09:58,767] {logging_mixin.py:115} INFO - [2023-01-05 22:09:58,767] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:09:58,767] {logging_mixin.py:115} INFO - [2023-01-05 22:09:58,767] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:09:58,774] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:09:58,797] {logging_mixin.py:115} INFO - [2023-01-05 22:09:58,797] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:09:58,818] {logging_mixin.py:115} INFO - [2023-01-05 22:09:58,818] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:09:58,828] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.117 seconds
[2023-01-05 22:10:28,902] {processor.py:153} INFO - Started process (PID=1853) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:10:28,904] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:10:28,905] {logging_mixin.py:115} INFO - [2023-01-05 22:10:28,904] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:10:30,047] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:10:30,048] {logging_mixin.py:115} INFO - [2023-01-05 22:10:30,048] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:10:30,049] {logging_mixin.py:115} INFO - [2023-01-05 22:10:30,048] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:10:30,056] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:10:30,078] {logging_mixin.py:115} INFO - [2023-01-05 22:10:30,078] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:10:30,100] {logging_mixin.py:115} INFO - [2023-01-05 22:10:30,099] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:10:30,110] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.213 seconds
[2023-01-05 22:11:00,192] {processor.py:153} INFO - Started process (PID=1871) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:11:00,194] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:11:00,195] {logging_mixin.py:115} INFO - [2023-01-05 22:11:00,195] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:11:01,471] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:11:01,473] {logging_mixin.py:115} INFO - [2023-01-05 22:11:01,473] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:11:01,474] {logging_mixin.py:115} INFO - [2023-01-05 22:11:01,473] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:11:01,485] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:11:01,518] {logging_mixin.py:115} INFO - [2023-01-05 22:11:01,518] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:11:01,550] {logging_mixin.py:115} INFO - [2023-01-05 22:11:01,550] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:11:01,573] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.388 seconds
[2023-01-05 22:11:31,652] {processor.py:153} INFO - Started process (PID=1895) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:11:31,653] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:11:31,653] {logging_mixin.py:115} INFO - [2023-01-05 22:11:31,653] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:11:32,569] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:11:32,570] {logging_mixin.py:115} INFO - [2023-01-05 22:11:32,570] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:11:32,571] {logging_mixin.py:115} INFO - [2023-01-05 22:11:32,571] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:11:32,578] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:11:32,602] {logging_mixin.py:115} INFO - [2023-01-05 22:11:32,602] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:11:32,624] {logging_mixin.py:115} INFO - [2023-01-05 22:11:32,624] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:11:32,634] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.988 seconds
[2023-01-05 22:12:02,728] {processor.py:153} INFO - Started process (PID=1918) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:12:02,729] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:12:02,730] {logging_mixin.py:115} INFO - [2023-01-05 22:12:02,730] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:12:03,687] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:12:03,689] {logging_mixin.py:115} INFO - [2023-01-05 22:12:03,689] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:12:03,689] {logging_mixin.py:115} INFO - [2023-01-05 22:12:03,689] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:12:03,696] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:12:03,720] {logging_mixin.py:115} INFO - [2023-01-05 22:12:03,719] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:12:03,741] {logging_mixin.py:115} INFO - [2023-01-05 22:12:03,741] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:12:03,751] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.027 seconds
[2023-01-05 22:12:33,818] {processor.py:153} INFO - Started process (PID=1944) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:12:33,819] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:12:33,820] {logging_mixin.py:115} INFO - [2023-01-05 22:12:33,820] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:12:34,920] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:12:34,921] {logging_mixin.py:115} INFO - [2023-01-05 22:12:34,921] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:12:34,922] {logging_mixin.py:115} INFO - [2023-01-05 22:12:34,921] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:12:34,929] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:12:34,952] {logging_mixin.py:115} INFO - [2023-01-05 22:12:34,952] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:12:34,975] {logging_mixin.py:115} INFO - [2023-01-05 22:12:34,975] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:12:34,985] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.172 seconds
[2023-01-05 22:13:05,065] {processor.py:153} INFO - Started process (PID=1964) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:13:05,068] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:13:05,069] {logging_mixin.py:115} INFO - [2023-01-05 22:13:05,069] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:13:06,030] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:13:06,032] {logging_mixin.py:115} INFO - [2023-01-05 22:13:06,032] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:13:06,032] {logging_mixin.py:115} INFO - [2023-01-05 22:13:06,032] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:13:06,039] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:13:06,070] {logging_mixin.py:115} INFO - [2023-01-05 22:13:06,069] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:13:06,098] {logging_mixin.py:115} INFO - [2023-01-05 22:13:06,098] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:13:06,110] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.050 seconds
[2023-01-05 22:13:36,185] {processor.py:153} INFO - Started process (PID=1990) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:13:36,186] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:13:36,187] {logging_mixin.py:115} INFO - [2023-01-05 22:13:36,187] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:13:37,138] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:13:37,139] {logging_mixin.py:115} INFO - [2023-01-05 22:13:37,139] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:13:37,140] {logging_mixin.py:115} INFO - [2023-01-05 22:13:37,139] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:13:37,147] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:13:37,169] {logging_mixin.py:115} INFO - [2023-01-05 22:13:37,169] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:13:37,190] {logging_mixin.py:115} INFO - [2023-01-05 22:13:37,189] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:13:37,199] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.020 seconds
[2023-01-05 22:14:07,265] {processor.py:153} INFO - Started process (PID=2014) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:14:07,267] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:14:07,267] {logging_mixin.py:115} INFO - [2023-01-05 22:14:07,267] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:14:08,217] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:14:08,219] {logging_mixin.py:115} INFO - [2023-01-05 22:14:08,219] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:14:08,219] {logging_mixin.py:115} INFO - [2023-01-05 22:14:08,219] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:14:08,226] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:14:08,249] {logging_mixin.py:115} INFO - [2023-01-05 22:14:08,249] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:14:08,271] {logging_mixin.py:115} INFO - [2023-01-05 22:14:08,271] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:14:08,282] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.021 seconds
[2023-01-05 22:14:38,359] {processor.py:153} INFO - Started process (PID=2038) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:14:38,360] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:14:38,360] {logging_mixin.py:115} INFO - [2023-01-05 22:14:38,360] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:14:39,359] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:14:39,360] {logging_mixin.py:115} INFO - [2023-01-05 22:14:39,360] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:14:39,361] {logging_mixin.py:115} INFO - [2023-01-05 22:14:39,361] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:14:39,368] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:14:39,393] {logging_mixin.py:115} INFO - [2023-01-05 22:14:39,392] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:14:39,414] {logging_mixin.py:115} INFO - [2023-01-05 22:14:39,414] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:14:39,425] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.072 seconds
[2023-01-05 22:15:09,549] {processor.py:153} INFO - Started process (PID=2056) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:15:09,552] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:15:09,552] {logging_mixin.py:115} INFO - [2023-01-05 22:15:09,552] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:15:10,630] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:15:10,631] {logging_mixin.py:115} INFO - [2023-01-05 22:15:10,631] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:15:10,631] {logging_mixin.py:115} INFO - [2023-01-05 22:15:10,631] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:15:10,638] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:15:10,662] {logging_mixin.py:115} INFO - [2023-01-05 22:15:10,661] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:15:10,683] {logging_mixin.py:115} INFO - [2023-01-05 22:15:10,683] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:15:10,693] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.149 seconds
[2023-01-05 22:15:40,768] {processor.py:153} INFO - Started process (PID=2084) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:15:40,768] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:15:40,769] {logging_mixin.py:115} INFO - [2023-01-05 22:15:40,769] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:15:41,719] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:15:41,720] {logging_mixin.py:115} INFO - [2023-01-05 22:15:41,720] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:15:41,721] {logging_mixin.py:115} INFO - [2023-01-05 22:15:41,720] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:15:41,728] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:15:41,750] {logging_mixin.py:115} INFO - [2023-01-05 22:15:41,750] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:15:41,774] {logging_mixin.py:115} INFO - [2023-01-05 22:15:41,774] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:15:41,787] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.024 seconds
[2023-01-05 22:16:11,855] {processor.py:153} INFO - Started process (PID=2111) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:16:11,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:16:11,856] {logging_mixin.py:115} INFO - [2023-01-05 22:16:11,856] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:16:12,829] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:16:12,830] {logging_mixin.py:115} INFO - [2023-01-05 22:16:12,830] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:16:12,830] {logging_mixin.py:115} INFO - [2023-01-05 22:16:12,830] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:16:12,837] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:16:12,860] {logging_mixin.py:115} INFO - [2023-01-05 22:16:12,860] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:16:12,880] {logging_mixin.py:115} INFO - [2023-01-05 22:16:12,880] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:16:12,890] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.042 seconds
[2023-01-05 22:16:42,944] {processor.py:153} INFO - Started process (PID=2138) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:16:42,947] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:16:42,947] {logging_mixin.py:115} INFO - [2023-01-05 22:16:42,947] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:16:44,326] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:16:44,328] {logging_mixin.py:115} INFO - [2023-01-05 22:16:44,328] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:16:44,329] {logging_mixin.py:115} INFO - [2023-01-05 22:16:44,328] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:16:44,340] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:16:44,372] {logging_mixin.py:115} INFO - [2023-01-05 22:16:44,371] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:16:44,402] {logging_mixin.py:115} INFO - [2023-01-05 22:16:44,402] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:16:44,415] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.477 seconds
[2023-01-05 22:17:14,464] {processor.py:153} INFO - Started process (PID=2156) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:17:14,465] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:17:14,466] {logging_mixin.py:115} INFO - [2023-01-05 22:17:14,466] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:17:15,512] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:17:15,514] {logging_mixin.py:115} INFO - [2023-01-05 22:17:15,514] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:17:15,514] {logging_mixin.py:115} INFO - [2023-01-05 22:17:15,514] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:17:15,521] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:17:15,544] {logging_mixin.py:115} INFO - [2023-01-05 22:17:15,544] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:17:15,565] {logging_mixin.py:115} INFO - [2023-01-05 22:17:15,565] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:17:15,575] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.115 seconds
[2023-01-05 22:17:45,651] {processor.py:153} INFO - Started process (PID=2182) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:17:45,653] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:17:45,654] {logging_mixin.py:115} INFO - [2023-01-05 22:17:45,654] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:17:46,639] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:17:46,641] {logging_mixin.py:115} INFO - [2023-01-05 22:17:46,641] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:17:46,641] {logging_mixin.py:115} INFO - [2023-01-05 22:17:46,641] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:17:46,648] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:17:46,671] {logging_mixin.py:115} INFO - [2023-01-05 22:17:46,670] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:17:46,691] {logging_mixin.py:115} INFO - [2023-01-05 22:17:46,691] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:17:46,701] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.054 seconds
[2023-01-05 22:18:16,745] {processor.py:153} INFO - Started process (PID=2207) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:18:16,746] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:18:16,746] {logging_mixin.py:115} INFO - [2023-01-05 22:18:16,746] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:18:17,940] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:18:17,942] {logging_mixin.py:115} INFO - [2023-01-05 22:18:17,942] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:18:17,942] {logging_mixin.py:115} INFO - [2023-01-05 22:18:17,942] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:18:17,949] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:18:17,972] {logging_mixin.py:115} INFO - [2023-01-05 22:18:17,972] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:18:17,996] {logging_mixin.py:115} INFO - [2023-01-05 22:18:17,996] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:18:18,008] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.270 seconds
[2023-01-05 22:18:48,107] {processor.py:153} INFO - Started process (PID=2232) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:18:48,109] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:18:48,109] {logging_mixin.py:115} INFO - [2023-01-05 22:18:48,109] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:18:49,142] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:18:49,143] {logging_mixin.py:115} INFO - [2023-01-05 22:18:49,143] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:18:49,144] {logging_mixin.py:115} INFO - [2023-01-05 22:18:49,144] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:18:49,154] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:18:49,178] {logging_mixin.py:115} INFO - [2023-01-05 22:18:49,177] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:18:49,199] {logging_mixin.py:115} INFO - [2023-01-05 22:18:49,198] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:18:49,208] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.107 seconds
[2023-01-05 22:19:19,257] {processor.py:153} INFO - Started process (PID=2249) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:19:19,259] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:19:19,260] {logging_mixin.py:115} INFO - [2023-01-05 22:19:19,260] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:19:20,418] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:19:20,420] {logging_mixin.py:115} INFO - [2023-01-05 22:19:20,419] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:19:20,420] {logging_mixin.py:115} INFO - [2023-01-05 22:19:20,420] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:19:20,427] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:19:20,450] {logging_mixin.py:115} INFO - [2023-01-05 22:19:20,450] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:19:20,471] {logging_mixin.py:115} INFO - [2023-01-05 22:19:20,471] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:19:20,482] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.229 seconds
[2023-01-05 22:19:50,560] {processor.py:153} INFO - Started process (PID=2274) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:19:50,561] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:19:50,562] {logging_mixin.py:115} INFO - [2023-01-05 22:19:50,562] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:19:51,733] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:19:51,735] {logging_mixin.py:115} INFO - [2023-01-05 22:19:51,734] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:19:51,735] {logging_mixin.py:115} INFO - [2023-01-05 22:19:51,735] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:19:51,742] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:19:51,766] {logging_mixin.py:115} INFO - [2023-01-05 22:19:51,766] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:19:51,787] {logging_mixin.py:115} INFO - [2023-01-05 22:19:51,787] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:19:51,797] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.244 seconds
[2023-01-05 22:20:21,870] {processor.py:153} INFO - Started process (PID=2298) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:20:21,874] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:20:21,875] {logging_mixin.py:115} INFO - [2023-01-05 22:20:21,875] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:20:22,867] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:20:22,868] {logging_mixin.py:115} INFO - [2023-01-05 22:20:22,868] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:20:22,868] {logging_mixin.py:115} INFO - [2023-01-05 22:20:22,868] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:20:22,876] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:20:22,900] {logging_mixin.py:115} INFO - [2023-01-05 22:20:22,899] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:20:22,922] {logging_mixin.py:115} INFO - [2023-01-05 22:20:22,921] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:20:22,932] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.066 seconds
[2023-01-05 22:20:53,000] {processor.py:153} INFO - Started process (PID=2324) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:20:53,001] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:20:53,001] {logging_mixin.py:115} INFO - [2023-01-05 22:20:53,001] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:20:53,898] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:20:53,899] {logging_mixin.py:115} INFO - [2023-01-05 22:20:53,899] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:20:53,899] {logging_mixin.py:115} INFO - [2023-01-05 22:20:53,899] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:20:53,906] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:20:53,929] {logging_mixin.py:115} INFO - [2023-01-05 22:20:53,929] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:20:53,951] {logging_mixin.py:115} INFO - [2023-01-05 22:20:53,951] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:20:53,961] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.965 seconds
[2023-01-05 22:21:24,031] {processor.py:153} INFO - Started process (PID=2351) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:21:24,032] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:21:24,033] {logging_mixin.py:115} INFO - [2023-01-05 22:21:24,033] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:21:25,423] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:21:25,424] {logging_mixin.py:115} INFO - [2023-01-05 22:21:25,424] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:21:25,425] {logging_mixin.py:115} INFO - [2023-01-05 22:21:25,425] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:21:25,432] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:21:25,456] {logging_mixin.py:115} INFO - [2023-01-05 22:21:25,456] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:21:25,484] {logging_mixin.py:115} INFO - [2023-01-05 22:21:25,484] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:21:25,498] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.472 seconds
[2023-01-05 22:21:55,582] {processor.py:153} INFO - Started process (PID=2369) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:21:55,583] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:21:55,584] {logging_mixin.py:115} INFO - [2023-01-05 22:21:55,584] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:21:56,585] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:21:56,587] {logging_mixin.py:115} INFO - [2023-01-05 22:21:56,587] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:21:56,588] {logging_mixin.py:115} INFO - [2023-01-05 22:21:56,587] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:21:56,598] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:21:56,621] {logging_mixin.py:115} INFO - [2023-01-05 22:21:56,620] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:21:56,641] {logging_mixin.py:115} INFO - [2023-01-05 22:21:56,641] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:21:56,651] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.074 seconds
[2023-01-05 22:22:26,724] {processor.py:153} INFO - Started process (PID=2394) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:22:26,726] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:22:26,726] {logging_mixin.py:115} INFO - [2023-01-05 22:22:26,726] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:22:27,685] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:22:27,686] {logging_mixin.py:115} INFO - [2023-01-05 22:22:27,686] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:22:27,686] {logging_mixin.py:115} INFO - [2023-01-05 22:22:27,686] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:22:27,693] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:22:27,716] {logging_mixin.py:115} INFO - [2023-01-05 22:22:27,716] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:22:27,737] {logging_mixin.py:115} INFO - [2023-01-05 22:22:27,737] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:22:27,747] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.027 seconds
[2023-01-05 22:22:57,809] {processor.py:153} INFO - Started process (PID=2420) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:22:57,810] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:22:57,811] {logging_mixin.py:115} INFO - [2023-01-05 22:22:57,810] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:22:58,740] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:22:58,741] {logging_mixin.py:115} INFO - [2023-01-05 22:22:58,741] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:22:58,742] {logging_mixin.py:115} INFO - [2023-01-05 22:22:58,741] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:22:58,749] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:22:58,771] {logging_mixin.py:115} INFO - [2023-01-05 22:22:58,771] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:22:58,791] {logging_mixin.py:115} INFO - [2023-01-05 22:22:58,791] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:22:58,801] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.997 seconds
[2023-01-05 22:23:28,890] {processor.py:153} INFO - Started process (PID=2438) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:23:28,892] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:23:28,892] {logging_mixin.py:115} INFO - [2023-01-05 22:23:28,892] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:23:29,953] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:23:29,955] {logging_mixin.py:115} INFO - [2023-01-05 22:23:29,955] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:23:29,955] {logging_mixin.py:115} INFO - [2023-01-05 22:23:29,955] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:23:29,962] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:23:29,985] {logging_mixin.py:115} INFO - [2023-01-05 22:23:29,985] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:23:30,006] {logging_mixin.py:115} INFO - [2023-01-05 22:23:30,006] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:23:30,016] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.131 seconds
[2023-01-05 22:24:00,088] {processor.py:153} INFO - Started process (PID=2464) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:24:00,089] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:24:00,089] {logging_mixin.py:115} INFO - [2023-01-05 22:24:00,089] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:24:01,053] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:24:01,054] {logging_mixin.py:115} INFO - [2023-01-05 22:24:01,054] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:24:01,054] {logging_mixin.py:115} INFO - [2023-01-05 22:24:01,054] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:24:01,061] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:24:01,084] {logging_mixin.py:115} INFO - [2023-01-05 22:24:01,083] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:24:01,104] {logging_mixin.py:115} INFO - [2023-01-05 22:24:01,104] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:24:01,114] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.031 seconds
[2023-01-05 22:24:31,173] {processor.py:153} INFO - Started process (PID=2488) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:24:31,174] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:24:31,175] {logging_mixin.py:115} INFO - [2023-01-05 22:24:31,175] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:24:32,153] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:24:32,155] {logging_mixin.py:115} INFO - [2023-01-05 22:24:32,155] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:24:32,155] {logging_mixin.py:115} INFO - [2023-01-05 22:24:32,155] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:24:32,162] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:24:32,184] {logging_mixin.py:115} INFO - [2023-01-05 22:24:32,184] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:24:32,205] {logging_mixin.py:115} INFO - [2023-01-05 22:24:32,205] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:24:32,214] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.048 seconds
[2023-01-05 22:25:02,285] {processor.py:153} INFO - Started process (PID=2513) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:25:02,286] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:25:02,287] {logging_mixin.py:115} INFO - [2023-01-05 22:25:02,287] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:25:03,226] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:25:03,228] {logging_mixin.py:115} INFO - [2023-01-05 22:25:03,228] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:25:03,228] {logging_mixin.py:115} INFO - [2023-01-05 22:25:03,228] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:25:03,235] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:25:03,258] {logging_mixin.py:115} INFO - [2023-01-05 22:25:03,257] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:25:03,278] {logging_mixin.py:115} INFO - [2023-01-05 22:25:03,278] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:25:03,289] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.010 seconds
[2023-01-05 22:25:33,373] {processor.py:153} INFO - Started process (PID=2531) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:25:33,374] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:25:33,374] {logging_mixin.py:115} INFO - [2023-01-05 22:25:33,374] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:25:34,354] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:25:34,355] {logging_mixin.py:115} INFO - [2023-01-05 22:25:34,355] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:25:34,356] {logging_mixin.py:115} INFO - [2023-01-05 22:25:34,355] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:25:34,363] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:25:34,388] {logging_mixin.py:115} INFO - [2023-01-05 22:25:34,388] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:25:34,418] {logging_mixin.py:115} INFO - [2023-01-05 22:25:34,418] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:25:34,431] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.063 seconds
[2023-01-05 22:26:04,537] {processor.py:153} INFO - Started process (PID=2556) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:26:04,538] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:26:04,539] {logging_mixin.py:115} INFO - [2023-01-05 22:26:04,539] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:26:05,450] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:26:05,451] {logging_mixin.py:115} INFO - [2023-01-05 22:26:05,451] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:26:05,452] {logging_mixin.py:115} INFO - [2023-01-05 22:26:05,452] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:26:05,459] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:26:05,481] {logging_mixin.py:115} INFO - [2023-01-05 22:26:05,481] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:26:05,502] {logging_mixin.py:115} INFO - [2023-01-05 22:26:05,502] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:26:05,511] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.979 seconds
[2023-01-05 22:26:35,582] {processor.py:153} INFO - Started process (PID=2581) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:26:35,582] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:26:35,583] {logging_mixin.py:115} INFO - [2023-01-05 22:26:35,583] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:26:36,516] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:26:36,517] {logging_mixin.py:115} INFO - [2023-01-05 22:26:36,517] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:26:36,518] {logging_mixin.py:115} INFO - [2023-01-05 22:26:36,518] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:26:36,525] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:26:36,549] {logging_mixin.py:115} INFO - [2023-01-05 22:26:36,549] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:26:36,570] {logging_mixin.py:115} INFO - [2023-01-05 22:26:36,570] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:26:36,579] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.002 seconds
[2023-01-05 22:27:06,664] {processor.py:153} INFO - Started process (PID=2606) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:27:06,665] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:27:06,666] {logging_mixin.py:115} INFO - [2023-01-05 22:27:06,666] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:27:07,827] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:27:07,828] {logging_mixin.py:115} INFO - [2023-01-05 22:27:07,828] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:27:07,829] {logging_mixin.py:115} INFO - [2023-01-05 22:27:07,829] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:27:07,836] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:27:07,858] {logging_mixin.py:115} INFO - [2023-01-05 22:27:07,858] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:27:07,879] {logging_mixin.py:115} INFO - [2023-01-05 22:27:07,879] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:27:07,889] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.230 seconds
[2023-01-05 22:27:37,962] {processor.py:153} INFO - Started process (PID=2625) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:27:37,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:27:37,963] {logging_mixin.py:115} INFO - [2023-01-05 22:27:37,963] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:27:38,916] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:27:38,917] {logging_mixin.py:115} INFO - [2023-01-05 22:27:38,917] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:27:38,917] {logging_mixin.py:115} INFO - [2023-01-05 22:27:38,917] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:27:38,924] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:27:38,948] {logging_mixin.py:115} INFO - [2023-01-05 22:27:38,948] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:27:38,970] {logging_mixin.py:115} INFO - [2023-01-05 22:27:38,970] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:27:38,980] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.025 seconds
[2023-01-05 22:28:09,041] {processor.py:153} INFO - Started process (PID=2649) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:28:09,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:28:09,042] {logging_mixin.py:115} INFO - [2023-01-05 22:28:09,042] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:28:10,019] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:28:10,020] {logging_mixin.py:115} INFO - [2023-01-05 22:28:10,020] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:28:10,021] {logging_mixin.py:115} INFO - [2023-01-05 22:28:10,020] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:28:10,028] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:28:10,052] {logging_mixin.py:115} INFO - [2023-01-05 22:28:10,052] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:28:10,074] {logging_mixin.py:115} INFO - [2023-01-05 22:28:10,073] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:28:10,084] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.047 seconds
[2023-01-05 22:28:40,129] {processor.py:153} INFO - Started process (PID=2676) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:28:40,129] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:28:40,130] {logging_mixin.py:115} INFO - [2023-01-05 22:28:40,130] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:28:41,292] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:28:41,293] {logging_mixin.py:115} INFO - [2023-01-05 22:28:41,293] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:28:41,294] {logging_mixin.py:115} INFO - [2023-01-05 22:28:41,293] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:28:41,301] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:28:41,324] {logging_mixin.py:115} INFO - [2023-01-05 22:28:41,324] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:28:41,346] {logging_mixin.py:115} INFO - [2023-01-05 22:28:41,345] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:28:41,356] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.233 seconds
[2023-01-05 22:29:11,431] {processor.py:153} INFO - Started process (PID=2700) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:29:11,432] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:29:11,433] {logging_mixin.py:115} INFO - [2023-01-05 22:29:11,433] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:29:12,386] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:29:12,387] {logging_mixin.py:115} INFO - [2023-01-05 22:29:12,387] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:29:12,388] {logging_mixin.py:115} INFO - [2023-01-05 22:29:12,387] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:29:12,394] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:29:12,418] {logging_mixin.py:115} INFO - [2023-01-05 22:29:12,417] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:29:12,439] {logging_mixin.py:115} INFO - [2023-01-05 22:29:12,438] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:29:12,451] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.026 seconds
[2023-01-05 22:29:42,555] {processor.py:153} INFO - Started process (PID=2717) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:29:42,557] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:29:42,558] {logging_mixin.py:115} INFO - [2023-01-05 22:29:42,557] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:29:43,556] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:29:43,557] {logging_mixin.py:115} INFO - [2023-01-05 22:29:43,557] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:29:43,558] {logging_mixin.py:115} INFO - [2023-01-05 22:29:43,557] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:29:43,568] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:29:43,592] {logging_mixin.py:115} INFO - [2023-01-05 22:29:43,591] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:29:43,621] {logging_mixin.py:115} INFO - [2023-01-05 22:29:43,621] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:29:43,631] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.081 seconds
[2023-01-05 22:30:13,691] {processor.py:153} INFO - Started process (PID=2743) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:30:13,691] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:30:13,692] {logging_mixin.py:115} INFO - [2023-01-05 22:30:13,692] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:30:14,832] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:30:14,833] {logging_mixin.py:115} INFO - [2023-01-05 22:30:14,833] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:30:14,834] {logging_mixin.py:115} INFO - [2023-01-05 22:30:14,834] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:30:14,841] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:30:14,863] {logging_mixin.py:115} INFO - [2023-01-05 22:30:14,863] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:30:14,891] {logging_mixin.py:115} INFO - [2023-01-05 22:30:14,890] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:30:14,903] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.218 seconds
[2023-01-05 22:30:44,976] {processor.py:153} INFO - Started process (PID=2769) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:30:44,977] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:30:44,978] {logging_mixin.py:115} INFO - [2023-01-05 22:30:44,978] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:30:45,914] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:30:45,916] {logging_mixin.py:115} INFO - [2023-01-05 22:30:45,916] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:30:45,916] {logging_mixin.py:115} INFO - [2023-01-05 22:30:45,916] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:30:45,923] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:30:45,947] {logging_mixin.py:115} INFO - [2023-01-05 22:30:45,946] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:30:45,968] {logging_mixin.py:115} INFO - [2023-01-05 22:30:45,968] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:30:45,978] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.007 seconds
[2023-01-05 22:31:16,060] {processor.py:153} INFO - Started process (PID=2793) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:31:16,060] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:31:16,061] {logging_mixin.py:115} INFO - [2023-01-05 22:31:16,061] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:31:17,040] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:31:17,041] {logging_mixin.py:115} INFO - [2023-01-05 22:31:17,041] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:31:17,042] {logging_mixin.py:115} INFO - [2023-01-05 22:31:17,042] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:31:17,049] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:31:17,071] {logging_mixin.py:115} INFO - [2023-01-05 22:31:17,071] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:31:17,092] {logging_mixin.py:115} INFO - [2023-01-05 22:31:17,092] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:31:17,102] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.047 seconds
[2023-01-05 22:31:47,202] {processor.py:153} INFO - Started process (PID=2810) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:31:47,204] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:31:47,204] {logging_mixin.py:115} INFO - [2023-01-05 22:31:47,204] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:31:48,161] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:31:48,163] {logging_mixin.py:115} INFO - [2023-01-05 22:31:48,163] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:31:48,163] {logging_mixin.py:115} INFO - [2023-01-05 22:31:48,163] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:31:48,175] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:31:48,208] {logging_mixin.py:115} INFO - [2023-01-05 22:31:48,207] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:31:48,237] {logging_mixin.py:115} INFO - [2023-01-05 22:31:48,237] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:31:48,250] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.052 seconds
[2023-01-05 22:32:18,359] {processor.py:153} INFO - Started process (PID=2837) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:32:18,360] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:32:18,361] {logging_mixin.py:115} INFO - [2023-01-05 22:32:18,361] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:32:19,279] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:32:19,280] {logging_mixin.py:115} INFO - [2023-01-05 22:32:19,280] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:32:19,281] {logging_mixin.py:115} INFO - [2023-01-05 22:32:19,281] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:32:19,288] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:32:19,314] {logging_mixin.py:115} INFO - [2023-01-05 22:32:19,314] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:32:19,337] {logging_mixin.py:115} INFO - [2023-01-05 22:32:19,337] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:32:19,347] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.993 seconds
[2023-01-05 22:32:49,453] {processor.py:153} INFO - Started process (PID=2864) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:32:49,453] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:32:49,454] {logging_mixin.py:115} INFO - [2023-01-05 22:32:49,454] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:32:50,389] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:32:50,390] {logging_mixin.py:115} INFO - [2023-01-05 22:32:50,390] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:32:50,391] {logging_mixin.py:115} INFO - [2023-01-05 22:32:50,390] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:32:50,397] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:32:50,421] {logging_mixin.py:115} INFO - [2023-01-05 22:32:50,420] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:32:50,443] {logging_mixin.py:115} INFO - [2023-01-05 22:32:50,443] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:32:50,453] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.005 seconds
[2023-01-05 22:33:20,559] {processor.py:153} INFO - Started process (PID=2889) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:33:20,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:33:20,561] {logging_mixin.py:115} INFO - [2023-01-05 22:33:20,561] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:33:22,045] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:33:22,046] {logging_mixin.py:115} INFO - [2023-01-05 22:33:22,046] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:33:22,047] {logging_mixin.py:115} INFO - [2023-01-05 22:33:22,047] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:33:22,054] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:33:22,077] {logging_mixin.py:115} INFO - [2023-01-05 22:33:22,076] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:33:22,097] {logging_mixin.py:115} INFO - [2023-01-05 22:33:22,097] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:33:22,107] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.555 seconds
[2023-01-05 22:33:52,181] {processor.py:153} INFO - Started process (PID=2908) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:33:52,182] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:33:52,183] {logging_mixin.py:115} INFO - [2023-01-05 22:33:52,182] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:33:53,147] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:33:53,149] {logging_mixin.py:115} INFO - [2023-01-05 22:33:53,149] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:33:53,149] {logging_mixin.py:115} INFO - [2023-01-05 22:33:53,149] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:33:53,156] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:33:53,182] {logging_mixin.py:115} INFO - [2023-01-05 22:33:53,182] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:33:53,207] {logging_mixin.py:115} INFO - [2023-01-05 22:33:53,207] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:33:53,217] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.043 seconds
[2023-01-05 22:34:23,287] {processor.py:153} INFO - Started process (PID=2935) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:34:23,288] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:34:23,288] {logging_mixin.py:115} INFO - [2023-01-05 22:34:23,288] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:34:24,250] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:34:24,252] {logging_mixin.py:115} INFO - [2023-01-05 22:34:24,252] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:34:24,252] {logging_mixin.py:115} INFO - [2023-01-05 22:34:24,252] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:34:24,259] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:34:24,282] {logging_mixin.py:115} INFO - [2023-01-05 22:34:24,281] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:34:24,302] {logging_mixin.py:115} INFO - [2023-01-05 22:34:24,302] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:34:24,312] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.030 seconds
[2023-01-05 22:34:54,375] {processor.py:153} INFO - Started process (PID=2958) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:34:54,378] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:34:54,378] {logging_mixin.py:115} INFO - [2023-01-05 22:34:54,378] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:34:55,313] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:34:55,314] {logging_mixin.py:115} INFO - [2023-01-05 22:34:55,314] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:34:55,315] {logging_mixin.py:115} INFO - [2023-01-05 22:34:55,314] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:34:55,322] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:34:55,345] {logging_mixin.py:115} INFO - [2023-01-05 22:34:55,345] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:34:55,367] {logging_mixin.py:115} INFO - [2023-01-05 22:34:55,367] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:34:55,377] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.006 seconds
[2023-01-05 22:35:25,474] {processor.py:153} INFO - Started process (PID=2984) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:35:25,475] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:35:25,476] {logging_mixin.py:115} INFO - [2023-01-05 22:35:25,476] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:35:26,583] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:35:26,584] {logging_mixin.py:115} INFO - [2023-01-05 22:35:26,584] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:35:26,585] {logging_mixin.py:115} INFO - [2023-01-05 22:35:26,584] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:35:26,592] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:35:26,615] {logging_mixin.py:115} INFO - [2023-01-05 22:35:26,615] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:35:26,637] {logging_mixin.py:115} INFO - [2023-01-05 22:35:26,637] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:35:26,648] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.179 seconds
[2023-01-05 22:35:56,721] {processor.py:153} INFO - Started process (PID=3003) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:35:56,722] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:35:56,723] {logging_mixin.py:115} INFO - [2023-01-05 22:35:56,723] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:35:57,651] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:35:57,652] {logging_mixin.py:115} INFO - [2023-01-05 22:35:57,652] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:35:57,653] {logging_mixin.py:115} INFO - [2023-01-05 22:35:57,653] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:35:57,660] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:35:57,683] {logging_mixin.py:115} INFO - [2023-01-05 22:35:57,683] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:35:57,704] {logging_mixin.py:115} INFO - [2023-01-05 22:35:57,704] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:35:57,714] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.999 seconds
[2023-01-05 22:36:27,800] {processor.py:153} INFO - Started process (PID=3028) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:36:27,801] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:36:27,802] {logging_mixin.py:115} INFO - [2023-01-05 22:36:27,802] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:36:28,783] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:36:28,785] {logging_mixin.py:115} INFO - [2023-01-05 22:36:28,785] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:36:28,785] {logging_mixin.py:115} INFO - [2023-01-05 22:36:28,785] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:36:28,792] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:36:28,816] {logging_mixin.py:115} INFO - [2023-01-05 22:36:28,816] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:36:28,840] {logging_mixin.py:115} INFO - [2023-01-05 22:36:28,840] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:36:28,852] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.057 seconds
[2023-01-05 22:36:58,949] {processor.py:153} INFO - Started process (PID=3052) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:36:58,951] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:36:58,952] {logging_mixin.py:115} INFO - [2023-01-05 22:36:58,951] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:36:59,920] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:36:59,921] {logging_mixin.py:115} INFO - [2023-01-05 22:36:59,921] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:36:59,922] {logging_mixin.py:115} INFO - [2023-01-05 22:36:59,921] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:36:59,929] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:36:59,954] {logging_mixin.py:115} INFO - [2023-01-05 22:36:59,953] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:36:59,976] {logging_mixin.py:115} INFO - [2023-01-05 22:36:59,976] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:36:59,987] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.044 seconds
[2023-01-05 22:37:30,061] {processor.py:153} INFO - Started process (PID=3080) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:37:30,061] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:37:30,062] {logging_mixin.py:115} INFO - [2023-01-05 22:37:30,062] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:37:31,101] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:37:31,103] {logging_mixin.py:115} INFO - [2023-01-05 22:37:31,103] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:37:31,104] {logging_mixin.py:115} INFO - [2023-01-05 22:37:31,103] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:37:31,115] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:37:31,139] {logging_mixin.py:115} INFO - [2023-01-05 22:37:31,139] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:37:31,160] {logging_mixin.py:115} INFO - [2023-01-05 22:37:31,160] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:37:31,170] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.115 seconds
[2023-01-05 22:38:01,251] {processor.py:153} INFO - Started process (PID=3099) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:38:01,252] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:38:01,253] {logging_mixin.py:115} INFO - [2023-01-05 22:38:01,253] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:38:02,157] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:38:02,159] {logging_mixin.py:115} INFO - [2023-01-05 22:38:02,159] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:38:02,159] {logging_mixin.py:115} INFO - [2023-01-05 22:38:02,159] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:38:02,166] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:38:02,189] {logging_mixin.py:115} INFO - [2023-01-05 22:38:02,189] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:38:02,210] {logging_mixin.py:115} INFO - [2023-01-05 22:38:02,210] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:38:02,220] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.975 seconds
[2023-01-05 22:38:32,325] {processor.py:153} INFO - Started process (PID=3126) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:38:32,328] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:38:32,329] {logging_mixin.py:115} INFO - [2023-01-05 22:38:32,329] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:38:33,250] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:38:33,251] {logging_mixin.py:115} INFO - [2023-01-05 22:38:33,251] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:38:33,252] {logging_mixin.py:115} INFO - [2023-01-05 22:38:33,252] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:38:33,259] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:38:33,282] {logging_mixin.py:115} INFO - [2023-01-05 22:38:33,282] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:38:33,304] {logging_mixin.py:115} INFO - [2023-01-05 22:38:33,304] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:38:33,315] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-05 22:39:03,402] {processor.py:153} INFO - Started process (PID=3150) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:39:03,403] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:39:03,403] {logging_mixin.py:115} INFO - [2023-01-05 22:39:03,403] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:39:04,374] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:39:04,375] {logging_mixin.py:115} INFO - [2023-01-05 22:39:04,375] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:39:04,376] {logging_mixin.py:115} INFO - [2023-01-05 22:39:04,375] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:39:04,383] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:39:04,409] {logging_mixin.py:115} INFO - [2023-01-05 22:39:04,408] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:39:04,434] {logging_mixin.py:115} INFO - [2023-01-05 22:39:04,434] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:39:04,446] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.050 seconds
[2023-01-05 22:39:34,518] {processor.py:153} INFO - Started process (PID=3175) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:39:34,520] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:39:34,521] {logging_mixin.py:115} INFO - [2023-01-05 22:39:34,520] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:39:35,434] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:39:35,435] {logging_mixin.py:115} INFO - [2023-01-05 22:39:35,435] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:39:35,436] {logging_mixin.py:115} INFO - [2023-01-05 22:39:35,435] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:39:35,443] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:39:35,467] {logging_mixin.py:115} INFO - [2023-01-05 22:39:35,467] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:39:35,488] {logging_mixin.py:115} INFO - [2023-01-05 22:39:35,488] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:39:35,497] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.985 seconds
[2023-01-05 22:40:05,609] {processor.py:153} INFO - Started process (PID=3192) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:40:05,610] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:40:05,610] {logging_mixin.py:115} INFO - [2023-01-05 22:40:05,610] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:40:06,508] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:40:06,510] {logging_mixin.py:115} INFO - [2023-01-05 22:40:06,510] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:40:06,511] {logging_mixin.py:115} INFO - [2023-01-05 22:40:06,510] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:40:06,518] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:40:06,552] {logging_mixin.py:115} INFO - [2023-01-05 22:40:06,551] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:40:06,575] {logging_mixin.py:115} INFO - [2023-01-05 22:40:06,575] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:40:06,586] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.982 seconds
[2023-01-05 22:40:36,684] {processor.py:153} INFO - Started process (PID=3217) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:40:36,686] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:40:36,687] {logging_mixin.py:115} INFO - [2023-01-05 22:40:36,687] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:40:37,701] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:40:37,702] {logging_mixin.py:115} INFO - [2023-01-05 22:40:37,702] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:40:37,703] {logging_mixin.py:115} INFO - [2023-01-05 22:40:37,703] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:40:37,710] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:40:37,741] {logging_mixin.py:115} INFO - [2023-01-05 22:40:37,741] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:40:37,764] {logging_mixin.py:115} INFO - [2023-01-05 22:40:37,764] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:40:37,774] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.094 seconds
[2023-01-05 22:41:07,852] {processor.py:153} INFO - Started process (PID=3243) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:41:07,853] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:41:07,854] {logging_mixin.py:115} INFO - [2023-01-05 22:41:07,854] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:41:08,806] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:41:08,807] {logging_mixin.py:115} INFO - [2023-01-05 22:41:08,807] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:41:08,808] {logging_mixin.py:115} INFO - [2023-01-05 22:41:08,807] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:41:08,815] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:41:08,838] {logging_mixin.py:115} INFO - [2023-01-05 22:41:08,837] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:41:08,858] {logging_mixin.py:115} INFO - [2023-01-05 22:41:08,858] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:41:08,868] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.022 seconds
[2023-01-05 22:41:38,916] {processor.py:153} INFO - Started process (PID=3268) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:41:38,917] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:41:38,918] {logging_mixin.py:115} INFO - [2023-01-05 22:41:38,918] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:41:39,845] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:41:39,847] {logging_mixin.py:115} INFO - [2023-01-05 22:41:39,847] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:41:39,847] {logging_mixin.py:115} INFO - [2023-01-05 22:41:39,847] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:41:39,854] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:41:39,877] {logging_mixin.py:115} INFO - [2023-01-05 22:41:39,877] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:41:39,900] {logging_mixin.py:115} INFO - [2023-01-05 22:41:39,900] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:41:39,910] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.998 seconds
[2023-01-05 22:42:09,943] {processor.py:153} INFO - Started process (PID=3287) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:42:09,944] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:42:09,945] {logging_mixin.py:115} INFO - [2023-01-05 22:42:09,945] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:42:10,886] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:42:10,887] {logging_mixin.py:115} INFO - [2023-01-05 22:42:10,887] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:42:10,888] {logging_mixin.py:115} INFO - [2023-01-05 22:42:10,887] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:42:10,895] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:42:10,925] {logging_mixin.py:115} INFO - [2023-01-05 22:42:10,925] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:42:10,956] {logging_mixin.py:115} INFO - [2023-01-05 22:42:10,955] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:42:10,968] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.030 seconds
[2023-01-05 22:42:41,019] {processor.py:153} INFO - Started process (PID=3312) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:42:41,020] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:42:41,021] {logging_mixin.py:115} INFO - [2023-01-05 22:42:41,021] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:42:41,948] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:42:41,949] {logging_mixin.py:115} INFO - [2023-01-05 22:42:41,949] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:42:41,950] {logging_mixin.py:115} INFO - [2023-01-05 22:42:41,949] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:42:41,957] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:42:41,979] {logging_mixin.py:115} INFO - [2023-01-05 22:42:41,979] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:42:42,000] {logging_mixin.py:115} INFO - [2023-01-05 22:42:42,000] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:42:42,010] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.997 seconds
[2023-01-05 22:43:12,091] {processor.py:153} INFO - Started process (PID=3338) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:43:12,093] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:43:12,094] {logging_mixin.py:115} INFO - [2023-01-05 22:43:12,094] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:43:13,029] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:43:13,030] {logging_mixin.py:115} INFO - [2023-01-05 22:43:13,030] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:43:13,031] {logging_mixin.py:115} INFO - [2023-01-05 22:43:13,030] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:43:13,038] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:43:13,062] {logging_mixin.py:115} INFO - [2023-01-05 22:43:13,061] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:43:13,083] {logging_mixin.py:115} INFO - [2023-01-05 22:43:13,083] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:43:13,094] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.008 seconds
[2023-01-05 22:43:43,132] {processor.py:153} INFO - Started process (PID=3363) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:43:43,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:43:43,134] {logging_mixin.py:115} INFO - [2023-01-05 22:43:43,134] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:43:44,167] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:43:44,168] {logging_mixin.py:115} INFO - [2023-01-05 22:43:44,168] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:43:44,169] {logging_mixin.py:115} INFO - [2023-01-05 22:43:44,168] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:43:44,176] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:43:44,200] {logging_mixin.py:115} INFO - [2023-01-05 22:43:44,200] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:43:44,222] {logging_mixin.py:115} INFO - [2023-01-05 22:43:44,222] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:43:44,232] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.105 seconds
[2023-01-05 22:44:14,311] {processor.py:153} INFO - Started process (PID=3382) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:44:14,312] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:44:14,313] {logging_mixin.py:115} INFO - [2023-01-05 22:44:14,313] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:44:15,238] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:44:15,239] {logging_mixin.py:115} INFO - [2023-01-05 22:44:15,239] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:44:15,240] {logging_mixin.py:115} INFO - [2023-01-05 22:44:15,239] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:44:15,247] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:44:15,271] {logging_mixin.py:115} INFO - [2023-01-05 22:44:15,271] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:44:15,294] {logging_mixin.py:115} INFO - [2023-01-05 22:44:15,294] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:44:15,305] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.999 seconds
[2023-01-05 22:44:45,385] {processor.py:153} INFO - Started process (PID=3409) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:44:45,386] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:44:45,387] {logging_mixin.py:115} INFO - [2023-01-05 22:44:45,387] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:44:46,309] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:44:46,311] {logging_mixin.py:115} INFO - [2023-01-05 22:44:46,311] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:44:46,311] {logging_mixin.py:115} INFO - [2023-01-05 22:44:46,311] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:44:46,318] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:44:46,343] {logging_mixin.py:115} INFO - [2023-01-05 22:44:46,342] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:44:46,364] {logging_mixin.py:115} INFO - [2023-01-05 22:44:46,364] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:44:46,374] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.994 seconds
[2023-01-05 22:45:16,481] {processor.py:153} INFO - Started process (PID=3434) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:45:16,482] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:45:16,483] {logging_mixin.py:115} INFO - [2023-01-05 22:45:16,482] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:45:17,418] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:45:17,420] {logging_mixin.py:115} INFO - [2023-01-05 22:45:17,420] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:45:17,421] {logging_mixin.py:115} INFO - [2023-01-05 22:45:17,420] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:45:17,428] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:45:17,451] {logging_mixin.py:115} INFO - [2023-01-05 22:45:17,451] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:45:17,472] {logging_mixin.py:115} INFO - [2023-01-05 22:45:17,472] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:45:17,481] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.006 seconds
[2023-01-05 22:45:47,531] {processor.py:153} INFO - Started process (PID=3460) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:45:47,533] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:45:47,534] {logging_mixin.py:115} INFO - [2023-01-05 22:45:47,534] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:45:48,527] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:45:48,528] {logging_mixin.py:115} INFO - [2023-01-05 22:45:48,528] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:45:48,529] {logging_mixin.py:115} INFO - [2023-01-05 22:45:48,529] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:45:48,536] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:45:48,560] {logging_mixin.py:115} INFO - [2023-01-05 22:45:48,560] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:45:48,582] {logging_mixin.py:115} INFO - [2023-01-05 22:45:48,582] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:45:48,591] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.066 seconds
[2023-01-05 22:46:18,663] {processor.py:153} INFO - Started process (PID=3477) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:46:18,664] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:46:18,665] {logging_mixin.py:115} INFO - [2023-01-05 22:46:18,665] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:46:19,567] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:46:19,568] {logging_mixin.py:115} INFO - [2023-01-05 22:46:19,568] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:46:19,569] {logging_mixin.py:115} INFO - [2023-01-05 22:46:19,568] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:46:19,576] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:46:19,599] {logging_mixin.py:115} INFO - [2023-01-05 22:46:19,598] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:46:19,620] {logging_mixin.py:115} INFO - [2023-01-05 22:46:19,619] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:46:19,629] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.972 seconds
[2023-01-05 22:46:49,699] {processor.py:153} INFO - Started process (PID=3501) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:46:49,699] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:46:49,700] {logging_mixin.py:115} INFO - [2023-01-05 22:46:49,700] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:46:50,637] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:46:50,639] {logging_mixin.py:115} INFO - [2023-01-05 22:46:50,639] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:46:50,639] {logging_mixin.py:115} INFO - [2023-01-05 22:46:50,639] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:46:50,646] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:46:50,669] {logging_mixin.py:115} INFO - [2023-01-05 22:46:50,669] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:46:50,692] {logging_mixin.py:115} INFO - [2023-01-05 22:46:50,692] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:46:50,702] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.008 seconds
[2023-01-05 22:47:20,772] {processor.py:153} INFO - Started process (PID=3527) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:47:20,773] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:47:20,774] {logging_mixin.py:115} INFO - [2023-01-05 22:47:20,774] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:47:21,699] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:47:21,700] {logging_mixin.py:115} INFO - [2023-01-05 22:47:21,700] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:47:21,701] {logging_mixin.py:115} INFO - [2023-01-05 22:47:21,700] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:47:21,708] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:47:21,740] {logging_mixin.py:115} INFO - [2023-01-05 22:47:21,740] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:47:21,763] {logging_mixin.py:115} INFO - [2023-01-05 22:47:21,763] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:47:21,773] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.006 seconds
[2023-01-05 22:47:51,808] {processor.py:153} INFO - Started process (PID=3553) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:47:51,812] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:47:51,813] {logging_mixin.py:115} INFO - [2023-01-05 22:47:51,813] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:47:52,816] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:47:52,817] {logging_mixin.py:115} INFO - [2023-01-05 22:47:52,817] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:47:52,818] {logging_mixin.py:115} INFO - [2023-01-05 22:47:52,817] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:47:52,825] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:47:52,848] {logging_mixin.py:115} INFO - [2023-01-05 22:47:52,848] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:47:52,869] {logging_mixin.py:115} INFO - [2023-01-05 22:47:52,869] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:47:52,878] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.075 seconds
[2023-01-05 22:48:22,913] {processor.py:153} INFO - Started process (PID=3571) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:48:22,916] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:48:22,917] {logging_mixin.py:115} INFO - [2023-01-05 22:48:22,917] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:48:23,849] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:48:23,850] {logging_mixin.py:115} INFO - [2023-01-05 22:48:23,850] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:48:23,851] {logging_mixin.py:115} INFO - [2023-01-05 22:48:23,851] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:48:23,858] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:48:23,882] {logging_mixin.py:115} INFO - [2023-01-05 22:48:23,882] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:48:23,904] {logging_mixin.py:115} INFO - [2023-01-05 22:48:23,904] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:48:23,915] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.007 seconds
[2023-01-05 22:48:54,010] {processor.py:153} INFO - Started process (PID=3597) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:48:54,011] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:48:54,012] {logging_mixin.py:115} INFO - [2023-01-05 22:48:54,012] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:48:54,937] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:48:54,938] {logging_mixin.py:115} INFO - [2023-01-05 22:48:54,938] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:48:54,939] {logging_mixin.py:115} INFO - [2023-01-05 22:48:54,938] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:48:54,945] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:48:54,970] {logging_mixin.py:115} INFO - [2023-01-05 22:48:54,969] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:48:54,991] {logging_mixin.py:115} INFO - [2023-01-05 22:48:54,991] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:48:55,001] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-05 22:49:25,084] {processor.py:153} INFO - Started process (PID=3622) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:49:25,090] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:49:25,091] {logging_mixin.py:115} INFO - [2023-01-05 22:49:25,091] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:49:26,167] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:49:26,168] {logging_mixin.py:115} INFO - [2023-01-05 22:49:26,168] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:49:26,169] {logging_mixin.py:115} INFO - [2023-01-05 22:49:26,169] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:49:26,176] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:49:26,200] {logging_mixin.py:115} INFO - [2023-01-05 22:49:26,200] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:49:26,222] {logging_mixin.py:115} INFO - [2023-01-05 22:49:26,222] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:49:26,232] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.154 seconds
[2023-01-05 22:49:56,306] {processor.py:153} INFO - Started process (PID=3649) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:49:56,307] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:49:56,308] {logging_mixin.py:115} INFO - [2023-01-05 22:49:56,308] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:49:57,252] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:49:57,253] {logging_mixin.py:115} INFO - [2023-01-05 22:49:57,253] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:49:57,254] {logging_mixin.py:115} INFO - [2023-01-05 22:49:57,253] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:49:57,261] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:49:57,283] {logging_mixin.py:115} INFO - [2023-01-05 22:49:57,283] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:49:57,304] {logging_mixin.py:115} INFO - [2023-01-05 22:49:57,304] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:49:57,314] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.013 seconds
[2023-01-05 22:50:27,396] {processor.py:153} INFO - Started process (PID=3667) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:50:27,398] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:50:27,398] {logging_mixin.py:115} INFO - [2023-01-05 22:50:27,398] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:50:28,328] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:50:28,329] {logging_mixin.py:115} INFO - [2023-01-05 22:50:28,329] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:50:28,330] {logging_mixin.py:115} INFO - [2023-01-05 22:50:28,329] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:50:28,337] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:50:28,360] {logging_mixin.py:115} INFO - [2023-01-05 22:50:28,359] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:50:28,382] {logging_mixin.py:115} INFO - [2023-01-05 22:50:28,382] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:50:28,393] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.001 seconds
[2023-01-05 22:50:58,468] {processor.py:153} INFO - Started process (PID=3692) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:50:58,469] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:50:58,470] {logging_mixin.py:115} INFO - [2023-01-05 22:50:58,470] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:50:59,415] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:50:59,416] {logging_mixin.py:115} INFO - [2023-01-05 22:50:59,416] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:50:59,417] {logging_mixin.py:115} INFO - [2023-01-05 22:50:59,416] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:50:59,424] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:50:59,448] {logging_mixin.py:115} INFO - [2023-01-05 22:50:59,447] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:50:59,469] {logging_mixin.py:115} INFO - [2023-01-05 22:50:59,469] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:50:59,479] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.017 seconds
[2023-01-05 22:51:29,554] {processor.py:153} INFO - Started process (PID=3717) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:51:29,554] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:51:29,555] {logging_mixin.py:115} INFO - [2023-01-05 22:51:29,555] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:51:30,471] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:51:30,472] {logging_mixin.py:115} INFO - [2023-01-05 22:51:30,472] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:51:30,473] {logging_mixin.py:115} INFO - [2023-01-05 22:51:30,472] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:51:30,480] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:51:30,503] {logging_mixin.py:115} INFO - [2023-01-05 22:51:30,502] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:51:30,524] {logging_mixin.py:115} INFO - [2023-01-05 22:51:30,524] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:51:30,534] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.985 seconds
[2023-01-05 22:52:00,565] {processor.py:153} INFO - Started process (PID=3741) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:52:00,566] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:52:00,567] {logging_mixin.py:115} INFO - [2023-01-05 22:52:00,567] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:52:01,547] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:52:01,548] {logging_mixin.py:115} INFO - [2023-01-05 22:52:01,548] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:52:01,549] {logging_mixin.py:115} INFO - [2023-01-05 22:52:01,549] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:52:01,556] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:52:01,583] {logging_mixin.py:115} INFO - [2023-01-05 22:52:01,582] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:52:01,607] {logging_mixin.py:115} INFO - [2023-01-05 22:52:01,607] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:52:01,618] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.058 seconds
[2023-01-05 22:52:31,695] {processor.py:153} INFO - Started process (PID=3759) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:52:31,695] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:52:31,696] {logging_mixin.py:115} INFO - [2023-01-05 22:52:31,696] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:52:32,658] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:52:32,659] {logging_mixin.py:115} INFO - [2023-01-05 22:52:32,659] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:52:32,660] {logging_mixin.py:115} INFO - [2023-01-05 22:52:32,659] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:52:32,667] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:52:32,689] {logging_mixin.py:115} INFO - [2023-01-05 22:52:32,689] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:52:32,710] {logging_mixin.py:115} INFO - [2023-01-05 22:52:32,710] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:52:32,720] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.030 seconds
[2023-01-05 22:53:02,792] {processor.py:153} INFO - Started process (PID=3785) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:53:02,794] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:53:02,795] {logging_mixin.py:115} INFO - [2023-01-05 22:53:02,795] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:53:03,709] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:53:03,710] {logging_mixin.py:115} INFO - [2023-01-05 22:53:03,710] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:53:03,711] {logging_mixin.py:115} INFO - [2023-01-05 22:53:03,710] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:53:03,717] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:53:03,740] {logging_mixin.py:115} INFO - [2023-01-05 22:53:03,740] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:53:03,761] {logging_mixin.py:115} INFO - [2023-01-05 22:53:03,760] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:53:03,770] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.983 seconds
[2023-01-05 22:53:33,845] {processor.py:153} INFO - Started process (PID=3811) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:53:33,845] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:53:33,846] {logging_mixin.py:115} INFO - [2023-01-05 22:53:33,846] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:53:34,778] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:53:34,779] {logging_mixin.py:115} INFO - [2023-01-05 22:53:34,779] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:53:34,780] {logging_mixin.py:115} INFO - [2023-01-05 22:53:34,779] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:53:34,787] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:53:34,809] {logging_mixin.py:115} INFO - [2023-01-05 22:53:34,809] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:53:34,830] {logging_mixin.py:115} INFO - [2023-01-05 22:53:34,830] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:00:00+00:00, run_after=2023-01-06T23:00:00+00:00
[2023-01-05 22:53:34,839] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.000 seconds
[2023-01-05 22:54:00,858] {processor.py:153} INFO - Started process (PID=3829) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:54:00,859] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:54:00,860] {logging_mixin.py:115} INFO - [2023-01-05 22:54:00,860] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:54:01,823] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:54:01,824] {logging_mixin.py:115} INFO - [2023-01-05 22:54:01,824] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:54:01,825] {logging_mixin.py:115} INFO - [2023-01-05 22:54:01,824] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:54:01,832] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:54:01,890] {logging_mixin.py:115} INFO - [2023-01-05 22:54:01,890] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:54:01,912] {logging_mixin.py:115} INFO - [2023-01-05 22:54:01,912] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 22:54:01,928] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.075 seconds
[2023-01-05 22:54:32,019] {processor.py:153} INFO - Started process (PID=3854) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:54:32,020] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:54:32,021] {logging_mixin.py:115} INFO - [2023-01-05 22:54:32,021] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:54:32,939] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:54:32,941] {logging_mixin.py:115} INFO - [2023-01-05 22:54:32,940] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:54:32,941] {logging_mixin.py:115} INFO - [2023-01-05 22:54:32,941] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:54:32,952] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:54:32,977] {logging_mixin.py:115} INFO - [2023-01-05 22:54:32,976] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:54:32,998] {logging_mixin.py:115} INFO - [2023-01-05 22:54:32,998] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 22:54:33,010] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-05 22:54:58,021] {processor.py:153} INFO - Started process (PID=3871) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:54:58,022] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:54:58,023] {logging_mixin.py:115} INFO - [2023-01-05 22:54:58,023] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:54:58,944] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:54:58,945] {logging_mixin.py:115} INFO - [2023-01-05 22:54:58,945] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:54:58,946] {logging_mixin.py:115} INFO - [2023-01-05 22:54:58,946] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:54:58,953] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:54:59,010] {logging_mixin.py:115} INFO - [2023-01-05 22:54:59,009] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:54:59,032] {logging_mixin.py:115} INFO - [2023-01-05 22:54:59,032] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 22:54:59,046] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.030 seconds
[2023-01-05 22:55:29,120] {processor.py:153} INFO - Started process (PID=3896) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:55:29,122] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:55:29,123] {logging_mixin.py:115} INFO - [2023-01-05 22:55:29,122] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:55:30,059] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:55:30,061] {logging_mixin.py:115} INFO - [2023-01-05 22:55:30,061] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:55:30,061] {logging_mixin.py:115} INFO - [2023-01-05 22:55:30,061] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:55:30,068] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:55:30,092] {logging_mixin.py:115} INFO - [2023-01-05 22:55:30,091] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:55:30,113] {logging_mixin.py:115} INFO - [2023-01-05 22:55:30,113] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 22:55:30,123] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.008 seconds
[2023-01-05 22:55:41,150] {processor.py:153} INFO - Started process (PID=3906) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:55:41,151] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:55:41,151] {logging_mixin.py:115} INFO - [2023-01-05 22:55:41,151] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:55:42,100] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:55:42,102] {logging_mixin.py:115} INFO - [2023-01-05 22:55:42,101] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:55:42,102] {logging_mixin.py:115} INFO - [2023-01-05 22:55:42,102] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:55:42,109] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:55:42,133] {logging_mixin.py:115} INFO - [2023-01-05 22:55:42,132] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:55:42,155] {logging_mixin.py:115} INFO - [2023-01-05 22:55:42,154] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 22:55:42,167] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.022 seconds
[2023-01-05 22:56:12,236] {processor.py:153} INFO - Started process (PID=3932) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:56:12,238] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:56:12,238] {logging_mixin.py:115} INFO - [2023-01-05 22:56:12,238] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:56:13,173] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:56:13,175] {logging_mixin.py:115} INFO - [2023-01-05 22:56:13,175] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:56:13,175] {logging_mixin.py:115} INFO - [2023-01-05 22:56:13,175] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:56:13,183] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:56:13,207] {logging_mixin.py:115} INFO - [2023-01-05 22:56:13,207] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:56:13,229] {logging_mixin.py:115} INFO - [2023-01-05 22:56:13,229] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 22:56:13,241] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.009 seconds
[2023-01-05 22:56:43,277] {processor.py:153} INFO - Started process (PID=3949) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:56:43,280] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:56:43,281] {logging_mixin.py:115} INFO - [2023-01-05 22:56:43,280] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:56:44,212] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:56:44,213] {logging_mixin.py:115} INFO - [2023-01-05 22:56:44,213] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:56:44,214] {logging_mixin.py:115} INFO - [2023-01-05 22:56:44,213] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:56:44,221] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:56:44,258] {logging_mixin.py:115} INFO - [2023-01-05 22:56:44,257] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:56:44,289] {logging_mixin.py:115} INFO - [2023-01-05 22:56:44,289] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 22:56:44,299] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.027 seconds
[2023-01-05 22:57:14,379] {processor.py:153} INFO - Started process (PID=3974) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:57:14,380] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:57:14,381] {logging_mixin.py:115} INFO - [2023-01-05 22:57:14,381] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:57:15,344] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:57:15,345] {logging_mixin.py:115} INFO - [2023-01-05 22:57:15,345] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:57:15,346] {logging_mixin.py:115} INFO - [2023-01-05 22:57:15,345] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:57:15,353] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:57:15,377] {logging_mixin.py:115} INFO - [2023-01-05 22:57:15,376] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:57:15,400] {logging_mixin.py:115} INFO - [2023-01-05 22:57:15,399] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 22:57:15,409] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.035 seconds
[2023-01-05 22:57:45,480] {processor.py:153} INFO - Started process (PID=4000) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:57:45,482] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:57:45,482] {logging_mixin.py:115} INFO - [2023-01-05 22:57:45,482] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:57:46,394] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:57:46,396] {logging_mixin.py:115} INFO - [2023-01-05 22:57:46,395] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:57:46,396] {logging_mixin.py:115} INFO - [2023-01-05 22:57:46,396] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:57:46,405] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:57:46,430] {logging_mixin.py:115} INFO - [2023-01-05 22:57:46,430] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:57:46,462] {logging_mixin.py:115} INFO - [2023-01-05 22:57:46,462] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 22:57:46,473] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.998 seconds
[2023-01-05 22:58:16,533] {processor.py:153} INFO - Started process (PID=4024) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:58:16,534] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:58:16,535] {logging_mixin.py:115} INFO - [2023-01-05 22:58:16,535] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:58:17,506] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:58:17,507] {logging_mixin.py:115} INFO - [2023-01-05 22:58:17,507] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:58:17,508] {logging_mixin.py:115} INFO - [2023-01-05 22:58:17,508] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:58:17,515] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:58:17,538] {logging_mixin.py:115} INFO - [2023-01-05 22:58:17,538] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:58:17,559] {logging_mixin.py:115} INFO - [2023-01-05 22:58:17,559] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 22:58:17,570] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.041 seconds
[2023-01-05 22:58:47,660] {processor.py:153} INFO - Started process (PID=4043) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:58:47,661] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:58:47,662] {logging_mixin.py:115} INFO - [2023-01-05 22:58:47,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:58:48,880] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:58:48,882] {logging_mixin.py:115} INFO - [2023-01-05 22:58:48,882] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:58:48,883] {logging_mixin.py:115} INFO - [2023-01-05 22:58:48,882] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:58:48,895] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:58:48,931] {logging_mixin.py:115} INFO - [2023-01-05 22:58:48,930] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:58:48,964] {logging_mixin.py:115} INFO - [2023-01-05 22:58:48,964] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 22:58:48,979] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.324 seconds
[2023-01-05 22:59:19,054] {processor.py:153} INFO - Started process (PID=4070) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:59:19,054] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:59:19,055] {logging_mixin.py:115} INFO - [2023-01-05 22:59:19,055] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:59:19,970] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:59:19,971] {logging_mixin.py:115} INFO - [2023-01-05 22:59:19,971] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:59:19,972] {logging_mixin.py:115} INFO - [2023-01-05 22:59:19,971] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:59:19,979] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:59:20,001] {logging_mixin.py:115} INFO - [2023-01-05 22:59:20,001] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:59:20,022] {logging_mixin.py:115} INFO - [2023-01-05 22:59:20,022] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 22:59:20,032] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.983 seconds
[2023-01-05 22:59:50,114] {processor.py:153} INFO - Started process (PID=4096) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:59:50,115] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:59:50,116] {logging_mixin.py:115} INFO - [2023-01-05 22:59:50,116] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:59:51,040] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:59:51,041] {logging_mixin.py:115} INFO - [2023-01-05 22:59:51,041] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:59:51,042] {logging_mixin.py:115} INFO - [2023-01-05 22:59:51,041] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:59:51,049] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 22:59:51,071] {logging_mixin.py:115} INFO - [2023-01-05 22:59:51,071] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:59:51,095] {logging_mixin.py:115} INFO - [2023-01-05 22:59:51,095] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 22:59:51,105] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-05 23:00:21,180] {processor.py:153} INFO - Started process (PID=4121) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:00:21,181] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:00:21,181] {logging_mixin.py:115} INFO - [2023-01-05 23:00:21,181] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:00:22,172] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:00:22,174] {logging_mixin.py:115} INFO - [2023-01-05 23:00:22,173] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:00:22,174] {logging_mixin.py:115} INFO - [2023-01-05 23:00:22,174] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:00:22,182] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:00:22,205] {logging_mixin.py:115} INFO - [2023-01-05 23:00:22,205] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:00:22,226] {logging_mixin.py:115} INFO - [2023-01-05 23:00:22,226] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:00:22,237] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.062 seconds
[2023-01-05 23:00:52,312] {processor.py:153} INFO - Started process (PID=4139) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:00:52,314] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:00:52,315] {logging_mixin.py:115} INFO - [2023-01-05 23:00:52,314] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:00:53,291] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:00:53,293] {logging_mixin.py:115} INFO - [2023-01-05 23:00:53,293] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:00:53,293] {logging_mixin.py:115} INFO - [2023-01-05 23:00:53,293] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:00:53,300] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:00:53,333] {logging_mixin.py:115} INFO - [2023-01-05 23:00:53,333] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:00:53,365] {logging_mixin.py:115} INFO - [2023-01-05 23:00:53,365] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:00:53,378] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.070 seconds
[2023-01-05 23:01:23,450] {processor.py:153} INFO - Started process (PID=4164) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:01:23,450] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:01:23,451] {logging_mixin.py:115} INFO - [2023-01-05 23:01:23,451] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:01:24,362] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:01:24,363] {logging_mixin.py:115} INFO - [2023-01-05 23:01:24,363] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:01:24,364] {logging_mixin.py:115} INFO - [2023-01-05 23:01:24,363] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:01:24,371] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:01:24,394] {logging_mixin.py:115} INFO - [2023-01-05 23:01:24,394] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:01:24,415] {logging_mixin.py:115} INFO - [2023-01-05 23:01:24,415] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:01:24,425] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.980 seconds
[2023-01-05 23:01:54,497] {processor.py:153} INFO - Started process (PID=4189) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:01:54,499] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:01:54,499] {logging_mixin.py:115} INFO - [2023-01-05 23:01:54,499] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:01:55,403] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:01:55,405] {logging_mixin.py:115} INFO - [2023-01-05 23:01:55,404] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:01:55,405] {logging_mixin.py:115} INFO - [2023-01-05 23:01:55,405] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:01:55,413] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:01:55,436] {logging_mixin.py:115} INFO - [2023-01-05 23:01:55,436] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:01:55,458] {logging_mixin.py:115} INFO - [2023-01-05 23:01:55,458] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:01:55,468] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.975 seconds
[2023-01-05 23:02:25,540] {processor.py:153} INFO - Started process (PID=4214) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:02:25,541] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:02:25,542] {logging_mixin.py:115} INFO - [2023-01-05 23:02:25,542] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:02:26,469] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:02:26,470] {logging_mixin.py:115} INFO - [2023-01-05 23:02:26,470] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:02:26,471] {logging_mixin.py:115} INFO - [2023-01-05 23:02:26,471] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:02:26,478] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:02:26,504] {logging_mixin.py:115} INFO - [2023-01-05 23:02:26,503] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:02:26,526] {logging_mixin.py:115} INFO - [2023-01-05 23:02:26,526] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:02:26,537] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.003 seconds
[2023-01-05 23:02:56,612] {processor.py:153} INFO - Started process (PID=4232) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:02:56,614] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:02:56,614] {logging_mixin.py:115} INFO - [2023-01-05 23:02:56,614] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:02:57,556] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:02:57,558] {logging_mixin.py:115} INFO - [2023-01-05 23:02:57,558] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:02:57,558] {logging_mixin.py:115} INFO - [2023-01-05 23:02:57,558] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:02:57,566] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:02:57,596] {logging_mixin.py:115} INFO - [2023-01-05 23:02:57,596] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:02:57,619] {logging_mixin.py:115} INFO - [2023-01-05 23:02:57,619] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:02:57,630] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.024 seconds
[2023-01-05 23:03:27,700] {processor.py:153} INFO - Started process (PID=4256) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:03:27,701] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:03:27,702] {logging_mixin.py:115} INFO - [2023-01-05 23:03:27,702] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:03:28,625] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:03:28,626] {logging_mixin.py:115} INFO - [2023-01-05 23:03:28,626] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:03:28,627] {logging_mixin.py:115} INFO - [2023-01-05 23:03:28,626] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:03:28,634] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:03:28,658] {logging_mixin.py:115} INFO - [2023-01-05 23:03:28,658] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:03:28,679] {logging_mixin.py:115} INFO - [2023-01-05 23:03:28,679] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:03:28,689] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.994 seconds
[2023-01-05 23:03:58,763] {processor.py:153} INFO - Started process (PID=4280) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:03:58,765] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:03:58,766] {logging_mixin.py:115} INFO - [2023-01-05 23:03:58,765] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:03:59,716] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:03:59,717] {logging_mixin.py:115} INFO - [2023-01-05 23:03:59,717] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:03:59,718] {logging_mixin.py:115} INFO - [2023-01-05 23:03:59,717] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:03:59,725] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:03:59,748] {logging_mixin.py:115} INFO - [2023-01-05 23:03:59,748] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:03:59,769] {logging_mixin.py:115} INFO - [2023-01-05 23:03:59,769] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:03:59,779] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.020 seconds
[2023-01-05 23:04:29,854] {processor.py:153} INFO - Started process (PID=4306) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:04:29,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:04:29,857] {logging_mixin.py:115} INFO - [2023-01-05 23:04:29,857] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:04:30,858] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:04:30,859] {logging_mixin.py:115} INFO - [2023-01-05 23:04:30,859] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:04:30,860] {logging_mixin.py:115} INFO - [2023-01-05 23:04:30,860] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:04:30,867] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:04:30,898] {logging_mixin.py:115} INFO - [2023-01-05 23:04:30,898] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:04:30,930] {logging_mixin.py:115} INFO - [2023-01-05 23:04:30,929] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:04:30,944] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.096 seconds
[2023-01-05 23:05:01,015] {processor.py:153} INFO - Started process (PID=4324) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:05:01,015] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:05:01,016] {logging_mixin.py:115} INFO - [2023-01-05 23:05:01,016] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:05:01,957] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:05:01,958] {logging_mixin.py:115} INFO - [2023-01-05 23:05:01,958] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:05:01,958] {logging_mixin.py:115} INFO - [2023-01-05 23:05:01,958] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:05:01,965] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:05:01,987] {logging_mixin.py:115} INFO - [2023-01-05 23:05:01,987] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:05:02,008] {logging_mixin.py:115} INFO - [2023-01-05 23:05:02,008] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:05:02,018] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.008 seconds
[2023-01-05 23:05:32,093] {processor.py:153} INFO - Started process (PID=4348) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:05:32,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:05:32,097] {logging_mixin.py:115} INFO - [2023-01-05 23:05:32,097] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:05:33,027] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:05:33,028] {logging_mixin.py:115} INFO - [2023-01-05 23:05:33,028] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:05:33,029] {logging_mixin.py:115} INFO - [2023-01-05 23:05:33,028] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:05:33,036] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:05:33,059] {logging_mixin.py:115} INFO - [2023-01-05 23:05:33,059] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:05:33,080] {logging_mixin.py:115} INFO - [2023-01-05 23:05:33,080] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:05:33,090] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.003 seconds
[2023-01-05 23:06:03,180] {processor.py:153} INFO - Started process (PID=4374) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:06:03,183] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:06:03,184] {logging_mixin.py:115} INFO - [2023-01-05 23:06:03,184] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:06:04,093] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:06:04,094] {logging_mixin.py:115} INFO - [2023-01-05 23:06:04,094] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:06:04,094] {logging_mixin.py:115} INFO - [2023-01-05 23:06:04,094] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:06:04,101] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:06:04,125] {logging_mixin.py:115} INFO - [2023-01-05 23:06:04,125] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:06:04,146] {logging_mixin.py:115} INFO - [2023-01-05 23:06:04,146] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:06:04,156] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.983 seconds
[2023-01-05 23:06:34,239] {processor.py:153} INFO - Started process (PID=4398) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:06:34,240] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:06:34,241] {logging_mixin.py:115} INFO - [2023-01-05 23:06:34,241] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:06:35,165] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:06:35,167] {logging_mixin.py:115} INFO - [2023-01-05 23:06:35,166] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:06:35,167] {logging_mixin.py:115} INFO - [2023-01-05 23:06:35,167] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:06:35,174] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:06:35,197] {logging_mixin.py:115} INFO - [2023-01-05 23:06:35,197] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:06:35,219] {logging_mixin.py:115} INFO - [2023-01-05 23:06:35,219] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:06:35,229] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-05 23:07:05,303] {processor.py:153} INFO - Started process (PID=4415) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:07:05,304] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:07:05,305] {logging_mixin.py:115} INFO - [2023-01-05 23:07:05,305] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:07:06,217] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:07:06,219] {logging_mixin.py:115} INFO - [2023-01-05 23:07:06,218] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:07:06,219] {logging_mixin.py:115} INFO - [2023-01-05 23:07:06,219] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:07:06,226] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:07:06,250] {logging_mixin.py:115} INFO - [2023-01-05 23:07:06,249] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:07:06,271] {logging_mixin.py:115} INFO - [2023-01-05 23:07:06,271] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:07:06,281] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.984 seconds
[2023-01-05 23:07:36,330] {processor.py:153} INFO - Started process (PID=4440) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:07:36,331] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:07:36,332] {logging_mixin.py:115} INFO - [2023-01-05 23:07:36,332] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:07:37,265] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:07:37,266] {logging_mixin.py:115} INFO - [2023-01-05 23:07:37,266] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:07:37,267] {logging_mixin.py:115} INFO - [2023-01-05 23:07:37,267] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:07:37,274] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:07:37,297] {logging_mixin.py:115} INFO - [2023-01-05 23:07:37,297] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:07:37,320] {logging_mixin.py:115} INFO - [2023-01-05 23:07:37,319] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:07:37,331] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.006 seconds
[2023-01-05 23:08:07,403] {processor.py:153} INFO - Started process (PID=4464) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:08:07,403] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:08:07,404] {logging_mixin.py:115} INFO - [2023-01-05 23:08:07,404] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:08:08,336] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:08:08,337] {logging_mixin.py:115} INFO - [2023-01-05 23:08:08,337] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:08:08,338] {logging_mixin.py:115} INFO - [2023-01-05 23:08:08,338] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:08:08,345] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:08:08,368] {logging_mixin.py:115} INFO - [2023-01-05 23:08:08,368] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:08:08,391] {logging_mixin.py:115} INFO - [2023-01-05 23:08:08,391] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:08:08,401] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.005 seconds
[2023-01-05 23:08:38,473] {processor.py:153} INFO - Started process (PID=4489) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:08:38,475] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:08:38,475] {logging_mixin.py:115} INFO - [2023-01-05 23:08:38,475] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:08:39,398] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:08:39,399] {logging_mixin.py:115} INFO - [2023-01-05 23:08:39,399] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:08:39,400] {logging_mixin.py:115} INFO - [2023-01-05 23:08:39,400] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:08:39,407] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:08:39,431] {logging_mixin.py:115} INFO - [2023-01-05 23:08:39,430] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:08:39,454] {logging_mixin.py:115} INFO - [2023-01-05 23:08:39,454] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:08:39,466] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.998 seconds
[2023-01-05 23:09:09,543] {processor.py:153} INFO - Started process (PID=4507) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:09:09,544] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:09:09,545] {logging_mixin.py:115} INFO - [2023-01-05 23:09:09,544] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:09:10,455] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:09:10,457] {logging_mixin.py:115} INFO - [2023-01-05 23:09:10,457] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:09:10,457] {logging_mixin.py:115} INFO - [2023-01-05 23:09:10,457] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:09:10,469] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:09:10,495] {logging_mixin.py:115} INFO - [2023-01-05 23:09:10,495] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:09:10,522] {logging_mixin.py:115} INFO - [2023-01-05 23:09:10,522] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:09:10,536] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.000 seconds
[2023-01-05 23:09:40,569] {processor.py:153} INFO - Started process (PID=4532) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:09:40,571] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:09:40,571] {logging_mixin.py:115} INFO - [2023-01-05 23:09:40,571] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:09:41,480] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:09:41,481] {logging_mixin.py:115} INFO - [2023-01-05 23:09:41,481] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:09:41,482] {logging_mixin.py:115} INFO - [2023-01-05 23:09:41,481] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:09:41,489] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:09:41,516] {logging_mixin.py:115} INFO - [2023-01-05 23:09:41,516] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:09:41,542] {logging_mixin.py:115} INFO - [2023-01-05 23:09:41,542] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:09:41,552] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.988 seconds
[2023-01-05 23:10:11,658] {processor.py:153} INFO - Started process (PID=4557) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:10:11,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:10:11,660] {logging_mixin.py:115} INFO - [2023-01-05 23:10:11,660] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:10:12,620] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:10:12,621] {logging_mixin.py:115} INFO - [2023-01-05 23:10:12,621] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:10:12,622] {logging_mixin.py:115} INFO - [2023-01-05 23:10:12,621] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:10:12,629] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:10:12,652] {logging_mixin.py:115} INFO - [2023-01-05 23:10:12,652] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:10:12,673] {logging_mixin.py:115} INFO - [2023-01-05 23:10:12,673] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:10:12,684] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.030 seconds
[2023-01-05 23:10:42,753] {processor.py:153} INFO - Started process (PID=4581) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:10:42,753] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:10:42,754] {logging_mixin.py:115} INFO - [2023-01-05 23:10:42,754] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:10:43,660] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:10:43,661] {logging_mixin.py:115} INFO - [2023-01-05 23:10:43,661] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:10:43,662] {logging_mixin.py:115} INFO - [2023-01-05 23:10:43,662] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:10:43,669] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:10:43,691] {logging_mixin.py:115} INFO - [2023-01-05 23:10:43,691] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:10:43,713] {logging_mixin.py:115} INFO - [2023-01-05 23:10:43,713] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:10:43,724] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.976 seconds
[2023-01-05 23:11:13,823] {processor.py:153} INFO - Started process (PID=4599) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:11:13,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:11:13,825] {logging_mixin.py:115} INFO - [2023-01-05 23:11:13,825] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:11:14,753] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:11:14,754] {logging_mixin.py:115} INFO - [2023-01-05 23:11:14,754] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:11:14,755] {logging_mixin.py:115} INFO - [2023-01-05 23:11:14,754] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:11:14,762] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:11:14,784] {logging_mixin.py:115} INFO - [2023-01-05 23:11:14,784] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:11:14,805] {logging_mixin.py:115} INFO - [2023-01-05 23:11:14,805] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:11:14,814] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-05 23:11:44,891] {processor.py:153} INFO - Started process (PID=4624) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:11:44,891] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:11:44,892] {logging_mixin.py:115} INFO - [2023-01-05 23:11:44,892] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:11:45,831] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:11:45,833] {logging_mixin.py:115} INFO - [2023-01-05 23:11:45,833] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:11:45,833] {logging_mixin.py:115} INFO - [2023-01-05 23:11:45,833] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:11:45,840] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:11:45,862] {logging_mixin.py:115} INFO - [2023-01-05 23:11:45,862] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:11:45,884] {logging_mixin.py:115} INFO - [2023-01-05 23:11:45,884] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:11:45,894] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.009 seconds
[2023-01-05 23:12:15,967] {processor.py:153} INFO - Started process (PID=4650) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:12:15,968] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:12:15,969] {logging_mixin.py:115} INFO - [2023-01-05 23:12:15,969] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:12:16,895] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:12:16,896] {logging_mixin.py:115} INFO - [2023-01-05 23:12:16,896] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:12:16,897] {logging_mixin.py:115} INFO - [2023-01-05 23:12:16,897] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:12:16,904] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:12:16,936] {logging_mixin.py:115} INFO - [2023-01-05 23:12:16,935] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:12:16,958] {logging_mixin.py:115} INFO - [2023-01-05 23:12:16,957] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:12:16,972] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.010 seconds
[2023-01-05 23:12:47,048] {processor.py:153} INFO - Started process (PID=4676) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:12:47,048] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:12:47,049] {logging_mixin.py:115} INFO - [2023-01-05 23:12:47,049] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:12:47,988] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:12:47,989] {logging_mixin.py:115} INFO - [2023-01-05 23:12:47,989] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:12:47,989] {logging_mixin.py:115} INFO - [2023-01-05 23:12:47,989] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:12:47,996] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:12:48,021] {logging_mixin.py:115} INFO - [2023-01-05 23:12:48,021] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:12:48,042] {logging_mixin.py:115} INFO - [2023-01-05 23:12:48,042] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:12:48,052] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.009 seconds
[2023-01-05 23:13:18,134] {processor.py:153} INFO - Started process (PID=4693) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:13:18,136] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:13:18,136] {logging_mixin.py:115} INFO - [2023-01-05 23:13:18,136] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:13:19,082] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:13:19,083] {logging_mixin.py:115} INFO - [2023-01-05 23:13:19,083] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:13:19,083] {logging_mixin.py:115} INFO - [2023-01-05 23:13:19,083] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:13:19,090] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:13:19,115] {logging_mixin.py:115} INFO - [2023-01-05 23:13:19,114] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:13:19,137] {logging_mixin.py:115} INFO - [2023-01-05 23:13:19,137] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:13:19,148] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.018 seconds
[2023-01-05 23:13:49,226] {processor.py:153} INFO - Started process (PID=4719) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:13:49,227] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:13:49,228] {logging_mixin.py:115} INFO - [2023-01-05 23:13:49,228] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:13:50,136] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:13:50,137] {logging_mixin.py:115} INFO - [2023-01-05 23:13:50,137] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:13:50,138] {logging_mixin.py:115} INFO - [2023-01-05 23:13:50,137] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:13:50,145] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:13:50,167] {logging_mixin.py:115} INFO - [2023-01-05 23:13:50,167] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:13:50,187] {logging_mixin.py:115} INFO - [2023-01-05 23:13:50,187] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:13:50,197] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.976 seconds
[2023-01-05 23:14:20,270] {processor.py:153} INFO - Started process (PID=4744) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:14:20,272] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:14:20,272] {logging_mixin.py:115} INFO - [2023-01-05 23:14:20,272] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:14:21,279] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:14:21,281] {logging_mixin.py:115} INFO - [2023-01-05 23:14:21,280] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:14:21,281] {logging_mixin.py:115} INFO - [2023-01-05 23:14:21,281] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:14:21,288] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:14:21,310] {logging_mixin.py:115} INFO - [2023-01-05 23:14:21,310] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:14:21,333] {logging_mixin.py:115} INFO - [2023-01-05 23:14:21,333] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:14:21,343] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.078 seconds
[2023-01-05 23:14:51,441] {processor.py:153} INFO - Started process (PID=4773) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:14:51,443] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:14:51,444] {logging_mixin.py:115} INFO - [2023-01-05 23:14:51,444] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:14:52,603] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:14:52,605] {logging_mixin.py:115} INFO - [2023-01-05 23:14:52,605] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:14:52,605] {logging_mixin.py:115} INFO - [2023-01-05 23:14:52,605] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:14:52,612] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:14:52,635] {logging_mixin.py:115} INFO - [2023-01-05 23:14:52,635] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:14:52,656] {logging_mixin.py:115} INFO - [2023-01-05 23:14:52,656] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:15:00+00:00
[2023-01-05 23:14:52,666] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.230 seconds
[2023-01-05 23:15:22,767] {processor.py:153} INFO - Started process (PID=4791) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:15:22,768] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:15:22,769] {logging_mixin.py:115} INFO - [2023-01-05 23:15:22,769] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:15:23,688] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:15:23,689] {logging_mixin.py:115} INFO - [2023-01-05 23:15:23,689] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:15:23,690] {logging_mixin.py:115} INFO - [2023-01-05 23:15:23,690] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:15:23,697] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:15:23,721] {logging_mixin.py:115} INFO - [2023-01-05 23:15:23,721] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:15:23,743] {logging_mixin.py:115} INFO - [2023-01-05 23:15:23,743] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:15:23,753] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.991 seconds
[2023-01-05 23:15:53,830] {processor.py:153} INFO - Started process (PID=4815) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:15:53,831] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:15:53,832] {logging_mixin.py:115} INFO - [2023-01-05 23:15:53,832] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:15:54,746] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:15:54,747] {logging_mixin.py:115} INFO - [2023-01-05 23:15:54,747] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:15:54,748] {logging_mixin.py:115} INFO - [2023-01-05 23:15:54,748] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:15:54,755] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:15:54,779] {logging_mixin.py:115} INFO - [2023-01-05 23:15:54,779] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:15:54,801] {logging_mixin.py:115} INFO - [2023-01-05 23:15:54,801] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:15:54,812] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.987 seconds
[2023-01-05 23:16:24,918] {processor.py:153} INFO - Started process (PID=4841) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:16:24,919] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:16:24,920] {logging_mixin.py:115} INFO - [2023-01-05 23:16:24,920] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:16:25,898] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:16:25,900] {logging_mixin.py:115} INFO - [2023-01-05 23:16:25,900] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:16:25,901] {logging_mixin.py:115} INFO - [2023-01-05 23:16:25,901] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:16:25,913] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:16:25,945] {logging_mixin.py:115} INFO - [2023-01-05 23:16:25,944] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:16:25,975] {logging_mixin.py:115} INFO - [2023-01-05 23:16:25,975] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:16:25,986] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.073 seconds
[2023-01-05 23:16:56,088] {processor.py:153} INFO - Started process (PID=4866) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:16:56,089] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:16:56,090] {logging_mixin.py:115} INFO - [2023-01-05 23:16:56,090] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:16:57,047] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:16:57,049] {logging_mixin.py:115} INFO - [2023-01-05 23:16:57,049] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:16:57,049] {logging_mixin.py:115} INFO - [2023-01-05 23:16:57,049] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:16:57,056] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:16:57,083] {logging_mixin.py:115} INFO - [2023-01-05 23:16:57,083] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:16:57,106] {logging_mixin.py:115} INFO - [2023-01-05 23:16:57,106] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:16:57,116] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.033 seconds
[2023-01-05 23:17:27,186] {processor.py:153} INFO - Started process (PID=4884) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:17:27,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:17:27,188] {logging_mixin.py:115} INFO - [2023-01-05 23:17:27,188] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:17:28,098] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:17:28,099] {logging_mixin.py:115} INFO - [2023-01-05 23:17:28,099] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:17:28,099] {logging_mixin.py:115} INFO - [2023-01-05 23:17:28,099] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:17:28,106] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:17:28,129] {logging_mixin.py:115} INFO - [2023-01-05 23:17:28,128] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:17:28,150] {logging_mixin.py:115} INFO - [2023-01-05 23:17:28,149] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:17:28,160] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.978 seconds
[2023-01-05 23:17:58,231] {processor.py:153} INFO - Started process (PID=4910) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:17:58,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:17:58,232] {logging_mixin.py:115} INFO - [2023-01-05 23:17:58,232] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:17:59,133] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:17:59,134] {logging_mixin.py:115} INFO - [2023-01-05 23:17:59,134] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:17:59,135] {logging_mixin.py:115} INFO - [2023-01-05 23:17:59,134] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:17:59,142] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:17:59,165] {logging_mixin.py:115} INFO - [2023-01-05 23:17:59,164] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:17:59,185] {logging_mixin.py:115} INFO - [2023-01-05 23:17:59,185] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:17:59,195] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.968 seconds
[2023-01-05 23:18:29,268] {processor.py:153} INFO - Started process (PID=4935) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:18:29,272] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:18:29,273] {logging_mixin.py:115} INFO - [2023-01-05 23:18:29,273] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:18:30,204] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:18:30,205] {logging_mixin.py:115} INFO - [2023-01-05 23:18:30,205] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:18:30,206] {logging_mixin.py:115} INFO - [2023-01-05 23:18:30,205] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:18:30,213] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:18:30,237] {logging_mixin.py:115} INFO - [2023-01-05 23:18:30,236] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:18:30,258] {logging_mixin.py:115} INFO - [2023-01-05 23:18:30,258] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:18:30,268] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.005 seconds
[2023-01-05 23:19:00,346] {processor.py:153} INFO - Started process (PID=4954) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:19:00,346] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:19:00,347] {logging_mixin.py:115} INFO - [2023-01-05 23:19:00,347] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:19:01,288] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:19:01,289] {logging_mixin.py:115} INFO - [2023-01-05 23:19:01,289] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:19:01,290] {logging_mixin.py:115} INFO - [2023-01-05 23:19:01,289] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:19:01,297] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:19:01,322] {logging_mixin.py:115} INFO - [2023-01-05 23:19:01,322] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:19:01,344] {logging_mixin.py:115} INFO - [2023-01-05 23:19:01,344] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:19:01,355] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.019 seconds
[2023-01-05 23:19:31,427] {processor.py:153} INFO - Started process (PID=4978) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:19:31,428] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:19:31,429] {logging_mixin.py:115} INFO - [2023-01-05 23:19:31,429] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:19:32,341] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:19:32,342] {logging_mixin.py:115} INFO - [2023-01-05 23:19:32,342] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:19:32,343] {logging_mixin.py:115} INFO - [2023-01-05 23:19:32,343] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:19:32,350] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:19:32,376] {logging_mixin.py:115} INFO - [2023-01-05 23:19:32,375] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:19:32,400] {logging_mixin.py:115} INFO - [2023-01-05 23:19:32,400] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:19:32,414] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.992 seconds
[2023-01-05 23:20:02,455] {processor.py:153} INFO - Started process (PID=5005) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:20:02,455] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:20:02,456] {logging_mixin.py:115} INFO - [2023-01-05 23:20:02,456] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:20:03,376] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:20:03,377] {logging_mixin.py:115} INFO - [2023-01-05 23:20:03,377] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:20:03,377] {logging_mixin.py:115} INFO - [2023-01-05 23:20:03,377] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:20:03,384] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:20:03,440] {logging_mixin.py:115} INFO - [2023-01-05 23:20:03,439] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:20:03,461] {logging_mixin.py:115} INFO - [2023-01-05 23:20:03,461] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:20:03,472] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.023 seconds
[2023-01-05 23:20:33,556] {processor.py:153} INFO - Started process (PID=5030) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:20:33,556] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:20:33,557] {logging_mixin.py:115} INFO - [2023-01-05 23:20:33,557] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:20:34,499] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:20:34,501] {logging_mixin.py:115} INFO - [2023-01-05 23:20:34,501] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:20:34,501] {logging_mixin.py:115} INFO - [2023-01-05 23:20:34,501] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:20:34,509] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:20:34,533] {logging_mixin.py:115} INFO - [2023-01-05 23:20:34,532] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:20:34,554] {logging_mixin.py:115} INFO - [2023-01-05 23:20:34,554] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:20:34,564] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.013 seconds
[2023-01-05 23:21:04,595] {processor.py:153} INFO - Started process (PID=5048) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:21:04,596] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:21:04,597] {logging_mixin.py:115} INFO - [2023-01-05 23:21:04,597] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:21:05,539] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:21:05,541] {logging_mixin.py:115} INFO - [2023-01-05 23:21:05,541] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:21:05,541] {logging_mixin.py:115} INFO - [2023-01-05 23:21:05,541] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:21:05,549] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:21:05,573] {logging_mixin.py:115} INFO - [2023-01-05 23:21:05,572] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:21:05,594] {logging_mixin.py:115} INFO - [2023-01-05 23:21:05,594] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:21:05,605] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.016 seconds
[2023-01-05 23:21:35,653] {processor.py:153} INFO - Started process (PID=5073) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:21:35,654] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:21:35,655] {logging_mixin.py:115} INFO - [2023-01-05 23:21:35,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:21:36,557] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:21:36,558] {logging_mixin.py:115} INFO - [2023-01-05 23:21:36,558] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:21:36,559] {logging_mixin.py:115} INFO - [2023-01-05 23:21:36,559] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:21:36,566] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:21:36,589] {logging_mixin.py:115} INFO - [2023-01-05 23:21:36,589] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:21:36,611] {logging_mixin.py:115} INFO - [2023-01-05 23:21:36,611] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:21:36,621] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.974 seconds
[2023-01-05 23:22:06,720] {processor.py:153} INFO - Started process (PID=5099) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:22:06,721] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:22:06,722] {logging_mixin.py:115} INFO - [2023-01-05 23:22:06,722] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:22:07,730] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:22:07,731] {logging_mixin.py:115} INFO - [2023-01-05 23:22:07,731] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:22:07,732] {logging_mixin.py:115} INFO - [2023-01-05 23:22:07,731] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:22:07,738] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:22:07,761] {logging_mixin.py:115} INFO - [2023-01-05 23:22:07,761] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:22:07,783] {logging_mixin.py:115} INFO - [2023-01-05 23:22:07,782] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:22:07,793] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.078 seconds
[2023-01-05 23:22:37,873] {processor.py:153} INFO - Started process (PID=5124) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:22:37,875] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:22:37,876] {logging_mixin.py:115} INFO - [2023-01-05 23:22:37,876] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:22:38,826] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:22:38,828] {logging_mixin.py:115} INFO - [2023-01-05 23:22:38,828] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:22:38,828] {logging_mixin.py:115} INFO - [2023-01-05 23:22:38,828] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:22:38,835] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:22:38,860] {logging_mixin.py:115} INFO - [2023-01-05 23:22:38,860] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:22:38,882] {logging_mixin.py:115} INFO - [2023-01-05 23:22:38,882] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:22:38,893] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.025 seconds
[2023-01-05 23:23:08,965] {processor.py:153} INFO - Started process (PID=5143) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:23:08,966] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:23:08,967] {logging_mixin.py:115} INFO - [2023-01-05 23:23:08,967] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:23:09,905] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:23:09,906] {logging_mixin.py:115} INFO - [2023-01-05 23:23:09,906] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:23:09,907] {logging_mixin.py:115} INFO - [2023-01-05 23:23:09,907] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:23:09,914] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:23:09,937] {logging_mixin.py:115} INFO - [2023-01-05 23:23:09,937] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:23:09,959] {logging_mixin.py:115} INFO - [2023-01-05 23:23:09,959] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:23:09,969] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.010 seconds
[2023-01-05 23:23:40,044] {processor.py:153} INFO - Started process (PID=5168) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:23:40,046] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:23:40,046] {logging_mixin.py:115} INFO - [2023-01-05 23:23:40,046] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:23:40,992] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:23:40,993] {logging_mixin.py:115} INFO - [2023-01-05 23:23:40,993] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:23:40,994] {logging_mixin.py:115} INFO - [2023-01-05 23:23:40,993] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:23:41,001] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:23:41,023] {logging_mixin.py:115} INFO - [2023-01-05 23:23:41,023] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:23:41,045] {logging_mixin.py:115} INFO - [2023-01-05 23:23:41,045] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:23:41,055] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.016 seconds
[2023-01-05 23:24:11,131] {processor.py:153} INFO - Started process (PID=5192) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:24:11,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:24:11,134] {logging_mixin.py:115} INFO - [2023-01-05 23:24:11,133] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:24:12,076] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:24:12,077] {logging_mixin.py:115} INFO - [2023-01-05 23:24:12,077] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:24:12,078] {logging_mixin.py:115} INFO - [2023-01-05 23:24:12,077] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:24:12,085] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:24:12,108] {logging_mixin.py:115} INFO - [2023-01-05 23:24:12,108] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:24:12,130] {logging_mixin.py:115} INFO - [2023-01-05 23:24:12,130] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:24:12,140] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.013 seconds
[2023-01-05 23:24:42,193] {processor.py:153} INFO - Started process (PID=5219) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:24:42,194] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:24:42,194] {logging_mixin.py:115} INFO - [2023-01-05 23:24:42,194] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:24:43,109] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:24:43,110] {logging_mixin.py:115} INFO - [2023-01-05 23:24:43,110] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:24:43,111] {logging_mixin.py:115} INFO - [2023-01-05 23:24:43,110] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:24:43,118] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:24:43,151] {logging_mixin.py:115} INFO - [2023-01-05 23:24:43,151] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:24:43,174] {logging_mixin.py:115} INFO - [2023-01-05 23:24:43,173] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:24:43,184] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-05 23:25:13,258] {processor.py:153} INFO - Started process (PID=5238) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:25:13,259] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:25:13,260] {logging_mixin.py:115} INFO - [2023-01-05 23:25:13,259] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:25:14,266] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:25:14,268] {logging_mixin.py:115} INFO - [2023-01-05 23:25:14,268] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:25:14,268] {logging_mixin.py:115} INFO - [2023-01-05 23:25:14,268] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:25:14,276] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:25:14,299] {logging_mixin.py:115} INFO - [2023-01-05 23:25:14,299] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:25:14,321] {logging_mixin.py:115} INFO - [2023-01-05 23:25:14,320] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:25:14,331] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.078 seconds
[2023-01-05 23:25:44,407] {processor.py:153} INFO - Started process (PID=5264) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:25:44,409] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:25:44,410] {logging_mixin.py:115} INFO - [2023-01-05 23:25:44,410] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:25:45,333] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:25:45,334] {logging_mixin.py:115} INFO - [2023-01-05 23:25:45,334] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:25:45,335] {logging_mixin.py:115} INFO - [2023-01-05 23:25:45,334] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:25:45,342] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:25:45,365] {logging_mixin.py:115} INFO - [2023-01-05 23:25:45,365] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:25:45,387] {logging_mixin.py:115} INFO - [2023-01-05 23:25:45,387] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:25:45,398] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-05 23:26:15,453] {processor.py:153} INFO - Started process (PID=5289) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:26:15,454] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:26:15,455] {logging_mixin.py:115} INFO - [2023-01-05 23:26:15,455] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:26:16,374] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:26:16,375] {logging_mixin.py:115} INFO - [2023-01-05 23:26:16,375] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:26:16,376] {logging_mixin.py:115} INFO - [2023-01-05 23:26:16,375] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:26:16,383] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:26:16,407] {logging_mixin.py:115} INFO - [2023-01-05 23:26:16,406] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:26:16,427] {logging_mixin.py:115} INFO - [2023-01-05 23:26:16,427] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:26:16,437] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.991 seconds
[2023-01-05 23:26:46,479] {processor.py:153} INFO - Started process (PID=5314) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:26:46,480] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:26:46,480] {logging_mixin.py:115} INFO - [2023-01-05 23:26:46,480] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:26:47,422] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:26:47,424] {logging_mixin.py:115} INFO - [2023-01-05 23:26:47,424] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:26:47,424] {logging_mixin.py:115} INFO - [2023-01-05 23:26:47,424] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:26:47,432] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:26:47,456] {logging_mixin.py:115} INFO - [2023-01-05 23:26:47,456] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:26:47,477] {logging_mixin.py:115} INFO - [2023-01-05 23:26:47,477] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:26:47,487] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.013 seconds
[2023-01-05 23:27:17,564] {processor.py:153} INFO - Started process (PID=5332) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:27:17,568] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:27:17,569] {logging_mixin.py:115} INFO - [2023-01-05 23:27:17,569] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:27:18,492] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:27:18,493] {logging_mixin.py:115} INFO - [2023-01-05 23:27:18,493] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:27:18,494] {logging_mixin.py:115} INFO - [2023-01-05 23:27:18,493] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:27:18,503] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:27:18,528] {logging_mixin.py:115} INFO - [2023-01-05 23:27:18,527] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:27:18,550] {logging_mixin.py:115} INFO - [2023-01-05 23:27:18,550] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:27:18,560] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.002 seconds
[2023-01-05 23:27:48,636] {processor.py:153} INFO - Started process (PID=5358) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:27:48,638] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:27:48,639] {logging_mixin.py:115} INFO - [2023-01-05 23:27:48,638] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:27:49,595] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:27:49,596] {logging_mixin.py:115} INFO - [2023-01-05 23:27:49,596] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:27:49,597] {logging_mixin.py:115} INFO - [2023-01-05 23:27:49,596] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:27:49,604] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:27:49,627] {logging_mixin.py:115} INFO - [2023-01-05 23:27:49,627] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:27:49,650] {logging_mixin.py:115} INFO - [2023-01-05 23:27:49,650] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:27:49,661] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.031 seconds
[2023-01-05 23:28:19,692] {processor.py:153} INFO - Started process (PID=5381) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:28:19,693] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:28:19,693] {logging_mixin.py:115} INFO - [2023-01-05 23:28:19,693] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:28:20,733] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:28:20,735] {logging_mixin.py:115} INFO - [2023-01-05 23:28:20,735] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:28:20,735] {logging_mixin.py:115} INFO - [2023-01-05 23:28:20,735] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:28:20,742] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:28:20,766] {logging_mixin.py:115} INFO - [2023-01-05 23:28:20,766] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:28:20,788] {logging_mixin.py:115} INFO - [2023-01-05 23:28:20,788] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:28:20,799] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.112 seconds
[2023-01-05 23:28:50,870] {processor.py:153} INFO - Started process (PID=5405) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:28:50,872] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:28:50,873] {logging_mixin.py:115} INFO - [2023-01-05 23:28:50,873] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:28:51,772] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:28:51,773] {logging_mixin.py:115} INFO - [2023-01-05 23:28:51,773] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:28:51,774] {logging_mixin.py:115} INFO - [2023-01-05 23:28:51,773] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:28:51,781] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:28:51,804] {logging_mixin.py:115} INFO - [2023-01-05 23:28:51,803] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:28:51,824] {logging_mixin.py:115} INFO - [2023-01-05 23:28:51,824] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:28:51,834] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.969 seconds
[2023-01-05 23:29:21,903] {processor.py:153} INFO - Started process (PID=5423) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:29:21,904] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:29:21,905] {logging_mixin.py:115} INFO - [2023-01-05 23:29:21,905] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:29:22,963] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:29:22,964] {logging_mixin.py:115} INFO - [2023-01-05 23:29:22,964] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:29:22,965] {logging_mixin.py:115} INFO - [2023-01-05 23:29:22,964] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:29:22,971] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:29:22,994] {logging_mixin.py:115} INFO - [2023-01-05 23:29:22,994] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:29:23,016] {logging_mixin.py:115} INFO - [2023-01-05 23:29:23,015] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:29:23,026] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.128 seconds
[2023-01-05 23:29:53,096] {processor.py:153} INFO - Started process (PID=5448) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:29:53,099] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:29:53,100] {logging_mixin.py:115} INFO - [2023-01-05 23:29:53,099] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:29:54,044] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:29:54,046] {logging_mixin.py:115} INFO - [2023-01-05 23:29:54,046] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:29:54,046] {logging_mixin.py:115} INFO - [2023-01-05 23:29:54,046] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:29:54,053] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:29:54,076] {logging_mixin.py:115} INFO - [2023-01-05 23:29:54,076] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:29:54,097] {logging_mixin.py:115} INFO - [2023-01-05 23:29:54,097] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:29:54,107] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.016 seconds
[2023-01-05 23:30:24,161] {processor.py:153} INFO - Started process (PID=5474) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:30:24,162] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:30:24,163] {logging_mixin.py:115} INFO - [2023-01-05 23:30:24,163] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:30:25,108] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:30:25,109] {logging_mixin.py:115} INFO - [2023-01-05 23:30:25,109] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:30:25,110] {logging_mixin.py:115} INFO - [2023-01-05 23:30:25,109] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:30:25,117] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:30:25,139] {logging_mixin.py:115} INFO - [2023-01-05 23:30:25,139] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:30:25,160] {logging_mixin.py:115} INFO - [2023-01-05 23:30:25,160] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:30:25,170] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.014 seconds
[2023-01-05 23:30:55,251] {processor.py:153} INFO - Started process (PID=5499) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:30:55,252] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:30:55,253] {logging_mixin.py:115} INFO - [2023-01-05 23:30:55,253] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:30:56,222] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:30:56,223] {logging_mixin.py:115} INFO - [2023-01-05 23:30:56,223] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:30:56,225] {logging_mixin.py:115} INFO - [2023-01-05 23:30:56,224] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:30:56,232] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:30:56,264] {logging_mixin.py:115} INFO - [2023-01-05 23:30:56,263] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:30:56,295] {logging_mixin.py:115} INFO - [2023-01-05 23:30:56,295] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:30:56,305] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.059 seconds
[2023-01-05 23:31:26,375] {processor.py:153} INFO - Started process (PID=5518) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:31:26,376] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:31:26,377] {logging_mixin.py:115} INFO - [2023-01-05 23:31:26,376] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:31:27,274] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:31:27,276] {logging_mixin.py:115} INFO - [2023-01-05 23:31:27,276] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:31:27,276] {logging_mixin.py:115} INFO - [2023-01-05 23:31:27,276] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:31:27,283] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:31:27,306] {logging_mixin.py:115} INFO - [2023-01-05 23:31:27,306] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:31:27,329] {logging_mixin.py:115} INFO - [2023-01-05 23:31:27,329] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:31:27,339] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.969 seconds
[2023-01-05 23:31:57,424] {processor.py:153} INFO - Started process (PID=5542) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:31:57,426] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:31:57,426] {logging_mixin.py:115} INFO - [2023-01-05 23:31:57,426] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:31:58,385] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:31:58,386] {logging_mixin.py:115} INFO - [2023-01-05 23:31:58,386] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:31:58,387] {logging_mixin.py:115} INFO - [2023-01-05 23:31:58,387] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:31:58,394] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:31:58,418] {logging_mixin.py:115} INFO - [2023-01-05 23:31:58,418] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:31:58,439] {logging_mixin.py:115} INFO - [2023-01-05 23:31:58,439] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:31:58,449] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.030 seconds
[2023-01-05 23:32:28,542] {processor.py:153} INFO - Started process (PID=5566) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:32:28,543] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:32:28,544] {logging_mixin.py:115} INFO - [2023-01-05 23:32:28,544] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:32:29,542] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:32:29,544] {logging_mixin.py:115} INFO - [2023-01-05 23:32:29,543] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:32:29,544] {logging_mixin.py:115} INFO - [2023-01-05 23:32:29,544] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:32:29,551] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:32:29,574] {logging_mixin.py:115} INFO - [2023-01-05 23:32:29,574] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:32:29,595] {logging_mixin.py:115} INFO - [2023-01-05 23:32:29,595] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:32:29,605] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.067 seconds
[2023-01-05 23:32:59,679] {processor.py:153} INFO - Started process (PID=5590) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:32:59,680] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:32:59,681] {logging_mixin.py:115} INFO - [2023-01-05 23:32:59,681] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:33:00,611] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:33:00,613] {logging_mixin.py:115} INFO - [2023-01-05 23:33:00,612] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:33:00,613] {logging_mixin.py:115} INFO - [2023-01-05 23:33:00,613] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:33:00,623] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:33:00,647] {logging_mixin.py:115} INFO - [2023-01-05 23:33:00,646] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:33:00,667] {logging_mixin.py:115} INFO - [2023-01-05 23:33:00,667] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:33:00,677] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.003 seconds
[2023-01-05 23:33:30,752] {processor.py:153} INFO - Started process (PID=5608) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:33:30,753] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:33:30,754] {logging_mixin.py:115} INFO - [2023-01-05 23:33:30,754] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:33:31,674] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:33:31,676] {logging_mixin.py:115} INFO - [2023-01-05 23:33:31,676] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:33:31,676] {logging_mixin.py:115} INFO - [2023-01-05 23:33:31,676] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:33:31,683] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:33:31,707] {logging_mixin.py:115} INFO - [2023-01-05 23:33:31,707] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:33:31,729] {logging_mixin.py:115} INFO - [2023-01-05 23:33:31,729] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:33:31,739] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.992 seconds
[2023-01-05 23:34:01,776] {processor.py:153} INFO - Started process (PID=5635) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:34:01,777] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:34:01,778] {logging_mixin.py:115} INFO - [2023-01-05 23:34:01,777] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:34:02,708] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:34:02,710] {logging_mixin.py:115} INFO - [2023-01-05 23:34:02,709] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:34:02,710] {logging_mixin.py:115} INFO - [2023-01-05 23:34:02,710] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:34:02,717] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:34:02,740] {logging_mixin.py:115} INFO - [2023-01-05 23:34:02,739] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:34:02,761] {logging_mixin.py:115} INFO - [2023-01-05 23:34:02,761] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:34:02,770] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.999 seconds
[2023-01-05 23:34:32,849] {processor.py:153} INFO - Started process (PID=5659) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:34:32,852] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:34:32,852] {logging_mixin.py:115} INFO - [2023-01-05 23:34:32,852] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:34:33,835] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:34:33,836] {logging_mixin.py:115} INFO - [2023-01-05 23:34:33,836] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:34:33,837] {logging_mixin.py:115} INFO - [2023-01-05 23:34:33,836] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:34:33,844] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:34:33,873] {logging_mixin.py:115} INFO - [2023-01-05 23:34:33,873] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:34:33,895] {logging_mixin.py:115} INFO - [2023-01-05 23:34:33,895] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:34:33,906] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.062 seconds
[2023-01-05 23:35:03,983] {processor.py:153} INFO - Started process (PID=5684) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:35:03,984] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:35:03,985] {logging_mixin.py:115} INFO - [2023-01-05 23:35:03,985] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:35:04,983] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:35:04,985] {logging_mixin.py:115} INFO - [2023-01-05 23:35:04,985] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:35:04,986] {logging_mixin.py:115} INFO - [2023-01-05 23:35:04,986] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:35:04,995] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:35:05,019] {logging_mixin.py:115} INFO - [2023-01-05 23:35:05,018] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:35:05,040] {logging_mixin.py:115} INFO - [2023-01-05 23:35:05,040] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:35:05,050] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.074 seconds
[2023-01-05 23:35:35,122] {processor.py:153} INFO - Started process (PID=5703) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:35:35,123] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:35:35,125] {logging_mixin.py:115} INFO - [2023-01-05 23:35:35,125] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:35:36,059] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:35:36,061] {logging_mixin.py:115} INFO - [2023-01-05 23:35:36,061] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:35:36,061] {logging_mixin.py:115} INFO - [2023-01-05 23:35:36,061] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:35:36,068] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:35:36,092] {logging_mixin.py:115} INFO - [2023-01-05 23:35:36,092] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:35:36,113] {logging_mixin.py:115} INFO - [2023-01-05 23:35:36,113] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:35:36,124] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.007 seconds
[2023-01-05 23:36:06,201] {processor.py:153} INFO - Started process (PID=5729) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:36:06,202] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:36:06,203] {logging_mixin.py:115} INFO - [2023-01-05 23:36:06,203] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:36:07,130] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:36:07,131] {logging_mixin.py:115} INFO - [2023-01-05 23:36:07,131] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:36:07,132] {logging_mixin.py:115} INFO - [2023-01-05 23:36:07,131] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:36:07,139] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:36:07,162] {logging_mixin.py:115} INFO - [2023-01-05 23:36:07,162] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:36:07,185] {logging_mixin.py:115} INFO - [2023-01-05 23:36:07,185] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:36:07,195] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.000 seconds
[2023-01-05 23:36:37,269] {processor.py:153} INFO - Started process (PID=5755) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:36:37,271] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:36:37,272] {logging_mixin.py:115} INFO - [2023-01-05 23:36:37,272] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:36:38,232] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:36:38,233] {logging_mixin.py:115} INFO - [2023-01-05 23:36:38,233] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:36:38,234] {logging_mixin.py:115} INFO - [2023-01-05 23:36:38,234] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:36:38,241] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:36:38,265] {logging_mixin.py:115} INFO - [2023-01-05 23:36:38,265] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:36:38,286] {logging_mixin.py:115} INFO - [2023-01-05 23:36:38,286] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:36:38,296] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.031 seconds
[2023-01-05 23:37:08,375] {processor.py:153} INFO - Started process (PID=5773) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:37:08,376] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:37:08,377] {logging_mixin.py:115} INFO - [2023-01-05 23:37:08,377] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:37:09,349] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:37:09,350] {logging_mixin.py:115} INFO - [2023-01-05 23:37:09,350] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:37:09,351] {logging_mixin.py:115} INFO - [2023-01-05 23:37:09,351] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:37:09,363] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:37:09,386] {logging_mixin.py:115} INFO - [2023-01-05 23:37:09,386] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:37:09,407] {logging_mixin.py:115} INFO - [2023-01-05 23:37:09,407] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:37:09,417] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.047 seconds
[2023-01-05 23:37:39,504] {processor.py:153} INFO - Started process (PID=5798) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:37:39,505] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:37:39,507] {logging_mixin.py:115} INFO - [2023-01-05 23:37:39,507] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:37:40,424] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:37:40,425] {logging_mixin.py:115} INFO - [2023-01-05 23:37:40,425] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:37:40,426] {logging_mixin.py:115} INFO - [2023-01-05 23:37:40,425] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:37:40,433] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:37:40,456] {logging_mixin.py:115} INFO - [2023-01-05 23:37:40,455] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:37:40,478] {logging_mixin.py:115} INFO - [2023-01-05 23:37:40,478] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:37:40,488] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.990 seconds
[2023-01-05 23:38:10,522] {processor.py:153} INFO - Started process (PID=5823) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:38:10,522] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:38:10,524] {logging_mixin.py:115} INFO - [2023-01-05 23:38:10,524] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:38:11,531] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:38:11,532] {logging_mixin.py:115} INFO - [2023-01-05 23:38:11,532] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:38:11,533] {logging_mixin.py:115} INFO - [2023-01-05 23:38:11,532] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:38:11,540] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:38:11,566] {logging_mixin.py:115} INFO - [2023-01-05 23:38:11,566] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:38:11,588] {logging_mixin.py:115} INFO - [2023-01-05 23:38:11,588] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:38:11,599] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.083 seconds
[2023-01-05 23:38:41,673] {processor.py:153} INFO - Started process (PID=5848) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:38:41,677] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:38:41,678] {logging_mixin.py:115} INFO - [2023-01-05 23:38:41,678] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:38:42,592] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:38:42,593] {logging_mixin.py:115} INFO - [2023-01-05 23:38:42,593] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:38:42,594] {logging_mixin.py:115} INFO - [2023-01-05 23:38:42,593] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:38:42,601] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:38:42,624] {logging_mixin.py:115} INFO - [2023-01-05 23:38:42,624] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:38:42,645] {logging_mixin.py:115} INFO - [2023-01-05 23:38:42,645] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:38:42,655] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.988 seconds
[2023-01-05 23:39:12,742] {processor.py:153} INFO - Started process (PID=5866) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:39:12,743] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:39:12,745] {logging_mixin.py:115} INFO - [2023-01-05 23:39:12,744] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:39:13,708] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:39:13,709] {logging_mixin.py:115} INFO - [2023-01-05 23:39:13,709] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:39:13,710] {logging_mixin.py:115} INFO - [2023-01-05 23:39:13,709] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:39:13,717] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:39:13,746] {logging_mixin.py:115} INFO - [2023-01-05 23:39:13,746] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:39:13,778] {logging_mixin.py:115} INFO - [2023-01-05 23:39:13,778] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:39:13,791] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.055 seconds
[2023-01-05 23:39:43,867] {processor.py:153} INFO - Started process (PID=5892) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:39:43,870] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:39:43,871] {logging_mixin.py:115} INFO - [2023-01-05 23:39:43,871] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:39:44,804] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:39:44,805] {logging_mixin.py:115} INFO - [2023-01-05 23:39:44,805] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:39:44,806] {logging_mixin.py:115} INFO - [2023-01-05 23:39:44,806] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:39:44,813] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:39:44,836] {logging_mixin.py:115} INFO - [2023-01-05 23:39:44,836] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:39:44,858] {logging_mixin.py:115} INFO - [2023-01-05 23:39:44,858] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:39:44,868] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.005 seconds
[2023-01-05 23:40:14,941] {processor.py:153} INFO - Started process (PID=5917) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:40:14,942] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:40:14,943] {logging_mixin.py:115} INFO - [2023-01-05 23:40:14,943] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:40:15,871] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:40:15,873] {logging_mixin.py:115} INFO - [2023-01-05 23:40:15,873] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:40:15,873] {logging_mixin.py:115} INFO - [2023-01-05 23:40:15,873] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:40:15,880] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:40:15,903] {logging_mixin.py:115} INFO - [2023-01-05 23:40:15,902] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:40:15,924] {logging_mixin.py:115} INFO - [2023-01-05 23:40:15,924] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:40:15,934] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.999 seconds
[2023-01-05 23:40:46,011] {processor.py:153} INFO - Started process (PID=5942) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:40:46,012] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:40:46,013] {logging_mixin.py:115} INFO - [2023-01-05 23:40:46,013] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:40:46,915] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:40:46,916] {logging_mixin.py:115} INFO - [2023-01-05 23:40:46,916] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:40:46,917] {logging_mixin.py:115} INFO - [2023-01-05 23:40:46,916] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:40:46,924] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:40:46,947] {logging_mixin.py:115} INFO - [2023-01-05 23:40:46,946] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:40:46,968] {logging_mixin.py:115} INFO - [2023-01-05 23:40:46,968] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:40:46,978] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.973 seconds
[2023-01-05 23:41:17,046] {processor.py:153} INFO - Started process (PID=5961) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:41:17,047] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:41:17,048] {logging_mixin.py:115} INFO - [2023-01-05 23:41:17,048] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:41:17,988] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:41:17,990] {logging_mixin.py:115} INFO - [2023-01-05 23:41:17,989] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:41:17,990] {logging_mixin.py:115} INFO - [2023-01-05 23:41:17,990] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:41:17,997] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:41:18,026] {logging_mixin.py:115} INFO - [2023-01-05 23:41:18,025] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:41:18,053] {logging_mixin.py:115} INFO - [2023-01-05 23:41:18,053] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:41:18,070] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.029 seconds
[2023-01-05 23:41:48,140] {processor.py:153} INFO - Started process (PID=5987) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:41:48,143] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:41:48,144] {logging_mixin.py:115} INFO - [2023-01-05 23:41:48,143] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:41:49,107] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:41:49,109] {logging_mixin.py:115} INFO - [2023-01-05 23:41:49,109] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:41:49,109] {logging_mixin.py:115} INFO - [2023-01-05 23:41:49,109] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:41:49,116] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:41:49,145] {logging_mixin.py:115} INFO - [2023-01-05 23:41:49,145] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:41:49,173] {logging_mixin.py:115} INFO - [2023-01-05 23:41:49,173] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:41:49,184] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.049 seconds
[2023-01-05 23:42:19,258] {processor.py:153} INFO - Started process (PID=6013) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:42:19,260] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:42:19,260] {logging_mixin.py:115} INFO - [2023-01-05 23:42:19,260] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:42:20,242] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:42:20,243] {logging_mixin.py:115} INFO - [2023-01-05 23:42:20,243] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:42:20,244] {logging_mixin.py:115} INFO - [2023-01-05 23:42:20,243] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:42:20,251] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:42:20,278] {logging_mixin.py:115} INFO - [2023-01-05 23:42:20,278] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:42:20,300] {logging_mixin.py:115} INFO - [2023-01-05 23:42:20,300] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:42:20,309] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.056 seconds
[2023-01-05 23:42:50,383] {processor.py:153} INFO - Started process (PID=6038) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:42:50,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:42:50,385] {logging_mixin.py:115} INFO - [2023-01-05 23:42:50,385] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:42:51,302] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:42:51,304] {logging_mixin.py:115} INFO - [2023-01-05 23:42:51,304] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:42:51,304] {logging_mixin.py:115} INFO - [2023-01-05 23:42:51,304] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:42:51,311] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:42:51,334] {logging_mixin.py:115} INFO - [2023-01-05 23:42:51,334] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:42:51,355] {logging_mixin.py:115} INFO - [2023-01-05 23:42:51,355] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:42:51,365] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.987 seconds
[2023-01-05 23:43:21,447] {processor.py:153} INFO - Started process (PID=6055) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:43:21,449] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:43:21,449] {logging_mixin.py:115} INFO - [2023-01-05 23:43:21,449] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:43:22,373] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:43:22,374] {logging_mixin.py:115} INFO - [2023-01-05 23:43:22,374] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:43:22,375] {logging_mixin.py:115} INFO - [2023-01-05 23:43:22,375] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:43:22,382] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:43:22,404] {logging_mixin.py:115} INFO - [2023-01-05 23:43:22,404] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:43:22,425] {logging_mixin.py:115} INFO - [2023-01-05 23:43:22,425] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:43:22,436] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.994 seconds
[2023-01-05 23:43:52,519] {processor.py:153} INFO - Started process (PID=6081) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:43:52,521] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:43:52,522] {logging_mixin.py:115} INFO - [2023-01-05 23:43:52,522] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:43:53,475] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:43:53,477] {logging_mixin.py:115} INFO - [2023-01-05 23:43:53,477] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:43:53,477] {logging_mixin.py:115} INFO - [2023-01-05 23:43:53,477] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:43:53,490] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:43:53,514] {logging_mixin.py:115} INFO - [2023-01-05 23:43:53,514] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:43:53,536] {logging_mixin.py:115} INFO - [2023-01-05 23:43:53,536] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:43:53,546] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.032 seconds
[2023-01-05 23:44:23,616] {processor.py:153} INFO - Started process (PID=6106) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:44:23,617] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:44:23,618] {logging_mixin.py:115} INFO - [2023-01-05 23:44:23,617] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:44:24,533] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:44:24,534] {logging_mixin.py:115} INFO - [2023-01-05 23:44:24,534] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:44:24,535] {logging_mixin.py:115} INFO - [2023-01-05 23:44:24,534] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:44:24,542] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:44:24,566] {logging_mixin.py:115} INFO - [2023-01-05 23:44:24,565] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:44:24,586] {logging_mixin.py:115} INFO - [2023-01-05 23:44:24,586] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:44:24,597] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.985 seconds
[2023-01-05 23:44:54,686] {processor.py:153} INFO - Started process (PID=6131) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:44:54,687] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:44:54,688] {logging_mixin.py:115} INFO - [2023-01-05 23:44:54,688] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:44:55,609] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:44:55,611] {logging_mixin.py:115} INFO - [2023-01-05 23:44:55,610] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:44:55,611] {logging_mixin.py:115} INFO - [2023-01-05 23:44:55,611] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:44:55,618] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:44:55,642] {logging_mixin.py:115} INFO - [2023-01-05 23:44:55,642] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:44:55,664] {logging_mixin.py:115} INFO - [2023-01-05 23:44:55,664] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:44:55,675] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.994 seconds
[2023-01-05 23:45:25,722] {processor.py:153} INFO - Started process (PID=6149) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:45:25,722] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:45:25,723] {logging_mixin.py:115} INFO - [2023-01-05 23:45:25,723] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:45:26,652] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:45:26,653] {logging_mixin.py:115} INFO - [2023-01-05 23:45:26,653] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:45:26,654] {logging_mixin.py:115} INFO - [2023-01-05 23:45:26,654] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:45:26,661] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:45:26,684] {logging_mixin.py:115} INFO - [2023-01-05 23:45:26,683] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:45:26,705] {logging_mixin.py:115} INFO - [2023-01-05 23:45:26,705] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:45:26,715] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.999 seconds
[2023-01-05 23:45:56,797] {processor.py:153} INFO - Started process (PID=6174) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:45:56,798] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:45:56,799] {logging_mixin.py:115} INFO - [2023-01-05 23:45:56,799] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:45:57,706] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:45:57,707] {logging_mixin.py:115} INFO - [2023-01-05 23:45:57,707] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:45:57,707] {logging_mixin.py:115} INFO - [2023-01-05 23:45:57,707] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:45:57,714] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:45:57,737] {logging_mixin.py:115} INFO - [2023-01-05 23:45:57,737] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:45:57,759] {logging_mixin.py:115} INFO - [2023-01-05 23:45:57,759] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:45:57,769] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.978 seconds
[2023-01-05 23:46:27,802] {processor.py:153} INFO - Started process (PID=6199) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:46:27,803] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:46:27,804] {logging_mixin.py:115} INFO - [2023-01-05 23:46:27,804] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:46:28,740] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:46:28,741] {logging_mixin.py:115} INFO - [2023-01-05 23:46:28,741] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:46:28,742] {logging_mixin.py:115} INFO - [2023-01-05 23:46:28,741] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:46:28,749] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:46:28,771] {logging_mixin.py:115} INFO - [2023-01-05 23:46:28,771] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:46:28,791] {logging_mixin.py:115} INFO - [2023-01-05 23:46:28,791] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:46:28,801] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.004 seconds
[2023-01-05 23:46:58,877] {processor.py:153} INFO - Started process (PID=6224) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:46:58,878] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:46:58,879] {logging_mixin.py:115} INFO - [2023-01-05 23:46:58,878] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:46:59,854] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:46:59,856] {logging_mixin.py:115} INFO - [2023-01-05 23:46:59,856] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:46:59,856] {logging_mixin.py:115} INFO - [2023-01-05 23:46:59,856] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:46:59,863] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:46:59,887] {logging_mixin.py:115} INFO - [2023-01-05 23:46:59,886] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:46:59,909] {logging_mixin.py:115} INFO - [2023-01-05 23:46:59,909] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:46:59,919] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.047 seconds
[2023-01-05 23:47:29,997] {processor.py:153} INFO - Started process (PID=6241) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:47:29,999] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:47:30,000] {logging_mixin.py:115} INFO - [2023-01-05 23:47:29,999] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:47:30,903] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:47:30,904] {logging_mixin.py:115} INFO - [2023-01-05 23:47:30,904] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:47:30,904] {logging_mixin.py:115} INFO - [2023-01-05 23:47:30,904] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:47:30,911] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:47:30,934] {logging_mixin.py:115} INFO - [2023-01-05 23:47:30,934] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:47:30,954] {logging_mixin.py:115} INFO - [2023-01-05 23:47:30,954] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:47:30,964] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.972 seconds
[2023-01-05 23:48:01,034] {processor.py:153} INFO - Started process (PID=6266) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:48:01,035] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:48:01,035] {logging_mixin.py:115} INFO - [2023-01-05 23:48:01,035] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:48:01,968] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:48:01,970] {logging_mixin.py:115} INFO - [2023-01-05 23:48:01,970] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:48:01,970] {logging_mixin.py:115} INFO - [2023-01-05 23:48:01,970] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:48:01,977] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:48:02,002] {logging_mixin.py:115} INFO - [2023-01-05 23:48:02,002] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:48:02,024] {logging_mixin.py:115} INFO - [2023-01-05 23:48:02,023] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:48:02,034] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.005 seconds
[2023-01-05 23:48:32,081] {processor.py:153} INFO - Started process (PID=6291) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:48:32,082] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:48:32,083] {logging_mixin.py:115} INFO - [2023-01-05 23:48:32,083] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:48:33,084] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:48:33,086] {logging_mixin.py:115} INFO - [2023-01-05 23:48:33,085] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:48:33,086] {logging_mixin.py:115} INFO - [2023-01-05 23:48:33,086] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:48:33,093] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:48:33,116] {logging_mixin.py:115} INFO - [2023-01-05 23:48:33,116] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:48:33,138] {logging_mixin.py:115} INFO - [2023-01-05 23:48:33,138] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:48:33,148] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.073 seconds
[2023-01-05 23:49:03,228] {processor.py:153} INFO - Started process (PID=6317) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:49:03,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:49:03,231] {logging_mixin.py:115} INFO - [2023-01-05 23:49:03,231] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:49:04,198] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:49:04,200] {logging_mixin.py:115} INFO - [2023-01-05 23:49:04,200] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:49:04,200] {logging_mixin.py:115} INFO - [2023-01-05 23:49:04,200] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:49:04,207] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:49:04,231] {logging_mixin.py:115} INFO - [2023-01-05 23:49:04,231] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:49:04,253] {logging_mixin.py:115} INFO - [2023-01-05 23:49:04,253] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:49:04,264] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.042 seconds
[2023-01-05 23:49:34,334] {processor.py:153} INFO - Started process (PID=6335) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:49:34,335] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:49:34,336] {logging_mixin.py:115} INFO - [2023-01-05 23:49:34,336] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:49:35,264] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:49:35,266] {logging_mixin.py:115} INFO - [2023-01-05 23:49:35,265] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:49:35,266] {logging_mixin.py:115} INFO - [2023-01-05 23:49:35,266] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:49:35,273] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:49:35,296] {logging_mixin.py:115} INFO - [2023-01-05 23:49:35,296] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:49:35,318] {logging_mixin.py:115} INFO - [2023-01-05 23:49:35,318] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:49:35,328] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.999 seconds
[2023-01-05 23:50:05,400] {processor.py:153} INFO - Started process (PID=6361) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:50:05,402] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:50:05,402] {logging_mixin.py:115} INFO - [2023-01-05 23:50:05,402] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:50:06,340] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:50:06,342] {logging_mixin.py:115} INFO - [2023-01-05 23:50:06,342] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:50:06,342] {logging_mixin.py:115} INFO - [2023-01-05 23:50:06,342] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:50:06,349] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:50:06,375] {logging_mixin.py:115} INFO - [2023-01-05 23:50:06,374] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:50:06,398] {logging_mixin.py:115} INFO - [2023-01-05 23:50:06,398] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:50:06,408] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.013 seconds
[2023-01-05 23:50:36,448] {processor.py:153} INFO - Started process (PID=6387) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:50:36,451] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:50:36,451] {logging_mixin.py:115} INFO - [2023-01-05 23:50:36,451] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:50:37,411] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:50:37,412] {logging_mixin.py:115} INFO - [2023-01-05 23:50:37,412] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:50:37,413] {logging_mixin.py:115} INFO - [2023-01-05 23:50:37,412] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:50:37,420] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:50:37,449] {logging_mixin.py:115} INFO - [2023-01-05 23:50:37,449] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:50:37,479] {logging_mixin.py:115} INFO - [2023-01-05 23:50:37,479] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:50:37,492] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.048 seconds
[2023-01-05 23:51:07,567] {processor.py:153} INFO - Started process (PID=6412) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:51:07,569] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:51:07,569] {logging_mixin.py:115} INFO - [2023-01-05 23:51:07,569] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:51:08,511] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:51:08,513] {logging_mixin.py:115} INFO - [2023-01-05 23:51:08,513] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:51:08,513] {logging_mixin.py:115} INFO - [2023-01-05 23:51:08,513] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:51:08,520] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:51:08,544] {logging_mixin.py:115} INFO - [2023-01-05 23:51:08,544] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:51:08,567] {logging_mixin.py:115} INFO - [2023-01-05 23:51:08,566] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:51:08,577] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.014 seconds
[2023-01-05 23:51:38,648] {processor.py:153} INFO - Started process (PID=6431) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:51:38,651] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:51:38,651] {logging_mixin.py:115} INFO - [2023-01-05 23:51:38,651] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:51:39,584] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:51:39,586] {logging_mixin.py:115} INFO - [2023-01-05 23:51:39,586] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:51:39,586] {logging_mixin.py:115} INFO - [2023-01-05 23:51:39,586] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:51:39,593] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:51:39,617] {logging_mixin.py:115} INFO - [2023-01-05 23:51:39,616] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:51:39,638] {logging_mixin.py:115} INFO - [2023-01-05 23:51:39,638] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:51:39,647] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.004 seconds
[2023-01-05 23:52:09,718] {processor.py:153} INFO - Started process (PID=6455) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:52:09,719] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:52:09,720] {logging_mixin.py:115} INFO - [2023-01-05 23:52:09,720] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:52:10,667] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:52:10,669] {logging_mixin.py:115} INFO - [2023-01-05 23:52:10,669] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:52:10,669] {logging_mixin.py:115} INFO - [2023-01-05 23:52:10,669] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:52:10,676] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:52:10,700] {logging_mixin.py:115} INFO - [2023-01-05 23:52:10,700] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:52:10,721] {logging_mixin.py:115} INFO - [2023-01-05 23:52:10,721] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:52:10,731] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.019 seconds
[2023-01-05 23:52:40,771] {processor.py:153} INFO - Started process (PID=6481) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:52:40,773] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:52:40,774] {logging_mixin.py:115} INFO - [2023-01-05 23:52:40,774] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:52:41,717] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:52:41,718] {logging_mixin.py:115} INFO - [2023-01-05 23:52:41,718] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:52:41,719] {logging_mixin.py:115} INFO - [2023-01-05 23:52:41,718] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:52:41,725] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:52:41,748] {logging_mixin.py:115} INFO - [2023-01-05 23:52:41,747] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:52:41,769] {logging_mixin.py:115} INFO - [2023-01-05 23:52:41,768] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:52:41,779] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.013 seconds
[2023-01-05 23:53:11,863] {processor.py:153} INFO - Started process (PID=6505) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:53:11,864] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:53:11,864] {logging_mixin.py:115} INFO - [2023-01-05 23:53:11,864] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:53:12,787] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:53:12,788] {logging_mixin.py:115} INFO - [2023-01-05 23:53:12,788] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:53:12,789] {logging_mixin.py:115} INFO - [2023-01-05 23:53:12,789] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:53:12,796] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:53:12,820] {logging_mixin.py:115} INFO - [2023-01-05 23:53:12,820] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:53:12,842] {logging_mixin.py:115} INFO - [2023-01-05 23:53:12,841] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:53:12,854] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-05 23:53:42,932] {processor.py:153} INFO - Started process (PID=6523) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:53:42,934] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:53:42,935] {logging_mixin.py:115} INFO - [2023-01-05 23:53:42,935] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:53:43,846] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:53:43,847] {logging_mixin.py:115} INFO - [2023-01-05 23:53:43,847] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:53:43,848] {logging_mixin.py:115} INFO - [2023-01-05 23:53:43,848] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:53:43,855] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:53:43,877] {logging_mixin.py:115} INFO - [2023-01-05 23:53:43,877] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:53:43,898] {logging_mixin.py:115} INFO - [2023-01-05 23:53:43,898] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:53:43,908] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.981 seconds
[2023-01-05 23:54:13,981] {processor.py:153} INFO - Started process (PID=6549) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:54:13,982] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:54:13,983] {logging_mixin.py:115} INFO - [2023-01-05 23:54:13,982] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:54:14,899] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:54:14,901] {logging_mixin.py:115} INFO - [2023-01-05 23:54:14,901] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:54:14,901] {logging_mixin.py:115} INFO - [2023-01-05 23:54:14,901] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:54:14,908] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:54:14,934] {logging_mixin.py:115} INFO - [2023-01-05 23:54:14,934] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:54:14,957] {logging_mixin.py:115} INFO - [2023-01-05 23:54:14,957] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:54:14,967] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.991 seconds
[2023-01-05 23:54:45,051] {processor.py:153} INFO - Started process (PID=6575) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:54:45,052] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:54:45,053] {logging_mixin.py:115} INFO - [2023-01-05 23:54:45,052] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:54:45,992] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:54:45,993] {logging_mixin.py:115} INFO - [2023-01-05 23:54:45,993] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:54:45,993] {logging_mixin.py:115} INFO - [2023-01-05 23:54:45,993] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:54:46,000] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:54:46,024] {logging_mixin.py:115} INFO - [2023-01-05 23:54:46,023] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:54:46,045] {logging_mixin.py:115} INFO - [2023-01-05 23:54:46,045] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:54:46,055] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.009 seconds
[2023-01-05 23:55:16,126] {processor.py:153} INFO - Started process (PID=6599) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:55:16,128] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:55:16,128] {logging_mixin.py:115} INFO - [2023-01-05 23:55:16,128] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:55:17,101] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:55:17,102] {logging_mixin.py:115} INFO - [2023-01-05 23:55:17,102] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:55:17,102] {logging_mixin.py:115} INFO - [2023-01-05 23:55:17,102] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:55:17,109] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:55:17,132] {logging_mixin.py:115} INFO - [2023-01-05 23:55:17,132] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:55:17,154] {logging_mixin.py:115} INFO - [2023-01-05 23:55:17,154] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:55:17,164] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.043 seconds
[2023-01-05 23:55:47,235] {processor.py:153} INFO - Started process (PID=6617) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:55:47,236] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:55:47,237] {logging_mixin.py:115} INFO - [2023-01-05 23:55:47,237] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:55:48,180] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:55:48,181] {logging_mixin.py:115} INFO - [2023-01-05 23:55:48,181] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:55:48,182] {logging_mixin.py:115} INFO - [2023-01-05 23:55:48,181] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:55:48,189] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:55:48,218] {logging_mixin.py:115} INFO - [2023-01-05 23:55:48,218] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:55:48,247] {logging_mixin.py:115} INFO - [2023-01-05 23:55:48,247] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:55:48,257] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.026 seconds
[2023-01-05 23:56:18,328] {processor.py:153} INFO - Started process (PID=6642) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:56:18,329] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:56:18,330] {logging_mixin.py:115} INFO - [2023-01-05 23:56:18,330] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:56:19,257] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:56:19,258] {logging_mixin.py:115} INFO - [2023-01-05 23:56:19,258] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:56:19,258] {logging_mixin.py:115} INFO - [2023-01-05 23:56:19,258] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:56:19,265] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:56:19,288] {logging_mixin.py:115} INFO - [2023-01-05 23:56:19,288] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:56:19,309] {logging_mixin.py:115} INFO - [2023-01-05 23:56:19,308] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:56:19,319] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.996 seconds
[2023-01-05 23:56:49,416] {processor.py:153} INFO - Started process (PID=6667) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:56:49,417] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:56:49,417] {logging_mixin.py:115} INFO - [2023-01-05 23:56:49,417] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:56:50,367] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:56:50,369] {logging_mixin.py:115} INFO - [2023-01-05 23:56:50,368] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:56:50,369] {logging_mixin.py:115} INFO - [2023-01-05 23:56:50,369] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:56:50,376] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:56:50,401] {logging_mixin.py:115} INFO - [2023-01-05 23:56:50,401] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:56:50,424] {logging_mixin.py:115} INFO - [2023-01-05 23:56:50,423] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:56:50,434] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.023 seconds
[2023-01-05 23:57:20,520] {processor.py:153} INFO - Started process (PID=6691) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:57:20,521] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:57:20,522] {logging_mixin.py:115} INFO - [2023-01-05 23:57:20,522] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:57:21,752] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:57:21,753] {logging_mixin.py:115} INFO - [2023-01-05 23:57:21,753] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:57:21,754] {logging_mixin.py:115} INFO - [2023-01-05 23:57:21,754] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:57:21,766] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:57:21,796] {logging_mixin.py:115} INFO - [2023-01-05 23:57:21,796] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:57:21,826] {logging_mixin.py:115} INFO - [2023-01-05 23:57:21,826] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:57:21,839] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.324 seconds
[2023-01-05 23:57:51,917] {processor.py:153} INFO - Started process (PID=6710) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:57:51,918] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:57:51,918] {logging_mixin.py:115} INFO - [2023-01-05 23:57:51,918] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:57:52,818] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:57:52,819] {logging_mixin.py:115} INFO - [2023-01-05 23:57:52,819] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:57:52,820] {logging_mixin.py:115} INFO - [2023-01-05 23:57:52,819] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:57:52,826] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:57:52,849] {logging_mixin.py:115} INFO - [2023-01-05 23:57:52,849] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:57:52,870] {logging_mixin.py:115} INFO - [2023-01-05 23:57:52,870] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:57:52,879] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.967 seconds
[2023-01-05 23:58:23,560] {processor.py:153} INFO - Started process (PID=6737) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:58:23,561] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:58:23,562] {logging_mixin.py:115} INFO - [2023-01-05 23:58:23,562] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:58:24,496] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:58:24,497] {logging_mixin.py:115} INFO - [2023-01-05 23:58:24,497] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:58:24,498] {logging_mixin.py:115} INFO - [2023-01-05 23:58:24,497] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:58:24,505] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:58:24,530] {logging_mixin.py:115} INFO - [2023-01-05 23:58:24,529] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:58:24,551] {logging_mixin.py:115} INFO - [2023-01-05 23:58:24,551] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:58:24,561] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.007 seconds
[2023-01-05 23:58:54,633] {processor.py:153} INFO - Started process (PID=6762) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:58:54,634] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:58:54,634] {logging_mixin.py:115} INFO - [2023-01-05 23:58:54,634] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:58:55,788] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:58:55,790] {logging_mixin.py:115} INFO - [2023-01-05 23:58:55,790] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:58:55,791] {logging_mixin.py:115} INFO - [2023-01-05 23:58:55,790] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:58:55,802] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:58:55,831] {logging_mixin.py:115} INFO - [2023-01-05 23:58:55,831] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:58:55,853] {logging_mixin.py:115} INFO - [2023-01-05 23:58:55,853] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:58:55,863] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.235 seconds
[2023-01-05 23:59:25,937] {processor.py:153} INFO - Started process (PID=6788) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:59:25,939] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:59:25,939] {logging_mixin.py:115} INFO - [2023-01-05 23:59:25,939] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:59:26,874] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:59:26,875] {logging_mixin.py:115} INFO - [2023-01-05 23:59:26,875] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:59:26,876] {logging_mixin.py:115} INFO - [2023-01-05 23:59:26,876] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:59:26,883] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:59:26,906] {logging_mixin.py:115} INFO - [2023-01-05 23:59:26,905] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:59:26,930] {logging_mixin.py:115} INFO - [2023-01-05 23:59:26,930] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:59:26,940] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 1.009 seconds
[2023-01-05 23:59:57,013] {processor.py:153} INFO - Started process (PID=6805) to work on /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:59:57,014] {processor.py:641} INFO - Processing file /opt/airflow/dags/stock_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:59:57,015] {logging_mixin.py:115} INFO - [2023-01-05 23:59:57,015] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:59:57,919] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:59:57,921] {logging_mixin.py:115} INFO - [2023-01-05 23:59:57,921] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:59:57,921] {logging_mixin.py:115} INFO - [2023-01-05 23:59:57,921] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:59:57,932] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/stock_data_pipeline_dag.py
[2023-01-05 23:59:57,956] {logging_mixin.py:115} INFO - [2023-01-05 23:59:57,956] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:59:57,978] {logging_mixin.py:115} INFO - [2023-01-05 23:59:57,978] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T23:15:00+00:00, run_after=2023-01-06T23:15:00+00:00
[2023-01-05 23:59:57,989] {processor.py:161} INFO - Processing /opt/airflow/dags/stock_data_pipeline_dag.py took 0.980 seconds

[2023-01-05 02:51:32,755] {processor.py:153} INFO - Started process (PID=33) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:51:32,756] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:51:32,757] {logging_mixin.py:115} INFO - [2023-01-05 02:51:32,757] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:51:37,673] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:51:37,674] {logging_mixin.py:115} INFO - [2023-01-05 02:51:37,674] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:51:37,675] {logging_mixin.py:115} INFO - [2023-01-05 02:51:37,675] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:51:37,688] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:51:37,797] {logging_mixin.py:115} INFO - [2023-01-05 02:51:37,797] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:51:37,860] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 5.113 seconds
[2023-01-05 02:52:07,949] {processor.py:153} INFO - Started process (PID=57) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:52:07,951] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:52:07,952] {logging_mixin.py:115} INFO - [2023-01-05 02:52:07,952] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:52:09,292] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:52:09,294] {logging_mixin.py:115} INFO - [2023-01-05 02:52:09,294] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:52:09,295] {logging_mixin.py:115} INFO - [2023-01-05 02:52:09,294] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:52:09,302] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:52:09,326] {logging_mixin.py:115} INFO - [2023-01-05 02:52:09,326] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:52:09,350] {logging_mixin.py:115} INFO - [2023-01-05 02:52:09,350] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 02:52:09,364] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.421 seconds
[2023-01-05 02:52:39,458] {processor.py:153} INFO - Started process (PID=84) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:52:39,459] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:52:39,460] {logging_mixin.py:115} INFO - [2023-01-05 02:52:39,459] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:52:40,938] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:52:40,940] {logging_mixin.py:115} INFO - [2023-01-05 02:52:40,940] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:52:40,940] {logging_mixin.py:115} INFO - [2023-01-05 02:52:40,940] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:52:40,949] {processor.py:651} INFO - DAG(s) dict_keys(['stock_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:52:40,988] {logging_mixin.py:115} INFO - [2023-01-05 02:52:40,987] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:52:41,023] {logging_mixin.py:115} INFO - [2023-01-05 02:52:41,023] {dag.py:2927} INFO - Setting next_dagrun for stock_data_pipeline_dag to 2023-01-05T01:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 02:52:41,041] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.590 seconds
[2023-01-05 02:52:48,705] {processor.py:153} INFO - Started process (PID=86) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:52:48,709] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:52:48,710] {logging_mixin.py:115} INFO - [2023-01-05 02:52:48,710] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:52:49,725] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:52:49,727] {logging_mixin.py:115} INFO - [2023-01-05 02:52:49,727] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:52:49,728] {logging_mixin.py:115} INFO - [2023-01-05 02:52:49,727] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:52:49,735] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:52:49,813] {logging_mixin.py:115} INFO - [2023-01-05 02:52:49,813] {manager.py:508} INFO - Created Permission View: can read on DAG:btc_data_pipeline_dag
[2023-01-05 02:52:49,824] {logging_mixin.py:115} INFO - [2023-01-05 02:52:49,824] {manager.py:508} INFO - Created Permission View: can edit on DAG:btc_data_pipeline_dag
[2023-01-05 02:52:49,831] {logging_mixin.py:115} INFO - [2023-01-05 02:52:49,831] {manager.py:508} INFO - Created Permission View: can delete on DAG:btc_data_pipeline_dag
[2023-01-05 02:52:49,832] {logging_mixin.py:115} INFO - [2023-01-05 02:52:49,831] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:52:49,841] {logging_mixin.py:115} INFO - [2023-01-05 02:52:49,841] {dag.py:2398} INFO - Creating ORM DAG for btc_data_pipeline_dag
[2023-01-05 02:52:50,051] {logging_mixin.py:115} INFO - [2023-01-05 02:52:50,051] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T23:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 02:52:50,066] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.366 seconds
[2023-01-05 02:53:14,153] {processor.py:153} INFO - Started process (PID=103) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:53:14,154] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:53:14,154] {logging_mixin.py:115} INFO - [2023-01-05 02:53:14,154] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:53:15,287] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:53:15,289] {logging_mixin.py:115} INFO - [2023-01-05 02:53:15,289] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:53:15,290] {logging_mixin.py:115} INFO - [2023-01-05 02:53:15,289] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:53:15,297] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:53:15,312] {logging_mixin.py:115} INFO - [2023-01-05 02:53:15,311] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:53:15,335] {logging_mixin.py:115} INFO - [2023-01-05 02:53:15,335] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T23:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 02:53:15,348] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.200 seconds
[2023-01-05 02:53:45,386] {processor.py:153} INFO - Started process (PID=128) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:53:45,389] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:53:45,390] {logging_mixin.py:115} INFO - [2023-01-05 02:53:45,389] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:53:46,357] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:53:46,359] {logging_mixin.py:115} INFO - [2023-01-05 02:53:46,359] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:53:46,359] {logging_mixin.py:115} INFO - [2023-01-05 02:53:46,359] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:53:46,366] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:53:46,425] {logging_mixin.py:115} INFO - [2023-01-05 02:53:46,425] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:53:46,446] {logging_mixin.py:115} INFO - [2023-01-05 02:53:46,445] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T23:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 02:53:46,458] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.077 seconds
[2023-01-05 02:54:16,517] {processor.py:153} INFO - Started process (PID=152) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:54:16,518] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:54:16,518] {logging_mixin.py:115} INFO - [2023-01-05 02:54:16,518] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:54:17,507] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:54:17,508] {logging_mixin.py:115} INFO - [2023-01-05 02:54:17,508] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:54:17,509] {logging_mixin.py:115} INFO - [2023-01-05 02:54:17,509] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:54:17,516] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:54:17,541] {logging_mixin.py:115} INFO - [2023-01-05 02:54:17,541] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:54:17,564] {logging_mixin.py:115} INFO - [2023-01-05 02:54:17,564] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T23:00:00+00:00, run_after=2023-01-05T23:00:00+00:00
[2023-01-05 02:54:17,575] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.063 seconds
[2023-01-05 02:54:35,581] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:54:35,589] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:54:35,590] {logging_mixin.py:115} INFO - [2023-01-05 02:54:35,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:54:36,779] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:54:36,781] {logging_mixin.py:115} INFO - [2023-01-05 02:54:36,781] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:54:36,781] {logging_mixin.py:115} INFO - [2023-01-05 02:54:36,781] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:54:36,788] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:54:36,846] {logging_mixin.py:115} INFO - [2023-01-05 02:54:36,846] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:54:36,866] {logging_mixin.py:115} INFO - [2023-01-05 02:54:36,866] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 02:54:36,880] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.306 seconds
[2023-01-05 02:55:07,717] {processor.py:153} INFO - Started process (PID=187) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:55:07,718] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:55:07,719] {logging_mixin.py:115} INFO - [2023-01-05 02:55:07,719] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:55:08,719] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:55:08,721] {logging_mixin.py:115} INFO - [2023-01-05 02:55:08,721] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:55:08,722] {logging_mixin.py:115} INFO - [2023-01-05 02:55:08,721] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:55:08,730] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:55:08,769] {logging_mixin.py:115} INFO - [2023-01-05 02:55:08,768] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:55:08,793] {logging_mixin.py:115} INFO - [2023-01-05 02:55:08,793] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 02:55:08,803] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.091 seconds
[2023-01-05 02:55:38,837] {processor.py:153} INFO - Started process (PID=212) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:55:38,838] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:55:38,839] {logging_mixin.py:115} INFO - [2023-01-05 02:55:38,839] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:55:39,842] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:55:39,844] {logging_mixin.py:115} INFO - [2023-01-05 02:55:39,844] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:55:39,844] {logging_mixin.py:115} INFO - [2023-01-05 02:55:39,844] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:55:39,851] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:55:39,875] {logging_mixin.py:115} INFO - [2023-01-05 02:55:39,875] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:55:39,897] {logging_mixin.py:115} INFO - [2023-01-05 02:55:39,897] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 02:55:39,907] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.075 seconds
[2023-01-05 02:55:48,871] {processor.py:153} INFO - Started process (PID=224) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:55:48,872] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:55:48,872] {logging_mixin.py:115} INFO - [2023-01-05 02:55:48,872] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:55:48,879] {logging_mixin.py:115} INFO - [2023-01-05 02:55:48,878] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 3, in <module>
    import Move_Current_BTC_Data_From_GCS_to_BigQuery
  File "/opt/airflow/dags/Move_Current_BTC_Data_From_GCS_to_BigQuery.py", line 1, in <module>
    import pyspark
ModuleNotFoundError: No module named 'pyspark'
[2023-01-05 02:55:48,879] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:55:48,908] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.042 seconds
[2023-01-05 02:56:19,014] {processor.py:153} INFO - Started process (PID=248) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:56:19,020] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:56:19,021] {logging_mixin.py:115} INFO - [2023-01-05 02:56:19,021] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:56:19,031] {logging_mixin.py:115} INFO - [2023-01-05 02:56:19,030] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 3, in <module>
    import Move_Current_BTC_Data_From_GCS_to_BigQuery
  File "/opt/airflow/dags/Move_Current_BTC_Data_From_GCS_to_BigQuery.py", line 1, in <module>
    import pyspark
ModuleNotFoundError: No module named 'pyspark'
[2023-01-05 02:56:19,032] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:56:19,087] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.087 seconds
[2023-01-05 02:56:33,185] {processor.py:153} INFO - Started process (PID=256) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:56:33,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:56:33,187] {logging_mixin.py:115} INFO - [2023-01-05 02:56:33,187] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:56:33,194] {logging_mixin.py:115} INFO - [2023-01-05 02:56:33,193] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 3, in <module>
    import Move_Current_BTC_Data_From_GCS_to_BigQuery
  File "/opt/airflow/dags/Move_Current_BTC_Data_From_GCS_to_BigQuery.py", line 1, in <module>
    import pyspark
ModuleNotFoundError: No module named 'pyspark'
[2023-01-05 02:56:33,194] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:56:33,225] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.045 seconds
[2023-01-05 02:57:03,313] {processor.py:153} INFO - Started process (PID=273) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:57:03,313] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:57:03,314] {logging_mixin.py:115} INFO - [2023-01-05 02:57:03,314] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:57:03,319] {logging_mixin.py:115} INFO - [2023-01-05 02:57:03,317] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/btc_data_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/btc_data_pipeline_dag.py", line 3, in <module>
    import Move_Current_BTC_Data_From_GCS_to_BigQuery
  File "/opt/airflow/dags/Move_Current_BTC_Data_From_GCS_to_BigQuery.py", line 1, in <module>
    import pyspark
ModuleNotFoundError: No module named 'pyspark'
[2023-01-05 02:57:03,319] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:57:03,344] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.037 seconds
[2023-01-05 02:57:29,426] {processor.py:153} INFO - Started process (PID=298) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:57:29,428] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:57:29,429] {logging_mixin.py:115} INFO - [2023-01-05 02:57:29,428] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:57:30,497] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:57:30,499] {logging_mixin.py:115} INFO - [2023-01-05 02:57:30,499] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:57:30,500] {logging_mixin.py:115} INFO - [2023-01-05 02:57:30,499] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:57:30,507] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:57:30,533] {logging_mixin.py:115} INFO - [2023-01-05 02:57:30,533] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:57:30,556] {logging_mixin.py:115} INFO - [2023-01-05 02:57:30,556] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 02:57:30,571] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.152 seconds
[2023-01-05 02:58:00,662] {processor.py:153} INFO - Started process (PID=317) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:58:00,663] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:58:00,664] {logging_mixin.py:115} INFO - [2023-01-05 02:58:00,663] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:58:01,581] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:58:01,583] {logging_mixin.py:115} INFO - [2023-01-05 02:58:01,583] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:58:01,584] {logging_mixin.py:115} INFO - [2023-01-05 02:58:01,583] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:58:01,591] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:58:01,616] {logging_mixin.py:115} INFO - [2023-01-05 02:58:01,616] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:58:01,646] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.990 seconds
[2023-01-05 02:58:31,746] {processor.py:153} INFO - Started process (PID=344) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:58:31,747] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:58:31,748] {logging_mixin.py:115} INFO - [2023-01-05 02:58:31,747] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:58:32,654] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:58:32,655] {logging_mixin.py:115} INFO - [2023-01-05 02:58:32,655] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:58:32,656] {logging_mixin.py:115} INFO - [2023-01-05 02:58:32,655] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:58:32,663] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:58:32,688] {logging_mixin.py:115} INFO - [2023-01-05 02:58:32,688] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:58:32,718] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.979 seconds
[2023-01-05 02:58:58,861] {processor.py:153} INFO - Started process (PID=362) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:58:58,863] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:58:58,863] {logging_mixin.py:115} INFO - [2023-01-05 02:58:58,863] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:58:59,741] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:58:59,743] {logging_mixin.py:115} INFO - [2023-01-05 02:58:59,743] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:58:59,744] {logging_mixin.py:115} INFO - [2023-01-05 02:58:59,743] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:58:59,751] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:58:59,807] {logging_mixin.py:115} INFO - [2023-01-05 02:58:59,807] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:58:59,840] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.984 seconds
[2023-01-05 02:59:30,017] {processor.py:153} INFO - Started process (PID=387) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:59:30,017] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 02:59:30,018] {logging_mixin.py:115} INFO - [2023-01-05 02:59:30,018] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:59:30,918] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 02:59:30,920] {logging_mixin.py:115} INFO - [2023-01-05 02:59:30,920] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 02:59:30,920] {logging_mixin.py:115} INFO - [2023-01-05 02:59:30,920] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 02:59:30,927] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 02:59:30,951] {logging_mixin.py:115} INFO - [2023-01-05 02:59:30,951] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 02:59:30,983] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.972 seconds
[2023-01-05 03:00:01,145] {processor.py:153} INFO - Started process (PID=412) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:00:01,146] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:00:01,147] {logging_mixin.py:115} INFO - [2023-01-05 03:00:01,147] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:00:02,060] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:00:02,062] {logging_mixin.py:115} INFO - [2023-01-05 03:00:02,062] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:00:02,063] {logging_mixin.py:115} INFO - [2023-01-05 03:00:02,062] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:00:02,070] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:00:02,094] {logging_mixin.py:115} INFO - [2023-01-05 03:00:02,094] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:00:02,131] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.991 seconds
[2023-01-05 03:00:32,230] {processor.py:153} INFO - Started process (PID=438) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:00:32,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:00:32,232] {logging_mixin.py:115} INFO - [2023-01-05 03:00:32,232] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:00:33,439] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:00:33,441] {logging_mixin.py:115} INFO - [2023-01-05 03:00:33,441] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:00:33,441] {logging_mixin.py:115} INFO - [2023-01-05 03:00:33,441] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:00:33,448] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:00:33,472] {logging_mixin.py:115} INFO - [2023-01-05 03:00:33,472] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:00:33,502] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.279 seconds
[2023-01-05 03:01:04,377] {processor.py:153} INFO - Started process (PID=455) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:01:04,383] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:01:04,384] {logging_mixin.py:115} INFO - [2023-01-05 03:01:04,383] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:01:05,377] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:01:05,379] {logging_mixin.py:115} INFO - [2023-01-05 03:01:05,379] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:01:05,379] {logging_mixin.py:115} INFO - [2023-01-05 03:01:05,379] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:01:05,386] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:01:05,413] {logging_mixin.py:115} INFO - [2023-01-05 03:01:05,413] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:01:05,448] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.079 seconds
[2023-01-05 03:01:35,551] {processor.py:153} INFO - Started process (PID=480) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:01:35,554] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:01:35,554] {logging_mixin.py:115} INFO - [2023-01-05 03:01:35,554] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:01:36,437] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:01:36,439] {logging_mixin.py:115} INFO - [2023-01-05 03:01:36,439] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:01:36,439] {logging_mixin.py:115} INFO - [2023-01-05 03:01:36,439] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:01:36,446] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:01:36,472] {logging_mixin.py:115} INFO - [2023-01-05 03:01:36,471] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:01:36,501] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.954 seconds
[2023-01-05 03:02:06,660] {processor.py:153} INFO - Started process (PID=504) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:02:06,661] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:02:06,662] {logging_mixin.py:115} INFO - [2023-01-05 03:02:06,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:02:07,530] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:02:07,532] {logging_mixin.py:115} INFO - [2023-01-05 03:02:07,532] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:02:07,533] {logging_mixin.py:115} INFO - [2023-01-05 03:02:07,532] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:02:07,540] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:02:07,564] {logging_mixin.py:115} INFO - [2023-01-05 03:02:07,564] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:02:07,594] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.939 seconds
[2023-01-05 03:02:37,792] {processor.py:153} INFO - Started process (PID=520) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:02:37,793] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:02:37,793] {logging_mixin.py:115} INFO - [2023-01-05 03:02:37,793] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:02:38,672] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:02:38,673] {logging_mixin.py:115} INFO - [2023-01-05 03:02:38,673] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:02:38,674] {logging_mixin.py:115} INFO - [2023-01-05 03:02:38,673] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:02:38,681] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:02:38,706] {logging_mixin.py:115} INFO - [2023-01-05 03:02:38,706] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:02:38,735] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.948 seconds
[2023-01-05 03:03:08,945] {processor.py:153} INFO - Started process (PID=544) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:03:08,947] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:03:08,948] {logging_mixin.py:115} INFO - [2023-01-05 03:03:08,947] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:03:09,820] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:03:09,822] {logging_mixin.py:115} INFO - [2023-01-05 03:03:09,822] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:03:09,822] {logging_mixin.py:115} INFO - [2023-01-05 03:03:09,822] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:03:09,829] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:03:09,853] {logging_mixin.py:115} INFO - [2023-01-05 03:03:09,853] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:03:09,882] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.941 seconds
[2023-01-05 03:03:40,106] {processor.py:153} INFO - Started process (PID=570) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:03:40,107] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:03:40,108] {logging_mixin.py:115} INFO - [2023-01-05 03:03:40,108] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:03:41,012] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:03:41,014] {logging_mixin.py:115} INFO - [2023-01-05 03:03:41,013] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:03:41,014] {logging_mixin.py:115} INFO - [2023-01-05 03:03:41,014] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:03:41,021] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:03:41,045] {logging_mixin.py:115} INFO - [2023-01-05 03:03:41,044] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:03:41,074] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.973 seconds
[2023-01-05 03:04:11,236] {processor.py:153} INFO - Started process (PID=595) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:04:11,237] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:04:11,238] {logging_mixin.py:115} INFO - [2023-01-05 03:04:11,238] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:04:12,380] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:04:12,382] {logging_mixin.py:115} INFO - [2023-01-05 03:04:12,381] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:04:12,382] {logging_mixin.py:115} INFO - [2023-01-05 03:04:12,382] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:04:12,394] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:04:12,420] {logging_mixin.py:115} INFO - [2023-01-05 03:04:12,420] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:04:12,452] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.222 seconds
[2023-01-05 03:04:42,553] {processor.py:153} INFO - Started process (PID=613) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:04:42,554] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:04:42,555] {logging_mixin.py:115} INFO - [2023-01-05 03:04:42,555] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:04:43,466] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:04:43,468] {logging_mixin.py:115} INFO - [2023-01-05 03:04:43,467] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:04:43,468] {logging_mixin.py:115} INFO - [2023-01-05 03:04:43,468] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:04:43,476] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:04:43,503] {logging_mixin.py:115} INFO - [2023-01-05 03:04:43,502] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:04:43,533] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.986 seconds
[2023-01-05 03:05:13,634] {processor.py:153} INFO - Started process (PID=638) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:05:13,635] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:05:13,636] {logging_mixin.py:115} INFO - [2023-01-05 03:05:13,636] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:05:14,537] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:05:14,539] {logging_mixin.py:115} INFO - [2023-01-05 03:05:14,539] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:05:14,540] {logging_mixin.py:115} INFO - [2023-01-05 03:05:14,539] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:05:14,547] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:05:14,572] {logging_mixin.py:115} INFO - [2023-01-05 03:05:14,572] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:05:14,603] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.975 seconds
[2023-01-05 03:05:44,780] {processor.py:153} INFO - Started process (PID=661) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:05:44,781] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:05:44,782] {logging_mixin.py:115} INFO - [2023-01-05 03:05:44,782] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:05:45,727] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:05:45,729] {logging_mixin.py:115} INFO - [2023-01-05 03:05:45,728] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:05:45,729] {logging_mixin.py:115} INFO - [2023-01-05 03:05:45,729] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:05:45,737] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:05:45,762] {logging_mixin.py:115} INFO - [2023-01-05 03:05:45,762] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:05:45,794] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.019 seconds
[2023-01-05 03:06:15,879] {processor.py:153} INFO - Started process (PID=678) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:06:15,880] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:06:15,881] {logging_mixin.py:115} INFO - [2023-01-05 03:06:15,881] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:06:16,835] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:06:16,837] {logging_mixin.py:115} INFO - [2023-01-05 03:06:16,836] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:06:16,837] {logging_mixin.py:115} INFO - [2023-01-05 03:06:16,837] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:06:16,846] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:06:16,871] {logging_mixin.py:115} INFO - [2023-01-05 03:06:16,871] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:06:16,903] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.029 seconds
[2023-01-05 03:06:46,980] {processor.py:153} INFO - Started process (PID=703) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:06:46,981] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:06:46,982] {logging_mixin.py:115} INFO - [2023-01-05 03:06:46,981] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:06:47,886] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:06:47,887] {logging_mixin.py:115} INFO - [2023-01-05 03:06:47,887] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:06:47,888] {logging_mixin.py:115} INFO - [2023-01-05 03:06:47,887] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:06:47,895] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:06:47,919] {logging_mixin.py:115} INFO - [2023-01-05 03:06:47,918] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:06:47,949] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.974 seconds
[2023-01-05 03:07:18,375] {processor.py:153} INFO - Started process (PID=729) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:07:18,376] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:07:18,377] {logging_mixin.py:115} INFO - [2023-01-05 03:07:18,377] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:07:19,294] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:07:19,297] {logging_mixin.py:115} INFO - [2023-01-05 03:07:19,297] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:07:19,298] {logging_mixin.py:115} INFO - [2023-01-05 03:07:19,298] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:07:19,305] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:07:19,331] {logging_mixin.py:115} INFO - [2023-01-05 03:07:19,331] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:07:19,362] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.994 seconds
[2023-01-05 03:07:49,463] {processor.py:153} INFO - Started process (PID=756) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:07:49,464] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:07:49,465] {logging_mixin.py:115} INFO - [2023-01-05 03:07:49,465] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:07:50,785] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:07:50,787] {logging_mixin.py:115} INFO - [2023-01-05 03:07:50,787] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:07:50,788] {logging_mixin.py:115} INFO - [2023-01-05 03:07:50,788] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:07:50,801] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:07:50,847] {logging_mixin.py:115} INFO - [2023-01-05 03:07:50,846] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:07:50,899] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.443 seconds
[2023-01-05 03:08:21,601] {processor.py:153} INFO - Started process (PID=775) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:08:21,602] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:08:21,603] {logging_mixin.py:115} INFO - [2023-01-05 03:08:21,603] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:08:22,481] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:08:22,482] {logging_mixin.py:115} INFO - [2023-01-05 03:08:22,482] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:08:22,483] {logging_mixin.py:115} INFO - [2023-01-05 03:08:22,482] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:08:22,490] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:08:22,515] {logging_mixin.py:115} INFO - [2023-01-05 03:08:22,515] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:08:22,544] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.948 seconds
[2023-01-05 03:08:52,808] {processor.py:153} INFO - Started process (PID=800) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:08:52,808] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:08:52,809] {logging_mixin.py:115} INFO - [2023-01-05 03:08:52,809] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:08:53,692] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:08:53,694] {logging_mixin.py:115} INFO - [2023-01-05 03:08:53,694] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:08:53,694] {logging_mixin.py:115} INFO - [2023-01-05 03:08:53,694] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:08:53,702] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:08:53,726] {logging_mixin.py:115} INFO - [2023-01-05 03:08:53,726] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:08:53,755] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.953 seconds
[2023-01-05 03:09:23,969] {processor.py:153} INFO - Started process (PID=824) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:09:23,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:09:23,971] {logging_mixin.py:115} INFO - [2023-01-05 03:09:23,971] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:09:24,884] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:09:24,886] {logging_mixin.py:115} INFO - [2023-01-05 03:09:24,886] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:09:24,887] {logging_mixin.py:115} INFO - [2023-01-05 03:09:24,886] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:09:24,894] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:09:24,917] {logging_mixin.py:115} INFO - [2023-01-05 03:09:24,917] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:09:24,948] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.985 seconds
[2023-01-05 03:09:55,057] {processor.py:153} INFO - Started process (PID=843) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:09:55,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:09:55,058] {logging_mixin.py:115} INFO - [2023-01-05 03:09:55,058] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:09:55,956] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:09:55,957] {logging_mixin.py:115} INFO - [2023-01-05 03:09:55,957] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:09:55,958] {logging_mixin.py:115} INFO - [2023-01-05 03:09:55,957] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:09:55,965] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:09:55,989] {logging_mixin.py:115} INFO - [2023-01-05 03:09:55,989] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:09:56,017] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.966 seconds
[2023-01-05 03:10:26,195] {processor.py:153} INFO - Started process (PID=868) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:10:26,198] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:10:26,198] {logging_mixin.py:115} INFO - [2023-01-05 03:10:26,198] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:10:27,095] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:10:27,096] {logging_mixin.py:115} INFO - [2023-01-05 03:10:27,096] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:10:27,097] {logging_mixin.py:115} INFO - [2023-01-05 03:10:27,097] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:10:27,105] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:10:27,130] {logging_mixin.py:115} INFO - [2023-01-05 03:10:27,129] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:10:27,160] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.971 seconds
[2023-01-05 03:10:57,722] {processor.py:153} INFO - Started process (PID=894) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:10:57,723] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:10:57,724] {logging_mixin.py:115} INFO - [2023-01-05 03:10:57,723] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:10:58,626] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:10:58,628] {logging_mixin.py:115} INFO - [2023-01-05 03:10:58,628] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:10:58,628] {logging_mixin.py:115} INFO - [2023-01-05 03:10:58,628] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:10:58,636] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:10:58,661] {logging_mixin.py:115} INFO - [2023-01-05 03:10:58,661] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:10:58,692] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.975 seconds
[2023-01-05 03:11:28,875] {processor.py:153} INFO - Started process (PID=911) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:11:28,876] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:11:28,877] {logging_mixin.py:115} INFO - [2023-01-05 03:11:28,877] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:11:30,023] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:11:30,025] {logging_mixin.py:115} INFO - [2023-01-05 03:11:30,025] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:11:30,026] {logging_mixin.py:115} INFO - [2023-01-05 03:11:30,025] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:11:30,038] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:11:30,071] {logging_mixin.py:115} INFO - [2023-01-05 03:11:30,071] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:11:30,114] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.244 seconds
[2023-01-05 03:12:00,201] {processor.py:153} INFO - Started process (PID=936) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:12:00,203] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:12:00,204] {logging_mixin.py:115} INFO - [2023-01-05 03:12:00,204] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:12:01,166] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:12:01,168] {logging_mixin.py:115} INFO - [2023-01-05 03:12:01,168] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:12:01,169] {logging_mixin.py:115} INFO - [2023-01-05 03:12:01,168] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:12:01,176] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:12:01,204] {logging_mixin.py:115} INFO - [2023-01-05 03:12:01,203] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:12:01,226] {logging_mixin.py:115} INFO - [2023-01-05 03:12:01,226] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:12:01,237] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.041 seconds
[2023-01-05 03:12:31,318] {processor.py:153} INFO - Started process (PID=960) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:12:31,321] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:12:31,322] {logging_mixin.py:115} INFO - [2023-01-05 03:12:31,322] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:12:32,253] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:12:32,254] {logging_mixin.py:115} INFO - [2023-01-05 03:12:32,254] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:12:32,255] {logging_mixin.py:115} INFO - [2023-01-05 03:12:32,254] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:12:32,262] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:12:32,289] {logging_mixin.py:115} INFO - [2023-01-05 03:12:32,288] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:12:32,312] {logging_mixin.py:115} INFO - [2023-01-05 03:12:32,312] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:12:32,324] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.011 seconds
[2023-01-05 03:13:02,409] {processor.py:153} INFO - Started process (PID=985) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:13:02,411] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:13:02,412] {logging_mixin.py:115} INFO - [2023-01-05 03:13:02,411] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:13:03,399] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:13:03,401] {logging_mixin.py:115} INFO - [2023-01-05 03:13:03,400] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:13:03,401] {logging_mixin.py:115} INFO - [2023-01-05 03:13:03,401] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:13:03,408] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:13:03,433] {logging_mixin.py:115} INFO - [2023-01-05 03:13:03,433] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:13:03,455] {logging_mixin.py:115} INFO - [2023-01-05 03:13:03,455] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:13:03,466] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.063 seconds
[2023-01-05 03:13:33,553] {processor.py:153} INFO - Started process (PID=1002) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:13:33,555] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:13:33,556] {logging_mixin.py:115} INFO - [2023-01-05 03:13:33,555] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:13:34,507] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:13:34,508] {logging_mixin.py:115} INFO - [2023-01-05 03:13:34,508] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:13:34,509] {logging_mixin.py:115} INFO - [2023-01-05 03:13:34,508] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:13:34,516] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:13:34,542] {logging_mixin.py:115} INFO - [2023-01-05 03:13:34,542] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:13:34,565] {logging_mixin.py:115} INFO - [2023-01-05 03:13:34,565] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:13:34,577] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.028 seconds
[2023-01-05 03:14:03,667] {processor.py:153} INFO - Started process (PID=1027) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:14:03,671] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:14:03,671] {logging_mixin.py:115} INFO - [2023-01-05 03:14:03,671] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:14:04,608] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:14:04,609] {logging_mixin.py:115} INFO - [2023-01-05 03:14:04,609] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:14:04,610] {logging_mixin.py:115} INFO - [2023-01-05 03:14:04,610] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:14:04,617] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:14:04,676] {logging_mixin.py:115} INFO - [2023-01-05 03:14:04,676] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:14:04,698] {logging_mixin.py:115} INFO - [2023-01-05 03:14:04,697] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:14:04,712] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.050 seconds
[2023-01-05 03:14:34,808] {processor.py:153} INFO - Started process (PID=1052) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:14:34,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:14:34,810] {logging_mixin.py:115} INFO - [2023-01-05 03:14:34,810] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:14:36,136] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:14:36,139] {logging_mixin.py:115} INFO - [2023-01-05 03:14:36,139] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:14:36,140] {logging_mixin.py:115} INFO - [2023-01-05 03:14:36,139] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:14:36,152] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:14:36,186] {logging_mixin.py:115} INFO - [2023-01-05 03:14:36,185] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:14:36,220] {logging_mixin.py:115} INFO - [2023-01-05 03:14:36,220] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:14:36,235] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.434 seconds
[2023-01-05 03:15:06,979] {processor.py:153} INFO - Started process (PID=1070) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:15:06,981] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:15:06,981] {logging_mixin.py:115} INFO - [2023-01-05 03:15:06,981] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:15:07,883] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:15:07,884] {logging_mixin.py:115} INFO - [2023-01-05 03:15:07,884] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:15:07,885] {logging_mixin.py:115} INFO - [2023-01-05 03:15:07,885] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:15:07,892] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:15:07,918] {logging_mixin.py:115} INFO - [2023-01-05 03:15:07,918] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:15:07,939] {logging_mixin.py:115} INFO - [2023-01-05 03:15:07,939] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:15:07,949] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.975 seconds
[2023-01-05 03:15:38,144] {processor.py:153} INFO - Started process (PID=1095) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:15:38,145] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:15:38,145] {logging_mixin.py:115} INFO - [2023-01-05 03:15:38,145] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:15:39,047] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:15:39,048] {logging_mixin.py:115} INFO - [2023-01-05 03:15:39,048] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:15:39,049] {logging_mixin.py:115} INFO - [2023-01-05 03:15:39,048] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:15:39,056] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:15:39,080] {logging_mixin.py:115} INFO - [2023-01-05 03:15:39,079] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:15:39,101] {logging_mixin.py:115} INFO - [2023-01-05 03:15:39,101] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:15:39,111] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.972 seconds
[2023-01-05 03:16:09,355] {processor.py:153} INFO - Started process (PID=1123) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:16:09,358] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:16:09,359] {logging_mixin.py:115} INFO - [2023-01-05 03:16:09,359] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:16:10,236] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:16:10,238] {logging_mixin.py:115} INFO - [2023-01-05 03:16:10,237] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:16:10,238] {logging_mixin.py:115} INFO - [2023-01-05 03:16:10,238] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:16:10,246] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:16:10,272] {logging_mixin.py:115} INFO - [2023-01-05 03:16:10,272] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:16:10,294] {logging_mixin.py:115} INFO - [2023-01-05 03:16:10,294] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:16:10,305] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.955 seconds
[2023-01-05 03:16:40,535] {processor.py:153} INFO - Started process (PID=1142) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:16:40,536] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:16:40,536] {logging_mixin.py:115} INFO - [2023-01-05 03:16:40,536] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:16:41,509] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:16:41,511] {logging_mixin.py:115} INFO - [2023-01-05 03:16:41,511] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:16:41,512] {logging_mixin.py:115} INFO - [2023-01-05 03:16:41,511] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:16:41,525] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:16:41,561] {logging_mixin.py:115} INFO - [2023-01-05 03:16:41,561] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:16:41,594] {logging_mixin.py:115} INFO - [2023-01-05 03:16:41,593] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:16:41,608] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.078 seconds
[2023-01-05 03:17:11,707] {processor.py:153} INFO - Started process (PID=1168) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:17:11,712] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:17:11,713] {logging_mixin.py:115} INFO - [2023-01-05 03:17:11,713] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:17:12,614] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:17:12,616] {logging_mixin.py:115} INFO - [2023-01-05 03:17:12,616] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:17:12,616] {logging_mixin.py:115} INFO - [2023-01-05 03:17:12,616] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:17:12,623] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:17:12,648] {logging_mixin.py:115} INFO - [2023-01-05 03:17:12,648] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:17:12,670] {logging_mixin.py:115} INFO - [2023-01-05 03:17:12,669] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:17:12,680] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.978 seconds
[2023-01-05 03:17:42,798] {processor.py:153} INFO - Started process (PID=1193) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:17:42,798] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:17:42,799] {logging_mixin.py:115} INFO - [2023-01-05 03:17:42,799] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:17:43,672] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:17:43,674] {logging_mixin.py:115} INFO - [2023-01-05 03:17:43,674] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:17:43,674] {logging_mixin.py:115} INFO - [2023-01-05 03:17:43,674] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:17:43,681] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:17:43,705] {logging_mixin.py:115} INFO - [2023-01-05 03:17:43,704] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:17:43,727] {logging_mixin.py:115} INFO - [2023-01-05 03:17:43,726] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:17:43,737] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.944 seconds
[2023-01-05 03:18:14,060] {processor.py:153} INFO - Started process (PID=1218) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:18:14,062] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:18:14,062] {logging_mixin.py:115} INFO - [2023-01-05 03:18:14,062] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:18:15,074] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:18:15,075] {logging_mixin.py:115} INFO - [2023-01-05 03:18:15,075] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:18:15,076] {logging_mixin.py:115} INFO - [2023-01-05 03:18:15,075] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:18:15,083] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:18:15,110] {logging_mixin.py:115} INFO - [2023-01-05 03:18:15,109] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:18:15,133] {logging_mixin.py:115} INFO - [2023-01-05 03:18:15,133] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:18:15,144] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.090 seconds
[2023-01-05 03:18:45,237] {processor.py:153} INFO - Started process (PID=1235) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:18:45,239] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:18:45,239] {logging_mixin.py:115} INFO - [2023-01-05 03:18:45,239] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:18:46,181] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:18:46,182] {logging_mixin.py:115} INFO - [2023-01-05 03:18:46,182] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:18:46,183] {logging_mixin.py:115} INFO - [2023-01-05 03:18:46,182] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:18:46,190] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:18:46,214] {logging_mixin.py:115} INFO - [2023-01-05 03:18:46,214] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:18:46,240] {logging_mixin.py:115} INFO - [2023-01-05 03:18:46,240] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:18:46,250] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.018 seconds
[2023-01-05 03:19:16,343] {processor.py:153} INFO - Started process (PID=1260) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:19:16,344] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:19:16,345] {logging_mixin.py:115} INFO - [2023-01-05 03:19:16,345] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:19:17,259] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:19:17,261] {logging_mixin.py:115} INFO - [2023-01-05 03:19:17,261] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:19:17,261] {logging_mixin.py:115} INFO - [2023-01-05 03:19:17,261] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:19:17,268] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:19:17,294] {logging_mixin.py:115} INFO - [2023-01-05 03:19:17,293] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:19:17,316] {logging_mixin.py:115} INFO - [2023-01-05 03:19:17,316] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:19:17,328] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.990 seconds
[2023-01-05 03:19:47,425] {processor.py:153} INFO - Started process (PID=1286) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:19:47,425] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:19:47,426] {logging_mixin.py:115} INFO - [2023-01-05 03:19:47,426] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:19:48,325] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:19:48,326] {logging_mixin.py:115} INFO - [2023-01-05 03:19:48,326] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:19:48,327] {logging_mixin.py:115} INFO - [2023-01-05 03:19:48,327] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:19:48,334] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:19:48,360] {logging_mixin.py:115} INFO - [2023-01-05 03:19:48,360] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:19:48,382] {logging_mixin.py:115} INFO - [2023-01-05 03:19:48,382] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:19:48,393] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.974 seconds
[2023-01-05 03:20:18,792] {processor.py:153} INFO - Started process (PID=1304) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:20:18,795] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:20:18,796] {logging_mixin.py:115} INFO - [2023-01-05 03:20:18,796] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:20:19,713] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:20:19,715] {logging_mixin.py:115} INFO - [2023-01-05 03:20:19,715] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:20:19,716] {logging_mixin.py:115} INFO - [2023-01-05 03:20:19,715] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:20:19,723] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:20:19,750] {logging_mixin.py:115} INFO - [2023-01-05 03:20:19,750] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:20:19,773] {logging_mixin.py:115} INFO - [2023-01-05 03:20:19,773] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:20:19,786] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.999 seconds
[2023-01-05 03:20:49,889] {processor.py:153} INFO - Started process (PID=1329) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:20:49,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:20:49,891] {logging_mixin.py:115} INFO - [2023-01-05 03:20:49,891] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:20:50,793] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:20:50,795] {logging_mixin.py:115} INFO - [2023-01-05 03:20:50,794] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:20:50,795] {logging_mixin.py:115} INFO - [2023-01-05 03:20:50,795] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:20:50,802] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:20:50,827] {logging_mixin.py:115} INFO - [2023-01-05 03:20:50,826] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:20:50,849] {logging_mixin.py:115} INFO - [2023-01-05 03:20:50,849] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:20:50,860] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.976 seconds
[2023-01-05 03:21:21,040] {processor.py:153} INFO - Started process (PID=1354) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:21:21,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:21:21,043] {logging_mixin.py:115} INFO - [2023-01-05 03:21:21,043] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:21:21,945] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:21:21,947] {logging_mixin.py:115} INFO - [2023-01-05 03:21:21,946] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:21:21,947] {logging_mixin.py:115} INFO - [2023-01-05 03:21:21,947] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:21:21,954] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:21:21,980] {logging_mixin.py:115} INFO - [2023-01-05 03:21:21,980] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:21:22,005] {logging_mixin.py:115} INFO - [2023-01-05 03:21:22,005] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:21:22,017] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.983 seconds
[2023-01-05 03:21:52,146] {processor.py:153} INFO - Started process (PID=1372) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:21:52,147] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:21:52,148] {logging_mixin.py:115} INFO - [2023-01-05 03:21:52,148] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:21:53,066] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:21:53,067] {logging_mixin.py:115} INFO - [2023-01-05 03:21:53,067] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:21:53,068] {logging_mixin.py:115} INFO - [2023-01-05 03:21:53,068] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:21:53,075] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:21:53,100] {logging_mixin.py:115} INFO - [2023-01-05 03:21:53,099] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:21:53,123] {logging_mixin.py:115} INFO - [2023-01-05 03:21:53,122] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:21:53,134] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.994 seconds
[2023-01-05 03:22:23,232] {processor.py:153} INFO - Started process (PID=1397) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:22:23,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:22:23,233] {logging_mixin.py:115} INFO - [2023-01-05 03:22:23,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:22:24,121] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:22:24,122] {logging_mixin.py:115} INFO - [2023-01-05 03:22:24,122] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:22:24,123] {logging_mixin.py:115} INFO - [2023-01-05 03:22:24,122] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:22:24,130] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:22:24,154] {logging_mixin.py:115} INFO - [2023-01-05 03:22:24,154] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:22:24,176] {logging_mixin.py:115} INFO - [2023-01-05 03:22:24,176] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:22:24,187] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.961 seconds
[2023-01-05 03:22:54,362] {processor.py:153} INFO - Started process (PID=1422) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:22:54,363] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:22:54,364] {logging_mixin.py:115} INFO - [2023-01-05 03:22:54,364] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:22:55,259] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:22:55,260] {logging_mixin.py:115} INFO - [2023-01-05 03:22:55,260] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:22:55,261] {logging_mixin.py:115} INFO - [2023-01-05 03:22:55,260] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:22:55,268] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:22:55,294] {logging_mixin.py:115} INFO - [2023-01-05 03:22:55,294] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:22:55,321] {logging_mixin.py:115} INFO - [2023-01-05 03:22:55,321] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:22:55,333] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.977 seconds
[2023-01-05 03:23:25,502] {processor.py:153} INFO - Started process (PID=1446) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:23:25,503] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:23:25,504] {logging_mixin.py:115} INFO - [2023-01-05 03:23:25,504] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:23:26,564] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:23:26,565] {logging_mixin.py:115} INFO - [2023-01-05 03:23:26,565] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:23:26,566] {logging_mixin.py:115} INFO - [2023-01-05 03:23:26,566] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:23:26,573] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:23:26,598] {logging_mixin.py:115} INFO - [2023-01-05 03:23:26,598] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:23:26,621] {logging_mixin.py:115} INFO - [2023-01-05 03:23:26,621] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:23:26,632] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.138 seconds
[2023-01-05 03:23:56,732] {processor.py:153} INFO - Started process (PID=1464) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:23:56,733] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:23:56,734] {logging_mixin.py:115} INFO - [2023-01-05 03:23:56,734] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:23:57,633] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:23:57,635] {logging_mixin.py:115} INFO - [2023-01-05 03:23:57,634] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:23:57,635] {logging_mixin.py:115} INFO - [2023-01-05 03:23:57,635] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:23:57,642] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:23:57,666] {logging_mixin.py:115} INFO - [2023-01-05 03:23:57,666] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:23:57,688] {logging_mixin.py:115} INFO - [2023-01-05 03:23:57,688] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:23:57,699] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.974 seconds
[2023-01-05 03:24:27,892] {processor.py:153} INFO - Started process (PID=1489) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:24:27,894] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:24:27,894] {logging_mixin.py:115} INFO - [2023-01-05 03:24:27,894] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:24:28,805] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:24:28,807] {logging_mixin.py:115} INFO - [2023-01-05 03:24:28,806] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:24:28,807] {logging_mixin.py:115} INFO - [2023-01-05 03:24:28,807] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:24:28,814] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:24:28,841] {logging_mixin.py:115} INFO - [2023-01-05 03:24:28,840] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:24:28,867] {logging_mixin.py:115} INFO - [2023-01-05 03:24:28,867] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:24:28,879] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.993 seconds
[2023-01-05 03:24:58,980] {processor.py:153} INFO - Started process (PID=1515) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:24:58,981] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:24:58,982] {logging_mixin.py:115} INFO - [2023-01-05 03:24:58,982] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:24:59,908] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:24:59,909] {logging_mixin.py:115} INFO - [2023-01-05 03:24:59,909] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:24:59,910] {logging_mixin.py:115} INFO - [2023-01-05 03:24:59,910] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:24:59,917] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:24:59,943] {logging_mixin.py:115} INFO - [2023-01-05 03:24:59,942] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:24:59,964] {logging_mixin.py:115} INFO - [2023-01-05 03:24:59,964] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:24:59,975] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.002 seconds
[2023-01-05 03:25:30,068] {processor.py:153} INFO - Started process (PID=1533) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:25:30,068] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:25:30,069] {logging_mixin.py:115} INFO - [2023-01-05 03:25:30,069] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:25:31,022] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:25:31,023] {logging_mixin.py:115} INFO - [2023-01-05 03:25:31,023] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:25:31,024] {logging_mixin.py:115} INFO - [2023-01-05 03:25:31,023] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:25:31,031] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:25:31,055] {logging_mixin.py:115} INFO - [2023-01-05 03:25:31,055] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:25:31,077] {logging_mixin.py:115} INFO - [2023-01-05 03:25:31,077] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:25:31,088] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.026 seconds
[2023-01-05 03:26:01,183] {processor.py:153} INFO - Started process (PID=1559) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:26:01,184] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:26:01,185] {logging_mixin.py:115} INFO - [2023-01-05 03:26:01,185] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:26:02,119] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:26:02,120] {logging_mixin.py:115} INFO - [2023-01-05 03:26:02,120] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:26:02,121] {logging_mixin.py:115} INFO - [2023-01-05 03:26:02,120] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:26:02,128] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:26:02,153] {logging_mixin.py:115} INFO - [2023-01-05 03:26:02,152] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:26:02,176] {logging_mixin.py:115} INFO - [2023-01-05 03:26:02,176] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:26:02,188] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.014 seconds
[2023-01-05 03:26:32,276] {processor.py:153} INFO - Started process (PID=1583) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:26:32,278] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:26:32,279] {logging_mixin.py:115} INFO - [2023-01-05 03:26:32,278] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:26:33,210] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:26:33,212] {logging_mixin.py:115} INFO - [2023-01-05 03:26:33,211] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:26:33,212] {logging_mixin.py:115} INFO - [2023-01-05 03:26:33,212] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:26:33,219] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:26:33,245] {logging_mixin.py:115} INFO - [2023-01-05 03:26:33,244] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:26:33,268] {logging_mixin.py:115} INFO - [2023-01-05 03:26:33,268] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:26:33,282] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.011 seconds
[2023-01-05 03:27:03,380] {processor.py:153} INFO - Started process (PID=1602) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:27:03,381] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:27:03,382] {logging_mixin.py:115} INFO - [2023-01-05 03:27:03,382] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:27:04,287] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:27:04,289] {logging_mixin.py:115} INFO - [2023-01-05 03:27:04,289] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:27:04,290] {logging_mixin.py:115} INFO - [2023-01-05 03:27:04,290] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:27:04,299] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:27:04,328] {logging_mixin.py:115} INFO - [2023-01-05 03:27:04,327] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:27:04,373] {logging_mixin.py:115} INFO - [2023-01-05 03:27:04,373] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:27:04,391] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.016 seconds
[2023-01-05 03:27:34,483] {processor.py:153} INFO - Started process (PID=1627) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:27:34,484] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:27:34,485] {logging_mixin.py:115} INFO - [2023-01-05 03:27:34,485] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:27:35,388] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:27:35,390] {logging_mixin.py:115} INFO - [2023-01-05 03:27:35,390] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:27:35,390] {logging_mixin.py:115} INFO - [2023-01-05 03:27:35,390] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:27:35,397] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:27:35,422] {logging_mixin.py:115} INFO - [2023-01-05 03:27:35,422] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:27:35,446] {logging_mixin.py:115} INFO - [2023-01-05 03:27:35,446] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:00:00+00:00, run_after=2023-01-05T22:00:00+00:00
[2023-01-05 03:27:35,458] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.980 seconds
[2023-01-05 03:27:51,528] {processor.py:153} INFO - Started process (PID=1642) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:27:51,529] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:27:51,530] {logging_mixin.py:115} INFO - [2023-01-05 03:27:51,530] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:27:52,679] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:27:52,681] {logging_mixin.py:115} INFO - [2023-01-05 03:27:52,681] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:27:52,681] {logging_mixin.py:115} INFO - [2023-01-05 03:27:52,681] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:27:52,689] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:27:52,754] {logging_mixin.py:115} INFO - [2023-01-05 03:27:52,754] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:27:52,777] {logging_mixin.py:115} INFO - [2023-01-05 03:27:52,777] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:30:00+00:00, run_after=2023-01-05T22:30:00+00:00
[2023-01-05 03:27:52,795] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.273 seconds
[2023-01-05 03:28:23,010] {processor.py:153} INFO - Started process (PID=1662) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:28:23,011] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:28:23,012] {logging_mixin.py:115} INFO - [2023-01-05 03:28:23,012] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:28:23,921] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:28:23,923] {logging_mixin.py:115} INFO - [2023-01-05 03:28:23,922] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:28:23,923] {logging_mixin.py:115} INFO - [2023-01-05 03:28:23,923] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:28:23,930] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:28:23,956] {logging_mixin.py:115} INFO - [2023-01-05 03:28:23,955] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:28:23,979] {logging_mixin.py:115} INFO - [2023-01-05 03:28:23,979] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:30:00+00:00, run_after=2023-01-05T22:30:00+00:00
[2023-01-05 03:28:23,991] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.987 seconds
[2023-01-05 03:28:54,098] {processor.py:153} INFO - Started process (PID=1686) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:28:54,099] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:28:54,100] {logging_mixin.py:115} INFO - [2023-01-05 03:28:54,100] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:28:55,006] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:28:55,007] {logging_mixin.py:115} INFO - [2023-01-05 03:28:55,007] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:28:55,008] {logging_mixin.py:115} INFO - [2023-01-05 03:28:55,008] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:28:55,015] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:28:55,040] {logging_mixin.py:115} INFO - [2023-01-05 03:28:55,040] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:28:55,062] {logging_mixin.py:115} INFO - [2023-01-05 03:28:55,062] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:30:00+00:00, run_after=2023-01-05T22:30:00+00:00
[2023-01-05 03:28:55,073] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.981 seconds
[2023-01-05 03:29:25,374] {processor.py:153} INFO - Started process (PID=1711) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:29:25,376] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:29:25,377] {logging_mixin.py:115} INFO - [2023-01-05 03:29:25,377] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:29:26,333] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:29:26,334] {logging_mixin.py:115} INFO - [2023-01-05 03:29:26,334] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:29:26,335] {logging_mixin.py:115} INFO - [2023-01-05 03:29:26,334] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:29:26,342] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:29:26,367] {logging_mixin.py:115} INFO - [2023-01-05 03:29:26,367] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:29:26,390] {logging_mixin.py:115} INFO - [2023-01-05 03:29:26,390] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:30:00+00:00, run_after=2023-01-05T22:30:00+00:00
[2023-01-05 03:29:26,402] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.033 seconds
[2023-01-05 03:29:56,497] {processor.py:153} INFO - Started process (PID=1730) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:29:56,498] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:29:56,499] {logging_mixin.py:115} INFO - [2023-01-05 03:29:56,499] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:29:57,441] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:29:57,442] {logging_mixin.py:115} INFO - [2023-01-05 03:29:57,442] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:29:57,443] {logging_mixin.py:115} INFO - [2023-01-05 03:29:57,442] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:29:57,450] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:29:57,476] {logging_mixin.py:115} INFO - [2023-01-05 03:29:57,476] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:29:57,501] {logging_mixin.py:115} INFO - [2023-01-05 03:29:57,501] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:30:00+00:00, run_after=2023-01-05T22:30:00+00:00
[2023-01-05 03:29:57,514] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.022 seconds
[2023-01-05 03:30:27,610] {processor.py:153} INFO - Started process (PID=1755) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:30:27,611] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:30:27,612] {logging_mixin.py:115} INFO - [2023-01-05 03:30:27,612] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:30:28,574] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:30:28,576] {logging_mixin.py:115} INFO - [2023-01-05 03:30:28,576] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:30:28,576] {logging_mixin.py:115} INFO - [2023-01-05 03:30:28,576] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:30:28,584] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:30:28,609] {logging_mixin.py:115} INFO - [2023-01-05 03:30:28,609] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:30:28,632] {logging_mixin.py:115} INFO - [2023-01-05 03:30:28,631] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:30:00+00:00, run_after=2023-01-05T22:30:00+00:00
[2023-01-05 03:30:28,643] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.039 seconds
[2023-01-05 03:30:58,730] {processor.py:153} INFO - Started process (PID=1780) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:30:58,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:30:58,731] {logging_mixin.py:115} INFO - [2023-01-05 03:30:58,731] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:30:59,643] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:30:59,645] {logging_mixin.py:115} INFO - [2023-01-05 03:30:59,645] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:30:59,645] {logging_mixin.py:115} INFO - [2023-01-05 03:30:59,645] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:30:59,653] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:30:59,681] {logging_mixin.py:115} INFO - [2023-01-05 03:30:59,681] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:30:59,710] {logging_mixin.py:115} INFO - [2023-01-05 03:30:59,710] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:30:00+00:00, run_after=2023-01-05T22:30:00+00:00
[2023-01-05 03:30:59,727] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.002 seconds
[2023-01-05 03:31:29,821] {processor.py:153} INFO - Started process (PID=1798) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:31:29,822] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:31:29,823] {logging_mixin.py:115} INFO - [2023-01-05 03:31:29,823] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:31:30,872] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:31:30,874] {logging_mixin.py:115} INFO - [2023-01-05 03:31:30,874] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:31:30,875] {logging_mixin.py:115} INFO - [2023-01-05 03:31:30,874] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:31:30,886] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:31:30,923] {logging_mixin.py:115} INFO - [2023-01-05 03:31:30,922] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:31:30,955] {logging_mixin.py:115} INFO - [2023-01-05 03:31:30,955] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:30:00+00:00, run_after=2023-01-05T22:30:00+00:00
[2023-01-05 03:31:30,969] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.154 seconds
[2023-01-05 03:32:01,069] {processor.py:153} INFO - Started process (PID=1824) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:32:01,070] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:32:01,071] {logging_mixin.py:115} INFO - [2023-01-05 03:32:01,071] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:32:01,979] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:32:01,981] {logging_mixin.py:115} INFO - [2023-01-05 03:32:01,981] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:32:01,981] {logging_mixin.py:115} INFO - [2023-01-05 03:32:01,981] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:32:01,988] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:32:02,014] {logging_mixin.py:115} INFO - [2023-01-05 03:32:02,014] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:32:02,037] {logging_mixin.py:115} INFO - [2023-01-05 03:32:02,037] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:30:00+00:00, run_after=2023-01-05T22:30:00+00:00
[2023-01-05 03:32:02,049] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.985 seconds
[2023-01-05 03:32:32,146] {processor.py:153} INFO - Started process (PID=1849) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:32:32,148] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:32:32,149] {logging_mixin.py:115} INFO - [2023-01-05 03:32:32,148] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:32:33,068] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:32:33,069] {logging_mixin.py:115} INFO - [2023-01-05 03:32:33,069] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:32:33,070] {logging_mixin.py:115} INFO - [2023-01-05 03:32:33,069] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:32:33,077] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:32:33,102] {logging_mixin.py:115} INFO - [2023-01-05 03:32:33,102] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:32:33,126] {logging_mixin.py:115} INFO - [2023-01-05 03:32:33,126] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:30:00+00:00, run_after=2023-01-05T22:30:00+00:00
[2023-01-05 03:32:33,137] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.996 seconds
[2023-01-05 03:33:03,240] {processor.py:153} INFO - Started process (PID=1875) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:33:03,241] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:33:03,242] {logging_mixin.py:115} INFO - [2023-01-05 03:33:03,241] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:33:04,199] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:33:04,201] {logging_mixin.py:115} INFO - [2023-01-05 03:33:04,201] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:33:04,202] {logging_mixin.py:115} INFO - [2023-01-05 03:33:04,201] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:33:04,214] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:33:04,248] {logging_mixin.py:115} INFO - [2023-01-05 03:33:04,247] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:33:04,282] {logging_mixin.py:115} INFO - [2023-01-05 03:33:04,282] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:30:00+00:00, run_after=2023-01-05T22:30:00+00:00
[2023-01-05 03:33:04,298] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.064 seconds
[2023-01-05 03:33:25,382] {processor.py:153} INFO - Started process (PID=1886) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:33:25,383] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:33:25,384] {logging_mixin.py:115} INFO - [2023-01-05 03:33:25,384] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:33:26,287] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:33:26,289] {logging_mixin.py:115} INFO - [2023-01-05 03:33:26,289] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:33:26,290] {logging_mixin.py:115} INFO - [2023-01-05 03:33:26,289] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:33:26,299] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:33:26,359] {logging_mixin.py:115} INFO - [2023-01-05 03:33:26,359] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:33:26,380] {logging_mixin.py:115} INFO - [2023-01-05 03:33:26,379] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-03T22:30:00+00:00, run_after=2023-01-04T22:30:00+00:00
[2023-01-05 03:33:26,395] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.018 seconds
[2023-01-05 03:33:56,480] {processor.py:153} INFO - Started process (PID=1913) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:33:56,482] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:33:56,483] {logging_mixin.py:115} INFO - [2023-01-05 03:33:56,483] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:33:57,366] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:33:57,368] {logging_mixin.py:115} INFO - [2023-01-05 03:33:57,368] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:33:57,369] {logging_mixin.py:115} INFO - [2023-01-05 03:33:57,368] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:33:57,376] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:33:57,403] {logging_mixin.py:115} INFO - [2023-01-05 03:33:57,402] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:33:57,436] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.962 seconds
[2023-01-05 03:34:27,624] {processor.py:153} INFO - Started process (PID=1937) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:34:27,625] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:34:27,626] {logging_mixin.py:115} INFO - [2023-01-05 03:34:27,626] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:34:28,530] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:34:28,531] {logging_mixin.py:115} INFO - [2023-01-05 03:34:28,531] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:34:28,532] {logging_mixin.py:115} INFO - [2023-01-05 03:34:28,531] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:34:28,539] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:34:28,563] {logging_mixin.py:115} INFO - [2023-01-05 03:34:28,563] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:34:28,592] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.974 seconds
[2023-01-05 03:34:58,870] {processor.py:153} INFO - Started process (PID=1962) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:34:58,871] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:34:58,872] {logging_mixin.py:115} INFO - [2023-01-05 03:34:58,872] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:34:59,930] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:34:59,931] {logging_mixin.py:115} INFO - [2023-01-05 03:34:59,931] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:34:59,932] {logging_mixin.py:115} INFO - [2023-01-05 03:34:59,931] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:34:59,939] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:34:59,963] {logging_mixin.py:115} INFO - [2023-01-05 03:34:59,963] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:35:00,003] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.139 seconds
[2023-01-05 03:35:30,086] {processor.py:153} INFO - Started process (PID=1980) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:35:30,086] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:35:30,087] {logging_mixin.py:115} INFO - [2023-01-05 03:35:30,087] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:35:31,039] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:35:31,041] {logging_mixin.py:115} INFO - [2023-01-05 03:35:31,041] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:35:31,042] {logging_mixin.py:115} INFO - [2023-01-05 03:35:31,042] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:35:31,051] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:35:31,078] {logging_mixin.py:115} INFO - [2023-01-05 03:35:31,078] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:35:31,109] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.028 seconds
[2023-01-05 03:36:01,189] {processor.py:153} INFO - Started process (PID=2006) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:36:01,190] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:36:01,191] {logging_mixin.py:115} INFO - [2023-01-05 03:36:01,191] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:36:02,079] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:36:02,080] {logging_mixin.py:115} INFO - [2023-01-05 03:36:02,080] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:36:02,081] {logging_mixin.py:115} INFO - [2023-01-05 03:36:02,080] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:36:02,088] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:36:02,112] {logging_mixin.py:115} INFO - [2023-01-05 03:36:02,112] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:36:02,144] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.960 seconds
[2023-01-05 03:36:32,329] {processor.py:153} INFO - Started process (PID=2032) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:36:32,330] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:36:32,331] {logging_mixin.py:115} INFO - [2023-01-05 03:36:32,331] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:36:33,240] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:36:33,242] {logging_mixin.py:115} INFO - [2023-01-05 03:36:33,242] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:36:33,242] {logging_mixin.py:115} INFO - [2023-01-05 03:36:33,242] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:36:33,250] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:36:33,275] {logging_mixin.py:115} INFO - [2023-01-05 03:36:33,274] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:36:33,307] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.983 seconds
[2023-01-05 03:36:48,388] {processor.py:153} INFO - Started process (PID=2041) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:36:48,389] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:36:48,390] {logging_mixin.py:115} INFO - [2023-01-05 03:36:48,390] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:36:49,321] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:36:49,323] {logging_mixin.py:115} INFO - [2023-01-05 03:36:49,323] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:36:49,323] {logging_mixin.py:115} INFO - [2023-01-05 03:36:49,323] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:36:49,330] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:36:49,393] {logging_mixin.py:115} INFO - [2023-01-05 03:36:49,392] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:36:49,424] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.042 seconds
[2023-01-05 03:37:19,517] {processor.py:153} INFO - Started process (PID=2066) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:37:19,518] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:37:19,518] {logging_mixin.py:115} INFO - [2023-01-05 03:37:19,518] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:37:20,407] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:37:20,409] {logging_mixin.py:115} INFO - [2023-01-05 03:37:20,409] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:37:20,409] {logging_mixin.py:115} INFO - [2023-01-05 03:37:20,409] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:37:20,417] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:37:20,442] {logging_mixin.py:115} INFO - [2023-01-05 03:37:20,441] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:37:20,474] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.962 seconds
[2023-01-05 03:37:50,630] {processor.py:153} INFO - Started process (PID=2084) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:37:50,631] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:37:50,632] {logging_mixin.py:115} INFO - [2023-01-05 03:37:50,632] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:37:51,522] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:37:51,524] {logging_mixin.py:115} INFO - [2023-01-05 03:37:51,524] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:37:51,524] {logging_mixin.py:115} INFO - [2023-01-05 03:37:51,524] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:37:51,531] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:37:51,558] {logging_mixin.py:115} INFO - [2023-01-05 03:37:51,558] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:37:51,592] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.967 seconds
[2023-01-05 03:38:21,797] {processor.py:153} INFO - Started process (PID=2112) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:38:21,798] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:38:21,798] {logging_mixin.py:115} INFO - [2023-01-05 03:38:21,798] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:38:22,692] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:38:22,694] {logging_mixin.py:115} INFO - [2023-01-05 03:38:22,694] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:38:22,694] {logging_mixin.py:115} INFO - [2023-01-05 03:38:22,694] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:38:22,701] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:38:22,726] {logging_mixin.py:115} INFO - [2023-01-05 03:38:22,726] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:38:22,747] {logging_mixin.py:115} INFO - [2023-01-05 03:38:22,747] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:30:00+00:00, run_after=2023-01-05T22:30:00+00:00
[2023-01-05 03:38:22,758] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.966 seconds
[2023-01-05 03:38:44,846] {processor.py:153} INFO - Started process (PID=2131) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:38:44,847] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:38:44,847] {logging_mixin.py:115} INFO - [2023-01-05 03:38:44,847] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:38:45,792] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:38:45,794] {logging_mixin.py:115} INFO - [2023-01-05 03:38:45,794] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:38:45,794] {logging_mixin.py:115} INFO - [2023-01-05 03:38:45,794] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:38:45,801] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:38:45,861] {logging_mixin.py:115} INFO - [2023-01-05 03:38:45,861] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:38:45,880] {logging_mixin.py:115} INFO - [2023-01-05 03:38:45,880] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:38:45,895] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.054 seconds
[2023-01-05 03:38:52,948] {processor.py:153} INFO - Started process (PID=2140) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:38:52,948] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:38:52,949] {logging_mixin.py:115} INFO - [2023-01-05 03:38:52,949] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:38:53,933] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:38:53,934] {logging_mixin.py:115} INFO - [2023-01-05 03:38:53,934] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:38:53,935] {logging_mixin.py:115} INFO - [2023-01-05 03:38:53,935] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:38:53,942] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:38:53,956] {logging_mixin.py:115} INFO - [2023-01-05 03:38:53,956] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:38:53,979] {logging_mixin.py:115} INFO - [2023-01-05 03:38:53,979] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:38:53,992] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.050 seconds
[2023-01-05 03:39:24,076] {processor.py:153} INFO - Started process (PID=2158) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:39:24,077] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:39:24,077] {logging_mixin.py:115} INFO - [2023-01-05 03:39:24,077] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:39:25,059] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:39:25,061] {logging_mixin.py:115} INFO - [2023-01-05 03:39:25,061] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:39:25,061] {logging_mixin.py:115} INFO - [2023-01-05 03:39:25,061] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:39:25,069] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:39:25,132] {logging_mixin.py:115} INFO - [2023-01-05 03:39:25,132] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:39:25,154] {logging_mixin.py:115} INFO - [2023-01-05 03:39:25,154] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:39:25,168] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.098 seconds
[2023-01-05 03:39:55,256] {processor.py:153} INFO - Started process (PID=2185) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:39:55,257] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:39:55,258] {logging_mixin.py:115} INFO - [2023-01-05 03:39:55,258] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:39:56,148] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:39:56,149] {logging_mixin.py:115} INFO - [2023-01-05 03:39:56,149] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:39:56,150] {logging_mixin.py:115} INFO - [2023-01-05 03:39:56,150] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:39:56,157] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:39:56,182] {logging_mixin.py:115} INFO - [2023-01-05 03:39:56,181] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:39:56,213] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.962 seconds
[2023-01-05 03:40:26,490] {processor.py:153} INFO - Started process (PID=2210) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:40:26,491] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:40:26,492] {logging_mixin.py:115} INFO - [2023-01-05 03:40:26,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:40:27,396] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:40:27,398] {logging_mixin.py:115} INFO - [2023-01-05 03:40:27,398] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:40:27,399] {logging_mixin.py:115} INFO - [2023-01-05 03:40:27,398] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:40:27,411] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:40:27,439] {logging_mixin.py:115} INFO - [2023-01-05 03:40:27,438] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:40:27,486] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.001 seconds
[2023-01-05 03:40:57,582] {processor.py:153} INFO - Started process (PID=2236) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:40:57,583] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:40:57,584] {logging_mixin.py:115} INFO - [2023-01-05 03:40:57,583] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:40:58,691] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:40:58,693] {logging_mixin.py:115} INFO - [2023-01-05 03:40:58,693] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:40:58,694] {logging_mixin.py:115} INFO - [2023-01-05 03:40:58,694] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:40:58,713] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:40:58,739] {logging_mixin.py:115} INFO - [2023-01-05 03:40:58,738] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:40:58,773] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.196 seconds
[2023-01-05 03:41:29,748] {processor.py:153} INFO - Started process (PID=2255) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:41:29,750] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:41:29,751] {logging_mixin.py:115} INFO - [2023-01-05 03:41:29,751] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:41:30,652] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:41:30,653] {logging_mixin.py:115} INFO - [2023-01-05 03:41:30,653] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:41:30,654] {logging_mixin.py:115} INFO - [2023-01-05 03:41:30,654] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:41:30,662] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:41:30,688] {logging_mixin.py:115} INFO - [2023-01-05 03:41:30,688] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:41:30,721] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.979 seconds
[2023-01-05 03:42:00,865] {processor.py:153} INFO - Started process (PID=2280) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:42:00,866] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:42:00,867] {logging_mixin.py:115} INFO - [2023-01-05 03:42:00,867] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:42:01,733] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:42:01,734] {logging_mixin.py:115} INFO - [2023-01-05 03:42:01,734] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:42:01,735] {logging_mixin.py:115} INFO - [2023-01-05 03:42:01,735] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:42:01,742] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:42:01,766] {logging_mixin.py:115} INFO - [2023-01-05 03:42:01,766] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:42:01,801] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.941 seconds
[2023-01-05 03:42:32,115] {processor.py:153} INFO - Started process (PID=2305) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:42:32,116] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:42:32,117] {logging_mixin.py:115} INFO - [2023-01-05 03:42:32,117] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:42:33,011] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:42:33,012] {logging_mixin.py:115} INFO - [2023-01-05 03:42:33,012] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:42:33,013] {logging_mixin.py:115} INFO - [2023-01-05 03:42:33,012] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:42:33,020] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:42:33,045] {logging_mixin.py:115} INFO - [2023-01-05 03:42:33,044] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:42:33,076] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.967 seconds
[2023-01-05 03:43:03,289] {processor.py:153} INFO - Started process (PID=2322) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:43:03,289] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:43:03,290] {logging_mixin.py:115} INFO - [2023-01-05 03:43:03,290] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:43:04,359] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:43:04,361] {logging_mixin.py:115} INFO - [2023-01-05 03:43:04,361] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:43:04,362] {logging_mixin.py:115} INFO - [2023-01-05 03:43:04,361] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:43:04,374] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:43:04,407] {logging_mixin.py:115} INFO - [2023-01-05 03:43:04,406] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:43:04,459] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.175 seconds
[2023-01-05 03:43:34,545] {processor.py:153} INFO - Started process (PID=2347) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:43:34,546] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:43:34,546] {logging_mixin.py:115} INFO - [2023-01-05 03:43:34,546] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:43:35,449] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:43:35,451] {logging_mixin.py:115} INFO - [2023-01-05 03:43:35,450] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:43:35,452] {logging_mixin.py:115} INFO - [2023-01-05 03:43:35,451] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:43:35,461] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:43:35,487] {logging_mixin.py:115} INFO - [2023-01-05 03:43:35,487] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:43:35,520] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.980 seconds
[2023-01-05 03:44:05,642] {processor.py:153} INFO - Started process (PID=2372) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:44:05,643] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:44:05,644] {logging_mixin.py:115} INFO - [2023-01-05 03:44:05,644] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:44:06,571] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:44:06,572] {logging_mixin.py:115} INFO - [2023-01-05 03:44:06,572] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:44:06,573] {logging_mixin.py:115} INFO - [2023-01-05 03:44:06,572] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:44:06,580] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:44:06,605] {logging_mixin.py:115} INFO - [2023-01-05 03:44:06,605] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:44:06,628] {logging_mixin.py:115} INFO - [2023-01-05 03:44:06,628] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:44:06,640] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.003 seconds
[2023-01-05 03:44:36,731] {processor.py:153} INFO - Started process (PID=2390) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:44:36,734] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:44:36,734] {logging_mixin.py:115} INFO - [2023-01-05 03:44:36,734] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:44:37,651] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:44:37,653] {logging_mixin.py:115} INFO - [2023-01-05 03:44:37,653] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:44:37,654] {logging_mixin.py:115} INFO - [2023-01-05 03:44:37,654] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:44:37,666] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:44:37,708] {logging_mixin.py:115} INFO - [2023-01-05 03:44:37,707] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:44:37,741] {logging_mixin.py:115} INFO - [2023-01-05 03:44:37,741] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:44:37,767] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.041 seconds
[2023-01-05 03:45:07,865] {processor.py:153} INFO - Started process (PID=2415) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:45:07,866] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:45:07,867] {logging_mixin.py:115} INFO - [2023-01-05 03:45:07,867] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:45:08,795] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:45:08,797] {logging_mixin.py:115} INFO - [2023-01-05 03:45:08,797] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:45:08,798] {logging_mixin.py:115} INFO - [2023-01-05 03:45:08,797] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:45:08,805] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:45:08,832] {logging_mixin.py:115} INFO - [2023-01-05 03:45:08,831] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:45:08,856] {logging_mixin.py:115} INFO - [2023-01-05 03:45:08,856] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:45:08,867] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.008 seconds
[2023-01-05 03:45:38,953] {processor.py:153} INFO - Started process (PID=2441) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:45:38,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:45:38,955] {logging_mixin.py:115} INFO - [2023-01-05 03:45:38,954] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:45:39,873] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:45:39,875] {logging_mixin.py:115} INFO - [2023-01-05 03:45:39,875] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:45:39,875] {logging_mixin.py:115} INFO - [2023-01-05 03:45:39,875] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:45:39,882] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:45:39,906] {logging_mixin.py:115} INFO - [2023-01-05 03:45:39,906] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:45:39,928] {logging_mixin.py:115} INFO - [2023-01-05 03:45:39,928] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:45:39,939] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.991 seconds
[2023-01-05 03:46:10,039] {processor.py:153} INFO - Started process (PID=2458) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:46:10,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:46:10,041] {logging_mixin.py:115} INFO - [2023-01-05 03:46:10,041] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:46:11,250] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:46:11,252] {logging_mixin.py:115} INFO - [2023-01-05 03:46:11,252] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:46:11,253] {logging_mixin.py:115} INFO - [2023-01-05 03:46:11,252] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:46:11,265] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:46:11,300] {logging_mixin.py:115} INFO - [2023-01-05 03:46:11,300] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:46:11,336] {logging_mixin.py:115} INFO - [2023-01-05 03:46:11,335] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:46:11,351] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.319 seconds
[2023-01-05 03:46:42,264] {processor.py:153} INFO - Started process (PID=2484) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:46:42,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:46:42,266] {logging_mixin.py:115} INFO - [2023-01-05 03:46:42,266] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:46:43,188] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:46:43,190] {logging_mixin.py:115} INFO - [2023-01-05 03:46:43,190] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:46:43,190] {logging_mixin.py:115} INFO - [2023-01-05 03:46:43,190] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:46:43,197] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:46:43,223] {logging_mixin.py:115} INFO - [2023-01-05 03:46:43,222] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:46:43,245] {logging_mixin.py:115} INFO - [2023-01-05 03:46:43,245] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:46:43,257] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.998 seconds
[2023-01-05 03:47:13,350] {processor.py:153} INFO - Started process (PID=2510) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:47:13,351] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:47:13,351] {logging_mixin.py:115} INFO - [2023-01-05 03:47:13,351] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:47:14,267] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:47:14,268] {logging_mixin.py:115} INFO - [2023-01-05 03:47:14,268] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:47:14,269] {logging_mixin.py:115} INFO - [2023-01-05 03:47:14,269] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:47:14,276] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:47:14,301] {logging_mixin.py:115} INFO - [2023-01-05 03:47:14,301] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:47:14,324] {logging_mixin.py:115} INFO - [2023-01-05 03:47:14,323] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:47:14,335] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.991 seconds
[2023-01-05 03:47:44,433] {processor.py:153} INFO - Started process (PID=2535) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:47:44,435] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:47:44,435] {logging_mixin.py:115} INFO - [2023-01-05 03:47:44,435] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:47:45,351] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:47:45,352] {logging_mixin.py:115} INFO - [2023-01-05 03:47:45,352] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:47:45,353] {logging_mixin.py:115} INFO - [2023-01-05 03:47:45,352] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:47:45,360] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:47:45,384] {logging_mixin.py:115} INFO - [2023-01-05 03:47:45,384] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:47:45,406] {logging_mixin.py:115} INFO - [2023-01-05 03:47:45,406] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:47:45,418] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.991 seconds
[2023-01-05 03:48:15,513] {processor.py:153} INFO - Started process (PID=2554) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:48:15,514] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:48:15,515] {logging_mixin.py:115} INFO - [2023-01-05 03:48:15,515] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:48:16,434] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:48:16,435] {logging_mixin.py:115} INFO - [2023-01-05 03:48:16,435] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:48:16,436] {logging_mixin.py:115} INFO - [2023-01-05 03:48:16,435] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:48:16,443] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:48:16,468] {logging_mixin.py:115} INFO - [2023-01-05 03:48:16,468] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:48:16,492] {logging_mixin.py:115} INFO - [2023-01-05 03:48:16,491] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:48:16,502] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.994 seconds
[2023-01-05 03:48:46,595] {processor.py:153} INFO - Started process (PID=2579) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:48:46,597] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:48:46,597] {logging_mixin.py:115} INFO - [2023-01-05 03:48:46,597] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:48:47,516] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:48:47,518] {logging_mixin.py:115} INFO - [2023-01-05 03:48:47,518] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:48:47,519] {logging_mixin.py:115} INFO - [2023-01-05 03:48:47,518] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:48:47,526] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:48:47,551] {logging_mixin.py:115} INFO - [2023-01-05 03:48:47,551] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:48:47,575] {logging_mixin.py:115} INFO - [2023-01-05 03:48:47,575] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:48:47,587] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.997 seconds
[2023-01-05 03:49:17,685] {processor.py:153} INFO - Started process (PID=2604) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:49:17,686] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:49:17,687] {logging_mixin.py:115} INFO - [2023-01-05 03:49:17,687] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:49:18,573] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:49:18,575] {logging_mixin.py:115} INFO - [2023-01-05 03:49:18,575] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:49:18,575] {logging_mixin.py:115} INFO - [2023-01-05 03:49:18,575] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:49:18,583] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:49:18,607] {logging_mixin.py:115} INFO - [2023-01-05 03:49:18,607] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:49:18,628] {logging_mixin.py:115} INFO - [2023-01-05 03:49:18,628] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:49:18,639] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.960 seconds
[2023-01-05 03:49:48,753] {processor.py:153} INFO - Started process (PID=2622) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:49:48,754] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:49:48,755] {logging_mixin.py:115} INFO - [2023-01-05 03:49:48,755] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:49:50,088] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:49:50,090] {logging_mixin.py:115} INFO - [2023-01-05 03:49:50,090] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:49:50,091] {logging_mixin.py:115} INFO - [2023-01-05 03:49:50,091] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:49:50,118] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:49:50,177] {logging_mixin.py:115} INFO - [2023-01-05 03:49:50,177] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:49:50,272] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.526 seconds
[2023-01-05 03:50:20,326] {processor.py:153} INFO - Started process (PID=2646) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:50:20,327] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:50:20,328] {logging_mixin.py:115} INFO - [2023-01-05 03:50:20,327] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:50:21,235] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:50:21,236] {logging_mixin.py:115} INFO - [2023-01-05 03:50:21,236] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:50:21,237] {logging_mixin.py:115} INFO - [2023-01-05 03:50:21,237] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:50:21,244] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:50:21,268] {logging_mixin.py:115} INFO - [2023-01-05 03:50:21,267] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:50:21,297] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.976 seconds
[2023-01-05 03:50:51,416] {processor.py:153} INFO - Started process (PID=2672) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:50:51,417] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:50:51,418] {logging_mixin.py:115} INFO - [2023-01-05 03:50:51,418] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:50:52,393] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:50:52,395] {logging_mixin.py:115} INFO - [2023-01-05 03:50:52,395] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:50:52,396] {logging_mixin.py:115} INFO - [2023-01-05 03:50:52,395] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:50:52,404] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:50:52,429] {logging_mixin.py:115} INFO - [2023-01-05 03:50:52,428] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:50:52,459] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.049 seconds
[2023-01-05 03:51:22,510] {processor.py:153} INFO - Started process (PID=2688) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:51:22,511] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:51:22,512] {logging_mixin.py:115} INFO - [2023-01-05 03:51:22,512] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:51:23,743] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:51:23,745] {logging_mixin.py:115} INFO - [2023-01-05 03:51:23,745] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:51:23,746] {logging_mixin.py:115} INFO - [2023-01-05 03:51:23,745] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:51:23,758] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:51:23,795] {logging_mixin.py:115} INFO - [2023-01-05 03:51:23,795] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:51:23,840] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.336 seconds
[2023-01-05 03:51:53,988] {processor.py:153} INFO - Started process (PID=2712) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:51:53,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:51:53,989] {logging_mixin.py:115} INFO - [2023-01-05 03:51:53,989] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:51:54,912] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:51:54,914] {logging_mixin.py:115} INFO - [2023-01-05 03:51:54,914] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:51:54,915] {logging_mixin.py:115} INFO - [2023-01-05 03:51:54,915] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:51:54,927] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:51:54,959] {logging_mixin.py:115} INFO - [2023-01-05 03:51:54,959] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:51:54,998] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.015 seconds
[2023-01-05 03:52:25,102] {processor.py:153} INFO - Started process (PID=2736) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:52:25,109] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:52:25,109] {logging_mixin.py:115} INFO - [2023-01-05 03:52:25,109] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:52:26,281] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:52:26,282] {logging_mixin.py:115} INFO - [2023-01-05 03:52:26,282] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:52:26,283] {logging_mixin.py:115} INFO - [2023-01-05 03:52:26,282] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:52:26,290] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:52:26,314] {logging_mixin.py:115} INFO - [2023-01-05 03:52:26,313] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:52:26,346] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.249 seconds
[2023-01-05 03:52:56,407] {processor.py:153} INFO - Started process (PID=2761) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:52:56,407] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:52:56,408] {logging_mixin.py:115} INFO - [2023-01-05 03:52:56,408] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:52:57,310] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:52:57,311] {logging_mixin.py:115} INFO - [2023-01-05 03:52:57,311] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:52:57,312] {logging_mixin.py:115} INFO - [2023-01-05 03:52:57,312] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:52:57,319] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:52:57,343] {logging_mixin.py:115} INFO - [2023-01-05 03:52:57,342] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:52:57,371] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.971 seconds
[2023-01-05 03:53:27,497] {processor.py:153} INFO - Started process (PID=2779) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:53:27,502] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:53:27,503] {logging_mixin.py:115} INFO - [2023-01-05 03:53:27,503] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:53:28,370] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:53:28,371] {logging_mixin.py:115} INFO - [2023-01-05 03:53:28,371] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:53:28,372] {logging_mixin.py:115} INFO - [2023-01-05 03:53:28,371] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:53:28,379] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:53:28,402] {logging_mixin.py:115} INFO - [2023-01-05 03:53:28,402] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:53:28,433] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.941 seconds
[2023-01-05 03:53:58,672] {processor.py:153} INFO - Started process (PID=2804) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:53:58,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:53:58,673] {logging_mixin.py:115} INFO - [2023-01-05 03:53:58,673] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:53:59,540] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:53:59,542] {logging_mixin.py:115} INFO - [2023-01-05 03:53:59,542] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:53:59,543] {logging_mixin.py:115} INFO - [2023-01-05 03:53:59,542] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:53:59,554] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:53:59,580] {logging_mixin.py:115} INFO - [2023-01-05 03:53:59,579] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:53:59,609] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.944 seconds
[2023-01-05 03:54:29,760] {processor.py:153} INFO - Started process (PID=2830) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:54:29,762] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:54:29,763] {logging_mixin.py:115} INFO - [2023-01-05 03:54:29,762] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:54:30,626] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:54:30,627] {logging_mixin.py:115} INFO - [2023-01-05 03:54:30,627] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:54:30,628] {logging_mixin.py:115} INFO - [2023-01-05 03:54:30,628] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:54:30,635] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:54:30,659] {logging_mixin.py:115} INFO - [2023-01-05 03:54:30,659] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:54:30,688] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.932 seconds
[2023-01-05 03:55:00,865] {processor.py:153} INFO - Started process (PID=2849) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:55:00,865] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:55:00,866] {logging_mixin.py:115} INFO - [2023-01-05 03:55:00,866] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:55:02,470] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:55:02,472] {logging_mixin.py:115} INFO - [2023-01-05 03:55:02,472] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:55:02,473] {logging_mixin.py:115} INFO - [2023-01-05 03:55:02,472] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:55:02,485] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:55:02,518] {logging_mixin.py:115} INFO - [2023-01-05 03:55:02,517] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:55:02,549] {logging_mixin.py:115} INFO - [2023-01-05 03:55:02,548] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:55:02,562] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.704 seconds
[2023-01-05 03:55:32,682] {processor.py:153} INFO - Started process (PID=2873) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:55:32,685] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 03:55:32,686] {logging_mixin.py:115} INFO - [2023-01-05 03:55:32,686] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:55:33,808] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 03:55:33,810] {logging_mixin.py:115} INFO - [2023-01-05 03:55:33,810] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 03:55:33,811] {logging_mixin.py:115} INFO - [2023-01-05 03:55:33,810] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 03:55:33,823] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 03:55:33,857] {logging_mixin.py:115} INFO - [2023-01-05 03:55:33,856] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 03:55:33,890] {logging_mixin.py:115} INFO - [2023-01-05 03:55:33,890] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 03:55:33,906] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.230 seconds
[2023-01-05 21:29:52,114] {processor.py:153} INFO - Started process (PID=33) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:29:52,131] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:29:52,131] {logging_mixin.py:115} INFO - [2023-01-05 21:29:52,131] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:29:55,957] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:29:55,959] {logging_mixin.py:115} INFO - [2023-01-05 21:29:55,958] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:29:55,959] {logging_mixin.py:115} INFO - [2023-01-05 21:29:55,959] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:29:55,990] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:29:56,036] {logging_mixin.py:115} INFO - [2023-01-05 21:29:56,035] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:29:56,078] {logging_mixin.py:115} INFO - [2023-01-05 21:29:56,078] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:29:56,096] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 4.000 seconds
[2023-01-05 21:30:26,230] {processor.py:153} INFO - Started process (PID=57) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:30:26,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:30:26,231] {logging_mixin.py:115} INFO - [2023-01-05 21:30:26,231] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:30:27,274] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:30:27,276] {logging_mixin.py:115} INFO - [2023-01-05 21:30:27,276] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:30:27,277] {logging_mixin.py:115} INFO - [2023-01-05 21:30:27,276] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:30:27,289] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:30:27,320] {logging_mixin.py:115} INFO - [2023-01-05 21:30:27,320] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:30:27,352] {logging_mixin.py:115} INFO - [2023-01-05 21:30:27,352] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:30:27,366] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.141 seconds
[2023-01-05 21:30:57,474] {processor.py:153} INFO - Started process (PID=83) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:30:57,480] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:30:57,481] {logging_mixin.py:115} INFO - [2023-01-05 21:30:57,481] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:30:58,685] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:30:58,687] {logging_mixin.py:115} INFO - [2023-01-05 21:30:58,687] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:30:58,688] {logging_mixin.py:115} INFO - [2023-01-05 21:30:58,687] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:30:58,699] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:30:58,730] {logging_mixin.py:115} INFO - [2023-01-05 21:30:58,729] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:30:58,757] {logging_mixin.py:115} INFO - [2023-01-05 21:30:58,757] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:30:58,768] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.299 seconds
[2023-01-05 21:31:28,862] {processor.py:153} INFO - Started process (PID=101) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:31:28,865] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:31:28,866] {logging_mixin.py:115} INFO - [2023-01-05 21:31:28,866] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:31:29,768] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:31:29,769] {logging_mixin.py:115} INFO - [2023-01-05 21:31:29,769] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:31:29,770] {logging_mixin.py:115} INFO - [2023-01-05 21:31:29,770] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:31:29,780] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:31:29,806] {logging_mixin.py:115} INFO - [2023-01-05 21:31:29,806] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:31:29,828] {logging_mixin.py:115} INFO - [2023-01-05 21:31:29,828] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:31:29,839] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.981 seconds
[2023-01-05 21:32:00,160] {processor.py:153} INFO - Started process (PID=126) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:32:00,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:32:00,167] {logging_mixin.py:115} INFO - [2023-01-05 21:32:00,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:32:01,257] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:32:01,258] {logging_mixin.py:115} INFO - [2023-01-05 21:32:01,258] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:32:01,259] {logging_mixin.py:115} INFO - [2023-01-05 21:32:01,259] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:32:01,270] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:32:01,302] {logging_mixin.py:115} INFO - [2023-01-05 21:32:01,302] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:32:01,323] {logging_mixin.py:115} INFO - [2023-01-05 21:32:01,323] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:32:01,333] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.178 seconds
[2023-01-05 21:32:31,383] {processor.py:153} INFO - Started process (PID=152) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:32:31,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:32:31,384] {logging_mixin.py:115} INFO - [2023-01-05 21:32:31,384] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:32:32,184] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:32:32,185] {logging_mixin.py:115} INFO - [2023-01-05 21:32:32,185] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:32:32,186] {logging_mixin.py:115} INFO - [2023-01-05 21:32:32,185] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:32:32,192] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:32:32,214] {logging_mixin.py:115} INFO - [2023-01-05 21:32:32,214] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:32:32,235] {logging_mixin.py:115} INFO - [2023-01-05 21:32:32,234] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:32:32,245] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.866 seconds
[2023-01-05 21:33:02,494] {processor.py:153} INFO - Started process (PID=170) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:33:02,499] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:33:02,500] {logging_mixin.py:115} INFO - [2023-01-05 21:33:02,500] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:33:03,734] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:33:03,736] {logging_mixin.py:115} INFO - [2023-01-05 21:33:03,736] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:33:03,737] {logging_mixin.py:115} INFO - [2023-01-05 21:33:03,736] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:33:03,748] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:33:03,778] {logging_mixin.py:115} INFO - [2023-01-05 21:33:03,777] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:33:03,808] {logging_mixin.py:115} INFO - [2023-01-05 21:33:03,808] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:33:03,821] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.343 seconds
[2023-01-05 21:33:33,933] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:33:33,934] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:33:33,934] {logging_mixin.py:115} INFO - [2023-01-05 21:33:33,934] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:33:34,750] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:33:34,752] {logging_mixin.py:115} INFO - [2023-01-05 21:33:34,752] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:33:34,752] {logging_mixin.py:115} INFO - [2023-01-05 21:33:34,752] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:33:34,759] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:33:34,784] {logging_mixin.py:115} INFO - [2023-01-05 21:33:34,783] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:33:34,805] {logging_mixin.py:115} INFO - [2023-01-05 21:33:34,805] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:33:34,817] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.889 seconds
[2023-01-05 21:34:05,074] {processor.py:153} INFO - Started process (PID=220) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:34:05,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:34:05,076] {logging_mixin.py:115} INFO - [2023-01-05 21:34:05,076] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:34:05,915] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:34:05,916] {logging_mixin.py:115} INFO - [2023-01-05 21:34:05,916] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:34:05,917] {logging_mixin.py:115} INFO - [2023-01-05 21:34:05,916] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:34:05,923] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:34:05,945] {logging_mixin.py:115} INFO - [2023-01-05 21:34:05,945] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:34:05,966] {logging_mixin.py:115} INFO - [2023-01-05 21:34:05,966] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:34:05,976] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.907 seconds
[2023-01-05 21:34:36,165] {processor.py:153} INFO - Started process (PID=245) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:34:36,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:34:36,166] {logging_mixin.py:115} INFO - [2023-01-05 21:34:36,166] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:34:36,971] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:34:36,973] {logging_mixin.py:115} INFO - [2023-01-05 21:34:36,973] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:34:36,973] {logging_mixin.py:115} INFO - [2023-01-05 21:34:36,973] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:34:36,980] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:34:37,002] {logging_mixin.py:115} INFO - [2023-01-05 21:34:37,002] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:34:37,023] {logging_mixin.py:115} INFO - [2023-01-05 21:34:37,022] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:34:37,032] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.872 seconds
[2023-01-05 21:35:07,254] {processor.py:153} INFO - Started process (PID=264) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:35:07,257] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:35:07,258] {logging_mixin.py:115} INFO - [2023-01-05 21:35:07,257] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:35:08,064] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:35:08,065] {logging_mixin.py:115} INFO - [2023-01-05 21:35:08,065] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:35:08,066] {logging_mixin.py:115} INFO - [2023-01-05 21:35:08,066] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:35:08,073] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:35:08,096] {logging_mixin.py:115} INFO - [2023-01-05 21:35:08,096] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:35:08,117] {logging_mixin.py:115} INFO - [2023-01-05 21:35:08,117] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:35:08,128] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.879 seconds
[2023-01-05 21:35:38,334] {processor.py:153} INFO - Started process (PID=289) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:35:38,336] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:35:38,336] {logging_mixin.py:115} INFO - [2023-01-05 21:35:38,336] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:35:39,183] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:35:39,184] {logging_mixin.py:115} INFO - [2023-01-05 21:35:39,184] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:35:39,185] {logging_mixin.py:115} INFO - [2023-01-05 21:35:39,184] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:35:39,192] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:35:39,214] {logging_mixin.py:115} INFO - [2023-01-05 21:35:39,214] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:35:39,235] {logging_mixin.py:115} INFO - [2023-01-05 21:35:39,235] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:35:39,245] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.915 seconds
[2023-01-05 21:36:09,418] {processor.py:153} INFO - Started process (PID=316) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:36:09,420] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:36:09,421] {logging_mixin.py:115} INFO - [2023-01-05 21:36:09,421] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:36:10,394] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:36:10,396] {logging_mixin.py:115} INFO - [2023-01-05 21:36:10,396] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:36:10,397] {logging_mixin.py:115} INFO - [2023-01-05 21:36:10,396] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:36:10,404] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:36:10,426] {logging_mixin.py:115} INFO - [2023-01-05 21:36:10,426] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:36:10,448] {logging_mixin.py:115} INFO - [2023-01-05 21:36:10,448] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:36:10,458] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.046 seconds
[2023-01-05 21:36:40,555] {processor.py:153} INFO - Started process (PID=334) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:36:40,556] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:36:40,557] {logging_mixin.py:115} INFO - [2023-01-05 21:36:40,557] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:36:41,574] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:36:41,576] {logging_mixin.py:115} INFO - [2023-01-05 21:36:41,576] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:36:41,577] {logging_mixin.py:115} INFO - [2023-01-05 21:36:41,577] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:36:41,589] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:36:41,622] {logging_mixin.py:115} INFO - [2023-01-05 21:36:41,622] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:36:41,653] {logging_mixin.py:115} INFO - [2023-01-05 21:36:41,653] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:36:41,666] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.116 seconds
[2023-01-05 21:37:11,749] {processor.py:153} INFO - Started process (PID=360) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:37:11,753] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:37:11,754] {logging_mixin.py:115} INFO - [2023-01-05 21:37:11,753] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:37:12,637] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:37:12,639] {logging_mixin.py:115} INFO - [2023-01-05 21:37:12,639] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:37:12,640] {logging_mixin.py:115} INFO - [2023-01-05 21:37:12,640] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:37:12,652] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:37:12,682] {logging_mixin.py:115} INFO - [2023-01-05 21:37:12,682] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:37:12,711] {logging_mixin.py:115} INFO - [2023-01-05 21:37:12,711] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:37:12,723] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.979 seconds
[2023-01-05 21:37:43,385] {processor.py:153} INFO - Started process (PID=385) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:37:43,387] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:37:43,388] {logging_mixin.py:115} INFO - [2023-01-05 21:37:43,388] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:37:44,308] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:37:44,309] {logging_mixin.py:115} INFO - [2023-01-05 21:37:44,309] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:37:44,310] {logging_mixin.py:115} INFO - [2023-01-05 21:37:44,309] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:37:44,316] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:37:44,339] {logging_mixin.py:115} INFO - [2023-01-05 21:37:44,339] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:37:44,364] {logging_mixin.py:115} INFO - [2023-01-05 21:37:44,363] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:37:44,377] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.997 seconds
[2023-01-05 21:38:14,472] {processor.py:153} INFO - Started process (PID=410) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:38:14,481] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:38:14,482] {logging_mixin.py:115} INFO - [2023-01-05 21:38:14,482] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:38:15,357] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:38:15,358] {logging_mixin.py:115} INFO - [2023-01-05 21:38:15,358] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:38:15,359] {logging_mixin.py:115} INFO - [2023-01-05 21:38:15,359] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:38:15,366] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:38:15,389] {logging_mixin.py:115} INFO - [2023-01-05 21:38:15,388] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:38:15,411] {logging_mixin.py:115} INFO - [2023-01-05 21:38:15,411] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:38:15,421] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.955 seconds
[2023-01-05 21:38:45,857] {processor.py:153} INFO - Started process (PID=427) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:38:45,859] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:38:45,859] {logging_mixin.py:115} INFO - [2023-01-05 21:38:45,859] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:38:46,905] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:38:46,907] {logging_mixin.py:115} INFO - [2023-01-05 21:38:46,906] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:38:46,908] {logging_mixin.py:115} INFO - [2023-01-05 21:38:46,907] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:38:46,919] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:38:46,952] {logging_mixin.py:115} INFO - [2023-01-05 21:38:46,952] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:38:46,984] {logging_mixin.py:115} INFO - [2023-01-05 21:38:46,984] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:38:46,998] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.147 seconds
[2023-01-05 21:39:17,113] {processor.py:153} INFO - Started process (PID=451) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:39:17,116] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:39:17,117] {logging_mixin.py:115} INFO - [2023-01-05 21:39:17,116] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:39:18,211] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:39:18,213] {logging_mixin.py:115} INFO - [2023-01-05 21:39:18,213] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:39:18,214] {logging_mixin.py:115} INFO - [2023-01-05 21:39:18,213] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:39:18,225] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:39:18,255] {logging_mixin.py:115} INFO - [2023-01-05 21:39:18,255] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:39:18,286] {logging_mixin.py:115} INFO - [2023-01-05 21:39:18,286] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:39:18,299] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.190 seconds
[2023-01-05 21:39:48,408] {processor.py:153} INFO - Started process (PID=475) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:39:48,409] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:39:48,410] {logging_mixin.py:115} INFO - [2023-01-05 21:39:48,410] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:39:49,235] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:39:49,236] {logging_mixin.py:115} INFO - [2023-01-05 21:39:49,236] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:39:49,237] {logging_mixin.py:115} INFO - [2023-01-05 21:39:49,237] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:39:49,244] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:39:49,273] {logging_mixin.py:115} INFO - [2023-01-05 21:39:49,273] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:39:49,294] {logging_mixin.py:115} INFO - [2023-01-05 21:39:49,294] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:39:49,304] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.901 seconds
[2023-01-05 21:40:19,573] {processor.py:153} INFO - Started process (PID=501) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:40:19,574] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:40:19,575] {logging_mixin.py:115} INFO - [2023-01-05 21:40:19,575] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:40:20,406] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:40:20,408] {logging_mixin.py:115} INFO - [2023-01-05 21:40:20,408] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:40:20,408] {logging_mixin.py:115} INFO - [2023-01-05 21:40:20,408] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:40:20,415] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:40:20,438] {logging_mixin.py:115} INFO - [2023-01-05 21:40:20,438] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:40:20,458] {logging_mixin.py:115} INFO - [2023-01-05 21:40:20,458] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:40:20,468] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.900 seconds
[2023-01-05 21:40:50,653] {processor.py:153} INFO - Started process (PID=519) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:40:50,654] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:40:50,655] {logging_mixin.py:115} INFO - [2023-01-05 21:40:50,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:40:51,651] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:40:51,653] {logging_mixin.py:115} INFO - [2023-01-05 21:40:51,653] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:40:51,654] {logging_mixin.py:115} INFO - [2023-01-05 21:40:51,653] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:40:51,688] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:40:51,733] {logging_mixin.py:115} INFO - [2023-01-05 21:40:51,732] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:40:51,771] {logging_mixin.py:115} INFO - [2023-01-05 21:40:51,771] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:40:51,792] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.145 seconds
[2023-01-05 21:41:21,895] {processor.py:153} INFO - Started process (PID=545) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:41:21,896] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:41:21,897] {logging_mixin.py:115} INFO - [2023-01-05 21:41:21,897] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:41:22,812] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:41:22,814] {logging_mixin.py:115} INFO - [2023-01-05 21:41:22,814] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:41:22,815] {logging_mixin.py:115} INFO - [2023-01-05 21:41:22,814] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:41:22,822] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:41:22,845] {logging_mixin.py:115} INFO - [2023-01-05 21:41:22,844] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:41:22,865] {logging_mixin.py:115} INFO - [2023-01-05 21:41:22,865] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:41:22,876] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.986 seconds
[2023-01-05 21:41:52,958] {processor.py:153} INFO - Started process (PID=571) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:41:52,960] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:41:52,960] {logging_mixin.py:115} INFO - [2023-01-05 21:41:52,960] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:41:53,822] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:41:53,823] {logging_mixin.py:115} INFO - [2023-01-05 21:41:53,823] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:41:53,824] {logging_mixin.py:115} INFO - [2023-01-05 21:41:53,823] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:41:53,830] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:41:53,852] {logging_mixin.py:115} INFO - [2023-01-05 21:41:53,852] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:41:53,872] {logging_mixin.py:115} INFO - [2023-01-05 21:41:53,872] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:41:53,882] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.929 seconds
[2023-01-05 21:42:24,351] {processor.py:153} INFO - Started process (PID=597) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:42:24,352] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:42:24,353] {logging_mixin.py:115} INFO - [2023-01-05 21:42:24,352] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:42:25,482] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:42:25,484] {logging_mixin.py:115} INFO - [2023-01-05 21:42:25,484] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:42:25,485] {logging_mixin.py:115} INFO - [2023-01-05 21:42:25,485] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:42:25,497] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:42:25,521] {logging_mixin.py:115} INFO - [2023-01-05 21:42:25,520] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:42:25,543] {logging_mixin.py:115} INFO - [2023-01-05 21:42:25,543] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:42:25,553] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.208 seconds
[2023-01-05 21:42:55,662] {processor.py:153} INFO - Started process (PID=616) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:42:55,665] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:42:55,666] {logging_mixin.py:115} INFO - [2023-01-05 21:42:55,666] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:42:56,487] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:42:56,489] {logging_mixin.py:115} INFO - [2023-01-05 21:42:56,489] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:42:56,489] {logging_mixin.py:115} INFO - [2023-01-05 21:42:56,489] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:42:56,496] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:42:56,520] {logging_mixin.py:115} INFO - [2023-01-05 21:42:56,520] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:42:56,542] {logging_mixin.py:115} INFO - [2023-01-05 21:42:56,542] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:42:56,553] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.896 seconds
[2023-01-05 21:43:26,860] {processor.py:153} INFO - Started process (PID=641) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:43:26,860] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:43:26,861] {logging_mixin.py:115} INFO - [2023-01-05 21:43:26,861] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:43:27,698] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:43:27,699] {logging_mixin.py:115} INFO - [2023-01-05 21:43:27,699] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:43:27,700] {logging_mixin.py:115} INFO - [2023-01-05 21:43:27,700] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:43:27,707] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:43:27,730] {logging_mixin.py:115} INFO - [2023-01-05 21:43:27,729] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:43:27,750] {logging_mixin.py:115} INFO - [2023-01-05 21:43:27,750] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:43:27,760] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.905 seconds
[2023-01-05 21:43:57,943] {processor.py:153} INFO - Started process (PID=667) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:43:57,944] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:43:57,945] {logging_mixin.py:115} INFO - [2023-01-05 21:43:57,945] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:43:58,767] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:43:58,769] {logging_mixin.py:115} INFO - [2023-01-05 21:43:58,769] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:43:58,769] {logging_mixin.py:115} INFO - [2023-01-05 21:43:58,769] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:43:58,776] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:43:58,802] {logging_mixin.py:115} INFO - [2023-01-05 21:43:58,802] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:43:58,826] {logging_mixin.py:115} INFO - [2023-01-05 21:43:58,825] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:43:58,838] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.900 seconds
[2023-01-05 21:44:29,019] {processor.py:153} INFO - Started process (PID=692) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:44:29,020] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:44:29,021] {logging_mixin.py:115} INFO - [2023-01-05 21:44:29,021] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:44:30,230] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:44:30,232] {logging_mixin.py:115} INFO - [2023-01-05 21:44:30,232] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:44:30,233] {logging_mixin.py:115} INFO - [2023-01-05 21:44:30,232] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:44:30,244] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:44:30,275] {logging_mixin.py:115} INFO - [2023-01-05 21:44:30,275] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:44:30,306] {logging_mixin.py:115} INFO - [2023-01-05 21:44:30,306] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:44:30,319] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.306 seconds
[2023-01-05 21:45:00,444] {processor.py:153} INFO - Started process (PID=710) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:45:00,447] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:45:00,448] {logging_mixin.py:115} INFO - [2023-01-05 21:45:00,448] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:45:01,286] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:45:01,288] {logging_mixin.py:115} INFO - [2023-01-05 21:45:01,288] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:45:01,288] {logging_mixin.py:115} INFO - [2023-01-05 21:45:01,288] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:45:01,295] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:45:01,319] {logging_mixin.py:115} INFO - [2023-01-05 21:45:01,319] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:45:01,341] {logging_mixin.py:115} INFO - [2023-01-05 21:45:01,340] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:45:01,351] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.912 seconds
[2023-01-05 21:45:31,568] {processor.py:153} INFO - Started process (PID=735) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:45:31,571] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:45:31,572] {logging_mixin.py:115} INFO - [2023-01-05 21:45:31,571] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:45:32,408] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:45:32,409] {logging_mixin.py:115} INFO - [2023-01-05 21:45:32,409] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:45:32,410] {logging_mixin.py:115} INFO - [2023-01-05 21:45:32,409] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:45:32,417] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:45:32,439] {logging_mixin.py:115} INFO - [2023-01-05 21:45:32,439] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:45:32,460] {logging_mixin.py:115} INFO - [2023-01-05 21:45:32,460] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:45:32,470] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.907 seconds
[2023-01-05 21:46:02,655] {processor.py:153} INFO - Started process (PID=760) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:46:02,657] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:46:02,658] {logging_mixin.py:115} INFO - [2023-01-05 21:46:02,658] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:46:03,484] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:46:03,485] {logging_mixin.py:115} INFO - [2023-01-05 21:46:03,485] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:46:03,486] {logging_mixin.py:115} INFO - [2023-01-05 21:46:03,485] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:46:03,493] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:46:03,518] {logging_mixin.py:115} INFO - [2023-01-05 21:46:03,518] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:46:03,539] {logging_mixin.py:115} INFO - [2023-01-05 21:46:03,539] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:46:03,550] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.899 seconds
[2023-01-05 21:46:33,730] {processor.py:153} INFO - Started process (PID=778) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:46:33,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:46:33,732] {logging_mixin.py:115} INFO - [2023-01-05 21:46:33,732] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:46:34,644] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:46:34,646] {logging_mixin.py:115} INFO - [2023-01-05 21:46:34,646] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:46:34,646] {logging_mixin.py:115} INFO - [2023-01-05 21:46:34,646] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:46:34,658] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:46:34,690] {logging_mixin.py:115} INFO - [2023-01-05 21:46:34,689] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:46:34,719] {logging_mixin.py:115} INFO - [2023-01-05 21:46:34,719] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:46:34,732] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.008 seconds
[2023-01-05 21:47:04,839] {processor.py:153} INFO - Started process (PID=802) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:47:04,840] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:47:04,840] {logging_mixin.py:115} INFO - [2023-01-05 21:47:04,840] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:47:05,664] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:47:05,665] {logging_mixin.py:115} INFO - [2023-01-05 21:47:05,665] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:47:05,666] {logging_mixin.py:115} INFO - [2023-01-05 21:47:05,665] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:47:05,673] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:47:05,701] {logging_mixin.py:115} INFO - [2023-01-05 21:47:05,701] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:47:05,725] {logging_mixin.py:115} INFO - [2023-01-05 21:47:05,725] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:47:05,735] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.901 seconds
[2023-01-05 21:47:36,155] {processor.py:153} INFO - Started process (PID=826) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:47:36,157] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:47:36,157] {logging_mixin.py:115} INFO - [2023-01-05 21:47:36,157] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:47:36,977] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:47:36,979] {logging_mixin.py:115} INFO - [2023-01-05 21:47:36,979] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:47:36,979] {logging_mixin.py:115} INFO - [2023-01-05 21:47:36,979] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:47:36,986] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:47:37,014] {logging_mixin.py:115} INFO - [2023-01-05 21:47:37,014] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:47:37,044] {logging_mixin.py:115} INFO - [2023-01-05 21:47:37,044] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:47:37,056] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.911 seconds
[2023-01-05 21:48:07,248] {processor.py:153} INFO - Started process (PID=850) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:48:07,248] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:48:07,249] {logging_mixin.py:115} INFO - [2023-01-05 21:48:07,249] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:48:08,636] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:48:08,637] {logging_mixin.py:115} INFO - [2023-01-05 21:48:08,637] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:48:08,638] {logging_mixin.py:115} INFO - [2023-01-05 21:48:08,638] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:48:08,645] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:48:08,667] {logging_mixin.py:115} INFO - [2023-01-05 21:48:08,667] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:48:08,687] {logging_mixin.py:115} INFO - [2023-01-05 21:48:08,687] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:48:08,697] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.455 seconds
[2023-01-05 21:48:38,793] {processor.py:153} INFO - Started process (PID=868) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:48:38,794] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:48:38,794] {logging_mixin.py:115} INFO - [2023-01-05 21:48:38,794] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:48:39,650] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:48:39,651] {logging_mixin.py:115} INFO - [2023-01-05 21:48:39,651] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:48:39,652] {logging_mixin.py:115} INFO - [2023-01-05 21:48:39,651] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:48:39,659] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:48:39,682] {logging_mixin.py:115} INFO - [2023-01-05 21:48:39,681] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:48:39,702] {logging_mixin.py:115} INFO - [2023-01-05 21:48:39,702] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:48:39,712] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.924 seconds
[2023-01-05 21:49:10,129] {processor.py:153} INFO - Started process (PID=894) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:49:10,130] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:49:10,131] {logging_mixin.py:115} INFO - [2023-01-05 21:49:10,131] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:49:10,976] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:49:10,977] {logging_mixin.py:115} INFO - [2023-01-05 21:49:10,977] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:49:10,978] {logging_mixin.py:115} INFO - [2023-01-05 21:49:10,978] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:49:10,985] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:49:11,009] {logging_mixin.py:115} INFO - [2023-01-05 21:49:11,009] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:49:11,030] {logging_mixin.py:115} INFO - [2023-01-05 21:49:11,030] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:49:11,041] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.918 seconds
[2023-01-05 21:49:41,142] {processor.py:153} INFO - Started process (PID=918) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:49:41,142] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:49:41,143] {logging_mixin.py:115} INFO - [2023-01-05 21:49:41,143] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:49:42,245] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:49:42,247] {logging_mixin.py:115} INFO - [2023-01-05 21:49:42,246] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:49:42,247] {logging_mixin.py:115} INFO - [2023-01-05 21:49:42,247] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:49:42,256] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:49:42,287] {logging_mixin.py:115} INFO - [2023-01-05 21:49:42,286] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:49:42,318] {logging_mixin.py:115} INFO - [2023-01-05 21:49:42,317] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:49:42,330] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.193 seconds
[2023-01-05 21:50:12,384] {processor.py:153} INFO - Started process (PID=942) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:50:12,388] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:50:12,389] {logging_mixin.py:115} INFO - [2023-01-05 21:50:12,389] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:50:13,493] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:50:13,494] {logging_mixin.py:115} INFO - [2023-01-05 21:50:13,494] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:50:13,495] {logging_mixin.py:115} INFO - [2023-01-05 21:50:13,494] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:50:13,501] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:50:13,524] {logging_mixin.py:115} INFO - [2023-01-05 21:50:13,524] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:50:13,544] {logging_mixin.py:115} INFO - [2023-01-05 21:50:13,544] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:50:13,554] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.176 seconds
[2023-01-05 21:50:43,653] {processor.py:153} INFO - Started process (PID=960) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:50:43,654] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:50:43,655] {logging_mixin.py:115} INFO - [2023-01-05 21:50:43,654] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:50:44,474] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:50:44,476] {logging_mixin.py:115} INFO - [2023-01-05 21:50:44,476] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:50:44,476] {logging_mixin.py:115} INFO - [2023-01-05 21:50:44,476] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:50:44,483] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:50:44,507] {logging_mixin.py:115} INFO - [2023-01-05 21:50:44,506] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:50:44,528] {logging_mixin.py:115} INFO - [2023-01-05 21:50:44,527] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:50:44,538] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.889 seconds
[2023-01-05 21:51:14,939] {processor.py:153} INFO - Started process (PID=985) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:51:14,941] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:51:14,941] {logging_mixin.py:115} INFO - [2023-01-05 21:51:14,941] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:51:15,928] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:51:15,930] {logging_mixin.py:115} INFO - [2023-01-05 21:51:15,930] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:51:15,930] {logging_mixin.py:115} INFO - [2023-01-05 21:51:15,930] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:51:15,937] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:51:15,968] {logging_mixin.py:115} INFO - [2023-01-05 21:51:15,967] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:51:15,997] {logging_mixin.py:115} INFO - [2023-01-05 21:51:15,997] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:51:16,010] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.075 seconds
[2023-01-05 21:51:46,107] {processor.py:153} INFO - Started process (PID=1010) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:51:46,109] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:51:46,109] {logging_mixin.py:115} INFO - [2023-01-05 21:51:46,109] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:51:46,969] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:51:46,970] {logging_mixin.py:115} INFO - [2023-01-05 21:51:46,970] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:51:46,970] {logging_mixin.py:115} INFO - [2023-01-05 21:51:46,970] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:51:46,977] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:51:47,001] {logging_mixin.py:115} INFO - [2023-01-05 21:51:47,001] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:51:47,023] {logging_mixin.py:115} INFO - [2023-01-05 21:51:47,022] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:51:47,034] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.932 seconds
[2023-01-05 21:52:17,319] {processor.py:153} INFO - Started process (PID=1036) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:52:17,320] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:52:17,321] {logging_mixin.py:115} INFO - [2023-01-05 21:52:17,321] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:52:18,565] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:52:18,567] {logging_mixin.py:115} INFO - [2023-01-05 21:52:18,567] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:52:18,568] {logging_mixin.py:115} INFO - [2023-01-05 21:52:18,567] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:52:18,579] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:52:18,611] {logging_mixin.py:115} INFO - [2023-01-05 21:52:18,611] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:52:18,642] {logging_mixin.py:115} INFO - [2023-01-05 21:52:18,642] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:52:18,667] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.355 seconds
[2023-01-05 21:52:48,775] {processor.py:153} INFO - Started process (PID=1053) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:52:48,779] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:52:48,780] {logging_mixin.py:115} INFO - [2023-01-05 21:52:48,780] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:52:49,658] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:52:49,660] {logging_mixin.py:115} INFO - [2023-01-05 21:52:49,660] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:52:49,661] {logging_mixin.py:115} INFO - [2023-01-05 21:52:49,660] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:52:49,677] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:52:49,710] {logging_mixin.py:115} INFO - [2023-01-05 21:52:49,710] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:52:49,742] {logging_mixin.py:115} INFO - [2023-01-05 21:52:49,742] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:52:49,755] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.985 seconds
[2023-01-05 21:53:19,868] {processor.py:153} INFO - Started process (PID=1080) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:53:19,869] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:53:19,870] {logging_mixin.py:115} INFO - [2023-01-05 21:53:19,870] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:53:20,741] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:53:20,742] {logging_mixin.py:115} INFO - [2023-01-05 21:53:20,742] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:53:20,743] {logging_mixin.py:115} INFO - [2023-01-05 21:53:20,742] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:53:20,750] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:53:20,773] {logging_mixin.py:115} INFO - [2023-01-05 21:53:20,773] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:53:20,794] {logging_mixin.py:115} INFO - [2023-01-05 21:53:20,794] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:53:20,805] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.942 seconds
[2023-01-05 21:53:51,231] {processor.py:153} INFO - Started process (PID=1107) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:53:51,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:53:51,233] {logging_mixin.py:115} INFO - [2023-01-05 21:53:51,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:53:52,110] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:53:52,111] {logging_mixin.py:115} INFO - [2023-01-05 21:53:52,111] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:53:52,111] {logging_mixin.py:115} INFO - [2023-01-05 21:53:52,111] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:53:52,118] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:53:52,141] {logging_mixin.py:115} INFO - [2023-01-05 21:53:52,141] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:53:52,162] {logging_mixin.py:115} INFO - [2023-01-05 21:53:52,162] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:53:52,173] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.947 seconds
[2023-01-05 21:54:22,325] {processor.py:153} INFO - Started process (PID=1124) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:54:22,327] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:54:22,327] {logging_mixin.py:115} INFO - [2023-01-05 21:54:22,327] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:54:23,150] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:54:23,151] {logging_mixin.py:115} INFO - [2023-01-05 21:54:23,151] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:54:23,152] {logging_mixin.py:115} INFO - [2023-01-05 21:54:23,151] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:54:23,158] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:54:23,182] {logging_mixin.py:115} INFO - [2023-01-05 21:54:23,182] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:54:23,204] {logging_mixin.py:115} INFO - [2023-01-05 21:54:23,204] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:54:23,215] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.894 seconds
[2023-01-05 21:54:53,409] {processor.py:153} INFO - Started process (PID=1148) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:54:53,411] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:54:53,411] {logging_mixin.py:115} INFO - [2023-01-05 21:54:53,411] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:54:54,290] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:54:54,291] {logging_mixin.py:115} INFO - [2023-01-05 21:54:54,291] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:54:54,291] {logging_mixin.py:115} INFO - [2023-01-05 21:54:54,291] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:54:54,298] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:54:54,320] {logging_mixin.py:115} INFO - [2023-01-05 21:54:54,320] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:54:54,340] {logging_mixin.py:115} INFO - [2023-01-05 21:54:54,340] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:54:54,349] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.944 seconds
[2023-01-05 21:55:24,497] {processor.py:153} INFO - Started process (PID=1172) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:55:24,499] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:55:24,500] {logging_mixin.py:115} INFO - [2023-01-05 21:55:24,499] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:55:25,322] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:55:25,324] {logging_mixin.py:115} INFO - [2023-01-05 21:55:25,324] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:55:25,324] {logging_mixin.py:115} INFO - [2023-01-05 21:55:25,324] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:55:25,331] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:55:25,355] {logging_mixin.py:115} INFO - [2023-01-05 21:55:25,355] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:55:25,376] {logging_mixin.py:115} INFO - [2023-01-05 21:55:25,376] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:55:25,386] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.894 seconds
[2023-01-05 21:55:55,587] {processor.py:153} INFO - Started process (PID=1196) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:55:55,589] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:55:55,589] {logging_mixin.py:115} INFO - [2023-01-05 21:55:55,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:55:56,620] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:55:56,621] {logging_mixin.py:115} INFO - [2023-01-05 21:55:56,621] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:55:56,622] {logging_mixin.py:115} INFO - [2023-01-05 21:55:56,621] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:55:56,628] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:55:56,652] {logging_mixin.py:115} INFO - [2023-01-05 21:55:56,652] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:55:56,679] {logging_mixin.py:115} INFO - [2023-01-05 21:55:56,679] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:55:56,692] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.110 seconds
[2023-01-05 21:56:26,801] {processor.py:153} INFO - Started process (PID=1216) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:56:26,802] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:56:26,803] {logging_mixin.py:115} INFO - [2023-01-05 21:56:26,803] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:56:27,634] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:56:27,636] {logging_mixin.py:115} INFO - [2023-01-05 21:56:27,636] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:56:27,636] {logging_mixin.py:115} INFO - [2023-01-05 21:56:27,636] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:56:27,643] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:56:27,673] {logging_mixin.py:115} INFO - [2023-01-05 21:56:27,673] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:56:27,703] {logging_mixin.py:115} INFO - [2023-01-05 21:56:27,703] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:56:27,715] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.919 seconds
[2023-01-05 21:56:57,967] {processor.py:153} INFO - Started process (PID=1241) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:56:57,968] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:56:57,969] {logging_mixin.py:115} INFO - [2023-01-05 21:56:57,969] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:56:58,852] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:56:58,853] {logging_mixin.py:115} INFO - [2023-01-05 21:56:58,853] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:56:58,853] {logging_mixin.py:115} INFO - [2023-01-05 21:56:58,853] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:56:58,860] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:56:58,885] {logging_mixin.py:115} INFO - [2023-01-05 21:56:58,885] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:56:58,908] {logging_mixin.py:115} INFO - [2023-01-05 21:56:58,908] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:56:58,918] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.957 seconds
[2023-01-05 21:57:29,057] {processor.py:153} INFO - Started process (PID=1265) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:57:29,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:57:29,059] {logging_mixin.py:115} INFO - [2023-01-05 21:57:29,059] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:57:29,881] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:57:29,883] {logging_mixin.py:115} INFO - [2023-01-05 21:57:29,883] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:57:29,883] {logging_mixin.py:115} INFO - [2023-01-05 21:57:29,883] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:57:29,890] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:57:29,913] {logging_mixin.py:115} INFO - [2023-01-05 21:57:29,913] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:57:29,934] {logging_mixin.py:115} INFO - [2023-01-05 21:57:29,934] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:57:29,944] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.893 seconds
[2023-01-05 21:58:00,213] {processor.py:153} INFO - Started process (PID=1290) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:58:00,215] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:58:00,215] {logging_mixin.py:115} INFO - [2023-01-05 21:58:00,215] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:58:01,117] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:58:01,118] {logging_mixin.py:115} INFO - [2023-01-05 21:58:01,118] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:58:01,119] {logging_mixin.py:115} INFO - [2023-01-05 21:58:01,118] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:58:01,126] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:58:01,156] {logging_mixin.py:115} INFO - [2023-01-05 21:58:01,155] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:58:01,182] {logging_mixin.py:115} INFO - [2023-01-05 21:58:01,181] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:58:01,193] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.986 seconds
[2023-01-05 21:58:31,296] {processor.py:153} INFO - Started process (PID=1309) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:58:31,297] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:58:31,298] {logging_mixin.py:115} INFO - [2023-01-05 21:58:31,298] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:58:32,190] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:58:32,191] {logging_mixin.py:115} INFO - [2023-01-05 21:58:32,191] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:58:32,192] {logging_mixin.py:115} INFO - [2023-01-05 21:58:32,192] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:58:32,199] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:58:32,223] {logging_mixin.py:115} INFO - [2023-01-05 21:58:32,222] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:58:32,244] {logging_mixin.py:115} INFO - [2023-01-05 21:58:32,244] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:58:32,254] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.963 seconds
[2023-01-05 21:59:02,550] {processor.py:153} INFO - Started process (PID=1334) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:59:02,551] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:59:02,552] {logging_mixin.py:115} INFO - [2023-01-05 21:59:02,552] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:59:03,413] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:59:03,415] {logging_mixin.py:115} INFO - [2023-01-05 21:59:03,415] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:59:03,416] {logging_mixin.py:115} INFO - [2023-01-05 21:59:03,415] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:59:03,422] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:59:03,445] {logging_mixin.py:115} INFO - [2023-01-05 21:59:03,444] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:59:03,466] {logging_mixin.py:115} INFO - [2023-01-05 21:59:03,465] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:59:03,475] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.930 seconds
[2023-01-05 21:59:33,634] {processor.py:153} INFO - Started process (PID=1361) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:59:33,635] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 21:59:33,636] {logging_mixin.py:115} INFO - [2023-01-05 21:59:33,636] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:59:34,503] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 21:59:34,504] {logging_mixin.py:115} INFO - [2023-01-05 21:59:34,504] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 21:59:34,505] {logging_mixin.py:115} INFO - [2023-01-05 21:59:34,504] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 21:59:34,512] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 21:59:34,536] {logging_mixin.py:115} INFO - [2023-01-05 21:59:34,536] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 21:59:34,558] {logging_mixin.py:115} INFO - [2023-01-05 21:59:34,558] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 21:59:34,570] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.941 seconds
[2023-01-05 22:00:04,786] {processor.py:153} INFO - Started process (PID=1385) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:00:04,786] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:00:04,788] {logging_mixin.py:115} INFO - [2023-01-05 22:00:04,788] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:00:06,124] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:00:06,126] {logging_mixin.py:115} INFO - [2023-01-05 22:00:06,126] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:00:06,127] {logging_mixin.py:115} INFO - [2023-01-05 22:00:06,126] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:00:06,138] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:00:06,170] {logging_mixin.py:115} INFO - [2023-01-05 22:00:06,170] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:00:06,201] {logging_mixin.py:115} INFO - [2023-01-05 22:00:06,201] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:00:06,215] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.440 seconds
[2023-01-05 22:00:36,315] {processor.py:153} INFO - Started process (PID=1402) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:00:36,315] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:00:36,316] {logging_mixin.py:115} INFO - [2023-01-05 22:00:36,316] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:00:37,125] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:00:37,126] {logging_mixin.py:115} INFO - [2023-01-05 22:00:37,126] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:00:37,126] {logging_mixin.py:115} INFO - [2023-01-05 22:00:37,126] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:00:37,133] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:00:37,158] {logging_mixin.py:115} INFO - [2023-01-05 22:00:37,158] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:00:37,180] {logging_mixin.py:115} INFO - [2023-01-05 22:00:37,179] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:00:37,190] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.880 seconds
[2023-01-05 22:01:07,289] {processor.py:153} INFO - Started process (PID=1428) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:01:07,290] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:01:07,290] {logging_mixin.py:115} INFO - [2023-01-05 22:01:07,290] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:01:08,118] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:01:08,120] {logging_mixin.py:115} INFO - [2023-01-05 22:01:08,120] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:01:08,120] {logging_mixin.py:115} INFO - [2023-01-05 22:01:08,120] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:01:08,127] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:01:08,149] {logging_mixin.py:115} INFO - [2023-01-05 22:01:08,149] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:01:08,169] {logging_mixin.py:115} INFO - [2023-01-05 22:01:08,169] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:01:08,179] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.896 seconds
[2023-01-05 22:01:38,279] {processor.py:153} INFO - Started process (PID=1453) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:01:38,280] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:01:38,280] {logging_mixin.py:115} INFO - [2023-01-05 22:01:38,280] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:01:39,240] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:01:39,242] {logging_mixin.py:115} INFO - [2023-01-05 22:01:39,242] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:01:39,243] {logging_mixin.py:115} INFO - [2023-01-05 22:01:39,242] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:01:39,254] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:01:39,285] {logging_mixin.py:115} INFO - [2023-01-05 22:01:39,284] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:01:39,314] {logging_mixin.py:115} INFO - [2023-01-05 22:01:39,314] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:01:39,327] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.052 seconds
[2023-01-05 22:02:09,414] {processor.py:153} INFO - Started process (PID=1479) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:02:09,417] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:02:09,417] {logging_mixin.py:115} INFO - [2023-01-05 22:02:09,417] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:02:10,280] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:02:10,282] {logging_mixin.py:115} INFO - [2023-01-05 22:02:10,281] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:02:10,282] {logging_mixin.py:115} INFO - [2023-01-05 22:02:10,282] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:02:10,289] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:02:10,311] {logging_mixin.py:115} INFO - [2023-01-05 22:02:10,311] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:02:10,331] {logging_mixin.py:115} INFO - [2023-01-05 22:02:10,331] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:02:10,341] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.932 seconds
[2023-01-05 22:02:40,878] {processor.py:153} INFO - Started process (PID=1497) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:02:40,879] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:02:40,880] {logging_mixin.py:115} INFO - [2023-01-05 22:02:40,880] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:02:41,724] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:02:41,725] {logging_mixin.py:115} INFO - [2023-01-05 22:02:41,725] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:02:41,726] {logging_mixin.py:115} INFO - [2023-01-05 22:02:41,725] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:02:41,733] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:02:41,755] {logging_mixin.py:115} INFO - [2023-01-05 22:02:41,755] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:02:41,775] {logging_mixin.py:115} INFO - [2023-01-05 22:02:41,775] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:02:41,785] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.913 seconds
[2023-01-05 22:03:12,157] {processor.py:153} INFO - Started process (PID=1522) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:03:12,157] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:03:12,158] {logging_mixin.py:115} INFO - [2023-01-05 22:03:12,158] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:03:13,309] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:03:13,311] {logging_mixin.py:115} INFO - [2023-01-05 22:03:13,310] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:03:13,311] {logging_mixin.py:115} INFO - [2023-01-05 22:03:13,311] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:03:13,322] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:03:13,354] {logging_mixin.py:115} INFO - [2023-01-05 22:03:13,354] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:03:13,387] {logging_mixin.py:115} INFO - [2023-01-05 22:03:13,387] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:03:13,400] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.249 seconds
[2023-01-05 22:03:43,469] {processor.py:153} INFO - Started process (PID=1547) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:03:43,471] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:03:43,471] {logging_mixin.py:115} INFO - [2023-01-05 22:03:43,471] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:03:44,294] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:03:44,295] {logging_mixin.py:115} INFO - [2023-01-05 22:03:44,295] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:03:44,296] {logging_mixin.py:115} INFO - [2023-01-05 22:03:44,296] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:03:44,303] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:03:44,325] {logging_mixin.py:115} INFO - [2023-01-05 22:03:44,325] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:03:44,345] {logging_mixin.py:115} INFO - [2023-01-05 22:03:44,345] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:03:44,355] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.891 seconds
[2023-01-05 22:04:14,561] {processor.py:153} INFO - Started process (PID=1571) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:04:14,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:04:14,563] {logging_mixin.py:115} INFO - [2023-01-05 22:04:14,563] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:04:15,599] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:04:15,600] {logging_mixin.py:115} INFO - [2023-01-05 22:04:15,600] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:04:15,600] {logging_mixin.py:115} INFO - [2023-01-05 22:04:15,600] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:04:15,614] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:04:15,638] {logging_mixin.py:115} INFO - [2023-01-05 22:04:15,638] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:04:15,659] {logging_mixin.py:115} INFO - [2023-01-05 22:04:15,658] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:04:15,668] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.113 seconds
[2023-01-05 22:04:45,773] {processor.py:153} INFO - Started process (PID=1590) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:04:45,774] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:04:45,775] {logging_mixin.py:115} INFO - [2023-01-05 22:04:45,775] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:04:46,973] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:04:46,975] {logging_mixin.py:115} INFO - [2023-01-05 22:04:46,975] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:04:46,976] {logging_mixin.py:115} INFO - [2023-01-05 22:04:46,976] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:04:46,987] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:04:47,018] {logging_mixin.py:115} INFO - [2023-01-05 22:04:47,018] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:04:47,048] {logging_mixin.py:115} INFO - [2023-01-05 22:04:47,048] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:04:47,061] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.294 seconds
[2023-01-05 22:05:17,181] {processor.py:153} INFO - Started process (PID=1615) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:05:17,185] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:05:17,185] {logging_mixin.py:115} INFO - [2023-01-05 22:05:17,185] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:05:18,022] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:05:18,024] {logging_mixin.py:115} INFO - [2023-01-05 22:05:18,024] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:05:18,025] {logging_mixin.py:115} INFO - [2023-01-05 22:05:18,024] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:05:18,032] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:05:18,061] {logging_mixin.py:115} INFO - [2023-01-05 22:05:18,061] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:05:18,085] {logging_mixin.py:115} INFO - [2023-01-05 22:05:18,085] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:05:18,096] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.919 seconds
[2023-01-05 22:05:48,363] {processor.py:153} INFO - Started process (PID=1639) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:05:48,364] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:05:48,364] {logging_mixin.py:115} INFO - [2023-01-05 22:05:48,364] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:05:49,212] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:05:49,214] {logging_mixin.py:115} INFO - [2023-01-05 22:05:49,214] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:05:49,215] {logging_mixin.py:115} INFO - [2023-01-05 22:05:49,214] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:05:49,226] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:05:49,251] {logging_mixin.py:115} INFO - [2023-01-05 22:05:49,250] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:05:49,272] {logging_mixin.py:115} INFO - [2023-01-05 22:05:49,272] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:05:49,282] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.923 seconds
[2023-01-05 22:06:19,453] {processor.py:153} INFO - Started process (PID=1664) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:06:19,454] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:06:19,454] {logging_mixin.py:115} INFO - [2023-01-05 22:06:19,454] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:06:20,306] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:06:20,307] {logging_mixin.py:115} INFO - [2023-01-05 22:06:20,307] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:06:20,307] {logging_mixin.py:115} INFO - [2023-01-05 22:06:20,307] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:06:20,314] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:06:20,337] {logging_mixin.py:115} INFO - [2023-01-05 22:06:20,336] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:06:20,357] {logging_mixin.py:115} INFO - [2023-01-05 22:06:20,357] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:06:20,367] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.919 seconds
[2023-01-05 22:06:50,540] {processor.py:153} INFO - Started process (PID=1682) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:06:50,543] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:06:50,543] {logging_mixin.py:115} INFO - [2023-01-05 22:06:50,543] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:06:51,390] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:06:51,392] {logging_mixin.py:115} INFO - [2023-01-05 22:06:51,392] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:06:51,392] {logging_mixin.py:115} INFO - [2023-01-05 22:06:51,392] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:06:51,399] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:06:51,421] {logging_mixin.py:115} INFO - [2023-01-05 22:06:51,421] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:06:51,441] {logging_mixin.py:115} INFO - [2023-01-05 22:06:51,441] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:06:51,451] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.916 seconds
[2023-01-05 22:07:21,988] {processor.py:153} INFO - Started process (PID=1707) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:07:21,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:07:21,990] {logging_mixin.py:115} INFO - [2023-01-05 22:07:21,990] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:07:22,873] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:07:22,874] {logging_mixin.py:115} INFO - [2023-01-05 22:07:22,874] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:07:22,875] {logging_mixin.py:115} INFO - [2023-01-05 22:07:22,874] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:07:22,882] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:07:22,905] {logging_mixin.py:115} INFO - [2023-01-05 22:07:22,905] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:07:22,926] {logging_mixin.py:115} INFO - [2023-01-05 22:07:22,926] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:07:22,936] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.953 seconds
[2023-01-05 22:07:53,087] {processor.py:153} INFO - Started process (PID=1732) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:07:53,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:07:53,089] {logging_mixin.py:115} INFO - [2023-01-05 22:07:53,089] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:07:53,908] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:07:53,909] {logging_mixin.py:115} INFO - [2023-01-05 22:07:53,909] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:07:53,910] {logging_mixin.py:115} INFO - [2023-01-05 22:07:53,909] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:07:53,921] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:07:53,956] {logging_mixin.py:115} INFO - [2023-01-05 22:07:53,956] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:07:53,977] {logging_mixin.py:115} INFO - [2023-01-05 22:07:53,977] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:07:53,990] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.907 seconds
[2023-01-05 22:08:24,179] {processor.py:153} INFO - Started process (PID=1757) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:08:24,180] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:08:24,181] {logging_mixin.py:115} INFO - [2023-01-05 22:08:24,181] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:08:25,194] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:08:25,195] {logging_mixin.py:115} INFO - [2023-01-05 22:08:25,195] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:08:25,196] {logging_mixin.py:115} INFO - [2023-01-05 22:08:25,195] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:08:25,202] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:08:25,225] {logging_mixin.py:115} INFO - [2023-01-05 22:08:25,225] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:08:25,247] {logging_mixin.py:115} INFO - [2023-01-05 22:08:25,247] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:08:25,257] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.084 seconds
[2023-01-05 22:08:55,361] {processor.py:153} INFO - Started process (PID=1775) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:08:55,362] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:08:55,362] {logging_mixin.py:115} INFO - [2023-01-05 22:08:55,362] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:08:56,224] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:08:56,225] {logging_mixin.py:115} INFO - [2023-01-05 22:08:56,225] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:08:56,226] {logging_mixin.py:115} INFO - [2023-01-05 22:08:56,226] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:08:56,233] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:08:56,254] {logging_mixin.py:115} INFO - [2023-01-05 22:08:56,254] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:08:56,275] {logging_mixin.py:115} INFO - [2023-01-05 22:08:56,274] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:08:56,284] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.929 seconds
[2023-01-05 22:09:26,521] {processor.py:153} INFO - Started process (PID=1802) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:09:26,522] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:09:26,523] {logging_mixin.py:115} INFO - [2023-01-05 22:09:26,523] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:09:27,353] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:09:27,354] {logging_mixin.py:115} INFO - [2023-01-05 22:09:27,354] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:09:27,354] {logging_mixin.py:115} INFO - [2023-01-05 22:09:27,354] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:09:27,366] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:09:27,397] {logging_mixin.py:115} INFO - [2023-01-05 22:09:27,396] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:09:27,425] {logging_mixin.py:115} INFO - [2023-01-05 22:09:27,425] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:09:27,438] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.922 seconds
[2023-01-05 22:09:57,710] {processor.py:153} INFO - Started process (PID=1826) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:09:57,712] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:09:57,712] {logging_mixin.py:115} INFO - [2023-01-05 22:09:57,712] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:09:58,654] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:09:58,655] {logging_mixin.py:115} INFO - [2023-01-05 22:09:58,655] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:09:58,655] {logging_mixin.py:115} INFO - [2023-01-05 22:09:58,655] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:09:58,663] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:09:58,688] {logging_mixin.py:115} INFO - [2023-01-05 22:09:58,687] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:09:58,718] {logging_mixin.py:115} INFO - [2023-01-05 22:09:58,718] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:09:58,732] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.027 seconds
[2023-01-05 22:10:28,844] {processor.py:153} INFO - Started process (PID=1852) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:10:28,845] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:10:28,846] {logging_mixin.py:115} INFO - [2023-01-05 22:10:28,846] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:10:29,891] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:10:29,892] {logging_mixin.py:115} INFO - [2023-01-05 22:10:29,892] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:10:29,893] {logging_mixin.py:115} INFO - [2023-01-05 22:10:29,893] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:10:29,900] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:10:29,925] {logging_mixin.py:115} INFO - [2023-01-05 22:10:29,924] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:10:29,946] {logging_mixin.py:115} INFO - [2023-01-05 22:10:29,946] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:10:29,956] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.118 seconds
[2023-01-05 22:11:00,060] {processor.py:153} INFO - Started process (PID=1869) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:11:00,061] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:11:00,062] {logging_mixin.py:115} INFO - [2023-01-05 22:11:00,062] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:11:01,207] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:11:01,209] {logging_mixin.py:115} INFO - [2023-01-05 22:11:01,209] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:11:01,210] {logging_mixin.py:115} INFO - [2023-01-05 22:11:01,209] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:11:01,222] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:11:01,252] {logging_mixin.py:115} INFO - [2023-01-05 22:11:01,251] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:11:01,282] {logging_mixin.py:115} INFO - [2023-01-05 22:11:01,282] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:11:01,294] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.240 seconds
[2023-01-05 22:11:31,399] {processor.py:153} INFO - Started process (PID=1893) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:11:31,400] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:11:31,400] {logging_mixin.py:115} INFO - [2023-01-05 22:11:31,400] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:11:32,250] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:11:32,251] {logging_mixin.py:115} INFO - [2023-01-05 22:11:32,251] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:11:32,251] {logging_mixin.py:115} INFO - [2023-01-05 22:11:32,251] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:11:32,258] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:11:32,281] {logging_mixin.py:115} INFO - [2023-01-05 22:11:32,281] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:11:32,302] {logging_mixin.py:115} INFO - [2023-01-05 22:11:32,302] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:11:32,312] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.917 seconds
[2023-01-05 22:12:02,722] {processor.py:153} INFO - Started process (PID=1917) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:12:02,723] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:12:02,724] {logging_mixin.py:115} INFO - [2023-01-05 22:12:02,724] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:12:03,543] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:12:03,544] {logging_mixin.py:115} INFO - [2023-01-05 22:12:03,544] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:12:03,545] {logging_mixin.py:115} INFO - [2023-01-05 22:12:03,544] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:12:03,552] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:12:03,579] {logging_mixin.py:115} INFO - [2023-01-05 22:12:03,578] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:12:03,600] {logging_mixin.py:115} INFO - [2023-01-05 22:12:03,600] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:12:03,610] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.893 seconds
[2023-01-05 22:12:33,812] {processor.py:153} INFO - Started process (PID=1943) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:12:33,814] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:12:33,814] {logging_mixin.py:115} INFO - [2023-01-05 22:12:33,814] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:12:34,687] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:12:34,689] {logging_mixin.py:115} INFO - [2023-01-05 22:12:34,689] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:12:34,689] {logging_mixin.py:115} INFO - [2023-01-05 22:12:34,689] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:12:34,696] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:12:34,720] {logging_mixin.py:115} INFO - [2023-01-05 22:12:34,720] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:12:34,742] {logging_mixin.py:115} INFO - [2023-01-05 22:12:34,742] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:12:34,752] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.947 seconds
[2023-01-05 22:13:04,898] {processor.py:153} INFO - Started process (PID=1962) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:13:04,904] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:13:04,905] {logging_mixin.py:115} INFO - [2023-01-05 22:13:04,905] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:13:05,786] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:13:05,788] {logging_mixin.py:115} INFO - [2023-01-05 22:13:05,788] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:13:05,788] {logging_mixin.py:115} INFO - [2023-01-05 22:13:05,788] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:13:05,800] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:13:05,832] {logging_mixin.py:115} INFO - [2023-01-05 22:13:05,832] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:13:05,862] {logging_mixin.py:115} INFO - [2023-01-05 22:13:05,862] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:13:05,876] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.983 seconds
[2023-01-05 22:13:35,986] {processor.py:153} INFO - Started process (PID=1988) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:13:35,988] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:13:35,988] {logging_mixin.py:115} INFO - [2023-01-05 22:13:35,988] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:13:36,852] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:13:36,854] {logging_mixin.py:115} INFO - [2023-01-05 22:13:36,853] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:13:36,854] {logging_mixin.py:115} INFO - [2023-01-05 22:13:36,854] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:13:36,861] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:13:36,883] {logging_mixin.py:115} INFO - [2023-01-05 22:13:36,883] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:13:36,904] {logging_mixin.py:115} INFO - [2023-01-05 22:13:36,904] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:13:36,913] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.933 seconds
[2023-01-05 22:14:07,258] {processor.py:153} INFO - Started process (PID=2013) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:14:07,260] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:14:07,260] {logging_mixin.py:115} INFO - [2023-01-05 22:14:07,260] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:14:08,094] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:14:08,096] {logging_mixin.py:115} INFO - [2023-01-05 22:14:08,096] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:14:08,096] {logging_mixin.py:115} INFO - [2023-01-05 22:14:08,096] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:14:08,103] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:14:08,127] {logging_mixin.py:115} INFO - [2023-01-05 22:14:08,127] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:14:08,148] {logging_mixin.py:115} INFO - [2023-01-05 22:14:08,148] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:14:08,159] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.905 seconds
[2023-01-05 22:14:38,350] {processor.py:153} INFO - Started process (PID=2037) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:14:38,350] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:14:38,351] {logging_mixin.py:115} INFO - [2023-01-05 22:14:38,351] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:14:39,414] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:14:39,415] {logging_mixin.py:115} INFO - [2023-01-05 22:14:39,415] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:14:39,416] {logging_mixin.py:115} INFO - [2023-01-05 22:14:39,415] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:14:39,423] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:14:39,451] {logging_mixin.py:115} INFO - [2023-01-05 22:14:39,451] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:14:39,474] {logging_mixin.py:115} INFO - [2023-01-05 22:14:39,474] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:14:39,484] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.140 seconds
[2023-01-05 22:15:09,543] {processor.py:153} INFO - Started process (PID=2055) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:15:09,546] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:15:09,547] {logging_mixin.py:115} INFO - [2023-01-05 22:15:09,547] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:15:10,432] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:15:10,434] {logging_mixin.py:115} INFO - [2023-01-05 22:15:10,433] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:15:10,434] {logging_mixin.py:115} INFO - [2023-01-05 22:15:10,434] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:15:10,446] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:15:10,478] {logging_mixin.py:115} INFO - [2023-01-05 22:15:10,477] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:15:10,509] {logging_mixin.py:115} INFO - [2023-01-05 22:15:10,509] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:15:10,522] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.986 seconds
[2023-01-05 22:15:40,631] {processor.py:153} INFO - Started process (PID=2082) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:15:40,632] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:15:40,632] {logging_mixin.py:115} INFO - [2023-01-05 22:15:40,632] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:15:41,485] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:15:41,487] {logging_mixin.py:115} INFO - [2023-01-05 22:15:41,487] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:15:41,487] {logging_mixin.py:115} INFO - [2023-01-05 22:15:41,487] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:15:41,494] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:15:41,516] {logging_mixin.py:115} INFO - [2023-01-05 22:15:41,516] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:15:41,536] {logging_mixin.py:115} INFO - [2023-01-05 22:15:41,536] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:15:41,546] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.920 seconds
[2023-01-05 22:16:11,846] {processor.py:153} INFO - Started process (PID=2110) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:16:11,848] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:16:11,848] {logging_mixin.py:115} INFO - [2023-01-05 22:16:11,848] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:16:12,703] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:16:12,704] {logging_mixin.py:115} INFO - [2023-01-05 22:16:12,704] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:16:12,705] {logging_mixin.py:115} INFO - [2023-01-05 22:16:12,705] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:16:12,714] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:16:12,738] {logging_mixin.py:115} INFO - [2023-01-05 22:16:12,737] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:16:12,758] {logging_mixin.py:115} INFO - [2023-01-05 22:16:12,758] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:16:12,767] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.927 seconds
[2023-01-05 22:16:42,935] {processor.py:153} INFO - Started process (PID=2137) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:16:42,936] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:16:42,937] {logging_mixin.py:115} INFO - [2023-01-05 22:16:42,937] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:16:44,263] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:16:44,265] {logging_mixin.py:115} INFO - [2023-01-05 22:16:44,265] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:16:44,266] {logging_mixin.py:115} INFO - [2023-01-05 22:16:44,265] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:16:44,277] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:16:44,309] {logging_mixin.py:115} INFO - [2023-01-05 22:16:44,308] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:16:44,337] {logging_mixin.py:115} INFO - [2023-01-05 22:16:44,337] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:16:44,350] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.421 seconds
[2023-01-05 22:17:14,458] {processor.py:153} INFO - Started process (PID=2155) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:17:14,460] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:17:14,460] {logging_mixin.py:115} INFO - [2023-01-05 22:17:14,460] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:17:15,374] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:17:15,376] {logging_mixin.py:115} INFO - [2023-01-05 22:17:15,376] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:17:15,377] {logging_mixin.py:115} INFO - [2023-01-05 22:17:15,377] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:17:15,388] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:17:15,419] {logging_mixin.py:115} INFO - [2023-01-05 22:17:15,419] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:17:15,450] {logging_mixin.py:115} INFO - [2023-01-05 22:17:15,450] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:17:15,463] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.010 seconds
[2023-01-05 22:17:45,572] {processor.py:153} INFO - Started process (PID=2181) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:17:45,574] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:17:45,575] {logging_mixin.py:115} INFO - [2023-01-05 22:17:45,575] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:17:46,429] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:17:46,431] {logging_mixin.py:115} INFO - [2023-01-05 22:17:46,430] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:17:46,431] {logging_mixin.py:115} INFO - [2023-01-05 22:17:46,431] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:17:46,438] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:17:46,460] {logging_mixin.py:115} INFO - [2023-01-05 22:17:46,460] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:17:46,481] {logging_mixin.py:115} INFO - [2023-01-05 22:17:46,481] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:17:46,492] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.925 seconds
[2023-01-05 22:18:16,736] {processor.py:153} INFO - Started process (PID=2206) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:18:16,737] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:18:16,738] {logging_mixin.py:115} INFO - [2023-01-05 22:18:16,738] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:18:17,919] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:18:17,921] {logging_mixin.py:115} INFO - [2023-01-05 22:18:17,921] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:18:17,922] {logging_mixin.py:115} INFO - [2023-01-05 22:18:17,921] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:18:17,933] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:18:17,966] {logging_mixin.py:115} INFO - [2023-01-05 22:18:17,966] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:18:17,999] {logging_mixin.py:115} INFO - [2023-01-05 22:18:17,999] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:18:18,015] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.286 seconds
[2023-01-05 22:18:48,101] {processor.py:153} INFO - Started process (PID=2231) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:18:48,102] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:18:48,102] {logging_mixin.py:115} INFO - [2023-01-05 22:18:48,102] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:18:49,068] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:18:49,069] {logging_mixin.py:115} INFO - [2023-01-05 22:18:49,069] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:18:49,070] {logging_mixin.py:115} INFO - [2023-01-05 22:18:49,069] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:18:49,081] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:18:49,112] {logging_mixin.py:115} INFO - [2023-01-05 22:18:49,112] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:18:49,134] {logging_mixin.py:115} INFO - [2023-01-05 22:18:49,134] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:18:49,144] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.049 seconds
[2023-01-05 22:19:19,251] {processor.py:153} INFO - Started process (PID=2248) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:19:19,253] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:19:19,253] {logging_mixin.py:115} INFO - [2023-01-05 22:19:19,253] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:19:20,265] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:19:20,267] {logging_mixin.py:115} INFO - [2023-01-05 22:19:20,267] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:19:20,268] {logging_mixin.py:115} INFO - [2023-01-05 22:19:20,267] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:19:20,280] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:19:20,311] {logging_mixin.py:115} INFO - [2023-01-05 22:19:20,311] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:19:20,342] {logging_mixin.py:115} INFO - [2023-01-05 22:19:20,342] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:19:20,356] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.109 seconds
[2023-01-05 22:19:50,464] {processor.py:153} INFO - Started process (PID=2272) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:19:50,465] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:19:50,466] {logging_mixin.py:115} INFO - [2023-01-05 22:19:50,466] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:19:51,451] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:19:51,452] {logging_mixin.py:115} INFO - [2023-01-05 22:19:51,452] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:19:51,453] {logging_mixin.py:115} INFO - [2023-01-05 22:19:51,453] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:19:51,465] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:19:51,500] {logging_mixin.py:115} INFO - [2023-01-05 22:19:51,499] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:19:51,531] {logging_mixin.py:115} INFO - [2023-01-05 22:19:51,531] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:19:51,544] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.085 seconds
[2023-01-05 22:20:21,664] {processor.py:153} INFO - Started process (PID=2296) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:20:21,665] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:20:21,666] {logging_mixin.py:115} INFO - [2023-01-05 22:20:21,666] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:20:22,551] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:20:22,552] {logging_mixin.py:115} INFO - [2023-01-05 22:20:22,552] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:20:22,553] {logging_mixin.py:115} INFO - [2023-01-05 22:20:22,553] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:20:22,560] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:20:22,589] {logging_mixin.py:115} INFO - [2023-01-05 22:20:22,589] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:20:22,614] {logging_mixin.py:115} INFO - [2023-01-05 22:20:22,613] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:20:22,624] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.965 seconds
[2023-01-05 22:20:52,948] {processor.py:153} INFO - Started process (PID=2323) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:20:52,949] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:20:52,949] {logging_mixin.py:115} INFO - [2023-01-05 22:20:52,949] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:20:53,773] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:20:53,775] {logging_mixin.py:115} INFO - [2023-01-05 22:20:53,775] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:20:53,775] {logging_mixin.py:115} INFO - [2023-01-05 22:20:53,775] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:20:53,782] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:20:53,806] {logging_mixin.py:115} INFO - [2023-01-05 22:20:53,806] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:20:53,826] {logging_mixin.py:115} INFO - [2023-01-05 22:20:53,826] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:20:53,836] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.893 seconds
[2023-01-05 22:21:23,943] {processor.py:153} INFO - Started process (PID=2342) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:21:23,945] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:21:23,945] {logging_mixin.py:115} INFO - [2023-01-05 22:21:23,945] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:21:25,225] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:21:25,226] {logging_mixin.py:115} INFO - [2023-01-05 22:21:25,226] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:21:25,227] {logging_mixin.py:115} INFO - [2023-01-05 22:21:25,227] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:21:25,238] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:21:25,270] {logging_mixin.py:115} INFO - [2023-01-05 22:21:25,270] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:21:25,304] {logging_mixin.py:115} INFO - [2023-01-05 22:21:25,304] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:21:25,319] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.381 seconds
[2023-01-05 22:21:55,427] {processor.py:153} INFO - Started process (PID=2367) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:21:55,429] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:21:55,430] {logging_mixin.py:115} INFO - [2023-01-05 22:21:55,430] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:21:56,321] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:21:56,322] {logging_mixin.py:115} INFO - [2023-01-05 22:21:56,322] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:21:56,323] {logging_mixin.py:115} INFO - [2023-01-05 22:21:56,322] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:21:56,330] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:21:56,352] {logging_mixin.py:115} INFO - [2023-01-05 22:21:56,352] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:21:56,374] {logging_mixin.py:115} INFO - [2023-01-05 22:21:56,374] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:21:56,385] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.963 seconds
[2023-01-05 22:22:26,661] {processor.py:153} INFO - Started process (PID=2393) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:22:26,664] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:22:26,665] {logging_mixin.py:115} INFO - [2023-01-05 22:22:26,665] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:22:27,487] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:22:27,488] {logging_mixin.py:115} INFO - [2023-01-05 22:22:27,488] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:22:27,489] {logging_mixin.py:115} INFO - [2023-01-05 22:22:27,489] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:22:27,496] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:22:27,526] {logging_mixin.py:115} INFO - [2023-01-05 22:22:27,525] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:22:27,550] {logging_mixin.py:115} INFO - [2023-01-05 22:22:27,550] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:22:27,561] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.905 seconds
[2023-01-05 22:22:57,801] {processor.py:153} INFO - Started process (PID=2419) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:22:57,803] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:22:57,803] {logging_mixin.py:115} INFO - [2023-01-05 22:22:57,803] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:22:58,627] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:22:58,628] {logging_mixin.py:115} INFO - [2023-01-05 22:22:58,628] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:22:58,629] {logging_mixin.py:115} INFO - [2023-01-05 22:22:58,628] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:22:58,635] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:22:58,658] {logging_mixin.py:115} INFO - [2023-01-05 22:22:58,657] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:22:58,678] {logging_mixin.py:115} INFO - [2023-01-05 22:22:58,678] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:22:58,688] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.891 seconds
[2023-01-05 22:23:28,883] {processor.py:153} INFO - Started process (PID=2437) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:23:28,884] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:23:28,885] {logging_mixin.py:115} INFO - [2023-01-05 22:23:28,885] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:23:29,812] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:23:29,813] {logging_mixin.py:115} INFO - [2023-01-05 22:23:29,813] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:23:29,814] {logging_mixin.py:115} INFO - [2023-01-05 22:23:29,814] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:23:29,821] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:23:29,847] {logging_mixin.py:115} INFO - [2023-01-05 22:23:29,847] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:23:29,867] {logging_mixin.py:115} INFO - [2023-01-05 22:23:29,867] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:23:29,877] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.999 seconds
[2023-01-05 22:23:59,980] {processor.py:153} INFO - Started process (PID=2462) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:23:59,981] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:23:59,981] {logging_mixin.py:115} INFO - [2023-01-05 22:23:59,981] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:24:00,813] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:24:00,814] {logging_mixin.py:115} INFO - [2023-01-05 22:24:00,814] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:24:00,815] {logging_mixin.py:115} INFO - [2023-01-05 22:24:00,814] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:24:00,821] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:24:00,845] {logging_mixin.py:115} INFO - [2023-01-05 22:24:00,844] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:24:00,865] {logging_mixin.py:115} INFO - [2023-01-05 22:24:00,865] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:24:00,874] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.899 seconds
[2023-01-05 22:24:31,165] {processor.py:153} INFO - Started process (PID=2487) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:24:31,167] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:24:31,168] {logging_mixin.py:115} INFO - [2023-01-05 22:24:31,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:24:32,060] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:24:32,061] {logging_mixin.py:115} INFO - [2023-01-05 22:24:32,061] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:24:32,062] {logging_mixin.py:115} INFO - [2023-01-05 22:24:32,061] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:24:32,068] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:24:32,091] {logging_mixin.py:115} INFO - [2023-01-05 22:24:32,091] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:24:32,111] {logging_mixin.py:115} INFO - [2023-01-05 22:24:32,111] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:24:32,121] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.961 seconds
[2023-01-05 22:25:02,279] {processor.py:153} INFO - Started process (PID=2512) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:25:02,281] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:25:02,281] {logging_mixin.py:115} INFO - [2023-01-05 22:25:02,281] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:25:03,152] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:25:03,153] {logging_mixin.py:115} INFO - [2023-01-05 22:25:03,153] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:25:03,153] {logging_mixin.py:115} INFO - [2023-01-05 22:25:03,153] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:25:03,160] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:25:03,183] {logging_mixin.py:115} INFO - [2023-01-05 22:25:03,182] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:25:03,203] {logging_mixin.py:115} INFO - [2023-01-05 22:25:03,203] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:25:03,214] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.942 seconds
[2023-01-05 22:25:33,365] {processor.py:153} INFO - Started process (PID=2530) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:25:33,366] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:25:33,367] {logging_mixin.py:115} INFO - [2023-01-05 22:25:33,366] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:25:34,365] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:25:34,368] {logging_mixin.py:115} INFO - [2023-01-05 22:25:34,368] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:25:34,369] {logging_mixin.py:115} INFO - [2023-01-05 22:25:34,369] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:25:34,381] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:25:34,411] {logging_mixin.py:115} INFO - [2023-01-05 22:25:34,411] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:25:34,436] {logging_mixin.py:115} INFO - [2023-01-05 22:25:34,436] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:25:34,446] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.085 seconds
[2023-01-05 22:26:04,530] {processor.py:153} INFO - Started process (PID=2555) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:26:04,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:26:04,533] {logging_mixin.py:115} INFO - [2023-01-05 22:26:04,533] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:26:05,359] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:26:05,360] {logging_mixin.py:115} INFO - [2023-01-05 22:26:05,360] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:26:05,361] {logging_mixin.py:115} INFO - [2023-01-05 22:26:05,360] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:26:05,367] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:26:05,390] {logging_mixin.py:115} INFO - [2023-01-05 22:26:05,390] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:26:05,410] {logging_mixin.py:115} INFO - [2023-01-05 22:26:05,410] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:26:05,420] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.894 seconds
[2023-01-05 22:26:35,521] {processor.py:153} INFO - Started process (PID=2580) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:26:35,522] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:26:35,522] {logging_mixin.py:115} INFO - [2023-01-05 22:26:35,522] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:26:36,357] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:26:36,359] {logging_mixin.py:115} INFO - [2023-01-05 22:26:36,359] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:26:36,359] {logging_mixin.py:115} INFO - [2023-01-05 22:26:36,359] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:26:36,366] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:26:36,390] {logging_mixin.py:115} INFO - [2023-01-05 22:26:36,390] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:26:36,412] {logging_mixin.py:115} INFO - [2023-01-05 22:26:36,412] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:26:36,423] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.907 seconds
[2023-01-05 22:27:06,658] {processor.py:153} INFO - Started process (PID=2605) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:27:06,659] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:27:06,660] {logging_mixin.py:115} INFO - [2023-01-05 22:27:06,660] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:27:07,543] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:27:07,544] {logging_mixin.py:115} INFO - [2023-01-05 22:27:07,544] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:27:07,545] {logging_mixin.py:115} INFO - [2023-01-05 22:27:07,545] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:27:07,552] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:27:07,582] {logging_mixin.py:115} INFO - [2023-01-05 22:27:07,581] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:27:07,610] {logging_mixin.py:115} INFO - [2023-01-05 22:27:07,609] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:27:07,621] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.969 seconds
[2023-01-05 22:27:37,747] {processor.py:153} INFO - Started process (PID=2623) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:27:37,747] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:27:37,748] {logging_mixin.py:115} INFO - [2023-01-05 22:27:37,748] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:27:38,609] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:27:38,610] {logging_mixin.py:115} INFO - [2023-01-05 22:27:38,610] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:27:38,611] {logging_mixin.py:115} INFO - [2023-01-05 22:27:38,611] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:27:38,618] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:27:38,650] {logging_mixin.py:115} INFO - [2023-01-05 22:27:38,650] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:27:38,673] {logging_mixin.py:115} INFO - [2023-01-05 22:27:38,673] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:27:38,684] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.942 seconds
[2023-01-05 22:28:09,034] {processor.py:153} INFO - Started process (PID=2648) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:28:09,036] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:28:09,037] {logging_mixin.py:115} INFO - [2023-01-05 22:28:09,037] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:28:09,892] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:28:09,893] {logging_mixin.py:115} INFO - [2023-01-05 22:28:09,893] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:28:09,894] {logging_mixin.py:115} INFO - [2023-01-05 22:28:09,894] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:28:09,901] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:28:09,930] {logging_mixin.py:115} INFO - [2023-01-05 22:28:09,929] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:28:09,960] {logging_mixin.py:115} INFO - [2023-01-05 22:28:09,960] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:28:09,973] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.944 seconds
[2023-01-05 22:28:40,121] {processor.py:153} INFO - Started process (PID=2675) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:28:40,122] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:28:40,122] {logging_mixin.py:115} INFO - [2023-01-05 22:28:40,122] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:28:41,192] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:28:41,193] {logging_mixin.py:115} INFO - [2023-01-05 22:28:41,193] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:28:41,194] {logging_mixin.py:115} INFO - [2023-01-05 22:28:41,193] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:28:41,200] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:28:41,225] {logging_mixin.py:115} INFO - [2023-01-05 22:28:41,225] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:28:41,246] {logging_mixin.py:115} INFO - [2023-01-05 22:28:41,246] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:28:41,256] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.140 seconds
[2023-01-05 22:29:11,355] {processor.py:153} INFO - Started process (PID=2699) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:29:11,356] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:29:11,356] {logging_mixin.py:115} INFO - [2023-01-05 22:29:11,356] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:29:12,502] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:29:12,504] {logging_mixin.py:115} INFO - [2023-01-05 22:29:12,504] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:29:12,505] {logging_mixin.py:115} INFO - [2023-01-05 22:29:12,504] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:29:12,516] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:29:12,539] {logging_mixin.py:115} INFO - [2023-01-05 22:29:12,539] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:29:12,559] {logging_mixin.py:115} INFO - [2023-01-05 22:29:12,559] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:29:12,569] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.219 seconds
[2023-01-05 22:29:42,638] {processor.py:153} INFO - Started process (PID=2718) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:29:42,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:29:42,640] {logging_mixin.py:115} INFO - [2023-01-05 22:29:42,640] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:29:43,496] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:29:43,497] {logging_mixin.py:115} INFO - [2023-01-05 22:29:43,497] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:29:43,498] {logging_mixin.py:115} INFO - [2023-01-05 22:29:43,497] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:29:43,504] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:29:43,527] {logging_mixin.py:115} INFO - [2023-01-05 22:29:43,526] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:29:43,548] {logging_mixin.py:115} INFO - [2023-01-05 22:29:43,547] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:29:43,557] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.924 seconds
[2023-01-05 22:30:13,684] {processor.py:153} INFO - Started process (PID=2742) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:30:13,685] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:30:13,686] {logging_mixin.py:115} INFO - [2023-01-05 22:30:13,686] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:30:14,520] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:30:14,521] {logging_mixin.py:115} INFO - [2023-01-05 22:30:14,521] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:30:14,522] {logging_mixin.py:115} INFO - [2023-01-05 22:30:14,521] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:30:14,529] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:30:14,552] {logging_mixin.py:115} INFO - [2023-01-05 22:30:14,552] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:30:14,580] {logging_mixin.py:115} INFO - [2023-01-05 22:30:14,580] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:30:14,593] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.914 seconds
[2023-01-05 22:30:44,773] {processor.py:153} INFO - Started process (PID=2767) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:30:44,776] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:30:44,776] {logging_mixin.py:115} INFO - [2023-01-05 22:30:44,776] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:30:45,614] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:30:45,616] {logging_mixin.py:115} INFO - [2023-01-05 22:30:45,616] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:30:45,616] {logging_mixin.py:115} INFO - [2023-01-05 22:30:45,616] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:30:45,623] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:30:45,646] {logging_mixin.py:115} INFO - [2023-01-05 22:30:45,645] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:30:45,666] {logging_mixin.py:115} INFO - [2023-01-05 22:30:45,666] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:30:45,676] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.908 seconds
[2023-01-05 22:31:16,053] {processor.py:153} INFO - Started process (PID=2792) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:31:16,054] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:31:16,055] {logging_mixin.py:115} INFO - [2023-01-05 22:31:16,054] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:31:17,162] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:31:17,163] {logging_mixin.py:115} INFO - [2023-01-05 22:31:17,163] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:31:17,164] {logging_mixin.py:115} INFO - [2023-01-05 22:31:17,164] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:31:17,171] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:31:17,193] {logging_mixin.py:115} INFO - [2023-01-05 22:31:17,193] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:31:17,214] {logging_mixin.py:115} INFO - [2023-01-05 22:31:17,214] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:31:17,224] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.176 seconds
[2023-01-05 22:31:47,306] {processor.py:153} INFO - Started process (PID=2811) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:31:47,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:31:47,310] {logging_mixin.py:115} INFO - [2023-01-05 22:31:47,310] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:31:48,398] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:31:48,399] {logging_mixin.py:115} INFO - [2023-01-05 22:31:48,399] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:31:48,400] {logging_mixin.py:115} INFO - [2023-01-05 22:31:48,399] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:31:48,406] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:31:48,428] {logging_mixin.py:115} INFO - [2023-01-05 22:31:48,428] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:31:48,448] {logging_mixin.py:115} INFO - [2023-01-05 22:31:48,448] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:31:48,458] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.158 seconds
[2023-01-05 22:32:18,530] {processor.py:153} INFO - Started process (PID=2838) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:32:18,531] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:32:18,532] {logging_mixin.py:115} INFO - [2023-01-05 22:32:18,532] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:32:19,341] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:32:19,342] {logging_mixin.py:115} INFO - [2023-01-05 22:32:19,342] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:32:19,342] {logging_mixin.py:115} INFO - [2023-01-05 22:32:19,342] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:32:19,351] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:32:19,375] {logging_mixin.py:115} INFO - [2023-01-05 22:32:19,375] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:32:19,396] {logging_mixin.py:115} INFO - [2023-01-05 22:32:19,396] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:32:19,405] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.880 seconds
[2023-01-05 22:32:49,447] {processor.py:153} INFO - Started process (PID=2863) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:32:49,447] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:32:49,448] {logging_mixin.py:115} INFO - [2023-01-05 22:32:49,448] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:32:50,283] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:32:50,285] {logging_mixin.py:115} INFO - [2023-01-05 22:32:50,284] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:32:50,285] {logging_mixin.py:115} INFO - [2023-01-05 22:32:50,285] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:32:50,294] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:32:50,321] {logging_mixin.py:115} INFO - [2023-01-05 22:32:50,321] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:32:50,344] {logging_mixin.py:115} INFO - [2023-01-05 22:32:50,344] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:32:50,356] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.913 seconds
[2023-01-05 22:33:20,544] {processor.py:153} INFO - Started process (PID=2888) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:33:20,545] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:33:20,546] {logging_mixin.py:115} INFO - [2023-01-05 22:33:20,546] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:33:21,825] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:33:21,827] {logging_mixin.py:115} INFO - [2023-01-05 22:33:21,827] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:33:21,828] {logging_mixin.py:115} INFO - [2023-01-05 22:33:21,827] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:33:21,839] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:33:21,889] {logging_mixin.py:115} INFO - [2023-01-05 22:33:21,889] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:33:21,923] {logging_mixin.py:115} INFO - [2023-01-05 22:33:21,923] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:33:21,968] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.430 seconds
[2023-01-05 22:33:52,090] {processor.py:153} INFO - Started process (PID=2906) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:33:52,091] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:33:52,091] {logging_mixin.py:115} INFO - [2023-01-05 22:33:52,091] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:33:53,007] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:33:53,009] {logging_mixin.py:115} INFO - [2023-01-05 22:33:53,008] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:33:53,009] {logging_mixin.py:115} INFO - [2023-01-05 22:33:53,009] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:33:53,021] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:33:53,052] {logging_mixin.py:115} INFO - [2023-01-05 22:33:53,051] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:33:53,082] {logging_mixin.py:115} INFO - [2023-01-05 22:33:53,082] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:33:53,094] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.010 seconds
[2023-01-05 22:34:23,204] {processor.py:153} INFO - Started process (PID=2933) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:34:23,205] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:34:23,205] {logging_mixin.py:115} INFO - [2023-01-05 22:34:23,205] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:34:24,082] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:34:24,084] {logging_mixin.py:115} INFO - [2023-01-05 22:34:24,084] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:34:24,084] {logging_mixin.py:115} INFO - [2023-01-05 22:34:24,084] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:34:24,091] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:34:24,113] {logging_mixin.py:115} INFO - [2023-01-05 22:34:24,112] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:34:24,133] {logging_mixin.py:115} INFO - [2023-01-05 22:34:24,133] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:34:24,142] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.944 seconds
[2023-01-05 22:34:54,369] {processor.py:153} INFO - Started process (PID=2957) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:34:54,370] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:34:54,371] {logging_mixin.py:115} INFO - [2023-01-05 22:34:54,371] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:34:55,208] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:34:55,209] {logging_mixin.py:115} INFO - [2023-01-05 22:34:55,209] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:34:55,210] {logging_mixin.py:115} INFO - [2023-01-05 22:34:55,210] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:34:55,217] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:34:55,242] {logging_mixin.py:115} INFO - [2023-01-05 22:34:55,242] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:34:55,264] {logging_mixin.py:115} INFO - [2023-01-05 22:34:55,264] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:34:55,274] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.909 seconds
[2023-01-05 22:35:25,468] {processor.py:153} INFO - Started process (PID=2983) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:35:25,469] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:35:25,470] {logging_mixin.py:115} INFO - [2023-01-05 22:35:25,470] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:35:26,347] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:35:26,349] {logging_mixin.py:115} INFO - [2023-01-05 22:35:26,349] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:35:26,349] {logging_mixin.py:115} INFO - [2023-01-05 22:35:26,349] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:35:26,356] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:35:26,388] {logging_mixin.py:115} INFO - [2023-01-05 22:35:26,387] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:35:26,419] {logging_mixin.py:115} INFO - [2023-01-05 22:35:26,419] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:35:26,433] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.971 seconds
[2023-01-05 22:35:56,553] {processor.py:153} INFO - Started process (PID=3001) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:35:56,554] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:35:56,555] {logging_mixin.py:115} INFO - [2023-01-05 22:35:56,555] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:35:57,385] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:35:57,387] {logging_mixin.py:115} INFO - [2023-01-05 22:35:57,387] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:35:57,387] {logging_mixin.py:115} INFO - [2023-01-05 22:35:57,387] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:35:57,394] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:35:57,417] {logging_mixin.py:115} INFO - [2023-01-05 22:35:57,417] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:35:57,437] {logging_mixin.py:115} INFO - [2023-01-05 22:35:57,437] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:35:57,447] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.901 seconds
[2023-01-05 22:36:27,794] {processor.py:153} INFO - Started process (PID=3027) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:36:27,797] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:36:27,798] {logging_mixin.py:115} INFO - [2023-01-05 22:36:27,798] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:36:28,667] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:36:28,669] {logging_mixin.py:115} INFO - [2023-01-05 22:36:28,668] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:36:28,669] {logging_mixin.py:115} INFO - [2023-01-05 22:36:28,669] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:36:28,676] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:36:28,699] {logging_mixin.py:115} INFO - [2023-01-05 22:36:28,699] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:36:28,720] {logging_mixin.py:115} INFO - [2023-01-05 22:36:28,720] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:36:28,731] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.942 seconds
[2023-01-05 22:36:58,882] {processor.py:153} INFO - Started process (PID=3051) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:36:58,883] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:36:58,884] {logging_mixin.py:115} INFO - [2023-01-05 22:36:58,884] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:36:59,753] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:36:59,754] {logging_mixin.py:115} INFO - [2023-01-05 22:36:59,754] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:36:59,755] {logging_mixin.py:115} INFO - [2023-01-05 22:36:59,754] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:36:59,762] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:36:59,785] {logging_mixin.py:115} INFO - [2023-01-05 22:36:59,785] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:36:59,809] {logging_mixin.py:115} INFO - [2023-01-05 22:36:59,808] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:30:00+00:00, run_after=2023-01-06T22:30:00+00:00
[2023-01-05 22:36:59,821] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.946 seconds
[2023-01-05 22:37:20,009] {processor.py:153} INFO - Started process (PID=3071) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:37:20,010] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:37:20,010] {logging_mixin.py:115} INFO - [2023-01-05 22:37:20,010] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:37:20,851] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:37:20,853] {logging_mixin.py:115} INFO - [2023-01-05 22:37:20,852] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:37:20,853] {logging_mixin.py:115} INFO - [2023-01-05 22:37:20,853] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:37:20,860] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:37:20,918] {logging_mixin.py:115} INFO - [2023-01-05 22:37:20,918] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:37:20,938] {logging_mixin.py:115} INFO - [2023-01-05 22:37:20,938] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:37:20,952] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.950 seconds
[2023-01-05 22:37:51,120] {processor.py:153} INFO - Started process (PID=3093) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:37:51,123] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:37:51,123] {logging_mixin.py:115} INFO - [2023-01-05 22:37:51,123] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:37:52,276] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:37:52,278] {logging_mixin.py:115} INFO - [2023-01-05 22:37:52,278] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:37:52,279] {logging_mixin.py:115} INFO - [2023-01-05 22:37:52,279] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:37:52,291] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:37:52,322] {logging_mixin.py:115} INFO - [2023-01-05 22:37:52,322] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:37:52,354] {logging_mixin.py:115} INFO - [2023-01-05 22:37:52,354] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:37:52,369] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.255 seconds
[2023-01-05 22:38:22,442] {processor.py:153} INFO - Started process (PID=3117) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:38:22,443] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:38:22,444] {logging_mixin.py:115} INFO - [2023-01-05 22:38:22,444] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:38:23,264] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:38:23,266] {logging_mixin.py:115} INFO - [2023-01-05 22:38:23,266] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:38:23,266] {logging_mixin.py:115} INFO - [2023-01-05 22:38:23,266] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:38:23,273] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:38:23,299] {logging_mixin.py:115} INFO - [2023-01-05 22:38:23,298] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:38:23,320] {logging_mixin.py:115} INFO - [2023-01-05 22:38:23,320] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:38:23,331] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.895 seconds
[2023-01-05 22:38:53,378] {processor.py:153} INFO - Started process (PID=3141) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:38:53,379] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:38:53,379] {logging_mixin.py:115} INFO - [2023-01-05 22:38:53,379] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:38:54,181] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:38:54,182] {logging_mixin.py:115} INFO - [2023-01-05 22:38:54,182] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:38:54,183] {logging_mixin.py:115} INFO - [2023-01-05 22:38:54,183] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:38:54,190] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:38:54,212] {logging_mixin.py:115} INFO - [2023-01-05 22:38:54,212] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:38:54,232] {logging_mixin.py:115} INFO - [2023-01-05 22:38:54,232] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:38:54,242] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.869 seconds
[2023-01-05 22:39:24,455] {processor.py:153} INFO - Started process (PID=3167) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:39:24,457] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:39:24,457] {logging_mixin.py:115} INFO - [2023-01-05 22:39:24,457] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:39:25,304] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:39:25,305] {logging_mixin.py:115} INFO - [2023-01-05 22:39:25,305] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:39:25,306] {logging_mixin.py:115} INFO - [2023-01-05 22:39:25,306] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:39:25,313] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:39:25,335] {logging_mixin.py:115} INFO - [2023-01-05 22:39:25,335] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:39:25,355] {logging_mixin.py:115} INFO - [2023-01-05 22:39:25,355] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:39:25,365] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.916 seconds
[2023-01-05 22:39:55,568] {processor.py:153} INFO - Started process (PID=3183) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:39:55,568] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:39:55,569] {logging_mixin.py:115} INFO - [2023-01-05 22:39:55,569] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:39:56,506] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:39:56,508] {logging_mixin.py:115} INFO - [2023-01-05 22:39:56,508] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:39:56,508] {logging_mixin.py:115} INFO - [2023-01-05 22:39:56,508] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:39:56,515] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:39:56,538] {logging_mixin.py:115} INFO - [2023-01-05 22:39:56,538] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:39:56,559] {logging_mixin.py:115} INFO - [2023-01-05 22:39:56,559] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:39:56,569] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.007 seconds
[2023-01-05 22:40:26,661] {processor.py:153} INFO - Started process (PID=3208) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:40:26,662] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:40:26,663] {logging_mixin.py:115} INFO - [2023-01-05 22:40:26,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:40:27,492] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:40:27,494] {logging_mixin.py:115} INFO - [2023-01-05 22:40:27,494] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:40:27,494] {logging_mixin.py:115} INFO - [2023-01-05 22:40:27,494] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:40:27,501] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:40:27,524] {logging_mixin.py:115} INFO - [2023-01-05 22:40:27,524] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:40:27,546] {logging_mixin.py:115} INFO - [2023-01-05 22:40:27,546] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:40:27,558] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.901 seconds
[2023-01-05 22:40:57,739] {processor.py:153} INFO - Started process (PID=3233) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:40:57,741] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:40:57,742] {logging_mixin.py:115} INFO - [2023-01-05 22:40:57,741] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:40:58,586] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:40:58,587] {logging_mixin.py:115} INFO - [2023-01-05 22:40:58,587] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:40:58,588] {logging_mixin.py:115} INFO - [2023-01-05 22:40:58,587] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:40:58,595] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:40:58,618] {logging_mixin.py:115} INFO - [2023-01-05 22:40:58,618] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:40:58,640] {logging_mixin.py:115} INFO - [2023-01-05 22:40:58,639] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:40:58,649] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.915 seconds
[2023-01-05 22:41:28,909] {processor.py:153} INFO - Started process (PID=3259) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:41:28,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:41:28,912] {logging_mixin.py:115} INFO - [2023-01-05 22:41:28,911] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:41:29,799] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:41:29,800] {logging_mixin.py:115} INFO - [2023-01-05 22:41:29,800] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:41:29,800] {logging_mixin.py:115} INFO - [2023-01-05 22:41:29,800] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:41:29,807] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:41:29,829] {logging_mixin.py:115} INFO - [2023-01-05 22:41:29,829] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:41:29,850] {logging_mixin.py:115} INFO - [2023-01-05 22:41:29,850] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:41:29,860] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.956 seconds
[2023-01-05 22:41:59,970] {processor.py:153} INFO - Started process (PID=3278) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:41:59,972] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:41:59,972] {logging_mixin.py:115} INFO - [2023-01-05 22:41:59,972] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:42:00,826] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:42:00,828] {logging_mixin.py:115} INFO - [2023-01-05 22:42:00,827] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:42:00,828] {logging_mixin.py:115} INFO - [2023-01-05 22:42:00,828] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:42:00,835] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:42:00,862] {logging_mixin.py:115} INFO - [2023-01-05 22:42:00,862] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:42:00,883] {logging_mixin.py:115} INFO - [2023-01-05 22:42:00,882] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:42:00,892] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.927 seconds
[2023-01-05 22:42:31,040] {processor.py:153} INFO - Started process (PID=3303) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:42:31,041] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:42:31,042] {logging_mixin.py:115} INFO - [2023-01-05 22:42:31,042] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:42:31,904] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:42:31,905] {logging_mixin.py:115} INFO - [2023-01-05 22:42:31,905] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:42:31,906] {logging_mixin.py:115} INFO - [2023-01-05 22:42:31,906] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:42:31,913] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:42:31,936] {logging_mixin.py:115} INFO - [2023-01-05 22:42:31,935] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:42:31,957] {logging_mixin.py:115} INFO - [2023-01-05 22:42:31,957] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:42:31,967] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.932 seconds
[2023-01-05 22:43:02,069] {processor.py:153} INFO - Started process (PID=3328) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:43:02,070] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:43:02,071] {logging_mixin.py:115} INFO - [2023-01-05 22:43:02,071] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:43:02,889] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:43:02,891] {logging_mixin.py:115} INFO - [2023-01-05 22:43:02,890] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:43:02,891] {logging_mixin.py:115} INFO - [2023-01-05 22:43:02,891] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:43:02,898] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:43:02,921] {logging_mixin.py:115} INFO - [2023-01-05 22:43:02,921] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:43:02,942] {logging_mixin.py:115} INFO - [2023-01-05 22:43:02,942] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:43:02,952] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.887 seconds
[2023-01-05 22:43:33,175] {processor.py:153} INFO - Started process (PID=3354) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:43:33,176] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:43:33,176] {logging_mixin.py:115} INFO - [2023-01-05 22:43:33,176] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:43:34,021] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:43:34,023] {logging_mixin.py:115} INFO - [2023-01-05 22:43:34,023] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:43:34,023] {logging_mixin.py:115} INFO - [2023-01-05 22:43:34,023] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:43:34,030] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:43:34,052] {logging_mixin.py:115} INFO - [2023-01-05 22:43:34,052] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:43:34,073] {logging_mixin.py:115} INFO - [2023-01-05 22:43:34,072] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:43:34,083] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.913 seconds
[2023-01-05 22:44:04,246] {processor.py:153} INFO - Started process (PID=3372) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:44:04,248] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:44:04,249] {logging_mixin.py:115} INFO - [2023-01-05 22:44:04,248] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:44:05,128] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:44:05,130] {logging_mixin.py:115} INFO - [2023-01-05 22:44:05,130] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:44:05,130] {logging_mixin.py:115} INFO - [2023-01-05 22:44:05,130] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:44:05,138] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:44:05,161] {logging_mixin.py:115} INFO - [2023-01-05 22:44:05,161] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:44:05,182] {logging_mixin.py:115} INFO - [2023-01-05 22:44:05,182] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:44:05,193] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.951 seconds
[2023-01-05 22:44:35,363] {processor.py:153} INFO - Started process (PID=3399) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:44:35,363] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:44:35,364] {logging_mixin.py:115} INFO - [2023-01-05 22:44:35,364] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:44:36,171] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:44:36,172] {logging_mixin.py:115} INFO - [2023-01-05 22:44:36,172] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:44:36,173] {logging_mixin.py:115} INFO - [2023-01-05 22:44:36,172] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:44:36,179] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:44:36,202] {logging_mixin.py:115} INFO - [2023-01-05 22:44:36,202] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:44:36,222] {logging_mixin.py:115} INFO - [2023-01-05 22:44:36,222] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:44:36,232] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.874 seconds
[2023-01-05 22:45:06,447] {processor.py:153} INFO - Started process (PID=3425) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:45:06,448] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:45:06,449] {logging_mixin.py:115} INFO - [2023-01-05 22:45:06,449] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:45:07,427] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:45:07,429] {logging_mixin.py:115} INFO - [2023-01-05 22:45:07,429] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:45:07,430] {logging_mixin.py:115} INFO - [2023-01-05 22:45:07,429] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:45:07,442] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:45:07,466] {logging_mixin.py:115} INFO - [2023-01-05 22:45:07,466] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:45:07,487] {logging_mixin.py:115} INFO - [2023-01-05 22:45:07,487] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:45:07,498] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.055 seconds
[2023-01-05 22:45:37,535] {processor.py:153} INFO - Started process (PID=3450) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:45:37,536] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:45:37,537] {logging_mixin.py:115} INFO - [2023-01-05 22:45:37,536] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:45:38,412] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:45:38,413] {logging_mixin.py:115} INFO - [2023-01-05 22:45:38,413] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:45:38,414] {logging_mixin.py:115} INFO - [2023-01-05 22:45:38,414] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:45:38,421] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:45:38,445] {logging_mixin.py:115} INFO - [2023-01-05 22:45:38,444] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:45:38,466] {logging_mixin.py:115} INFO - [2023-01-05 22:45:38,466] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:45:38,477] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.947 seconds
[2023-01-05 22:46:08,605] {processor.py:153} INFO - Started process (PID=3468) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:46:08,606] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:46:08,607] {logging_mixin.py:115} INFO - [2023-01-05 22:46:08,607] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:46:09,438] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:46:09,440] {logging_mixin.py:115} INFO - [2023-01-05 22:46:09,440] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:46:09,440] {logging_mixin.py:115} INFO - [2023-01-05 22:46:09,440] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:46:09,447] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:46:09,470] {logging_mixin.py:115} INFO - [2023-01-05 22:46:09,470] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:46:09,490] {logging_mixin.py:115} INFO - [2023-01-05 22:46:09,490] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:46:09,500] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.900 seconds
[2023-01-05 22:46:39,609] {processor.py:153} INFO - Started process (PID=3492) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:46:39,611] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:46:39,611] {logging_mixin.py:115} INFO - [2023-01-05 22:46:39,611] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:46:40,506] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:46:40,507] {logging_mixin.py:115} INFO - [2023-01-05 22:46:40,507] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:46:40,508] {logging_mixin.py:115} INFO - [2023-01-05 22:46:40,508] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:46:40,515] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:46:40,539] {logging_mixin.py:115} INFO - [2023-01-05 22:46:40,538] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:46:40,560] {logging_mixin.py:115} INFO - [2023-01-05 22:46:40,560] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:46:40,570] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.965 seconds
[2023-01-05 22:47:10,747] {processor.py:153} INFO - Started process (PID=3518) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:47:10,749] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:47:10,749] {logging_mixin.py:115} INFO - [2023-01-05 22:47:10,749] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:47:11,564] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:47:11,566] {logging_mixin.py:115} INFO - [2023-01-05 22:47:11,566] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:47:11,566] {logging_mixin.py:115} INFO - [2023-01-05 22:47:11,566] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:47:11,573] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:47:11,600] {logging_mixin.py:115} INFO - [2023-01-05 22:47:11,599] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:47:11,620] {logging_mixin.py:115} INFO - [2023-01-05 22:47:11,620] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:47:11,630] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.887 seconds
[2023-01-05 22:47:41,823] {processor.py:153} INFO - Started process (PID=3543) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:47:41,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:47:41,825] {logging_mixin.py:115} INFO - [2023-01-05 22:47:41,825] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:47:42,693] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:47:42,694] {logging_mixin.py:115} INFO - [2023-01-05 22:47:42,694] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:47:42,695] {logging_mixin.py:115} INFO - [2023-01-05 22:47:42,695] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:47:42,702] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:47:42,725] {logging_mixin.py:115} INFO - [2023-01-05 22:47:42,725] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:47:42,747] {logging_mixin.py:115} INFO - [2023-01-05 22:47:42,746] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:47:42,757] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.939 seconds
[2023-01-05 22:48:12,892] {processor.py:153} INFO - Started process (PID=3562) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:48:12,893] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:48:12,894] {logging_mixin.py:115} INFO - [2023-01-05 22:48:12,894] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:48:13,768] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:48:13,770] {logging_mixin.py:115} INFO - [2023-01-05 22:48:13,770] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:48:13,770] {logging_mixin.py:115} INFO - [2023-01-05 22:48:13,770] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:48:13,778] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:48:13,811] {logging_mixin.py:115} INFO - [2023-01-05 22:48:13,810] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:48:13,841] {logging_mixin.py:115} INFO - [2023-01-05 22:48:13,841] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:48:13,854] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.966 seconds
[2023-01-05 22:48:43,970] {processor.py:153} INFO - Started process (PID=3588) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:48:43,971] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:48:43,971] {logging_mixin.py:115} INFO - [2023-01-05 22:48:43,971] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:48:44,823] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:48:44,824] {logging_mixin.py:115} INFO - [2023-01-05 22:48:44,824] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:48:44,825] {logging_mixin.py:115} INFO - [2023-01-05 22:48:44,825] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:48:44,832] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:48:44,856] {logging_mixin.py:115} INFO - [2023-01-05 22:48:44,856] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:48:44,878] {logging_mixin.py:115} INFO - [2023-01-05 22:48:44,878] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:48:44,887] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.922 seconds
[2023-01-05 22:49:15,059] {processor.py:153} INFO - Started process (PID=3613) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:49:15,060] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:49:15,061] {logging_mixin.py:115} INFO - [2023-01-05 22:49:15,061] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:49:15,910] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:49:15,912] {logging_mixin.py:115} INFO - [2023-01-05 22:49:15,911] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:49:15,912] {logging_mixin.py:115} INFO - [2023-01-05 22:49:15,912] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:49:15,919] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:49:15,943] {logging_mixin.py:115} INFO - [2023-01-05 22:49:15,942] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:49:15,963] {logging_mixin.py:115} INFO - [2023-01-05 22:49:15,963] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:49:15,972] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.918 seconds
[2023-01-05 22:49:46,131] {processor.py:153} INFO - Started process (PID=3639) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:49:46,132] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:49:46,133] {logging_mixin.py:115} INFO - [2023-01-05 22:49:46,133] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:49:46,965] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:49:46,967] {logging_mixin.py:115} INFO - [2023-01-05 22:49:46,966] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:49:46,967] {logging_mixin.py:115} INFO - [2023-01-05 22:49:46,967] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:49:46,974] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:49:47,002] {logging_mixin.py:115} INFO - [2023-01-05 22:49:47,002] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:49:47,025] {logging_mixin.py:115} INFO - [2023-01-05 22:49:47,025] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:49:47,035] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.909 seconds
[2023-01-05 22:50:17,375] {processor.py:153} INFO - Started process (PID=3658) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:50:17,375] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:50:17,376] {logging_mixin.py:115} INFO - [2023-01-05 22:50:17,376] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:50:18,186] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:50:18,187] {logging_mixin.py:115} INFO - [2023-01-05 22:50:18,187] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:50:18,187] {logging_mixin.py:115} INFO - [2023-01-05 22:50:18,187] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:50:18,194] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:50:18,217] {logging_mixin.py:115} INFO - [2023-01-05 22:50:18,217] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:50:18,238] {logging_mixin.py:115} INFO - [2023-01-05 22:50:18,238] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:50:18,248] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.877 seconds
[2023-01-05 22:50:48,447] {processor.py:153} INFO - Started process (PID=3683) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:50:48,452] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:50:48,452] {logging_mixin.py:115} INFO - [2023-01-05 22:50:48,452] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:50:49,275] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:50:49,276] {logging_mixin.py:115} INFO - [2023-01-05 22:50:49,276] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:50:49,277] {logging_mixin.py:115} INFO - [2023-01-05 22:50:49,276] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:50:49,284] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:50:49,306] {logging_mixin.py:115} INFO - [2023-01-05 22:50:49,305] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:50:49,327] {logging_mixin.py:115} INFO - [2023-01-05 22:50:49,327] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:50:49,338] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.896 seconds
[2023-01-05 22:51:19,525] {processor.py:153} INFO - Started process (PID=3708) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:51:19,526] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:51:19,526] {logging_mixin.py:115} INFO - [2023-01-05 22:51:19,526] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:51:20,323] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:51:20,324] {logging_mixin.py:115} INFO - [2023-01-05 22:51:20,324] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:51:20,324] {logging_mixin.py:115} INFO - [2023-01-05 22:51:20,324] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:51:20,331] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:51:20,354] {logging_mixin.py:115} INFO - [2023-01-05 22:51:20,354] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:51:20,378] {logging_mixin.py:115} INFO - [2023-01-05 22:51:20,378] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:51:20,389] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.869 seconds
[2023-01-05 22:51:50,604] {processor.py:153} INFO - Started process (PID=3733) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:51:50,606] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:51:50,606] {logging_mixin.py:115} INFO - [2023-01-05 22:51:50,606] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:51:51,433] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:51:51,435] {logging_mixin.py:115} INFO - [2023-01-05 22:51:51,435] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:51:51,435] {logging_mixin.py:115} INFO - [2023-01-05 22:51:51,435] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:51:51,442] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:51:51,470] {logging_mixin.py:115} INFO - [2023-01-05 22:51:51,470] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:51:51,498] {logging_mixin.py:115} INFO - [2023-01-05 22:51:51,498] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:51:51,509] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.910 seconds
[2023-01-05 22:52:21,674] {processor.py:153} INFO - Started process (PID=3750) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:52:21,675] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:52:21,676] {logging_mixin.py:115} INFO - [2023-01-05 22:52:21,675] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:52:22,516] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:52:22,517] {logging_mixin.py:115} INFO - [2023-01-05 22:52:22,517] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:52:22,518] {logging_mixin.py:115} INFO - [2023-01-05 22:52:22,517] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:52:22,525] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:52:22,548] {logging_mixin.py:115} INFO - [2023-01-05 22:52:22,548] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:52:22,570] {logging_mixin.py:115} INFO - [2023-01-05 22:52:22,569] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:52:22,580] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.911 seconds
[2023-01-05 22:52:52,748] {processor.py:153} INFO - Started process (PID=3775) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:52:52,749] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:52:52,750] {logging_mixin.py:115} INFO - [2023-01-05 22:52:52,750] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:52:53,555] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:52:53,557] {logging_mixin.py:115} INFO - [2023-01-05 22:52:53,557] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:52:53,557] {logging_mixin.py:115} INFO - [2023-01-05 22:52:53,557] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:52:53,564] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:52:53,588] {logging_mixin.py:115} INFO - [2023-01-05 22:52:53,588] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:52:53,610] {logging_mixin.py:115} INFO - [2023-01-05 22:52:53,610] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:52:53,623] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.880 seconds
[2023-01-05 22:53:23,723] {processor.py:153} INFO - Started process (PID=3802) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:53:23,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:53:23,725] {logging_mixin.py:115} INFO - [2023-01-05 22:53:23,724] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:53:24,537] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:53:24,538] {logging_mixin.py:115} INFO - [2023-01-05 22:53:24,538] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:53:24,539] {logging_mixin.py:115} INFO - [2023-01-05 22:53:24,539] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:53:24,550] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:53:24,597] {logging_mixin.py:115} INFO - [2023-01-05 22:53:24,596] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:53:24,622] {logging_mixin.py:115} INFO - [2023-01-05 22:53:24,622] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:53:24,633] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.915 seconds
[2023-01-05 22:53:54,899] {processor.py:153} INFO - Started process (PID=3827) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:53:54,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:53:54,900] {logging_mixin.py:115} INFO - [2023-01-05 22:53:54,900] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:53:55,748] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:53:55,750] {logging_mixin.py:115} INFO - [2023-01-05 22:53:55,750] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:53:55,750] {logging_mixin.py:115} INFO - [2023-01-05 22:53:55,750] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:53:55,757] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:53:55,781] {logging_mixin.py:115} INFO - [2023-01-05 22:53:55,780] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:53:55,807] {logging_mixin.py:115} INFO - [2023-01-05 22:53:55,807] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:40:00+00:00, run_after=2023-01-06T22:40:00+00:00
[2023-01-05 22:53:55,818] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.924 seconds
[2023-01-05 22:54:15,950] {processor.py:153} INFO - Started process (PID=3838) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:54:15,950] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:54:15,951] {logging_mixin.py:115} INFO - [2023-01-05 22:54:15,951] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:54:16,865] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:54:16,866] {logging_mixin.py:115} INFO - [2023-01-05 22:54:16,866] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:54:16,867] {logging_mixin.py:115} INFO - [2023-01-05 22:54:16,866] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:54:16,874] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:54:16,930] {logging_mixin.py:115} INFO - [2023-01-05 22:54:16,930] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:54:16,950] {logging_mixin.py:115} INFO - [2023-01-05 22:54:16,949] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:55:00+00:00, run_after=2023-01-05T22:55:00+00:00
[2023-01-05 22:54:16,964] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.019 seconds
[2023-01-05 22:54:47,061] {processor.py:153} INFO - Started process (PID=3862) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:54:47,062] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:54:47,063] {logging_mixin.py:115} INFO - [2023-01-05 22:54:47,063] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:54:47,905] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:54:47,906] {logging_mixin.py:115} INFO - [2023-01-05 22:54:47,906] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:54:47,907] {logging_mixin.py:115} INFO - [2023-01-05 22:54:47,906] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:54:47,913] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:54:47,935] {logging_mixin.py:115} INFO - [2023-01-05 22:54:47,935] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:54:47,956] {logging_mixin.py:115} INFO - [2023-01-05 22:54:47,956] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-04T22:55:00+00:00, run_after=2023-01-05T22:55:00+00:00
[2023-01-05 22:54:47,966] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.910 seconds
[2023-01-05 22:55:18,094] {processor.py:153} INFO - Started process (PID=3887) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:55:18,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:55:18,097] {logging_mixin.py:115} INFO - [2023-01-05 22:55:18,096] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:55:18,919] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:55:18,920] {logging_mixin.py:115} INFO - [2023-01-05 22:55:18,920] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:55:18,921] {logging_mixin.py:115} INFO - [2023-01-05 22:55:18,921] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:55:18,928] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:55:18,950] {logging_mixin.py:115} INFO - [2023-01-05 22:55:18,950] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:55:18,971] {logging_mixin.py:115} INFO - [2023-01-05 22:55:18,970] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 22:55:18,981] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.892 seconds
[2023-01-05 22:55:49,185] {processor.py:153} INFO - Started process (PID=3915) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:55:49,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:55:49,187] {logging_mixin.py:115} INFO - [2023-01-05 22:55:49,187] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:55:50,024] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:55:50,026] {logging_mixin.py:115} INFO - [2023-01-05 22:55:50,026] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:55:50,027] {logging_mixin.py:115} INFO - [2023-01-05 22:55:50,026] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:55:50,036] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:55:50,058] {logging_mixin.py:115} INFO - [2023-01-05 22:55:50,058] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:55:50,079] {logging_mixin.py:115} INFO - [2023-01-05 22:55:50,079] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 22:55:50,089] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.908 seconds
[2023-01-05 22:56:20,262] {processor.py:153} INFO - Started process (PID=3934) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:56:20,264] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:56:20,264] {logging_mixin.py:115} INFO - [2023-01-05 22:56:20,264] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:56:21,133] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:56:21,134] {logging_mixin.py:115} INFO - [2023-01-05 22:56:21,134] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:56:21,135] {logging_mixin.py:115} INFO - [2023-01-05 22:56:21,134] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:56:21,142] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:56:21,164] {logging_mixin.py:115} INFO - [2023-01-05 22:56:21,164] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:56:21,184] {logging_mixin.py:115} INFO - [2023-01-05 22:56:21,184] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 22:56:21,194] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.937 seconds
[2023-01-05 22:56:51,330] {processor.py:153} INFO - Started process (PID=3959) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:56:51,332] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:56:51,333] {logging_mixin.py:115} INFO - [2023-01-05 22:56:51,332] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:56:52,172] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:56:52,173] {logging_mixin.py:115} INFO - [2023-01-05 22:56:52,173] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:56:52,174] {logging_mixin.py:115} INFO - [2023-01-05 22:56:52,173] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:56:52,181] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:56:52,203] {logging_mixin.py:115} INFO - [2023-01-05 22:56:52,203] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:56:52,224] {logging_mixin.py:115} INFO - [2023-01-05 22:56:52,224] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 22:56:52,234] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.909 seconds
[2023-01-05 22:57:22,408] {processor.py:153} INFO - Started process (PID=3983) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:57:22,410] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:57:22,410] {logging_mixin.py:115} INFO - [2023-01-05 22:57:22,410] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:57:23,239] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:57:23,241] {logging_mixin.py:115} INFO - [2023-01-05 22:57:23,241] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:57:23,242] {logging_mixin.py:115} INFO - [2023-01-05 22:57:23,241] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:57:23,250] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:57:23,300] {logging_mixin.py:115} INFO - [2023-01-05 22:57:23,300] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:57:23,323] {logging_mixin.py:115} INFO - [2023-01-05 22:57:23,323] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 22:57:23,334] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.931 seconds
[2023-01-05 22:57:53,506] {processor.py:153} INFO - Started process (PID=4008) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:57:53,507] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:57:53,507] {logging_mixin.py:115} INFO - [2023-01-05 22:57:53,507] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:57:54,385] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:57:54,386] {logging_mixin.py:115} INFO - [2023-01-05 22:57:54,386] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:57:54,387] {logging_mixin.py:115} INFO - [2023-01-05 22:57:54,386] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:57:54,394] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:57:54,418] {logging_mixin.py:115} INFO - [2023-01-05 22:57:54,418] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:57:54,440] {logging_mixin.py:115} INFO - [2023-01-05 22:57:54,440] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 22:57:54,450] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.949 seconds
[2023-01-05 22:58:24,580] {processor.py:153} INFO - Started process (PID=4026) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:58:24,582] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:58:24,582] {logging_mixin.py:115} INFO - [2023-01-05 22:58:24,582] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:58:25,517] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:58:25,519] {logging_mixin.py:115} INFO - [2023-01-05 22:58:25,519] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:58:25,519] {logging_mixin.py:115} INFO - [2023-01-05 22:58:25,519] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:58:25,531] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:58:25,562] {logging_mixin.py:115} INFO - [2023-01-05 22:58:25,562] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:58:25,593] {logging_mixin.py:115} INFO - [2023-01-05 22:58:25,592] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 22:58:25,607] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.031 seconds
[2023-01-05 22:58:55,689] {processor.py:153} INFO - Started process (PID=4052) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:58:55,689] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:58:55,690] {logging_mixin.py:115} INFO - [2023-01-05 22:58:55,690] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:58:56,501] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:58:56,502] {logging_mixin.py:115} INFO - [2023-01-05 22:58:56,502] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:58:56,503] {logging_mixin.py:115} INFO - [2023-01-05 22:58:56,503] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:58:56,510] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:58:56,534] {logging_mixin.py:115} INFO - [2023-01-05 22:58:56,534] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:58:56,557] {logging_mixin.py:115} INFO - [2023-01-05 22:58:56,557] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 22:58:56,570] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.887 seconds
[2023-01-05 22:59:27,076] {processor.py:153} INFO - Started process (PID=4080) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:59:27,077] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:59:27,078] {logging_mixin.py:115} INFO - [2023-01-05 22:59:27,078] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:59:27,889] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:59:27,890] {logging_mixin.py:115} INFO - [2023-01-05 22:59:27,890] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:59:27,891] {logging_mixin.py:115} INFO - [2023-01-05 22:59:27,891] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:59:27,898] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:59:27,922] {logging_mixin.py:115} INFO - [2023-01-05 22:59:27,921] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:59:27,943] {logging_mixin.py:115} INFO - [2023-01-05 22:59:27,943] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 22:59:27,953] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.883 seconds
[2023-01-05 22:59:58,138] {processor.py:153} INFO - Started process (PID=4104) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:59:58,138] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 22:59:58,139] {logging_mixin.py:115} INFO - [2023-01-05 22:59:58,139] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:59:59,012] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 22:59:59,013] {logging_mixin.py:115} INFO - [2023-01-05 22:59:59,013] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 22:59:59,014] {logging_mixin.py:115} INFO - [2023-01-05 22:59:59,014] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 22:59:59,021] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 22:59:59,045] {logging_mixin.py:115} INFO - [2023-01-05 22:59:59,044] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 22:59:59,066] {logging_mixin.py:115} INFO - [2023-01-05 22:59:59,065] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 22:59:59,076] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.942 seconds
[2023-01-05 23:00:29,207] {processor.py:153} INFO - Started process (PID=4123) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:00:29,209] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:00:29,210] {logging_mixin.py:115} INFO - [2023-01-05 23:00:29,210] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:00:30,044] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:00:30,045] {logging_mixin.py:115} INFO - [2023-01-05 23:00:30,045] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:00:30,046] {logging_mixin.py:115} INFO - [2023-01-05 23:00:30,046] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:00:30,053] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:00:30,076] {logging_mixin.py:115} INFO - [2023-01-05 23:00:30,076] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:00:30,098] {logging_mixin.py:115} INFO - [2023-01-05 23:00:30,097] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:00:30,107] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.905 seconds
[2023-01-05 23:01:00,338] {processor.py:153} INFO - Started process (PID=4148) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:01:00,339] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:01:00,339] {logging_mixin.py:115} INFO - [2023-01-05 23:01:00,339] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:01:01,207] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:01:01,208] {logging_mixin.py:115} INFO - [2023-01-05 23:01:01,208] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:01:01,209] {logging_mixin.py:115} INFO - [2023-01-05 23:01:01,209] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:01:01,216] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:01:01,240] {logging_mixin.py:115} INFO - [2023-01-05 23:01:01,239] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:01:01,262] {logging_mixin.py:115} INFO - [2023-01-05 23:01:01,261] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:01:01,272] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.939 seconds
[2023-01-05 23:01:31,373] {processor.py:153} INFO - Started process (PID=4173) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:01:31,374] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:01:31,375] {logging_mixin.py:115} INFO - [2023-01-05 23:01:31,374] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:01:32,234] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:01:32,236] {logging_mixin.py:115} INFO - [2023-01-05 23:01:32,236] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:01:32,236] {logging_mixin.py:115} INFO - [2023-01-05 23:01:32,236] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:01:32,243] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:01:32,267] {logging_mixin.py:115} INFO - [2023-01-05 23:01:32,267] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:01:32,289] {logging_mixin.py:115} INFO - [2023-01-05 23:01:32,289] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:01:32,299] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.931 seconds
[2023-01-05 23:02:02,399] {processor.py:153} INFO - Started process (PID=4198) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:02:02,399] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:02:02,400] {logging_mixin.py:115} INFO - [2023-01-05 23:02:02,400] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:02:03,249] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:02:03,250] {logging_mixin.py:115} INFO - [2023-01-05 23:02:03,250] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:02:03,251] {logging_mixin.py:115} INFO - [2023-01-05 23:02:03,251] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:02:03,258] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:02:03,282] {logging_mixin.py:115} INFO - [2023-01-05 23:02:03,281] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:02:03,302] {logging_mixin.py:115} INFO - [2023-01-05 23:02:03,302] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:02:03,312] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.918 seconds
[2023-01-05 23:02:33,562] {processor.py:153} INFO - Started process (PID=4216) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:02:33,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:02:33,564] {logging_mixin.py:115} INFO - [2023-01-05 23:02:33,564] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:02:34,378] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:02:34,379] {logging_mixin.py:115} INFO - [2023-01-05 23:02:34,379] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:02:34,380] {logging_mixin.py:115} INFO - [2023-01-05 23:02:34,379] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:02:34,386] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:02:34,410] {logging_mixin.py:115} INFO - [2023-01-05 23:02:34,410] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:02:34,432] {logging_mixin.py:115} INFO - [2023-01-05 23:02:34,432] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:02:34,442] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.885 seconds
[2023-01-05 23:03:04,635] {processor.py:153} INFO - Started process (PID=4241) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:03:04,637] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:03:04,637] {logging_mixin.py:115} INFO - [2023-01-05 23:03:04,637] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:03:05,463] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:03:05,465] {logging_mixin.py:115} INFO - [2023-01-05 23:03:05,465] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:03:05,465] {logging_mixin.py:115} INFO - [2023-01-05 23:03:05,465] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:03:05,473] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:03:05,496] {logging_mixin.py:115} INFO - [2023-01-05 23:03:05,495] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:03:05,517] {logging_mixin.py:115} INFO - [2023-01-05 23:03:05,517] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:03:05,527] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.897 seconds
[2023-01-05 23:03:35,723] {processor.py:153} INFO - Started process (PID=4265) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:03:35,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:03:35,725] {logging_mixin.py:115} INFO - [2023-01-05 23:03:35,724] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:03:36,556] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:03:36,557] {logging_mixin.py:115} INFO - [2023-01-05 23:03:36,557] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:03:36,558] {logging_mixin.py:115} INFO - [2023-01-05 23:03:36,557] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:03:36,565] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:03:36,587] {logging_mixin.py:115} INFO - [2023-01-05 23:03:36,587] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:03:36,607] {logging_mixin.py:115} INFO - [2023-01-05 23:03:36,607] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:03:36,617] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.898 seconds
[2023-01-05 23:04:06,785] {processor.py:153} INFO - Started process (PID=4289) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:04:06,786] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:04:06,787] {logging_mixin.py:115} INFO - [2023-01-05 23:04:06,787] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:04:07,593] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:04:07,594] {logging_mixin.py:115} INFO - [2023-01-05 23:04:07,594] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:04:07,595] {logging_mixin.py:115} INFO - [2023-01-05 23:04:07,594] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:04:07,601] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:04:07,624] {logging_mixin.py:115} INFO - [2023-01-05 23:04:07,624] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:04:07,646] {logging_mixin.py:115} INFO - [2023-01-05 23:04:07,646] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:04:07,656] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.876 seconds
[2023-01-05 23:04:37,876] {processor.py:153} INFO - Started process (PID=4308) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:04:37,877] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:04:37,877] {logging_mixin.py:115} INFO - [2023-01-05 23:04:37,877] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:04:38,751] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:04:38,752] {logging_mixin.py:115} INFO - [2023-01-05 23:04:38,752] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:04:38,753] {logging_mixin.py:115} INFO - [2023-01-05 23:04:38,753] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:04:38,760] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:04:38,784] {logging_mixin.py:115} INFO - [2023-01-05 23:04:38,783] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:04:38,805] {logging_mixin.py:115} INFO - [2023-01-05 23:04:38,805] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:04:38,815] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.944 seconds
[2023-01-05 23:05:09,039] {processor.py:153} INFO - Started process (PID=4333) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:05:09,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:05:09,041] {logging_mixin.py:115} INFO - [2023-01-05 23:05:09,041] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:05:09,855] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:05:09,857] {logging_mixin.py:115} INFO - [2023-01-05 23:05:09,856] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:05:09,857] {logging_mixin.py:115} INFO - [2023-01-05 23:05:09,857] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:05:09,864] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:05:09,888] {logging_mixin.py:115} INFO - [2023-01-05 23:05:09,887] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:05:09,910] {logging_mixin.py:115} INFO - [2023-01-05 23:05:09,909] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:05:09,922] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.888 seconds
[2023-01-05 23:05:40,117] {processor.py:153} INFO - Started process (PID=4357) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:05:40,118] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:05:40,119] {logging_mixin.py:115} INFO - [2023-01-05 23:05:40,119] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:05:41,044] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:05:41,046] {logging_mixin.py:115} INFO - [2023-01-05 23:05:41,046] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:05:41,046] {logging_mixin.py:115} INFO - [2023-01-05 23:05:41,046] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:05:41,053] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:05:41,078] {logging_mixin.py:115} INFO - [2023-01-05 23:05:41,077] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:05:41,100] {logging_mixin.py:115} INFO - [2023-01-05 23:05:41,099] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:05:41,112] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.001 seconds
[2023-01-05 23:06:11,201] {processor.py:153} INFO - Started process (PID=4382) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:06:11,201] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:06:11,202] {logging_mixin.py:115} INFO - [2023-01-05 23:06:11,202] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:06:12,027] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:06:12,029] {logging_mixin.py:115} INFO - [2023-01-05 23:06:12,029] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:06:12,029] {logging_mixin.py:115} INFO - [2023-01-05 23:06:12,029] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:06:12,036] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:06:12,059] {logging_mixin.py:115} INFO - [2023-01-05 23:06:12,059] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:06:12,079] {logging_mixin.py:115} INFO - [2023-01-05 23:06:12,079] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:06:12,090] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.895 seconds
[2023-01-05 23:06:42,262] {processor.py:153} INFO - Started process (PID=4400) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:06:42,263] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:06:42,264] {logging_mixin.py:115} INFO - [2023-01-05 23:06:42,264] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:06:43,101] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:06:43,102] {logging_mixin.py:115} INFO - [2023-01-05 23:06:43,102] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:06:43,103] {logging_mixin.py:115} INFO - [2023-01-05 23:06:43,103] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:06:43,110] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:06:43,133] {logging_mixin.py:115} INFO - [2023-01-05 23:06:43,133] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:06:43,155] {logging_mixin.py:115} INFO - [2023-01-05 23:06:43,155] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:06:43,166] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.910 seconds
[2023-01-05 23:07:13,323] {processor.py:153} INFO - Started process (PID=4424) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:07:13,324] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:07:13,325] {logging_mixin.py:115} INFO - [2023-01-05 23:07:13,325] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:07:14,170] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:07:14,172] {logging_mixin.py:115} INFO - [2023-01-05 23:07:14,172] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:07:14,172] {logging_mixin.py:115} INFO - [2023-01-05 23:07:14,172] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:07:14,179] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:07:14,210] {logging_mixin.py:115} INFO - [2023-01-05 23:07:14,209] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:07:14,235] {logging_mixin.py:115} INFO - [2023-01-05 23:07:14,235] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:07:14,247] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.929 seconds
[2023-01-05 23:07:44,353] {processor.py:153} INFO - Started process (PID=4448) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:07:44,356] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:07:44,357] {logging_mixin.py:115} INFO - [2023-01-05 23:07:44,356] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:07:45,201] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:07:45,202] {logging_mixin.py:115} INFO - [2023-01-05 23:07:45,202] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:07:45,203] {logging_mixin.py:115} INFO - [2023-01-05 23:07:45,203] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:07:45,210] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:07:45,232] {logging_mixin.py:115} INFO - [2023-01-05 23:07:45,232] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:07:45,253] {logging_mixin.py:115} INFO - [2023-01-05 23:07:45,253] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:07:45,264] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.917 seconds
[2023-01-05 23:08:15,424] {processor.py:153} INFO - Started process (PID=4473) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:08:15,425] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:08:15,426] {logging_mixin.py:115} INFO - [2023-01-05 23:08:15,426] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:08:16,243] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:08:16,245] {logging_mixin.py:115} INFO - [2023-01-05 23:08:16,245] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:08:16,246] {logging_mixin.py:115} INFO - [2023-01-05 23:08:16,245] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:08:16,253] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:08:16,287] {logging_mixin.py:115} INFO - [2023-01-05 23:08:16,286] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:08:16,315] {logging_mixin.py:115} INFO - [2023-01-05 23:08:16,315] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:08:16,330] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.911 seconds
[2023-01-05 23:08:46,496] {processor.py:153} INFO - Started process (PID=4491) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:08:46,496] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:08:46,497] {logging_mixin.py:115} INFO - [2023-01-05 23:08:46,497] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:08:47,350] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:08:47,351] {logging_mixin.py:115} INFO - [2023-01-05 23:08:47,351] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:08:47,352] {logging_mixin.py:115} INFO - [2023-01-05 23:08:47,351] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:08:47,359] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:08:47,383] {logging_mixin.py:115} INFO - [2023-01-05 23:08:47,383] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:08:47,404] {logging_mixin.py:115} INFO - [2023-01-05 23:08:47,404] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:08:47,416] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.926 seconds
[2023-01-05 23:09:17,563] {processor.py:153} INFO - Started process (PID=4516) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:09:17,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:09:17,564] {logging_mixin.py:115} INFO - [2023-01-05 23:09:17,564] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:09:18,419] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:09:18,420] {logging_mixin.py:115} INFO - [2023-01-05 23:09:18,420] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:09:18,421] {logging_mixin.py:115} INFO - [2023-01-05 23:09:18,421] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:09:18,428] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:09:18,451] {logging_mixin.py:115} INFO - [2023-01-05 23:09:18,451] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:09:18,473] {logging_mixin.py:115} INFO - [2023-01-05 23:09:18,472] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:09:18,485] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.928 seconds
[2023-01-05 23:09:48,592] {processor.py:153} INFO - Started process (PID=4541) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:09:48,593] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:09:48,593] {logging_mixin.py:115} INFO - [2023-01-05 23:09:48,593] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:09:49,507] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:09:49,508] {logging_mixin.py:115} INFO - [2023-01-05 23:09:49,508] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:09:49,509] {logging_mixin.py:115} INFO - [2023-01-05 23:09:49,509] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:09:49,516] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:09:49,539] {logging_mixin.py:115} INFO - [2023-01-05 23:09:49,539] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:09:49,560] {logging_mixin.py:115} INFO - [2023-01-05 23:09:49,560] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:09:49,571] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.985 seconds
[2023-01-05 23:10:19,685] {processor.py:153} INFO - Started process (PID=4566) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:10:19,686] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:10:19,687] {logging_mixin.py:115} INFO - [2023-01-05 23:10:19,687] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:10:20,522] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:10:20,524] {logging_mixin.py:115} INFO - [2023-01-05 23:10:20,524] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:10:20,524] {logging_mixin.py:115} INFO - [2023-01-05 23:10:20,524] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:10:20,531] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:10:20,555] {logging_mixin.py:115} INFO - [2023-01-05 23:10:20,555] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:10:20,576] {logging_mixin.py:115} INFO - [2023-01-05 23:10:20,576] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:10:20,587] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.907 seconds
[2023-01-05 23:10:50,781] {processor.py:153} INFO - Started process (PID=4583) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:10:50,783] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:10:50,783] {logging_mixin.py:115} INFO - [2023-01-05 23:10:50,783] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:10:51,600] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:10:51,602] {logging_mixin.py:115} INFO - [2023-01-05 23:10:51,601] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:10:51,602] {logging_mixin.py:115} INFO - [2023-01-05 23:10:51,602] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:10:51,609] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:10:51,632] {logging_mixin.py:115} INFO - [2023-01-05 23:10:51,631] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:10:51,654] {logging_mixin.py:115} INFO - [2023-01-05 23:10:51,654] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:10:51,665] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.889 seconds
[2023-01-05 23:11:21,848] {processor.py:153} INFO - Started process (PID=4608) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:11:21,849] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:11:21,850] {logging_mixin.py:115} INFO - [2023-01-05 23:11:21,850] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:11:22,690] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:11:22,692] {logging_mixin.py:115} INFO - [2023-01-05 23:11:22,692] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:11:22,692] {logging_mixin.py:115} INFO - [2023-01-05 23:11:22,692] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:11:22,701] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:11:22,723] {logging_mixin.py:115} INFO - [2023-01-05 23:11:22,723] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:11:22,744] {logging_mixin.py:115} INFO - [2023-01-05 23:11:22,743] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:11:22,755] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.911 seconds
[2023-01-05 23:11:52,913] {processor.py:153} INFO - Started process (PID=4633) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:11:52,914] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:11:52,914] {logging_mixin.py:115} INFO - [2023-01-05 23:11:52,914] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:11:53,739] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:11:53,740] {logging_mixin.py:115} INFO - [2023-01-05 23:11:53,740] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:11:53,741] {logging_mixin.py:115} INFO - [2023-01-05 23:11:53,740] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:11:53,748] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:11:53,777] {logging_mixin.py:115} INFO - [2023-01-05 23:11:53,777] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:11:53,806] {logging_mixin.py:115} INFO - [2023-01-05 23:11:53,806] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:11:53,820] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.912 seconds
[2023-01-05 23:12:23,996] {processor.py:153} INFO - Started process (PID=4660) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:12:23,998] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:12:23,999] {logging_mixin.py:115} INFO - [2023-01-05 23:12:23,999] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:12:24,832] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:12:24,833] {logging_mixin.py:115} INFO - [2023-01-05 23:12:24,833] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:12:24,834] {logging_mixin.py:115} INFO - [2023-01-05 23:12:24,834] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:12:24,841] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:12:24,863] {logging_mixin.py:115} INFO - [2023-01-05 23:12:24,863] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:12:24,883] {logging_mixin.py:115} INFO - [2023-01-05 23:12:24,883] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:12:24,894] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.902 seconds
[2023-01-05 23:12:55,074] {processor.py:153} INFO - Started process (PID=4678) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:12:55,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:12:55,077] {logging_mixin.py:115} INFO - [2023-01-05 23:12:55,077] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:12:55,905] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:12:55,907] {logging_mixin.py:115} INFO - [2023-01-05 23:12:55,907] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:12:55,907] {logging_mixin.py:115} INFO - [2023-01-05 23:12:55,907] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:12:55,914] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:12:55,939] {logging_mixin.py:115} INFO - [2023-01-05 23:12:55,938] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:12:55,960] {logging_mixin.py:115} INFO - [2023-01-05 23:12:55,960] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:12:55,972] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.904 seconds
[2023-01-05 23:13:26,160] {processor.py:153} INFO - Started process (PID=4703) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:13:26,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:13:26,167] {logging_mixin.py:115} INFO - [2023-01-05 23:13:26,166] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:13:26,999] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:13:27,001] {logging_mixin.py:115} INFO - [2023-01-05 23:13:27,000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:13:27,001] {logging_mixin.py:115} INFO - [2023-01-05 23:13:27,001] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:13:27,008] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:13:27,031] {logging_mixin.py:115} INFO - [2023-01-05 23:13:27,031] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:13:27,052] {logging_mixin.py:115} INFO - [2023-01-05 23:13:27,052] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:13:27,063] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.908 seconds
[2023-01-05 23:13:57,165] {processor.py:153} INFO - Started process (PID=4728) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:13:57,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:13:57,166] {logging_mixin.py:115} INFO - [2023-01-05 23:13:57,166] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:13:58,004] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:13:58,006] {logging_mixin.py:115} INFO - [2023-01-05 23:13:58,005] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:13:58,006] {logging_mixin.py:115} INFO - [2023-01-05 23:13:58,006] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:13:58,013] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:13:58,035] {logging_mixin.py:115} INFO - [2023-01-05 23:13:58,035] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:13:58,055] {logging_mixin.py:115} INFO - [2023-01-05 23:13:58,055] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:13:58,066] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.907 seconds
[2023-01-05 23:14:28,302] {processor.py:153} INFO - Started process (PID=4755) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:14:28,304] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:14:28,305] {logging_mixin.py:115} INFO - [2023-01-05 23:14:28,304] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:14:29,316] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:14:29,317] {logging_mixin.py:115} INFO - [2023-01-05 23:14:29,317] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:14:29,318] {logging_mixin.py:115} INFO - [2023-01-05 23:14:29,318] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:14:29,325] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:14:29,350] {logging_mixin.py:115} INFO - [2023-01-05 23:14:29,349] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:14:29,371] {logging_mixin.py:115} INFO - [2023-01-05 23:14:29,370] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:14:29,384] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.088 seconds
[2023-01-05 23:14:59,466] {processor.py:153} INFO - Started process (PID=4775) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:14:59,468] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:14:59,468] {logging_mixin.py:115} INFO - [2023-01-05 23:14:59,468] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:15:00,298] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:15:00,299] {logging_mixin.py:115} INFO - [2023-01-05 23:15:00,299] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:15:00,300] {logging_mixin.py:115} INFO - [2023-01-05 23:15:00,299] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:15:00,307] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:15:00,336] {logging_mixin.py:115} INFO - [2023-01-05 23:15:00,335] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:15:00,366] {logging_mixin.py:115} INFO - [2023-01-05 23:15:00,366] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:15:00,381] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.920 seconds
[2023-01-05 23:15:30,790] {processor.py:153} INFO - Started process (PID=4799) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:15:30,790] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:15:30,791] {logging_mixin.py:115} INFO - [2023-01-05 23:15:30,791] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:15:31,603] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:15:31,604] {logging_mixin.py:115} INFO - [2023-01-05 23:15:31,604] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:15:31,605] {logging_mixin.py:115} INFO - [2023-01-05 23:15:31,605] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:15:31,612] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:15:31,637] {logging_mixin.py:115} INFO - [2023-01-05 23:15:31,637] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:15:31,660] {logging_mixin.py:115} INFO - [2023-01-05 23:15:31,660] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:15:31,672] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.887 seconds
[2023-01-05 23:16:01,854] {processor.py:153} INFO - Started process (PID=4824) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:16:01,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:16:01,855] {logging_mixin.py:115} INFO - [2023-01-05 23:16:01,855] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:16:02,893] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:16:02,895] {logging_mixin.py:115} INFO - [2023-01-05 23:16:02,895] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:16:02,895] {logging_mixin.py:115} INFO - [2023-01-05 23:16:02,895] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:16:02,907] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:16:02,938] {logging_mixin.py:115} INFO - [2023-01-05 23:16:02,938] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:16:02,970] {logging_mixin.py:115} INFO - [2023-01-05 23:16:02,970] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:16:02,985] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.135 seconds
[2023-01-05 23:16:33,030] {processor.py:153} INFO - Started process (PID=4843) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:16:33,032] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:16:33,032] {logging_mixin.py:115} INFO - [2023-01-05 23:16:33,032] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:16:33,976] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:16:33,978] {logging_mixin.py:115} INFO - [2023-01-05 23:16:33,978] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:16:33,979] {logging_mixin.py:115} INFO - [2023-01-05 23:16:33,978] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:16:33,990] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:16:34,014] {logging_mixin.py:115} INFO - [2023-01-05 23:16:34,014] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:16:34,035] {logging_mixin.py:115} INFO - [2023-01-05 23:16:34,035] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:16:34,047] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.022 seconds
[2023-01-05 23:17:04,126] {processor.py:153} INFO - Started process (PID=4868) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:17:04,128] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:17:04,129] {logging_mixin.py:115} INFO - [2023-01-05 23:17:04,129] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:17:04,958] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:17:04,960] {logging_mixin.py:115} INFO - [2023-01-05 23:17:04,960] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:17:04,960] {logging_mixin.py:115} INFO - [2023-01-05 23:17:04,960] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:17:04,967] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:17:04,990] {logging_mixin.py:115} INFO - [2023-01-05 23:17:04,990] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:17:05,010] {logging_mixin.py:115} INFO - [2023-01-05 23:17:05,010] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:17:05,022] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.902 seconds
[2023-01-05 23:17:35,125] {processor.py:153} INFO - Started process (PID=4893) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:17:35,127] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:17:35,128] {logging_mixin.py:115} INFO - [2023-01-05 23:17:35,128] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:17:35,952] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:17:35,954] {logging_mixin.py:115} INFO - [2023-01-05 23:17:35,954] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:17:35,955] {logging_mixin.py:115} INFO - [2023-01-05 23:17:35,954] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:17:35,965] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:17:35,987] {logging_mixin.py:115} INFO - [2023-01-05 23:17:35,986] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:17:36,007] {logging_mixin.py:115} INFO - [2023-01-05 23:17:36,007] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:17:36,019] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.899 seconds
[2023-01-05 23:18:06,121] {processor.py:153} INFO - Started process (PID=4919) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:18:06,122] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:18:06,123] {logging_mixin.py:115} INFO - [2023-01-05 23:18:06,123] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:18:06,969] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:18:06,970] {logging_mixin.py:115} INFO - [2023-01-05 23:18:06,970] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:18:06,971] {logging_mixin.py:115} INFO - [2023-01-05 23:18:06,970] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:18:06,978] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:18:07,000] {logging_mixin.py:115} INFO - [2023-01-05 23:18:07,000] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:18:07,021] {logging_mixin.py:115} INFO - [2023-01-05 23:18:07,021] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:18:07,033] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.917 seconds
[2023-01-05 23:18:37,292] {processor.py:153} INFO - Started process (PID=4937) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:18:37,292] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:18:37,293] {logging_mixin.py:115} INFO - [2023-01-05 23:18:37,293] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:18:38,168] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:18:38,170] {logging_mixin.py:115} INFO - [2023-01-05 23:18:38,170] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:18:38,170] {logging_mixin.py:115} INFO - [2023-01-05 23:18:38,170] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:18:38,178] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:18:38,208] {logging_mixin.py:115} INFO - [2023-01-05 23:18:38,208] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:18:38,240] {logging_mixin.py:115} INFO - [2023-01-05 23:18:38,240] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:18:38,254] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.968 seconds
[2023-01-05 23:19:08,367] {processor.py:153} INFO - Started process (PID=4962) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:19:08,368] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:19:08,369] {logging_mixin.py:115} INFO - [2023-01-05 23:19:08,369] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:19:09,209] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:19:09,210] {logging_mixin.py:115} INFO - [2023-01-05 23:19:09,210] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:19:09,211] {logging_mixin.py:115} INFO - [2023-01-05 23:19:09,210] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:19:09,218] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:19:09,246] {logging_mixin.py:115} INFO - [2023-01-05 23:19:09,245] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:19:09,267] {logging_mixin.py:115} INFO - [2023-01-05 23:19:09,267] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:19:09,278] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.916 seconds
[2023-01-05 23:19:39,449] {processor.py:153} INFO - Started process (PID=4987) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:19:39,449] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:19:39,450] {logging_mixin.py:115} INFO - [2023-01-05 23:19:39,450] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:19:40,323] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:19:40,324] {logging_mixin.py:115} INFO - [2023-01-05 23:19:40,324] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:19:40,325] {logging_mixin.py:115} INFO - [2023-01-05 23:19:40,324] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:19:40,332] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:19:40,356] {logging_mixin.py:115} INFO - [2023-01-05 23:19:40,355] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:19:40,377] {logging_mixin.py:115} INFO - [2023-01-05 23:19:40,377] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:19:40,389] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.945 seconds
[2023-01-05 23:19:47,436] {processor.py:153} INFO - Started process (PID=4996) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:19:47,437] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:19:47,438] {logging_mixin.py:115} INFO - [2023-01-05 23:19:47,438] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:19:48,290] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:19:48,291] {logging_mixin.py:115} INFO - [2023-01-05 23:19:48,291] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:19:48,292] {logging_mixin.py:115} INFO - [2023-01-05 23:19:48,292] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:19:48,299] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:19:48,357] {logging_mixin.py:115} INFO - [2023-01-05 23:19:48,357] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:19:48,377] {logging_mixin.py:115} INFO - [2023-01-05 23:19:48,377] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:19:48,392] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.962 seconds
[2023-01-05 23:20:18,526] {processor.py:153} INFO - Started process (PID=5014) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:20:18,527] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:20:18,528] {logging_mixin.py:115} INFO - [2023-01-05 23:20:18,527] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:20:19,348] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:20:19,350] {logging_mixin.py:115} INFO - [2023-01-05 23:20:19,350] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:20:19,350] {logging_mixin.py:115} INFO - [2023-01-05 23:20:19,350] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:20:19,357] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:20:19,381] {logging_mixin.py:115} INFO - [2023-01-05 23:20:19,381] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:20:19,403] {logging_mixin.py:115} INFO - [2023-01-05 23:20:19,403] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:20:19,414] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.893 seconds
[2023-01-05 23:20:49,596] {processor.py:153} INFO - Started process (PID=5039) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:20:49,600] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:20:49,601] {logging_mixin.py:115} INFO - [2023-01-05 23:20:49,600] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:20:50,462] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:20:50,464] {logging_mixin.py:115} INFO - [2023-01-05 23:20:50,464] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:20:50,464] {logging_mixin.py:115} INFO - [2023-01-05 23:20:50,464] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:20:50,471] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:20:50,493] {logging_mixin.py:115} INFO - [2023-01-05 23:20:50,493] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:20:50,516] {logging_mixin.py:115} INFO - [2023-01-05 23:20:50,516] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:20:50,532] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.941 seconds
[2023-01-05 23:21:20,641] {processor.py:153} INFO - Started process (PID=5064) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:21:20,644] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:21:20,645] {logging_mixin.py:115} INFO - [2023-01-05 23:21:20,645] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:21:21,519] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:21:21,521] {logging_mixin.py:115} INFO - [2023-01-05 23:21:21,520] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:21:21,521] {logging_mixin.py:115} INFO - [2023-01-05 23:21:21,521] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:21:21,528] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:21:21,553] {logging_mixin.py:115} INFO - [2023-01-05 23:21:21,553] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:21:21,574] {logging_mixin.py:115} INFO - [2023-01-05 23:21:21,574] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:21:21,586] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.952 seconds
[2023-01-05 23:21:51,684] {processor.py:153} INFO - Started process (PID=5090) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:21:51,686] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:21:51,686] {logging_mixin.py:115} INFO - [2023-01-05 23:21:51,686] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:21:52,514] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:21:52,515] {logging_mixin.py:115} INFO - [2023-01-05 23:21:52,515] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:21:52,516] {logging_mixin.py:115} INFO - [2023-01-05 23:21:52,515] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:21:52,522] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:21:52,544] {logging_mixin.py:115} INFO - [2023-01-05 23:21:52,544] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:21:52,565] {logging_mixin.py:115} INFO - [2023-01-05 23:21:52,565] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:21:52,576] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.896 seconds
[2023-01-05 23:22:22,760] {processor.py:153} INFO - Started process (PID=5108) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:22:22,760] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:22:22,761] {logging_mixin.py:115} INFO - [2023-01-05 23:22:22,761] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:22:23,573] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:22:23,574] {logging_mixin.py:115} INFO - [2023-01-05 23:22:23,574] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:22:23,575] {logging_mixin.py:115} INFO - [2023-01-05 23:22:23,575] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:22:23,582] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:22:23,605] {logging_mixin.py:115} INFO - [2023-01-05 23:22:23,605] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:22:23,626] {logging_mixin.py:115} INFO - [2023-01-05 23:22:23,626] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:22:23,637] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.883 seconds
[2023-01-05 23:22:53,915] {processor.py:153} INFO - Started process (PID=5133) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:22:53,917] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:22:53,918] {logging_mixin.py:115} INFO - [2023-01-05 23:22:53,918] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:22:54,751] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:22:54,752] {logging_mixin.py:115} INFO - [2023-01-05 23:22:54,752] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:22:54,753] {logging_mixin.py:115} INFO - [2023-01-05 23:22:54,752] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:22:54,760] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:22:54,790] {logging_mixin.py:115} INFO - [2023-01-05 23:22:54,789] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:22:54,823] {logging_mixin.py:115} INFO - [2023-01-05 23:22:54,823] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:22:54,838] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.928 seconds
[2023-01-05 23:23:25,010] {processor.py:153} INFO - Started process (PID=5159) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:23:25,011] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:23:25,011] {logging_mixin.py:115} INFO - [2023-01-05 23:23:25,011] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:23:25,837] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:23:25,838] {logging_mixin.py:115} INFO - [2023-01-05 23:23:25,838] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:23:25,839] {logging_mixin.py:115} INFO - [2023-01-05 23:23:25,839] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:23:25,846] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:23:25,869] {logging_mixin.py:115} INFO - [2023-01-05 23:23:25,869] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:23:25,891] {logging_mixin.py:115} INFO - [2023-01-05 23:23:25,890] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:23:25,902] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.897 seconds
[2023-01-05 23:23:56,086] {processor.py:153} INFO - Started process (PID=5184) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:23:56,089] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:23:56,089] {logging_mixin.py:115} INFO - [2023-01-05 23:23:56,089] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:23:56,939] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:23:56,940] {logging_mixin.py:115} INFO - [2023-01-05 23:23:56,940] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:23:56,941] {logging_mixin.py:115} INFO - [2023-01-05 23:23:56,941] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:23:56,948] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:23:56,971] {logging_mixin.py:115} INFO - [2023-01-05 23:23:56,971] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:23:56,992] {logging_mixin.py:115} INFO - [2023-01-05 23:23:56,992] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:23:57,004] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.923 seconds
[2023-01-05 23:24:27,176] {processor.py:153} INFO - Started process (PID=5201) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:24:27,177] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:24:27,178] {logging_mixin.py:115} INFO - [2023-01-05 23:24:27,178] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:24:28,060] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:24:28,061] {logging_mixin.py:115} INFO - [2023-01-05 23:24:28,061] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:24:28,062] {logging_mixin.py:115} INFO - [2023-01-05 23:24:28,061] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:24:28,068] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:24:28,092] {logging_mixin.py:115} INFO - [2023-01-05 23:24:28,092] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:24:28,114] {logging_mixin.py:115} INFO - [2023-01-05 23:24:28,114] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:24:28,125] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.954 seconds
[2023-01-05 23:24:58,241] {processor.py:153} INFO - Started process (PID=5228) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:24:58,242] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:24:58,243] {logging_mixin.py:115} INFO - [2023-01-05 23:24:58,243] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:24:59,090] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:24:59,091] {logging_mixin.py:115} INFO - [2023-01-05 23:24:59,091] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:24:59,092] {logging_mixin.py:115} INFO - [2023-01-05 23:24:59,091] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:24:59,098] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:24:59,124] {logging_mixin.py:115} INFO - [2023-01-05 23:24:59,123] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:24:59,153] {logging_mixin.py:115} INFO - [2023-01-05 23:24:59,153] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:24:59,168] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.931 seconds
[2023-01-05 23:25:29,311] {processor.py:153} INFO - Started process (PID=5254) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:25:29,312] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:25:29,313] {logging_mixin.py:115} INFO - [2023-01-05 23:25:29,313] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:25:30,179] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:25:30,180] {logging_mixin.py:115} INFO - [2023-01-05 23:25:30,180] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:25:30,181] {logging_mixin.py:115} INFO - [2023-01-05 23:25:30,180] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:25:30,188] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:25:30,213] {logging_mixin.py:115} INFO - [2023-01-05 23:25:30,213] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:25:30,239] {logging_mixin.py:115} INFO - [2023-01-05 23:25:30,238] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:25:30,262] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.956 seconds
[2023-01-05 23:26:00,449] {processor.py:153} INFO - Started process (PID=5280) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:26:00,450] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:26:00,451] {logging_mixin.py:115} INFO - [2023-01-05 23:26:00,451] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:26:01,324] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:26:01,325] {logging_mixin.py:115} INFO - [2023-01-05 23:26:01,325] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:26:01,326] {logging_mixin.py:115} INFO - [2023-01-05 23:26:01,325] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:26:01,332] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:26:01,356] {logging_mixin.py:115} INFO - [2023-01-05 23:26:01,355] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:26:01,377] {logging_mixin.py:115} INFO - [2023-01-05 23:26:01,376] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:26:01,388] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.944 seconds
[2023-01-05 23:26:31,495] {processor.py:153} INFO - Started process (PID=5298) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:26:31,496] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:26:31,496] {logging_mixin.py:115} INFO - [2023-01-05 23:26:31,496] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:26:32,352] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:26:32,353] {logging_mixin.py:115} INFO - [2023-01-05 23:26:32,353] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:26:32,354] {logging_mixin.py:115} INFO - [2023-01-05 23:26:32,354] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:26:32,361] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:26:32,385] {logging_mixin.py:115} INFO - [2023-01-05 23:26:32,384] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:26:32,405] {logging_mixin.py:115} INFO - [2023-01-05 23:26:32,405] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:26:32,417] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.926 seconds
[2023-01-05 23:27:02,523] {processor.py:153} INFO - Started process (PID=5323) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:27:02,525] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:27:02,525] {logging_mixin.py:115} INFO - [2023-01-05 23:27:02,525] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:27:03,359] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:27:03,361] {logging_mixin.py:115} INFO - [2023-01-05 23:27:03,361] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:27:03,361] {logging_mixin.py:115} INFO - [2023-01-05 23:27:03,361] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:27:03,368] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:27:03,391] {logging_mixin.py:115} INFO - [2023-01-05 23:27:03,391] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:27:03,411] {logging_mixin.py:115} INFO - [2023-01-05 23:27:03,411] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:27:03,422] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.904 seconds
[2023-01-05 23:27:33,607] {processor.py:153} INFO - Started process (PID=5349) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:27:33,608] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:27:33,609] {logging_mixin.py:115} INFO - [2023-01-05 23:27:33,609] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:27:34,505] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:27:34,508] {logging_mixin.py:115} INFO - [2023-01-05 23:27:34,506] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:27:34,509] {logging_mixin.py:115} INFO - [2023-01-05 23:27:34,508] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:27:34,516] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:27:34,540] {logging_mixin.py:115} INFO - [2023-01-05 23:27:34,539] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:27:34,561] {logging_mixin.py:115} INFO - [2023-01-05 23:27:34,561] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:27:34,573] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.970 seconds
[2023-01-05 23:28:04,676] {processor.py:153} INFO - Started process (PID=5372) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:28:04,677] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:28:04,678] {logging_mixin.py:115} INFO - [2023-01-05 23:28:04,678] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:28:05,555] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:28:05,557] {logging_mixin.py:115} INFO - [2023-01-05 23:28:05,556] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:28:05,557] {logging_mixin.py:115} INFO - [2023-01-05 23:28:05,557] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:28:05,564] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:28:05,588] {logging_mixin.py:115} INFO - [2023-01-05 23:28:05,588] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:28:05,613] {logging_mixin.py:115} INFO - [2023-01-05 23:28:05,613] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:28:05,627] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.955 seconds
[2023-01-05 23:28:35,772] {processor.py:153} INFO - Started process (PID=5390) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:28:35,774] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:28:35,775] {logging_mixin.py:115} INFO - [2023-01-05 23:28:35,774] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:28:36,637] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:28:36,638] {logging_mixin.py:115} INFO - [2023-01-05 23:28:36,638] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:28:36,639] {logging_mixin.py:115} INFO - [2023-01-05 23:28:36,638] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:28:36,646] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:28:36,669] {logging_mixin.py:115} INFO - [2023-01-05 23:28:36,669] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:28:36,691] {logging_mixin.py:115} INFO - [2023-01-05 23:28:36,690] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:28:36,702] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.934 seconds
[2023-01-05 23:29:06,805] {processor.py:153} INFO - Started process (PID=5414) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:29:06,806] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:29:06,807] {logging_mixin.py:115} INFO - [2023-01-05 23:29:06,806] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:29:07,615] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:29:07,617] {logging_mixin.py:115} INFO - [2023-01-05 23:29:07,617] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:29:07,617] {logging_mixin.py:115} INFO - [2023-01-05 23:29:07,617] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:29:07,624] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:29:07,646] {logging_mixin.py:115} INFO - [2023-01-05 23:29:07,646] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:29:07,667] {logging_mixin.py:115} INFO - [2023-01-05 23:29:07,667] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:29:07,678] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.879 seconds
[2023-01-05 23:29:37,948] {processor.py:153} INFO - Started process (PID=5439) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:29:37,949] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:29:37,949] {logging_mixin.py:115} INFO - [2023-01-05 23:29:37,949] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:29:38,836] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:29:38,838] {logging_mixin.py:115} INFO - [2023-01-05 23:29:38,838] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:29:38,838] {logging_mixin.py:115} INFO - [2023-01-05 23:29:38,838] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:29:38,845] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:29:38,869] {logging_mixin.py:115} INFO - [2023-01-05 23:29:38,869] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:29:38,890] {logging_mixin.py:115} INFO - [2023-01-05 23:29:38,890] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:29:38,902] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.959 seconds
[2023-01-05 23:30:09,160] {processor.py:153} INFO - Started process (PID=5465) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:30:09,161] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:30:09,162] {logging_mixin.py:115} INFO - [2023-01-05 23:30:09,162] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:30:10,037] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:30:10,038] {logging_mixin.py:115} INFO - [2023-01-05 23:30:10,038] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:30:10,039] {logging_mixin.py:115} INFO - [2023-01-05 23:30:10,039] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:30:10,046] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:30:10,068] {logging_mixin.py:115} INFO - [2023-01-05 23:30:10,068] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:30:10,089] {logging_mixin.py:115} INFO - [2023-01-05 23:30:10,088] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:30:10,099] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.945 seconds
[2023-01-05 23:30:40,221] {processor.py:153} INFO - Started process (PID=5483) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:30:40,222] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:30:40,223] {logging_mixin.py:115} INFO - [2023-01-05 23:30:40,223] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:30:41,032] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:30:41,033] {logging_mixin.py:115} INFO - [2023-01-05 23:30:41,033] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:30:41,033] {logging_mixin.py:115} INFO - [2023-01-05 23:30:41,033] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:30:41,044] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:30:41,067] {logging_mixin.py:115} INFO - [2023-01-05 23:30:41,067] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:30:41,087] {logging_mixin.py:115} INFO - [2023-01-05 23:30:41,087] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:30:41,098] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.882 seconds
[2023-01-05 23:31:11,292] {processor.py:153} INFO - Started process (PID=5509) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:31:11,293] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:31:11,294] {logging_mixin.py:115} INFO - [2023-01-05 23:31:11,294] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:31:12,119] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:31:12,120] {logging_mixin.py:115} INFO - [2023-01-05 23:31:12,120] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:31:12,121] {logging_mixin.py:115} INFO - [2023-01-05 23:31:12,120] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:31:12,128] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:31:12,150] {logging_mixin.py:115} INFO - [2023-01-05 23:31:12,149] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:31:12,170] {logging_mixin.py:115} INFO - [2023-01-05 23:31:12,170] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:31:12,181] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.894 seconds
[2023-01-05 23:31:42,286] {processor.py:153} INFO - Started process (PID=5534) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:31:42,288] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:31:42,288] {logging_mixin.py:115} INFO - [2023-01-05 23:31:42,288] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:31:43,330] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:31:43,332] {logging_mixin.py:115} INFO - [2023-01-05 23:31:43,332] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:31:43,333] {logging_mixin.py:115} INFO - [2023-01-05 23:31:43,332] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:31:43,342] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:31:43,372] {logging_mixin.py:115} INFO - [2023-01-05 23:31:43,372] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:31:43,404] {logging_mixin.py:115} INFO - [2023-01-05 23:31:43,404] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:31:43,420] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.139 seconds
[2023-01-05 23:32:13,503] {processor.py:153} INFO - Started process (PID=5551) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:32:13,504] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:32:13,504] {logging_mixin.py:115} INFO - [2023-01-05 23:32:13,504] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:32:14,413] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:32:14,415] {logging_mixin.py:115} INFO - [2023-01-05 23:32:14,414] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:32:14,415] {logging_mixin.py:115} INFO - [2023-01-05 23:32:14,415] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:32:14,422] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:32:14,445] {logging_mixin.py:115} INFO - [2023-01-05 23:32:14,445] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:32:14,467] {logging_mixin.py:115} INFO - [2023-01-05 23:32:14,467] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:32:14,478] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.980 seconds
[2023-01-05 23:32:44,587] {processor.py:153} INFO - Started process (PID=5575) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:32:44,588] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:32:44,589] {logging_mixin.py:115} INFO - [2023-01-05 23:32:44,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:32:45,432] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:32:45,434] {logging_mixin.py:115} INFO - [2023-01-05 23:32:45,433] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:32:45,434] {logging_mixin.py:115} INFO - [2023-01-05 23:32:45,434] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:32:45,441] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:32:45,464] {logging_mixin.py:115} INFO - [2023-01-05 23:32:45,463] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:32:45,485] {logging_mixin.py:115} INFO - [2023-01-05 23:32:45,485] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:32:45,496] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.915 seconds
[2023-01-05 23:33:15,724] {processor.py:153} INFO - Started process (PID=5599) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:33:15,725] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:33:15,726] {logging_mixin.py:115} INFO - [2023-01-05 23:33:15,726] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:33:16,565] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:33:16,567] {logging_mixin.py:115} INFO - [2023-01-05 23:33:16,566] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:33:16,567] {logging_mixin.py:115} INFO - [2023-01-05 23:33:16,567] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:33:16,574] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:33:16,596] {logging_mixin.py:115} INFO - [2023-01-05 23:33:16,596] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:33:16,616] {logging_mixin.py:115} INFO - [2023-01-05 23:33:16,616] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:33:16,627] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.909 seconds
[2023-01-05 23:33:46,790] {processor.py:153} INFO - Started process (PID=5626) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:33:46,790] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:33:46,791] {logging_mixin.py:115} INFO - [2023-01-05 23:33:46,791] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:33:47,652] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:33:47,653] {logging_mixin.py:115} INFO - [2023-01-05 23:33:47,653] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:33:47,654] {logging_mixin.py:115} INFO - [2023-01-05 23:33:47,654] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:33:47,661] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:33:47,683] {logging_mixin.py:115} INFO - [2023-01-05 23:33:47,683] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:33:47,703] {logging_mixin.py:115} INFO - [2023-01-05 23:33:47,703] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:33:47,714] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.929 seconds
[2023-01-05 23:34:17,819] {processor.py:153} INFO - Started process (PID=5644) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:34:17,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:34:17,822] {logging_mixin.py:115} INFO - [2023-01-05 23:34:17,822] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:34:18,645] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:34:18,647] {logging_mixin.py:115} INFO - [2023-01-05 23:34:18,647] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:34:18,647] {logging_mixin.py:115} INFO - [2023-01-05 23:34:18,647] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:34:18,654] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:34:18,676] {logging_mixin.py:115} INFO - [2023-01-05 23:34:18,676] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:34:18,696] {logging_mixin.py:115} INFO - [2023-01-05 23:34:18,696] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:34:18,707] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.893 seconds
[2023-01-05 23:34:48,893] {processor.py:153} INFO - Started process (PID=5668) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:34:48,894] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:34:48,895] {logging_mixin.py:115} INFO - [2023-01-05 23:34:48,895] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:34:49,724] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:34:49,725] {logging_mixin.py:115} INFO - [2023-01-05 23:34:49,725] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:34:49,726] {logging_mixin.py:115} INFO - [2023-01-05 23:34:49,725] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:34:49,732] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:34:49,754] {logging_mixin.py:115} INFO - [2023-01-05 23:34:49,754] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:34:49,774] {logging_mixin.py:115} INFO - [2023-01-05 23:34:49,774] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:34:49,785] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.898 seconds
[2023-01-05 23:35:20,034] {processor.py:153} INFO - Started process (PID=5693) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:35:20,035] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:35:20,036] {logging_mixin.py:115} INFO - [2023-01-05 23:35:20,036] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:35:20,846] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:35:20,847] {logging_mixin.py:115} INFO - [2023-01-05 23:35:20,847] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:35:20,848] {logging_mixin.py:115} INFO - [2023-01-05 23:35:20,847] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:35:20,855] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:35:20,879] {logging_mixin.py:115} INFO - [2023-01-05 23:35:20,879] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:35:20,902] {logging_mixin.py:115} INFO - [2023-01-05 23:35:20,902] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:35:20,912] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.883 seconds
[2023-01-05 23:35:51,161] {processor.py:153} INFO - Started process (PID=5720) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:35:51,162] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:35:51,163] {logging_mixin.py:115} INFO - [2023-01-05 23:35:51,163] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:35:51,980] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:35:51,982] {logging_mixin.py:115} INFO - [2023-01-05 23:35:51,982] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:35:51,982] {logging_mixin.py:115} INFO - [2023-01-05 23:35:51,982] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:35:51,989] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:35:52,011] {logging_mixin.py:115} INFO - [2023-01-05 23:35:52,011] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:35:52,033] {logging_mixin.py:115} INFO - [2023-01-05 23:35:52,033] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:35:52,042] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.886 seconds
[2023-01-05 23:36:22,238] {processor.py:153} INFO - Started process (PID=5738) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:36:22,239] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:36:22,241] {logging_mixin.py:115} INFO - [2023-01-05 23:36:22,241] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:36:23,062] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:36:23,063] {logging_mixin.py:115} INFO - [2023-01-05 23:36:23,063] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:36:23,064] {logging_mixin.py:115} INFO - [2023-01-05 23:36:23,064] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:36:23,071] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:36:23,093] {logging_mixin.py:115} INFO - [2023-01-05 23:36:23,093] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:36:23,116] {logging_mixin.py:115} INFO - [2023-01-05 23:36:23,116] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:36:23,126] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.892 seconds
[2023-01-05 23:36:53,312] {processor.py:153} INFO - Started process (PID=5764) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:36:53,314] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:36:53,315] {logging_mixin.py:115} INFO - [2023-01-05 23:36:53,315] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:36:54,145] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:36:54,146] {logging_mixin.py:115} INFO - [2023-01-05 23:36:54,146] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:36:54,147] {logging_mixin.py:115} INFO - [2023-01-05 23:36:54,146] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:36:54,153] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:36:54,176] {logging_mixin.py:115} INFO - [2023-01-05 23:36:54,176] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:36:54,199] {logging_mixin.py:115} INFO - [2023-01-05 23:36:54,199] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:36:54,208] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.901 seconds
[2023-01-05 23:37:24,422] {processor.py:153} INFO - Started process (PID=5789) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:37:24,423] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:37:24,425] {logging_mixin.py:115} INFO - [2023-01-05 23:37:24,425] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:37:25,407] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:37:25,408] {logging_mixin.py:115} INFO - [2023-01-05 23:37:25,408] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:37:25,409] {logging_mixin.py:115} INFO - [2023-01-05 23:37:25,409] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:37:25,416] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:37:25,441] {logging_mixin.py:115} INFO - [2023-01-05 23:37:25,441] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:37:25,464] {logging_mixin.py:115} INFO - [2023-01-05 23:37:25,464] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:37:25,474] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.059 seconds
[2023-01-05 23:37:55,541] {processor.py:153} INFO - Started process (PID=5814) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:37:55,542] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:37:55,543] {logging_mixin.py:115} INFO - [2023-01-05 23:37:55,543] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:37:56,391] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:37:56,392] {logging_mixin.py:115} INFO - [2023-01-05 23:37:56,392] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:37:56,393] {logging_mixin.py:115} INFO - [2023-01-05 23:37:56,393] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:37:56,400] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:37:56,424] {logging_mixin.py:115} INFO - [2023-01-05 23:37:56,423] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:37:56,446] {logging_mixin.py:115} INFO - [2023-01-05 23:37:56,446] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:37:56,457] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.920 seconds
[2023-01-05 23:38:26,614] {processor.py:153} INFO - Started process (PID=5832) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:38:26,615] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:38:26,616] {logging_mixin.py:115} INFO - [2023-01-05 23:38:26,616] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:38:27,441] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:38:27,442] {logging_mixin.py:115} INFO - [2023-01-05 23:38:27,442] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:38:27,443] {logging_mixin.py:115} INFO - [2023-01-05 23:38:27,442] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:38:27,450] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:38:27,473] {logging_mixin.py:115} INFO - [2023-01-05 23:38:27,473] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:38:27,495] {logging_mixin.py:115} INFO - [2023-01-05 23:38:27,495] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:38:27,505] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.896 seconds
[2023-01-05 23:38:57,710] {processor.py:153} INFO - Started process (PID=5857) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:38:57,711] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:38:57,712] {logging_mixin.py:115} INFO - [2023-01-05 23:38:57,712] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:38:58,526] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:38:58,528] {logging_mixin.py:115} INFO - [2023-01-05 23:38:58,528] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:38:58,528] {logging_mixin.py:115} INFO - [2023-01-05 23:38:58,528] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:38:58,535] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:38:58,559] {logging_mixin.py:115} INFO - [2023-01-05 23:38:58,558] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:38:58,580] {logging_mixin.py:115} INFO - [2023-01-05 23:38:58,580] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:38:58,590] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.885 seconds
[2023-01-05 23:39:28,786] {processor.py:153} INFO - Started process (PID=5882) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:39:28,787] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:39:28,789] {logging_mixin.py:115} INFO - [2023-01-05 23:39:28,789] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:39:29,653] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:39:29,654] {logging_mixin.py:115} INFO - [2023-01-05 23:39:29,654] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:39:29,655] {logging_mixin.py:115} INFO - [2023-01-05 23:39:29,654] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:39:29,662] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:39:29,685] {logging_mixin.py:115} INFO - [2023-01-05 23:39:29,685] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:39:29,706] {logging_mixin.py:115} INFO - [2023-01-05 23:39:29,706] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:39:29,716] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.935 seconds
[2023-01-05 23:39:59,907] {processor.py:153} INFO - Started process (PID=5908) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:39:59,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:39:59,910] {logging_mixin.py:115} INFO - [2023-01-05 23:39:59,910] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:40:00,736] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:40:00,738] {logging_mixin.py:115} INFO - [2023-01-05 23:40:00,738] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:40:00,738] {logging_mixin.py:115} INFO - [2023-01-05 23:40:00,738] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:40:00,745] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:40:00,767] {logging_mixin.py:115} INFO - [2023-01-05 23:40:00,767] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:40:00,790] {logging_mixin.py:115} INFO - [2023-01-05 23:40:00,789] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:40:00,800] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.897 seconds
[2023-01-05 23:40:30,984] {processor.py:153} INFO - Started process (PID=5926) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:40:30,988] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:40:30,989] {logging_mixin.py:115} INFO - [2023-01-05 23:40:30,989] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:40:31,824] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:40:31,826] {logging_mixin.py:115} INFO - [2023-01-05 23:40:31,826] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:40:31,827] {logging_mixin.py:115} INFO - [2023-01-05 23:40:31,826] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:40:31,834] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:40:31,860] {logging_mixin.py:115} INFO - [2023-01-05 23:40:31,860] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:40:31,890] {logging_mixin.py:115} INFO - [2023-01-05 23:40:31,889] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:40:31,902] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.922 seconds
[2023-01-05 23:41:02,000] {processor.py:153} INFO - Started process (PID=5952) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:41:02,001] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:41:02,002] {logging_mixin.py:115} INFO - [2023-01-05 23:41:02,002] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:41:02,850] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:41:02,851] {logging_mixin.py:115} INFO - [2023-01-05 23:41:02,851] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:41:02,851] {logging_mixin.py:115} INFO - [2023-01-05 23:41:02,851] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:41:02,858] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:41:02,880] {logging_mixin.py:115} INFO - [2023-01-05 23:41:02,880] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:41:02,902] {logging_mixin.py:115} INFO - [2023-01-05 23:41:02,902] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:41:02,912] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.917 seconds
[2023-01-05 23:41:33,091] {processor.py:153} INFO - Started process (PID=5977) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:41:33,092] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:41:33,093] {logging_mixin.py:115} INFO - [2023-01-05 23:41:33,093] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:41:33,934] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:41:33,935] {logging_mixin.py:115} INFO - [2023-01-05 23:41:33,935] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:41:33,936] {logging_mixin.py:115} INFO - [2023-01-05 23:41:33,936] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:41:33,943] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:41:33,966] {logging_mixin.py:115} INFO - [2023-01-05 23:41:33,965] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:41:33,988] {logging_mixin.py:115} INFO - [2023-01-05 23:41:33,988] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:41:33,998] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.912 seconds
[2023-01-05 23:42:04,182] {processor.py:153} INFO - Started process (PID=6003) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:42:04,184] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:42:04,184] {logging_mixin.py:115} INFO - [2023-01-05 23:42:04,184] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:42:05,027] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:42:05,029] {logging_mixin.py:115} INFO - [2023-01-05 23:42:05,029] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:42:05,030] {logging_mixin.py:115} INFO - [2023-01-05 23:42:05,029] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:42:05,037] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:42:05,062] {logging_mixin.py:115} INFO - [2023-01-05 23:42:05,061] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:42:05,085] {logging_mixin.py:115} INFO - [2023-01-05 23:42:05,085] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:42:05,095] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.918 seconds
[2023-01-05 23:42:35,302] {processor.py:153} INFO - Started process (PID=6022) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:42:35,304] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:42:35,304] {logging_mixin.py:115} INFO - [2023-01-05 23:42:35,304] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:42:36,118] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:42:36,119] {logging_mixin.py:115} INFO - [2023-01-05 23:42:36,119] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:42:36,120] {logging_mixin.py:115} INFO - [2023-01-05 23:42:36,119] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:42:36,127] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:42:36,149] {logging_mixin.py:115} INFO - [2023-01-05 23:42:36,149] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:42:36,170] {logging_mixin.py:115} INFO - [2023-01-05 23:42:36,170] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:42:36,180] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.883 seconds
[2023-01-05 23:43:06,421] {processor.py:153} INFO - Started process (PID=6047) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:43:06,422] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:43:06,423] {logging_mixin.py:115} INFO - [2023-01-05 23:43:06,423] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:43:07,247] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:43:07,248] {logging_mixin.py:115} INFO - [2023-01-05 23:43:07,248] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:43:07,249] {logging_mixin.py:115} INFO - [2023-01-05 23:43:07,248] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:43:07,255] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:43:07,278] {logging_mixin.py:115} INFO - [2023-01-05 23:43:07,278] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:43:07,299] {logging_mixin.py:115} INFO - [2023-01-05 23:43:07,299] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:43:07,309] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.893 seconds
[2023-01-05 23:43:37,490] {processor.py:153} INFO - Started process (PID=6072) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:43:37,491] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:43:37,491] {logging_mixin.py:115} INFO - [2023-01-05 23:43:37,491] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:43:38,304] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:43:38,305] {logging_mixin.py:115} INFO - [2023-01-05 23:43:38,305] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:43:38,306] {logging_mixin.py:115} INFO - [2023-01-05 23:43:38,305] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:43:38,312] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:43:38,335] {logging_mixin.py:115} INFO - [2023-01-05 23:43:38,335] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:43:38,356] {logging_mixin.py:115} INFO - [2023-01-05 23:43:38,356] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:43:38,368] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.883 seconds
[2023-01-05 23:44:08,561] {processor.py:153} INFO - Started process (PID=6097) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:44:08,562] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:44:08,563] {logging_mixin.py:115} INFO - [2023-01-05 23:44:08,563] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:44:09,385] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:44:09,386] {logging_mixin.py:115} INFO - [2023-01-05 23:44:09,386] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:44:09,387] {logging_mixin.py:115} INFO - [2023-01-05 23:44:09,386] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:44:09,394] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:44:09,416] {logging_mixin.py:115} INFO - [2023-01-05 23:44:09,416] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:44:09,438] {logging_mixin.py:115} INFO - [2023-01-05 23:44:09,438] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:44:09,448] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.892 seconds
[2023-01-05 23:44:39,657] {processor.py:153} INFO - Started process (PID=6115) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:44:39,658] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:44:39,658] {logging_mixin.py:115} INFO - [2023-01-05 23:44:39,658] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:44:40,460] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:44:40,462] {logging_mixin.py:115} INFO - [2023-01-05 23:44:40,461] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:44:40,462] {logging_mixin.py:115} INFO - [2023-01-05 23:44:40,462] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:44:40,469] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:44:40,492] {logging_mixin.py:115} INFO - [2023-01-05 23:44:40,491] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:44:40,514] {logging_mixin.py:115} INFO - [2023-01-05 23:44:40,514] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:44:40,524] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.872 seconds
[2023-01-05 23:45:10,737] {processor.py:153} INFO - Started process (PID=6140) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:45:10,738] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:45:10,739] {logging_mixin.py:115} INFO - [2023-01-05 23:45:10,739] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:45:11,595] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:45:11,597] {logging_mixin.py:115} INFO - [2023-01-05 23:45:11,597] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:45:11,597] {logging_mixin.py:115} INFO - [2023-01-05 23:45:11,597] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:45:11,604] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:45:11,627] {logging_mixin.py:115} INFO - [2023-01-05 23:45:11,627] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:45:11,650] {logging_mixin.py:115} INFO - [2023-01-05 23:45:11,650] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:45:11,660] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.928 seconds
[2023-01-05 23:45:41,766] {processor.py:153} INFO - Started process (PID=6165) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:45:41,767] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:45:41,767] {logging_mixin.py:115} INFO - [2023-01-05 23:45:41,767] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:45:42,596] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:45:42,597] {logging_mixin.py:115} INFO - [2023-01-05 23:45:42,597] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:45:42,598] {logging_mixin.py:115} INFO - [2023-01-05 23:45:42,597] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:45:42,604] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:45:42,627] {logging_mixin.py:115} INFO - [2023-01-05 23:45:42,627] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:45:42,649] {logging_mixin.py:115} INFO - [2023-01-05 23:45:42,649] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:45:42,659] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.898 seconds
[2023-01-05 23:46:12,760] {processor.py:153} INFO - Started process (PID=6190) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:46:12,763] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:46:12,764] {logging_mixin.py:115} INFO - [2023-01-05 23:46:12,763] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:46:13,691] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:46:13,692] {logging_mixin.py:115} INFO - [2023-01-05 23:46:13,692] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:46:13,692] {logging_mixin.py:115} INFO - [2023-01-05 23:46:13,692] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:46:13,699] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:46:13,721] {logging_mixin.py:115} INFO - [2023-01-05 23:46:13,721] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:46:13,744] {logging_mixin.py:115} INFO - [2023-01-05 23:46:13,744] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:46:13,754] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.000 seconds
[2023-01-05 23:46:43,843] {processor.py:153} INFO - Started process (PID=6208) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:46:43,845] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:46:43,845] {logging_mixin.py:115} INFO - [2023-01-05 23:46:43,845] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:46:44,693] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:46:44,695] {logging_mixin.py:115} INFO - [2023-01-05 23:46:44,694] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:46:44,695] {logging_mixin.py:115} INFO - [2023-01-05 23:46:44,695] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:46:44,702] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:46:44,725] {logging_mixin.py:115} INFO - [2023-01-05 23:46:44,725] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:46:44,747] {logging_mixin.py:115} INFO - [2023-01-05 23:46:44,747] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:46:44,757] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.918 seconds
[2023-01-05 23:47:14,916] {processor.py:153} INFO - Started process (PID=6232) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:47:14,917] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:47:14,918] {logging_mixin.py:115} INFO - [2023-01-05 23:47:14,918] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:47:15,776] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:47:15,777] {logging_mixin.py:115} INFO - [2023-01-05 23:47:15,777] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:47:15,778] {logging_mixin.py:115} INFO - [2023-01-05 23:47:15,777] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:47:15,786] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:47:15,809] {logging_mixin.py:115} INFO - [2023-01-05 23:47:15,809] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:47:15,832] {logging_mixin.py:115} INFO - [2023-01-05 23:47:15,832] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:47:15,842] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.931 seconds
[2023-01-05 23:47:45,946] {processor.py:153} INFO - Started process (PID=6257) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:47:45,947] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:47:45,948] {logging_mixin.py:115} INFO - [2023-01-05 23:47:45,947] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:47:46,794] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:47:46,795] {logging_mixin.py:115} INFO - [2023-01-05 23:47:46,795] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:47:46,796] {logging_mixin.py:115} INFO - [2023-01-05 23:47:46,795] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:47:46,802] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:47:46,825] {logging_mixin.py:115} INFO - [2023-01-05 23:47:46,825] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:47:46,847] {logging_mixin.py:115} INFO - [2023-01-05 23:47:46,847] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:47:46,857] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.916 seconds
[2023-01-05 23:48:17,075] {processor.py:153} INFO - Started process (PID=6282) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:48:17,078] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:48:17,078] {logging_mixin.py:115} INFO - [2023-01-05 23:48:17,078] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:48:17,935] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:48:17,937] {logging_mixin.py:115} INFO - [2023-01-05 23:48:17,937] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:48:17,938] {logging_mixin.py:115} INFO - [2023-01-05 23:48:17,937] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:48:17,946] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:48:17,979] {logging_mixin.py:115} INFO - [2023-01-05 23:48:17,979] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:48:18,002] {logging_mixin.py:115} INFO - [2023-01-05 23:48:18,002] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:48:18,012] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.942 seconds
[2023-01-05 23:48:48,141] {processor.py:153} INFO - Started process (PID=6300) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:48:48,142] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:48:48,143] {logging_mixin.py:115} INFO - [2023-01-05 23:48:48,143] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:48:48,996] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:48:48,997] {logging_mixin.py:115} INFO - [2023-01-05 23:48:48,997] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:48:48,998] {logging_mixin.py:115} INFO - [2023-01-05 23:48:48,997] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:48:49,005] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:48:49,030] {logging_mixin.py:115} INFO - [2023-01-05 23:48:49,030] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:48:49,055] {logging_mixin.py:115} INFO - [2023-01-05 23:48:49,055] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:48:49,066] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.931 seconds
[2023-01-05 23:49:19,268] {processor.py:153} INFO - Started process (PID=6326) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:49:19,269] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:49:19,270] {logging_mixin.py:115} INFO - [2023-01-05 23:49:19,270] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:49:20,113] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:49:20,114] {logging_mixin.py:115} INFO - [2023-01-05 23:49:20,114] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:49:20,115] {logging_mixin.py:115} INFO - [2023-01-05 23:49:20,114] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:49:20,121] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:49:20,144] {logging_mixin.py:115} INFO - [2023-01-05 23:49:20,144] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:49:20,166] {logging_mixin.py:115} INFO - [2023-01-05 23:49:20,165] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:49:20,175] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.912 seconds
[2023-01-05 23:49:50,374] {processor.py:153} INFO - Started process (PID=6351) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:49:50,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:49:50,378] {logging_mixin.py:115} INFO - [2023-01-05 23:49:50,378] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:49:51,183] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:49:51,184] {logging_mixin.py:115} INFO - [2023-01-05 23:49:51,184] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:49:51,185] {logging_mixin.py:115} INFO - [2023-01-05 23:49:51,185] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:49:51,196] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:49:51,224] {logging_mixin.py:115} INFO - [2023-01-05 23:49:51,223] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:49:51,247] {logging_mixin.py:115} INFO - [2023-01-05 23:49:51,247] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:49:51,257] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.889 seconds
[2023-01-05 23:50:21,454] {processor.py:153} INFO - Started process (PID=6378) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:50:21,455] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:50:21,456] {logging_mixin.py:115} INFO - [2023-01-05 23:50:21,456] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:50:22,309] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:50:22,310] {logging_mixin.py:115} INFO - [2023-01-05 23:50:22,310] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:50:22,311] {logging_mixin.py:115} INFO - [2023-01-05 23:50:22,311] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:50:22,318] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:50:22,344] {logging_mixin.py:115} INFO - [2023-01-05 23:50:22,344] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:50:22,368] {logging_mixin.py:115} INFO - [2023-01-05 23:50:22,368] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:50:22,380] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.930 seconds
[2023-01-05 23:50:52,521] {processor.py:153} INFO - Started process (PID=6396) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:50:52,522] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:50:52,523] {logging_mixin.py:115} INFO - [2023-01-05 23:50:52,523] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:50:53,346] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:50:53,347] {logging_mixin.py:115} INFO - [2023-01-05 23:50:53,347] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:50:53,348] {logging_mixin.py:115} INFO - [2023-01-05 23:50:53,347] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:50:53,355] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:50:53,378] {logging_mixin.py:115} INFO - [2023-01-05 23:50:53,378] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:50:53,401] {logging_mixin.py:115} INFO - [2023-01-05 23:50:53,401] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:50:53,412] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.896 seconds
[2023-01-05 23:51:23,605] {processor.py:153} INFO - Started process (PID=6421) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:51:23,606] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:51:23,606] {logging_mixin.py:115} INFO - [2023-01-05 23:51:23,606] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:51:24,437] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:51:24,438] {logging_mixin.py:115} INFO - [2023-01-05 23:51:24,438] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:51:24,439] {logging_mixin.py:115} INFO - [2023-01-05 23:51:24,438] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:51:24,446] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:51:24,476] {logging_mixin.py:115} INFO - [2023-01-05 23:51:24,475] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:51:24,504] {logging_mixin.py:115} INFO - [2023-01-05 23:51:24,503] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:51:24,514] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.914 seconds
[2023-01-05 23:51:54,689] {processor.py:153} INFO - Started process (PID=6447) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:51:54,690] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:51:54,691] {logging_mixin.py:115} INFO - [2023-01-05 23:51:54,691] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:51:55,530] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:51:55,532] {logging_mixin.py:115} INFO - [2023-01-05 23:51:55,532] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:51:55,532] {logging_mixin.py:115} INFO - [2023-01-05 23:51:55,532] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:51:55,539] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:51:55,563] {logging_mixin.py:115} INFO - [2023-01-05 23:51:55,562] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:51:55,586] {logging_mixin.py:115} INFO - [2023-01-05 23:51:55,585] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:51:55,595] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.911 seconds
[2023-01-05 23:52:25,760] {processor.py:153} INFO - Started process (PID=6465) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:52:25,761] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:52:25,762] {logging_mixin.py:115} INFO - [2023-01-05 23:52:25,762] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:52:26,621] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:52:26,622] {logging_mixin.py:115} INFO - [2023-01-05 23:52:26,622] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:52:26,623] {logging_mixin.py:115} INFO - [2023-01-05 23:52:26,622] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:52:26,630] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:52:26,657] {logging_mixin.py:115} INFO - [2023-01-05 23:52:26,656] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:52:26,690] {logging_mixin.py:115} INFO - [2023-01-05 23:52:26,689] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:52:26,703] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.950 seconds
[2023-01-05 23:52:56,832] {processor.py:153} INFO - Started process (PID=6490) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:52:56,833] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:52:56,833] {logging_mixin.py:115} INFO - [2023-01-05 23:52:56,833] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:52:57,639] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:52:57,641] {logging_mixin.py:115} INFO - [2023-01-05 23:52:57,640] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:52:57,641] {logging_mixin.py:115} INFO - [2023-01-05 23:52:57,641] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:52:57,651] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:52:57,676] {logging_mixin.py:115} INFO - [2023-01-05 23:52:57,676] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:52:57,699] {logging_mixin.py:115} INFO - [2023-01-05 23:52:57,699] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:52:57,709] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.881 seconds
[2023-01-05 23:53:27,902] {processor.py:153} INFO - Started process (PID=6513) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:53:27,903] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:53:27,904] {logging_mixin.py:115} INFO - [2023-01-05 23:53:27,904] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:53:28,720] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:53:28,721] {logging_mixin.py:115} INFO - [2023-01-05 23:53:28,721] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:53:28,722] {logging_mixin.py:115} INFO - [2023-01-05 23:53:28,722] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:53:28,729] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:53:28,753] {logging_mixin.py:115} INFO - [2023-01-05 23:53:28,753] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:53:28,776] {logging_mixin.py:115} INFO - [2023-01-05 23:53:28,776] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:53:28,787] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.889 seconds
[2023-01-05 23:53:58,886] {processor.py:153} INFO - Started process (PID=6539) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:53:58,888] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:53:58,888] {logging_mixin.py:115} INFO - [2023-01-05 23:53:58,888] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:53:59,722] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:53:59,723] {logging_mixin.py:115} INFO - [2023-01-05 23:53:59,723] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:53:59,724] {logging_mixin.py:115} INFO - [2023-01-05 23:53:59,723] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:53:59,731] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:53:59,753] {logging_mixin.py:115} INFO - [2023-01-05 23:53:59,753] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:53:59,776] {logging_mixin.py:115} INFO - [2023-01-05 23:53:59,776] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:53:59,787] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.906 seconds
[2023-01-05 23:54:30,021] {processor.py:153} INFO - Started process (PID=6558) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:54:30,022] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:54:30,022] {logging_mixin.py:115} INFO - [2023-01-05 23:54:30,022] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:54:30,831] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:54:30,833] {logging_mixin.py:115} INFO - [2023-01-05 23:54:30,832] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:54:30,833] {logging_mixin.py:115} INFO - [2023-01-05 23:54:30,833] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:54:30,840] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:54:30,869] {logging_mixin.py:115} INFO - [2023-01-05 23:54:30,868] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:54:30,892] {logging_mixin.py:115} INFO - [2023-01-05 23:54:30,892] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:54:30,902] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.885 seconds
[2023-01-05 23:55:01,095] {processor.py:153} INFO - Started process (PID=6584) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:55:01,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:55:01,097] {logging_mixin.py:115} INFO - [2023-01-05 23:55:01,097] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:55:01,925] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:55:01,926] {logging_mixin.py:115} INFO - [2023-01-05 23:55:01,926] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:55:01,927] {logging_mixin.py:115} INFO - [2023-01-05 23:55:01,926] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:55:01,934] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:55:01,958] {logging_mixin.py:115} INFO - [2023-01-05 23:55:01,957] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:55:01,981] {logging_mixin.py:115} INFO - [2023-01-05 23:55:01,980] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:55:01,991] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.900 seconds
[2023-01-05 23:55:32,171] {processor.py:153} INFO - Started process (PID=6608) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:55:32,173] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:55:32,173] {logging_mixin.py:115} INFO - [2023-01-05 23:55:32,173] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:55:33,005] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:55:33,006] {logging_mixin.py:115} INFO - [2023-01-05 23:55:33,006] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:55:33,007] {logging_mixin.py:115} INFO - [2023-01-05 23:55:33,007] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:55:33,014] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:55:33,040] {logging_mixin.py:115} INFO - [2023-01-05 23:55:33,040] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:55:33,069] {logging_mixin.py:115} INFO - [2023-01-05 23:55:33,069] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:55:33,079] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.913 seconds
[2023-01-05 23:56:03,279] {processor.py:153} INFO - Started process (PID=6633) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:56:03,279] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:56:03,280] {logging_mixin.py:115} INFO - [2023-01-05 23:56:03,280] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:56:04,133] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:56:04,135] {logging_mixin.py:115} INFO - [2023-01-05 23:56:04,135] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:56:04,135] {logging_mixin.py:115} INFO - [2023-01-05 23:56:04,135] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:56:04,142] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:56:04,166] {logging_mixin.py:115} INFO - [2023-01-05 23:56:04,166] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:56:04,189] {logging_mixin.py:115} INFO - [2023-01-05 23:56:04,189] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:56:04,199] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.925 seconds
[2023-01-05 23:56:34,374] {processor.py:153} INFO - Started process (PID=6651) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:56:34,375] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:56:34,375] {logging_mixin.py:115} INFO - [2023-01-05 23:56:34,375] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:56:35,308] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:56:35,310] {logging_mixin.py:115} INFO - [2023-01-05 23:56:35,310] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:56:35,311] {logging_mixin.py:115} INFO - [2023-01-05 23:56:35,310] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:56:35,321] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:56:35,353] {logging_mixin.py:115} INFO - [2023-01-05 23:56:35,352] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:56:35,385] {logging_mixin.py:115} INFO - [2023-01-05 23:56:35,384] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:56:35,398] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.028 seconds
[2023-01-05 23:57:05,491] {processor.py:153} INFO - Started process (PID=6675) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:57:05,492] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:57:05,493] {logging_mixin.py:115} INFO - [2023-01-05 23:57:05,493] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:57:06,323] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:57:06,324] {logging_mixin.py:115} INFO - [2023-01-05 23:57:06,324] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:57:06,324] {logging_mixin.py:115} INFO - [2023-01-05 23:57:06,324] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:57:06,331] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:57:06,353] {logging_mixin.py:115} INFO - [2023-01-05 23:57:06,353] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:57:06,375] {logging_mixin.py:115} INFO - [2023-01-05 23:57:06,375] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:57:06,385] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.899 seconds
[2023-01-05 23:57:36,560] {processor.py:153} INFO - Started process (PID=6700) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:57:36,561] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:57:36,561] {logging_mixin.py:115} INFO - [2023-01-05 23:57:36,561] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:57:37,376] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:57:37,378] {logging_mixin.py:115} INFO - [2023-01-05 23:57:37,377] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:57:37,378] {logging_mixin.py:115} INFO - [2023-01-05 23:57:37,378] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:57:37,385] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:57:37,409] {logging_mixin.py:115} INFO - [2023-01-05 23:57:37,409] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:57:37,431] {logging_mixin.py:115} INFO - [2023-01-05 23:57:37,431] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:57:37,441] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.887 seconds
[2023-01-05 23:58:07,516] {processor.py:153} INFO - Started process (PID=6727) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:58:07,518] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:58:07,519] {logging_mixin.py:115} INFO - [2023-01-05 23:58:07,518] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:58:08,495] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:58:08,496] {logging_mixin.py:115} INFO - [2023-01-05 23:58:08,496] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:58:08,497] {logging_mixin.py:115} INFO - [2023-01-05 23:58:08,496] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:58:08,503] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:58:08,534] {logging_mixin.py:115} INFO - [2023-01-05 23:58:08,533] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:58:08,557] {logging_mixin.py:115} INFO - [2023-01-05 23:58:08,556] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:58:08,567] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 1.055 seconds
[2023-01-05 23:58:38,601] {processor.py:153} INFO - Started process (PID=6746) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:58:38,602] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:58:38,602] {logging_mixin.py:115} INFO - [2023-01-05 23:58:38,602] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:58:39,423] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:58:39,424] {logging_mixin.py:115} INFO - [2023-01-05 23:58:39,424] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:58:39,425] {logging_mixin.py:115} INFO - [2023-01-05 23:58:39,424] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:58:39,432] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:58:39,456] {logging_mixin.py:115} INFO - [2023-01-05 23:58:39,456] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:58:39,480] {logging_mixin.py:115} INFO - [2023-01-05 23:58:39,480] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:58:39,493] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.896 seconds
[2023-01-05 23:59:09,672] {processor.py:153} INFO - Started process (PID=6771) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:59:09,673] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:59:09,673] {logging_mixin.py:115} INFO - [2023-01-05 23:59:09,673] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:59:10,508] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:59:10,509] {logging_mixin.py:115} INFO - [2023-01-05 23:59:10,509] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:59:10,510] {logging_mixin.py:115} INFO - [2023-01-05 23:59:10,510] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:59:10,517] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:59:10,541] {logging_mixin.py:115} INFO - [2023-01-05 23:59:10,540] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:59:10,563] {logging_mixin.py:115} INFO - [2023-01-05 23:59:10,562] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:59:10,572] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.906 seconds
[2023-01-05 23:59:40,978] {processor.py:153} INFO - Started process (PID=6797) to work on /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:59:40,979] {processor.py:641} INFO - Processing file /opt/airflow/dags/btc_data_pipeline_dag.py for tasks to queue
[2023-01-05 23:59:40,980] {logging_mixin.py:115} INFO - [2023-01-05 23:59:40,980] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:59:41,818] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py:390 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2023-01-05 23:59:41,819] {logging_mixin.py:115} INFO - [2023-01-05 23:59:41,819] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-05 23:59:41,820] {logging_mixin.py:115} INFO - [2023-01-05 23:59:41,819] {base.py:68} INFO - Using connection ID 'google_cloud_default' for task execution.
[2023-01-05 23:59:41,826] {processor.py:651} INFO - DAG(s) dict_keys(['btc_data_pipeline_dag']) retrieved from /opt/airflow/dags/btc_data_pipeline_dag.py
[2023-01-05 23:59:41,849] {logging_mixin.py:115} INFO - [2023-01-05 23:59:41,848] {dag.py:2379} INFO - Sync 1 DAGs
[2023-01-05 23:59:41,870] {logging_mixin.py:115} INFO - [2023-01-05 23:59:41,870] {dag.py:2927} INFO - Setting next_dagrun for btc_data_pipeline_dag to 2023-01-05T22:55:00+00:00, run_after=2023-01-06T22:55:00+00:00
[2023-01-05 23:59:41,880] {processor.py:161} INFO - Processing /opt/airflow/dags/btc_data_pipeline_dag.py took 0.907 seconds
